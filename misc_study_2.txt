What is an endofunction?	a function whose domain and range are the same set.<br><br>crole pg 2
What is a partial function?	A partial function between X and Y is a subset f ⊆ X×Y such that given any elements (x,y) ∈ f and (x,y') ∈ f, then y=y'. <br><br>crole pg 3
If X is a set and R is an equivalence relation on X, then what does X/R denote?	The set of equivalence classes of X with respect to R.<br>pg 3
What is a preorder?	a binary relation which is reflexive and transitive.<br>pg 3
What does it mean for a preorder to be discrete?	The preorder X is discrete if any two elements of X are incomparable.<br><br>pg 3
What does it mean for two elements of a preorder to be isomorphic?	x and y are isomorphic iff x ≤ y and y ≤ x.<br>Crole pg 3
Let S ⊆X and x ∈X. What does x ≤ S mean?	x ≤ s for all s ∈S.<br>Crole pg 3
What is a partial order?	A relation which is reflexive, transitive, and anti-symmetric.<br><br>Crole pg 4
True or false: posets are preordered sets.	True<br>Crole pg 4
True or false: Preordered sets are posets.	False. Crole pg 4.
If x and y are elements of a poset, what does x < y mean?	x ≤ y and x ≠ y.<br>Crole pg 4
If X is a preordered set, what is the poset reflection of X?	The set of equivalence classes of x, with the following preorder:<br><br>[x] ≤ [y] iff x ≤ y for all x,y ∈X.<br><br>Crole pg 4.
What is a Hasse diagram?	Crole pg 4
If X is a poset, then what does X<sup>op</sup> denote?	its the preordered set whose underlying set is X and whose order is given by x ≤<sup>op</sup> y iff y ≤ x.<br><br>pg 5, example 5
If X is a preorder and A ⊆X, what does it mean for x ∈X to be an upper bound of A?	x ≥ a for all a ∈ A.<br><br>Crole pg 6
Consider the following statement:<br><br>Let X be a preordered set and A a subset of X. Then greatest and least elements of A are unique up to isomorphism if they exist.<br><br>Prove or give a counterexample: 	true. Crole pg 6
Identify the maximal elements of each of the posets on Crole pg 6.	Crole pg 6
Let X be a preordered set and X ⊆A. What is a <i>join</i> of A?	Crole pg 7
Let X be a preordered set and A ⊆X. What is <i>meet</i> of A?	it's the greatest lower bound of A in X. Note that not all subsets of a preordered set may have a meet.<br><br>Crole pg 7
If X is a preordered set and A ⊆ X, what do the notations ∨A, ∨<sub>X</sub>A, ∧A, and ∧<sub>X</sub>A mean?	respectively:<br>-an arbitrary join of A where the containing preordered set is clear<br>-an arbitrary join of A where the containing preordered set is X<br>-an arbitrary meet of A where the containing preordered set is clear from context<br>-an arbitrary meet of A where the containing preordered set is X.<br><br>Crole pg 7
Let X be a preorder. Consider Ø ⊆ X (i.e. the empty set). What can be said about ∨Ø if it exists? What about ∧Ø?	every element is an upper and lower bound of the empty set. so the join of the empty set must be bottom and the meet of the empty set must be top.<br><br>Crole pg 8
Let X be a preorder and consider {a,b} ⊆ X. What does a∧b denote? What about a∨b?	respectively:<br>∧{a,b}<br>∨{a,b}<br><br>Crole pg 8
Give the definition of a <i>chain</i>.	A subset of a preordered set such that every pair of elements in the set are comparable, i.e. C is a preorder if for all x,y ∈C, x ≤ y or y ≤ x.<br><br>Crole pg 8
Give the definition of an <i>ω-chain</i>.	A chain whose elements can be indexed by natural numbers.<br><br>crole pg 8
Give the definition of an <i>anti-chain</i>.	A subset C of a preorder such that for all x,y ∈ C, x ≤ y iff y ≤ x.<br><br>Crole pg 8
What does it mean for a subset D of X to be <i>directed</i>? 	It means that any finite subset of D has an upper bound in D.<br><br>Crole pg 8
What does it mean for a subset I of X to be <i>inductive</i>?<br>	It means that given a directed subset D ⊆ X for which D ⊆ I then ∨<sub>X</sub>D ∈ I.<br><br>Crole pg 8
What is an up-set of a subset of a preorder?	The up-set of a subset A of X is the set {x | x ≥ A};  i.e., it is the set of all upper bounds of A.<br><br>crole pg 8
What is the down-set of a subset of a preorder?	The down-set of a subset A of preorder X is the set {x | x ≤ A};  i.e., it is the set of all lower  bounds of A.<br><br>crole pg 8
Let A be a subset of a preorder X. What does ↑A denote? What about ↓A?	The up-set and down-sets of A, respectively.<br><br>Crole pg 8
Give the definition of the possible worlds model.	A possible worlds model is a triple <b>M</b>=(W,R,V) of a non-empty set of <i>possible worlds</i> W, a binary <i>accessibility relation</i> R between worlds, and a <i>valuation map</i> V assigning truth values V(p,s) in {0,1} to proposition letters p at worlds s. <br><br>van Benthem pg 15
What is a <i>pointed</i> possible worlds model?	It is a possible worlds model paired with one of the worlds in the worlds set (this world is the "vantage point")<br><br>van Benthem  pg 15<br>
Give the definition for the modal logic language.	van Benthem pg 11<br>
How does one go about finding out which worlds a formula is true in for a given possible worlds model?	bottom-up, first figuring out which worlds propositional atoms are true for (which is trivial), working up toward larger and larger subformulas.<br><br>van Benthem pg 17
What does it mean for a modal logic formula to be valid?	answer: It is true in all pointed possible worlds models.<br><br>van benthem pg 17
Give all rules for the "Modal Evaluation Game"	van Benthem pg 19
State and prove the key lemma which witnesses the significance of the modal evaluation game.	φ is true in model M at world s iff V has a winning strategy in game(M,s,φ)<br><br>van Bentham pg 22<br>
Give the definition of a modal bisimulation.	A <i>bisimulation</i> is a binary relation E between the worlds of two pointed models <b>M</b>,s and <b>N</b>,t such that sEt and also, for any worlds x,y, whenever xEy, then<br><br>1.) x,y verify the same proposition letters<br>2a.) If xRz in <b>M</b>, then there exists u in <b>N</b> with yRu and zEu<br>2b.) If yRu in <b>N</b>, then there exists z in <b>M</b> with xRz and zEu.<br><br>van Benthem pg 26 
Why is there no bisimulation between the models on top of page van Benthem pg 27, where top nodes are points?	van Benthem pg 26/27
Give the definition of a tree unravelling of a pointed modal model.	van Benthem pg 27, def 3.2.2
Modal Logic:<br>Explain how bisimulation can be used to guide model contraction.	van Benthem pg 27/28<br>
Modal logic:<br>State and prove the invariance lemma for bisimulation and modal logic.	van Bentham pg 28/29
Modal logic:<br>Prove that irreflexivity (¬Rxx) is not a property which can be defined in modal logic.	van Bentham pg 29
Modal Logic:<br>Look at the diagram on van Bentham page 30 without reading the text. Prove there is no bisimulation between the black worlds of N and K.	van Benthem pg 29/30
Consider the following statement:<br><br>Let worlds s,t satisfy the same modal formulas in two <i>finite</i> models <b>M</b> <b>N</b>. Then there exists a bisimulation between <b>M</b>,<b>N</b> connecting s to t.<br><br>Prove or give a counterexample.	True. Van Bentham pg 30
Consider the following statement:<br><br>Let worlds s,t satisfy the same modal formulas in two models <b>M</b> <b>N</b>. Then there exists a bisimulation between <b>M</b>,<b>N</b> connecting s to t.<br><br>Prove or give a counterexample.	False. This may not hold for infinite models.<br><br>Here is a counterexample: Let there be countably infinite propositional letters {p<sub>1</sub>,p<sub>2</sub>,...}<br><br>Model M has a child which has all propositional letters, a child which has only propositional letters with indices that are multiples of 2. Then 3, then 4, etc.<br><br>Model N has a child which has no propositional letters. Then one that only has odd-indexed propositional letters. Then one which has no propositional letters which are multiples of 3, etc.<br><br>I haven't proven that this a counterexample yet. TODO?<br><br>van Bentham pg 30/31<br>
What is a <i>bisimulation game</i>?	Player S ("Spoiler") claims that two models M,s and N,t are different, while player D ("Duplicator") says they are similar. They play over k rounds, starting from the match s - t. If objects matched in a round differ in any atomic property, S wins. In each round, starting with m - n, Spoiler chooses either model M, and an R-successor x of m, or model N, and an R-successor x of n. Next, Duplicator must respond with a successor y in the other model, and the world match after the round is x - y. If a player cannot choose a successor when it is her turn in a round, she loses.<br><br>van Bentham page 31
State and prove the adequacy theorem for bismulation games.	Statement:<br><br>The following are equivalent for any two models (M,s), (N,t), finite or infinite:<br><br>1. M,s and N,t satisfy the same formulas up to modal depth k,<br>2. Duplicator has a winning strategy in the k-round game starting from (M,s),(N,t).<br><br>Proof:<br><br>van Bentham pg 32
Consider the following statement:<br><br>Given any finite set of proposition letters, and a fixed natural number k, up to logical equivalence, there are only <i>finitely many modal formulas</i> of modal depth ≤ k.<br><br>Prove or give a counterexample.	True. van Bentham pg 32<br>NEEDS IMPOSTOR<br>
State and prove "strong adequacy for bisimulation games" 	Statement:<br><br>Spoiler's winning strategies in a k-round game between models M,s,N,t explicitly match the modal formulas of <i>operator depth k</i> on which s,t disagree.<br><br>Proof:<br>You're on your own.<br><br>van Bentham pg 34
What is the relevance of the adequacy theorem for bisimulation games?	Duplicator's winning strategies in an <i>infinite</i> game between (M,s),(N,t) match the bisimulations between them linking s to t.<br><br>van Bentham pg 34, Fact<br><br>
Is the minimal modal logic decidable?	Yes. <br><br>pg 38/37
Consider the following statement:<br><br>Basic modal logic has the effective finite model property.<br><br>Prove or give a counterexample.<br>	pg 38
What is the "finite depth property" of modal logic?<br>	pg 39
What is a modal sequent, and what does it mean for a modal sequent to be <i>valid</i>?<br>	A modal sequent consists of two sequences of modal formulas separated by a double arrow: <br>φ<sub>1</sub>,...,φ<sub>k</sub>⇒ψ<sub>1</sub>,...,ψ<sub>m</sub>.<br>Such a sequence is valid if in every world in every model, the conjunction of the φ's implies this disjunction of the ψ's.<br><br>van Bentham pg 40
Let A and B be sets of formulas. Consider the following statement:<br><br>(A, ¬φ ⇒ B) iff (A ⇒ B, φ)<br><br>Explain or give a counterexample.<br>	true. pg 40
Let A and B be sets of formulas. Consider the following statement:<br><br>(A ⇒ B, ¬φ) iff (A,φ ⇒ B)<br><br>Explain or give a counterexample.<br>	True. pg 40
Let A and B be sets of formulas. Consider the following statement:<br><br>(A, (φ ∧ ψ) ⇒ B) iff (A,φ,ψ ⇒ B)<br><br>Explain or give a counterexample.<br>	true. pg 40<br>IMPOSTOR NEEDED.<br>
Let <b>p</b> and <b>q</b> be sequences of proposition letters. <br><br>Consider the following statement:<br><br>A modal sequent of the form <b>p</b>,◊φ<sub>1</sub>,...,◊φ<sub>k</sub> ⇒ ψ<sub>1</sub>,...,ψ<sub>m</sub>,<b>q</b> is valid iff either<br>1. <b>p</b>,<b>q</b> overlap, or<br>2. for some i (1 ≤ i ≤ k), the sequent φ<sub>i</sub>⇒ψ<sub>1</sub>,...,ψ<sub>m</sub> is valid.<br><br>Prove or give a counterexample.	THIS IS AN IMPOSTOR<br>pg 41<br>
List the five principles of the minimal modal logic proof system K.<br>	pg 50/51<br>
Prove the following in the modal logic proof system K:<br><br>If φ → ψ is provable, then so is ◊φ→◊ψ<br>	pg 52<br>
Prove the following in the modal logic proof system K.<br><br>If φ → ψ is provable, then so is □φ→□ψ<br><br><br><br>	pg 51
State the "replacement by provable equivalents" principle.<br>	pg 52<br>
Prove or counter:<br><br>□(φ ∧ ψ) → (□φ ∧ □ψ)<br>	True. pg 52<br>TODO: add impostor
Prove or counter:<br><br>├<sub>K</sub> ◊(φ ∨ ψ) → (◊φ ∨ ◊ψ)<br><br>	True. pg 52<br>
Prove or counter:<br><br>├<sub>K</sub> ◊(φ ∧ ψ) ↔ (◊φ ∧ ◊ψ)<br><br>	IMPOSTOR! pg 52<br>
What does it mean for a set Σ of formulas to be consistent? What are some useful properties of consistency?	pg 54/55<br>
List some decomposition properties of maximally consistent sets.	pg 55 (see <b>Facts</b>)
Let Σ be a maximally consistent set such that ◊φ ∈ Σ, and let Γ={φ}∪{α | □α ∈ Σ}.<br><br>Consider the following statement:<br><br>Γ is consistent. <br><br>Prove or give a counterexample.<br><br><br>	true. pg 55<br>TODO: add counterexample<br>
Give the definition of the Henkin model.<br>	pg 56
State and prove the truth lemma.<br>	pg 56<br>
Explain the difference between strong completeness and weak completeness.<br>	pg 56<br>
How can the truth lemma be used to prove the completeness of K?<br>	<br>pg 54-56 <br>you really need to start reading on page 54 to get the hole argument. the key thing to remember is that its a proof by contrapositive. not derivable => not valid.<br>
If ├<sub>K</sub>□ψ then ├<sub>K</sub>ψ.<br><br>Prove or give a counterexample.<br><br>	true. pg 57/58<br>TODO: add impostor?<br>
What does it mean for two posets to be order isomorphic?	There exists a map φ from P onto Q such that x ≤ y in P if and only if φ(x) ≤ φ(y) in Q.<br><br>D&P pg 3<br>
Consider the following statement:<br><br>Every order isomorphism is bijective.<br><br>Prove or give a counterexample.<br>	true. <br><br>D&P pg 3<br>
Consider the following statement:<br><br>every bijective map between sets is an order isomorphism<br><br>prove or counter	should be a counterexample<br><br>D&P pg 3<br>
There is a chain in set theory known as ω. Give the concrete definition of this chain.	It's the natural numbers {0,1,...}, endowed with the standard order on natural numbers.<br><br>D&P pg 4<br>
Explain the relation between the predicate poset and the power set poset.<br>	D&P pg 5<br>
What is an interval order?	D&P pg 5
What does it mean for one element of an ordered set to <i>cover</i> another?	D&P pg 11<br>
Prove or counter:<br><br>If a partially ordered set P is finite, its order determines and is determined by its covering relation.<br>	true. D&P pg 11<br>TODO: impostor<br>
Consider the following statement:<br><br>Let P and Q be finite ordered sets and let φ : P → Q be a bijective map. Then the following are equivalent:<br><br>(i) φ is an order-isomorphism<br>(ii) x < y in P if and only if φ(x) < φ(y)<br>(iii) x ≺ y in P if and only if φ(x) ≺ φ(y)<br><br>prove or give a counterexample.<br>	true D&P pg 13<br>
Consider the following statement:<br><br>Let P and Q be finite ordered sets and let φ be a map from P to Q. Then the following are equivalent:<br><br>(i) φ is an order-isomorphism<br>(ii) x < y in P if and only if φ(x) < φ(y)<br>(iii) x ≺ y in P if and only if φ(x) ≺ φ(y)<br><br>Prove or give a counterexample.	should be a counterexample. this is only true when the map is bijective.<br><br>D&P pg 13<br>
Consider the following statement:<br><br>Two finite ordered sets P and Q are order-isomorphic if and only if they can be drawn with identical diagrams.<br><br>Prove or give a counterexample.<br>	true. D&P pg 14<br>
If P is a poset, then what does P<sup>∂</sup> denote?	D&P page 14<br>
If φ is a statement about an ordered set P, then what does φ<sup>∂</sup> denote?<br>	D&P pg 14<br>
State the duality principle.	D&P pg 15<br>
What do ┬ and ┴ denote w.r.t. posets?	D&P pg 15
How are ┬ and ┴ poset elements typically used in computer science models?	D&P pg 15<br>
What does it mean to <i>lift</i> an ordered set? What is a flat ordered set?<br>	D&P pg 15/16<br>
What are maximal and minimal elements of ordered sets?	D&P pg 16
What is the difference between maximal and maximum elements of ordered sets?	D&P pg 16
What role do maximal elements play when using posets to model information?	D&P top of pg 17
What is the disjoint union of two ordered sets? How is it denoted?	D&P pg 17
What is the linear sum P⊕Q of two disjoint ordered sets? How would we draw its Hasse diagram?	D&P pg 17
What is the default order relation for a cartesian product of ordered sets?	ans: pointwise, not lexicographic<br>D&P pg 18
Consider the following statement:<br><br>Let X = {1,2,...,n} and φ : 2<sup>X</sup>→2<sup><b>n</b></sup> by φ(A) = (ε<sub>1</sub>,...,ε<sub>n</sub>) where <br><br>ε<sub>i</sub>=1 if i ∈ A and 0 if i is not in A<br><br>Then φ is an order isomorphism. Prove or give a counterexample.<br>	true. D&P pg 19<br>todo: IMPOSTOR
Give the definition of a down-set. Give the definition of an up-set.	D&P pg 20<br>
If Q and P are ordered sets such that Q ⊆ P, what do ↓Q and ↑Q denote?	D&P pg 20
What does it mean for a downset to be <i>principal</i>?	pg 20
If P is a poset, what does O(P) denote?	the family of all downsets of P, ordered under the inclusion order<br><br>D&P pg 21
What can be said of O(P) if P is an anti-chain?	D&P pg 21 example.
What can be said of O(P) if P is the chain <b>n</b> = {1,...,n}? Is this true for all chains?<br>	It's a totally-ordered chain which is isomorphic to <b>n+1</b>. Its elements are Ø,↓1,↓2,...<br><br>O(P) for chains does not generally consist of Ø,↓1,↓2,... see page 21 for examples(HINT HINT: chains can be infinite).<br><br><br>D&P pg 21<br>
Prove lemma 1.30 D&P pg 21<br>	<br>
Discuss the way up-sets and down-sets are related.	D&P pg 22
Prove or counter:<br>O(P)<sup>∂</sup>≃O(P<sup>∂</sup>)<br>	A bijection which maps each downset to its complement should do the trick.<br><br>D&P pg 22
Demonstrate example 1.33 (1) on D&P pg 23<br>	<br>
Explain the difference between "order preserving" and "order embedding" maps between posets.<br>	D&P pg 23
Which of the posets in fig 1.11 of D&P pg 24 are order-preserving? Order embedding? Order isomorphisms?<br>	pg 23
Let <b>p</b> and <b>q</b> be sequences of proposition letters. <br><br>Consider the following statement:<br><br>A modal sequent of the form <b>p</b>,◊φ<sub>1</sub>,...,◊φ<sub>k</sub> ⇒ ◊ψ<sub>1</sub>,...,◊ψ<sub>m</sub>,<b>q</b> is valid iff either<br>1. <b>p</b>,<b>q</b> overlap, or<br>2. for some i (1 ≤ i ≤ k), the sequent φ<sub>i</sub>⇒ψ<sub>1</sub>,...,ψ<sub>m</sub> is valid.<br><br>Prove or give a counterexample.	true. pg 41<br>
Consider the following statement:<br><br>O(P ⊕ <b>1</b>) ≃ O(P) ⊕ 1<br><br>Prove or give a counterexample.<br>	true. pg 22<br>TODO: add impostor<br>
Consider the following statement:<br><br>O(<b>1</b>⊕P) ≃ <b>1</b> ⊕ O(P)<br><br>Prove or give a counterexample.	true. pg 22<br>TODO: add counterexample<br>
Consider the following statement:<br><br>O(P<sub>1</sub> ∪ P<sub>2</sub>) ≃ O(P<sub>1</sub>) × O(P<sub>2</sub>)<br><br>Prove or give a counterexample.<br>	true. pg 22<br>TODO: add impostor<br>
What do the notations ∨<sub>P</sub>S and ∧<sub>P</sub>S mean?	pg 34
What is a lattice?	pg 34
What is a complete lattice?	pg 34
Consider the following statement<br><br>x ≤ y iff x∨y = y and x∧y=x<br><br>Prove or give a counterexample.<br>	TRUE.<br>pg 34 (remark 2.5, 1)<br>An impostor exists somewhere in the deck<br> 
Consider the following statement<br><br>x ≤ y iff x∨y = x and x∧y=y<br><br>Prove or give a counterexample.	IMPOSOTOR!<br>pg 34
There are two reasons why x∨y may fail to exist in an ordered set. List them.<br>	top of pg 35
Let P be a lattice. Consider the following statement:<br><br>For all a,b,c,d ∈ P, a ≤ b implies a∨c ≤ b∨c and a∧c ≤ b∧c.<br><br>Prove or give a counterexample.<br>	true<br>pg 35 (4) i
Let P be a lattice. Consider the following statement:<br><br>For all a,b,c,d ∈ P, a ≤ b implies a∨c ≤ b∨c and a∧c ≥ b∧c.<br><br>Prove or give a counterexample.<br>	IMPOSTOR:<br>pg 35 (4) (i)
Let P be a lattice. Consider the following statement:<br><br>For all a,b,c,d ∈ P, a ≤ b and c ≤ d imply a∨c ≤ b∨d and a∧c ≤ b∧d.<br><br>Prove or give a counterexample.<br>	true <br>pg 35
Let P be a lattice. Consider the following statement:<br><br>For all a,b,c,d ∈ P, a ≤ b and c ≤ d imply a∨d ≤ b∨c and a∧d ≤ b∧c.<br><br>Prove or give a counterexample.<br>	IMPOSTOR.. it's supposed to be, at least<br>pg 35 (4) (ii)
Let P be a lattice. Let a,b, and c be elements of P and assume that b ≤ a ≤ b∨c. Consider the following statment:<br><br>a∨c = b∨c<br><br>Prove or give a counterexample.<br>	True. pg 35/36
Consider the following statement:<br><br>The real numbers form a lattice.<br><br>Prove or disprove.<br>	true<br>pg 36
Consider the following statement:<br><br>For any set X, the ordered set (P(X), ⊆) is a complete lattice.<br><br>Prove or give a counterexample.<br>	TRUE. PG 36
Give the definition of the term<br><i>lattice of sets</i>.	pg 37
Prove or give a counterexample:<br>O(P) is a complete lattice of sets for any ordered set P.<br>	true. pg 37
State and prove the correspondence theorem.	statement:<br>Let the map φ : G -> G' be a homomorphism of G onto G' with kernel K. If H' is a subgroup of G' and if <br><br>H = { a ϵ G | φ(a) ϵ H'},<br><br>then H is a subgroup of G, H ⊇ K,and H/K is isomorphic to H'. Finally, if H'◄G' then H ◄ G .<br><br>proof:<br>pg 86
State and prove the second homomorphism theorem.	statement:<br><br>Let H be a subgroup of a group G and N a normal subgroup of G. Then HN = { hn | h ϵ H, n ϵ N } is a subgroup of G, H ∩ N is a normal subgroup of H, and H/(H∩N) is isomorphic to (HN)/N.<br><br>proof:<br>pg 86
Prove or cntr:<br>"If p is a prime and p does not divide a, then a<sup>p-1</sup> ≡ 1 mod p"	pg 78
State and prove LaGrange's Theorem.	pg 59
What does it mean for two elements, a and b, of a group to be conjugates?	∃x ϵ G such that b = x<sup>-1</sup>ax<br>pg 73
Give the definitions of right cosets and left cosets.	If a ϵ G, and H is a subgroup of G, a set of the form aH is called a left coset and a set of the form Ha is called a right coset of H in G.<br><br>pg 58
"A group of prime order is cyclic"<br>prove or give a counterexample	pg 60
Give the definition of the order of a group.	the number of elements in G, i.e. |G|.<br>
"If G is a group and a ϵ G, then o(a) | |G|"<br>Prove or give a counterexample.<br>	IMPOSTOR! This would be true if G was finite, but for infinite groups, the statement doesn't even make sense.<br><br>pg 60
Prove or give a counterexample:<br>"If G is a finite group and a ϵ G, then o(a)|G"	<br><br>pg 60
Prove or cntr:<br>"If G is a finite group of order n, then a<sup>n</sup>=e for all a ϵ G"	pg 60
Give the definition of Euler's φ function.	φ(1) = 1<br>for n > 1, φ(n) = the number of positive integers m with 1 ≤ m < n such that (m,n) = 1.<br>pg 62
Prove or give a counterexample:<br>∀a,n ϵ <b>Z</b>,a<sup>φ(n)</sup>≡1 mod n.<br>	counter : <br>2 and 4<br>φ(4) = 2.<br>2^3=8≡0 mod 4<br><br>pg 62
Prove or give a counterexample:<br>If a is an integer relatively prime to n, then a<sup>φ(n)</sup>≡1 mod n.<br>	pg 63
pg 80, prb 26	<br>
pg 65, prb 29	<br>
pg 65, prb 32	<br>
pg 65, prb 34	<br>
Give the definition of a homomorphism. 	Let G and G' be two groups. A homomorphism is a mapping f : G → G' such that f(ab)=f(a)f(b) for all a,b ϵ G.<br><br>pg 67
Give the definition of a monomorphism.	a 1-1 homomorphism
Give the definition of an isomorphism.	a bijective homomorphism<br><br>pg 67
Give the definition of an automorphism	an isomorphism from some group into itself.<br>
State Cayley's Theorem	Every group G is isomorphic to some subgroup of A(S), for an appropriate S.<br><br>pg 69
Let G be a group and a ϵ G. What is "the inner automorphism of G induced by a" mean?	The function f(x) = a<sup>-1</sup>xa<br><br>pg 69
Consider the following statement:<br>If φ is a homomorphism of G into G' then<br>φ(e)=e', the unit element of G'<br><br>Prove or give a counterexample 	true<br>pg 70
Consider the following statement:<br><br>If φ is a homomorphism of G into G', then <br>φ(a<sup>-1</sup>)=φ(a)<sup>-1</sup>.	pg 70<br>
Consider the following statement:<br>The image of a group G under a homomorphism from G to G' is a subgroup of G'.	true <br>lemma 2.5.3 <br>pg 70
Give the definition of the kernel of a homomorphism<br>explain its significance.	it measures the degree of 1-1ness that a homomorphism has.<br><br>pg 70
Consider the following statement:<br>If w'ϵ G' is of the form φ(x) = w', then { y ϵ G | φ(y) = w' } = (Ker φ)x.<br><br>Prove or give a counterexample.<br>	pg 70
Consider the following statement:<br>If φ is a homomorphism of G into G', then Ker φ is a subgroup of G.<br><br>prove or give a counterexample.	pg 71
Consider the following statement:<br>Given a ϵ G, a<sup>-1</sup>(Ker φ)a ⊆ Ker φ.<br><br>prove or give a counterexample.	pg 71
Consider the following statement:<br>If φ is a homomorphism of G into G', then φ is a monomorphism iff Ker φ = (e).<br>	pg 71
Give the definition of the term "normal subgroup"	A subgroup N of G is said to be a <i>normal subgroup</i> of G if a<sup>-1</sup>Na ⊆ N for every a ∈ G.<br><br>pg 71
Prove or give a counterexample:<br>  N◄G iff every left coset of N in G is a right coset of N in G.	pdf pg 87<br>pg 72
Prove or give a counterexample:<br>For all subgroups G' of G, and all a ϵ G, aG' = G'a.<br>	IMPOSTOR: this would be true if G' were normal.<br>pg 72<br>
Give the definition of the notation G/N.	pg 78
Consider the following statement:<br><br>If N ◄ G then there is a homomorphism  φ of G onto G/n such that Ker φ = N.<br><br>Prove or show no such homomorphism exists.	true <br>pg 78
Consider the following statement:<br><br>If N ◄ G, then there is a  monomorphism φ of G onto G/N such that Ker φ, the kernel of φ is N.<br><br>Prove or disprove.	should be disprovable (I intend it to be an impostor but am too lazy to check it now).<br><br>pg 78
Consider the following statement:<br><br>If G is a finite group and N ◄ G, then |G/N|  = |G|/|N|.<br><br>Prove or give a counterexample.	pg 80
Consider the following statement:<br><br>If G is a finite abelian group of order |G| and p is a prime that divides |G|, then G has an element of order p.<br><br>Prove or give a counterexample.	true<br><br>pg 80
Consider the following statement:<br><br>If G is a finite abelian group of order |G| and n is a number that divides |G|, then G has an element of order n.<br><br>prove or disprove	should be a counterexample for this
pg 83 orb 8	<br>
pg 83 prb 10	<br>
pg 83 prb 12	<br>
State and prove the first homomorphism theorem.	Statement: Let φ be a homomorphism of G onto G' with kernel K. Then G' is isomorphic to G/K, the isomorphism between these being effected by the map α : G/K -> G' defined by α(Ka) = φ(a).<br><br>proof:<br>pg 85
State and prove the third homomorphism theorem.	statement:<br>If the map φ : G → G' is a homomorphism of G onto G' with kernel K then, if N' ◄ G' and N = {a ϵ G | φ(a) ϵ N'}, we conclude that G/N is isomorphic to G'/N'. Equivalently, G/N = (G/K)/(N/K).<br><br>proof:<br>pg 87
Give the meaning of the notation i<sub>G</sub>(H)	If G is a finite group and H is a subgroup of G, the number of right cosets of H in G, namely |G|/|H|, is called the <i>index</i> of H in G and is written as i<sub>G</sub>(H).
State and prove the connecting lemma.	pg 39
List the four basic algebraic laws (modulo duality) of lattices that ∧ and ∨ exhibit.	pg 39
How is the duality principle for ordered sets interpreted in the context of lattices? 	All ∧'s are replaced with ∨'s and vice-versa.<br><br>pg 39
Let (L;∨,∧) be a non-empty set equpped with two binary operations satisfying the four basic properties of lattices (and the duals of these properties). Consider the following statement:<br><br>For all a,b ∈ L, we have a∨b=b iff a∧b=a.<br><br>Prove or give a counterexample.	true pg 40<br>
Let (L;∨,∧) be a non-empty set equpped with two binary operations satisfying the four basic properties of lattices (and the duals of these properties). Consider the following statement:<br><br>For all a,b ∈ L, we have a∨b=b iff a∧b≤a.<br><br>Prove or give a counterexample.	IMPOSTOR pg 40
Let (L;∨,∧) be a non-empty set equpped with two binary operations satisfying the four basic properties of lattices (and the duals of these properties). Consider the following statement:<br><br>Define ≤ on L by a ≤ b if a∨b = b. Then ≤ is an order relation.<br><br>Prove or give a counterexample.	true.<br>pg 40<br>TODO: add impostor
Let (L;∨,∧) be a non-empty set equpped with two binary operations satisfying the four basic properties of lattices (and the duals of these properties). Consider the following statement:<br><br>Define ≤ on L by a ≤ b if a∨b = b. Then (L;≤) is a lattice in which the original operations agree with the induced operations, that is, for all a,b ∈ L,<br><br>a∨b=sup{a,b} and a∧b=inf{a,b}<br><br>Prove or give a counterexample.	true. <br>pg 40, 2.10 (iii)<br><br>
When viewing lattices as algebraic structures, the symbols ┬ and ┴ are not used. Other symbols are used in their place. What are these symbols and what accounts for this difference? 	they are 1 and 0. 1 is an identity for join. 0 is an identity for meet.<br><br>pg 41<br>
What does it mean for a lattice to be <i>bounded</i>?	It means that it has both a top and a bottom.<br><br>pg 41<br>
Give the definition of a <i>sublattice</i>.	Let L be a lattice and Ø ≠ M ⊆ L. Then M is a sublattice of L if<br>a,b ∈ M implies a∨b ∈ M and a ∧b ∈ M. <br><br>pg 41<br>
What do the notations Sub L and Sub<sub>0</sub>L denote? 	All sublattices of L, and Sub L ∪ {Ø}, respectively.<br><br>pg 41
Let L and K be lattices and let L×K be their cartesian ordered set product with pointwise order. Is L×K a lattice? Prove or give a counterexample.	True. <br>pg 42<br>TODO: add impostor
Let L and K be lattices. What does it mean for a map f : L → K to be a homomorphism?	<br>It means that for all a,b ∈ L, f(a∨b)=f(a)∨f(b) and f(a∧b)=f(a)∧f(b).<br><br>pg 43<br>
If L and K are lattices, what does it mean for a map f : L → K to be an isomorphism?	It means f is a bijective lattice homomorphism (where f(a∧b)=f(a)∧f(b) and f(a∨b)=f(a)∨f(b)).<br><br>pg 43<br>
If L and K are lattices, what does the notation L ↣ K mean?<br><br><br>	K has a sublattice isomorphic to L.<br><br>pg 43<br>
What does it mean for a lattice homomorphism between bounded lattices to be a {0,1} homomorphism?<br>	It means f(0)=0 and f(1)=1.<br><br>pg 43<br>
Let L and K be lattices and f : L → K a map. Consider the following statement: <br><br>The following are equivalent:<br>(a) f is order-preserving<br>(b) (∀a,b ∈ L) f(a∨b) ≥ f(a)∨f(b)<br>(c) (∀a,b ∈ L) f(a∧b) ≤ f(a)∧f(b)<br><br>Prove or give a counterexample.<br><br><br><br>	true. pg 44
Let L and K be lattices and f : L → K a map. Consider the following statement: <br><br>If f is a homomorphism, then f is order preserving.<br><br>Prove or give a counterexample.<br><br><br><br>	true. pg 44<br>TODO: add impostor
Let L and K be lattices and f : L → K a map. Consider the following statement: <br><br>f is a lattice isomorphism iff it is an order isomorphism.<br><br>Prove or give a counterexample.	true.<br>pg 44<br>TODO: add impostor.<br>
Give the definition an <i>ideal</i>.<br>	An <i>ideal</i> is a downset that is closed under join.<br><br>pg 44
Give the definition a <i>filter</i>	A filter is the dual concept to ideal: it's an upset that is closed under meet.<br><br>pg 45 
Consider the following statement:<br>an ideal J of a lattice is proper iff 1 is not an element of L.<br>Prove or give a counterexample.<br>	true. pg 45<br>
Consider the following statement:<br>an ideal J of a lattice is proper iff 0 is not an element of J.<br>Prove or give a counterexample.<br>	IMPOSTOR: it should be 1 rather than 0.<br>pg 45<br>
Let L be a lattice. Consider the following statement:<br>For any a ∈ L, ↓a is an ideal.<br>Prove or give a counterexample.<br><br><br><br>	true. <br>pg 45<br>
What is a <i>security</i>? What are the three main types of securities? Explain each.	Debt: to this class belong, in general, those securities that are “secure”, in the<br>sense of been risk-free, such as bonds, commercial notes and bank deposits.<br><br>Equity: refers generally to a company’s stocks or share value.<br><br>Derivatives: in this class are securities whose value depend on the values of other,<br>more basic underlying variables. Examples of derivatives are: futures and forward<br>contracts, swaps, and options. A stock option, for example, is a contract whose<br>value depends on the price of a stock at a certain date.<br><br>pg 1<br>
What is an <i>exchange market</i>?	Some debt contracts are established directly between two financial institutions,<br>or a financial institution and an investor, but in general securities are traded at<br>organized markets known as exchange markets. Examples of exchange markets of<br>stocks and options in the United States are the New York Stock Exchange (NYSE),<br>Chicago Board Options Exchange (CBOE) and Nasdaq; in Europe the London Stock<br>Exchange (LSE), Deutsche Börse, and Spanish Exchange Markets (BME); in Asia<br>the Tokyo Stock Exchange and Shanghai Stock Exchange, among others.<br><br>pg 2<br>
What is a <i>bond</i>?	A bond is a long-term loan contract between two parties, the issuer and the holder,<br>in which the issuer receives a specified amount of money from the holder and is<br>obliged to pay it back at a later date together with some interest.<br><br>arratia pg 2
What is considered the benchmark risk-free security in financial engineering?	Bonds are usually considered as the benchmark risk-free security in financial<br>engineering. <br><br>pg 2<br>
What is the <i>principal</i> of a bond?	the amount given by the lender<br><br>arratia pg 2<br>
What are the <i>coupons</i> of a bond?	the succsessive interest payments are called coupons<br><br>arratia pg 2
What is the <i>maturity date</i> of a bond?	the date that a bond expires<br><br>arratia pg 2<br>
Explain how <i>compounding interest</i> works.<br><br>	We should all be aware that most of all risk–free securities that earn interest at a certain fixed rate have their value computed through time by compounding the interest. This means that the interest earned at a certain moment is added to the current value of the investment and the next interest is computed over the resulting sum. Therefore the value of the security with interest depends not only on the interest rate, but also on the frequency in which the interest is compounded. Consider for example that an investor acquires a bond with a principal of $100, at an annual interest rate of 10%, and for n years. If the interest is paid annually then by the end of the first year the holder of the bond gets $110 = 100(1 + 0.1). By the second year the interest is computed over the previous sum and added to it (here is where compounding takes place), and thus the investor gets 110(1 + 0.1) = 100(1 + 0.1)<sup>2</sup>.<br><br>arratia pg 2/3<br><br>
With a principal of P<sub>0</sub>, give an expression for the value of the bond P<sub>n</sub> after the nth interest interval. 	P<sub>n</sub> = P<sub>0</sub>(1 + r)<sup>n</sup><br><br>arratia pg 3<br>
Suppose r is the interest rate per some interval (say, 1 year). If we augment interest frequency so that compounding interest happens at m evenly-distributed times per year, what is the value P<sub>n</sub> of the bond after the n<sup>th</sup> year, where P<sub>0</sub> is the principal?<br>	<br>P<sub>n</sub> = P<sub>0</sub>(1+r/m)<sup>nm</sup><br><br>arratia pg 3<br><br>
Derive the equation for the value of a bond with continuously-compounding interest with rate r over a generic time interval τ > 0.<br><br>	arratia pg 4<br>
If we have P<sub>t</sub>, the value of a continuously-compounded bond at time t with interest rate r, derive the formula for the value P<sub>t+τ</sub> of the bond at some later time t + τ. How do we recover the value at a previous time t - τ?<br>	arratia pg 4<br>
How can we choose an interest rate r for continuous compunding which coincides with a security with interest rate R per annum having m times per annum compounding?	arratia pg 4<br>
What is the <i>payoff</i> of a security?<br> 	The payoff of any security is its value at maturity. For a bond, its payoff is the principal plus all interests paid on the principal...<br><br>arratia pg 4<br>
What is the <i>profit</i> of a security? How is profit different from payoff?<br><br>	The payoff of any security is its value at maturity. For a bond, its payoff is the principal plus all interests paid on the principal, and given by Eq. (1.2), or if continuously compounding of interest is assumed it is given by Eq. (1.3). The profit of a security is its risk-adjusted payoff discounting the initial investment, which includes contract fees or any other transaction costs. (The idea of risk-adjusting the payoff will be clear from the ways we’ll settle each case of security to come.) For bonds there are usually no transactions costs or fees (or if there were, we can assume them to be included in the principal), and the risk is null; hence, the profit given by a bond is obtained by discounting the principal to the payoff.<br><br>arratia pg 4<br>
Give the expression for the profit given by a bond for a constant interest rate r through a period τ involving m coupons and a principal P<sub>0</sub>.	arratia pg 4<br>
Let P be an ordered set, let S, T ⊆ P and assume that ⋁S, ⋁T, ⋀S, and ⋀T exist in P.<br><br>Consider the following statement:<br><br>⋁S ⊆ ⋀T if and only if s ≤ t for all s ∈ S and all t ∈ T.<br><br>Prove or give a counterexample<br>	true.<br><br>d&p pg 46
Let P be an ordered set, let S, T ⊆ P and assume that ⋁S, ⋁T, ⋀S, and ⋀T exist in P.<br><br>Consider the following statement:<br><br>If S ⊆ T, then ⋁S ≤ ⋁T and ⋀S ≥ ⋀T<br><br>Prove or give a counterexample.<br>	d&p pg 46
Let P be an ordered set, let S, T ⊆ P and assume that ⋁S, ⋁T, ⋀S, and ⋀T exist in P.<br><br>Consider the following statement:<br><br>If S ⊆ T, then ⋀S ≤ ⋀T and ⋁S ≥ ⋁T<br><br>Prove or give a counterexample.<br>	IMPOSTOR<br><br>mstudy pg 24
Let P be a lattice, let S,T ⊆ P and assume that ⋁S, ⋁T, ⋀S, and ⋀T exist in P. Then<br><br>Consider the following statement<br><br>⋁(S ∪ T) = (⋁S) ∨ (⋁T)<br><br>Prove or give a counterexample	d&p pg 46<br><br>my solution starts with this reasoning.<br><br>Since (S ∪ T) ⊇ S, we have:<br>⋁(S ∪ T) ∨ ⋁S = ⋁(S ∪ T)<br><br>likewise, we have:<br>⋁(S ∪ T) ∨ ⋁T = ⋁(S ∪ T)<br><br>putting these together:<br>(⋁(S ∪ T) ∨ ⋁S) ∨ ⋁T = ⋁(S ∪ T)<br><br>Hence:<br>⋁(S ∪ T) ∨ (⋁S ∨ ⋁T) = ⋁(S ∪ T)<br><br>By the connecting lemma:<br>⋁(S ∪ T) ≥ (⋁S ∨ ⋁T)<br><br><br><br>
Let P be a lattice, let S,T ⊆ P and assume that ⋁S, ⋁T, ⋀S, and ⋀T exist in P. Then<br><br>Consider the following statement<br><br>⋁(S ∪ T) = (⋁S) ∧ (⋁T)<br><br>Prove or give a counterexample	IMPOSTOR<br><br>d&p pg 46<br>
Consider the following statement:<br><br>Every finite lattice is complete<br><br>True or false? why?	true.<br><br>d&p pg 46
What does it mean for a map φ : P → Q between ordered sets to <i>preserve existing joins</i>?<br>	whenever ⋁S exists in P then ⋁φ(S) exists in Q and φ(⋁S)=⋁φ(S). Preservation of existing meets is defined dually.<br><br>mstudy pg 24<br><br>
Let P and Q be ordered sets and φ : P → Q be an order-preserving map. Assume that S ⊆ P is such that ⋁S exists in P and ⋁φ(S) exists in Q.<br><br>Consider the followiung statement<br><br>φ(⋁S) ≥ ⋁φ(S)<br><br>Prove or give a counterexample<br><br>	true.<br><br>mstudy pg 24<br><br>
Let P and Q be ordered sets and φ : P → Q be an order-preserving map. Assume that S ⊆ P is such that ⋁S exists in P and ⋁φ(S) exists in Q.<br><br>Consider the followiung statement<br><br>φ(⋁S) ≤ ⋁φ(S)<br><br>Prove or give a counterexample<br><br>	IMPOSTOR<br><br>mstudy pg 24 (RIGHT PAGE)<br><br><br>
Let P and Q be ordered sets and φ : P → Q be an order isomorphism.<br><br>Consider the following statement:<br><br>φ preserves all existing joins and meets.<br><br>Prove or give a counterexample.<br>	true. d&p pg 47<br>
Let Q be a subset, with the induced order, of some ordered set P and let S ⊆ Q.<br><br>Consider the following statement:<br><br>If ⋁<sub>P</sub>S exists and belongs to Q, then ⋁<sub>Q</sub>S exists and equals ⋁<sub>P</sub>S.<br><br>Prove or give a counterexample.<br>	mstudy pg 24 (right-hand page)<br><br>
Let L be a family of subsets of a set X and let {A<sub>i</sub>}<sub>i ∈ L</sub> be a subset of L. Consider the following statement:<br><br>If ⋃<sub>i∈I</sub> A<sub>i</sub> ∈ L, then ⋁<sub>L</sub>{A<sub>i</sub> | i ∈ I} exists and equals ⋃<sub>i∈I</sub> A<sub>i</sub>.<br><br>Prove or give a counterexample.<br>	mstudy pg 24 (right page)<br>
Let L be a family of subsets of a set X and let {A<sub>i</sub>}<sub>i ∈ L</sub> be a subset of L. Consider the following statement:<br><br>If ⋃<sub>i∈I</sub> A<sub>i</sub> ∈ L, then ⋁<sub>L</sub>{A<sub>i</sub> | i∈I} exists and equals ⋂<sub>i∈I</sub> A<sub>i</sub>.<br><br>Prove or give a counterexample.	IMPOSTOR d&p pg 47<br>
If L is a family of sets that is closed under (posssibly infinite) union and intersection, is the ordered set (L,⊆) a complete lattice?<br><br>Prove or give a counterexample.<br>	it's true. it's called a "complete lattice of sets" d&p pg 47
Let P be an ordered set such that ⋀S exists in P for every non-empty subset S of P.<br><br>Consider the following statement:<br><br>Then ⋁S exists in P for every subset S of P which has an upper bound in P; indeed, ⋁S = ⋀S<sup>u</sup>.<br><br><br>	ideed, it's true: d&p pg 47, lemma 2.30<br>
Consider the following statement:<br><br>Let P be a non-empty ordered set. Then the following are equivalent:<br><br>i.) P is a complete lattice<br>ii.) ⋀S exists in P for every subset S of P<br>iii.) P has a top element, ⊤, and ⋀S exists in P for every non-empty subset S of P.<br><br>prove or give a counterexample.<br><br>	iii => i is the interesting case<br><br>every set in P has an inf: non-empty sets by fiat, the empty set's inf is ⊤.<br>does every set in P have a sup?<br><br>For each S ⊆ P, S<sup>U</sup>, the set of upper bounds of S, is non-empty because it contains ⊤. Hence, its a=⋀S<sup>U</sup> exists.<br><br>Claim: a=⋁S<br>a is clearly no greater than all other upper bounds of S.<br>We just need to show that a is itself an upper bound of S. For contradiction, suppose it is not. Then there is some s ∈ S such that a < s. s is a lower bound on S<sup>U</sup>, but it's greater than a, contradicting that a=⋀S<sup>U</sup>. Hence, a is an upper bound of S. <br><br>true d&p pg 47, thm 2.31<br>
Consider the following statement:<br><br>Let P be a non-empty ordered set. Then the following are equivalent:<br><br>i.) P is a complete lattice<br>ii.) ⋀S exists in P for every subset S of P<br>iii.) ⋀S exists in P for every non-empty subset S of P.<br><br>prove or give a counterexample.<br><br>	IMPOSTOR<br>d&p pg 47, thm 2.31<br>
Let X be a set and let L be a family of subsets of X, ordered by inclusion, such that<br><br>a) ⋂<sub>i∈I</sub>A<sub>i</sub> ∈ L for every non-empty family {A<sub>i</sub>}<sub>i∈I</sub> ⊆ L, and<br><br>b) X ∈ L<br><br><br>Consider the following statement:<br><br>⋀<sub>i∈I</sub> A<sub>i</sub> = ⋂<sub>i∈I</sub> A<sub>i</sub><br>and<br>⋁<sub>i∈I</sub> A<sub>i</sub> = ⋂{B ∈ L | ⋃<sub>i∈I</sub> A<sub>i</sub> ⊆ B}<br><br>Prove or give a counterexample<br>	true. d&p pg 48<br>
Let X be a set and let L be a family of subsets of X, ordered by inclusion, such that<br><br>a) ⋂<sub>i∈I</sub>A<sub>i</sub> ∈ L for every non-empty family {A<sub>i</sub>}<sub>i∈I</sub> ⊆ L, and<br><br>b) X ∈ L<br><br><br>Consider the following statement:<br><br>⋀<sub>i∈I</sub> A<sub>i</sub> = ⋂<sub>i ∈ I</sub>A<sub>i</sub><br>and<br>⋁<sub>i∈I</sub> A<sub>i</sub> = ⋃<sub>i ∈ I</sub>A<sub>i</sub><br><br>Prove or give a counterexample	IMPOSTOR<br><br>pg 25 (left)<br><br><br><br>
Consider the following statement:<br><br>the subgroups Sub G of a group G form a topped ⋂-structure<br><br>prove or give a counterexample<br><br><br><br>	true<br>TODO: add impostor<br><br>d&p pg 49<br>
Consider the following statement:<br><br>the normal subgroups N-SubG of a group G form a topped ⋂-structure<br><br>prove or give a counterexample<br><br><br><br>	true d&p pg 49<br>
Consider the following statement:<br><br>the subspaces Sub V of a vector space V form a topped ⋂-structure<br><br>prove or give a counterexample<br><br><br><br>	true d&p pg 49<br><br>I need some counterexamples for topped intersection structures<br>
State and prove the Knaster-Tarski fixpoint theorem.<br><br>	d&p pg 50<br>
Let <$>\beta</$> and <$>\beta'</$> be two ordered bases for a finite-dimensional vector space V, and let <br><$$>Q = [I_V]_{\beta'}^{\beta}.</$$><br><br>Prove:<br>a.) Q is invertible<br>b.) For any v in V, <$$>[v]_{\beta}=Q[v]_{\beta'}</$$> 	pg 111
Give the definition of a field.<br>	(FIS pg 553)<br>*Don't forget to mention that the additive identity and the multiplicitive identity are distinct.
Let a,b, and c be elements of a field.<br>Suppose a+b=c+b.<br>Prove a=c.<br>(This is referred to as the cancellation law for addition.)<br>	FIS pg 554
Let a,b, and c be elements of a field.<br>Is the following statement true?<br><$$>(a \cdot b = c \cdot b) \Rightarrow (a=c)</$$>	No. But it is if b =/= 0. <br>FIS pg 554<br>
Prove that the additive identity of a field is unique. 	FIS pg 554 (corollary)
Prove that the multiplicitive inverse of a field element is unique.	FIS pg 554 (corollary)
Let a and b be arbitrary elements of a field.<br><br>Prove <$$>a \cdot 0=0</$$>	FIS pg 555
Let a and b be arbitrary elements of a field.<br><br>Prove <$$>(-a) \cdot b = a \cdot (-b) = -(a \cdot b)</$$>	FIS pg 555
Let a and b be arbitrary elements of a field.<br><br>Prove <$$>(-a) \cdot (-b) = a \cdot b</$$>	FIS pg 555
Prove that the additive identity of a field has no multiplicitive inverse.	FIS pg 555
Give the definition of the charecteristic of a field.	FIS pg 555
Suppose we are given an arbitrary element x of field F, where x has charecteristic p. What can be said about <$$>\sum_{i=1}^{p}x?	It is equal to 0. <br><br>Why? x = 1 + 1 + ... . But the sum is equal to p*x, which is a sum of k 1's, where k is a multiple of p. This can be parenthesized in groups of p, which makes it a sum of 0's. Since 0 is the additive identity, the final result is 0.<br><br>FIS pg 555
Give the definition of a vector space.	(FIS pg 7)
What is <$>F^n</$>? Suppose we define the following operations on <$>F^n</$>:<br><br><$$>\mbox{vec addition}\ :\ (\vec{v}+\vec{u})_{i} = \vec{v}_i+\vec{u}_i</$$><br><$$>\mbox{scalar multiplication}\ :\ (a \vec{v})_i=a \vec{v}_i</$$><br><br>Is <$>F^n</$> a vector space with respect to these two operators? Prove your answer.<br>	pg 8
What is <$>M_{mxn}(F)</$>? Is <$>M_{mxn}(F)</$> a vector space with respect to the following two operations?<br><br><$$>\mbox{vec addition : }(A+B)_{ij}=A_{ij}+B_{ij}</$$><br><$$>\mbox{scalar mult : }(aA)_{ij}=aA_{ij}</$$><br><br>Prove your answer. 	pg 8-9
 <$$>\mbox{What is }\mathcal{F}(S,F)\mbox{?}</$$><br><$$>\mbox{Is }\mathcal{F}(S,F)\mbox{ a vector space using these operators?:}</$$><br><$$>(f+g)(s)=f(s)+g(s)</$$><br><$$>(af)(s)=af(s)</$$><br>Prove your answer	pg 9
Give the definition of a polynomial. Give the definition of the degree of a polynomial.	*Don't forget to take the 0-polynomial into account, the degree of which is -1*<br>pg 9
What is P(F)? Can some vector addition and scalar multiplication operators be defined so that P(F) can be considered a vector space? Prove your answer.<br>	pg 10
Let F be a field. Give the definition of a <b>sequence</b> in F. <br><br>Let V consist of all sequences <$>\{a_n\}</$> in F. Define<br><$$>\{a_n\}+\{b_n\}=\{a_n+b_n\}</$$> and <$$>t\{a_n\}=\{ta_n\}</$$><br><br>Is V a vector space under these operations?<br> 	TRICK QUESTION: There might be a deceptive, erroneous way of proving this for sequences with infinite non-zero terms. FIS places the restriction of finite non-zero terms.... TODO: figure out why<br><br>See pg 11<br>
<$$>\mbox{Let }S = \{(a_1,a_2) : a_1, a_2 \epsilon R\}.</$$><br><$$>\mbox{For }(a_1, a_2), (b_1, b_2) \epsilon S\mbox{ and }c \epsilon R,\mbox{ define}</$$><br><$$>(a_1,a_2)+(b_1,b_2)=(a_1+b_1,a_2-b_2) and c(a_1, a_2) = (ca_1, ca_2).</$$><br><br>Is S a vector space under the given operations? Prove your answer.<br> 	pg 11 example 6
<$$>\mbox{Let }S=\{(a_1,a_2) : a_1, a_2 \epsilon R\}.\mbox{ Under the operations: }</$$><br><$$>(a_1,a_2)+(b_1,b_2)=(a_1+b_1,0)</$$><br><$$>c(a_1,a_2)=(ca_1,0)</$$><br>Is this a vector space? Prove your answer.<br>	pg 11
Prove that if x, y, and z are vectors in a vector space V such that x+z=y+z, then x=y.	pg 11 Theorem 1.1
Prove that the additive identity of a vector space is unique.	pg 11
Prove that the additive inverse of a vector is unique.<br>	<$$>\mbox{Suppose }\vec{a}+\vec{x}=\vec{0}=\vec{b}+\vec{x}</$$><br>Then, by cancellation:<br><$$>\vec{a}=\vec{b}</$$><br>
<$$>\mbox{Prove }0\vec{x}=\vec{0}</$$>	pg 12
<$$>\mbox{Prove }(-a)\vec{x}=-(a\vec{x})=a(-\vec{x})</$$>	pg 12
<$$>\mbox{Prove }a\vec{0}=\vec{0}</$$>	pg 12
Give the definition of a subspace.	pg 16
Suppose V is a vector space. How do we prove some subset W of V is a subspace?<br>-Give the method.<br>-Prove it works.	pg 17
What is a diagonal matrix?	pg 18
What is P<sub>n</sub>(F)? Is it a vector space? Prove your answer. 	pg 18
Prove the intersection of subspaces of a vector space V is a subspace of V.	pg 19
Give the definition of an upper triangular matrix. Do the upper-triangular matrices of a certain width form a vector space (using standard matrix addition and scaling)? 	pg 21
Give the definition of a direct sum.	pg 22
What does it mean for a matrix to be <b>skew-symmetric?</b>.	pg 23
What is a coset?	pg 23
1.3 exercise 31 (pg 23)<br>(yes, I put this exercise in core concepts)	<br>
Give the definition of linear combination.	pg 24
Give the definition of the span of a subset of a vector space.	pg 30
Prove the following theorem:<br><br>The span of any subset S of a vector space V is a subspace of V. Moreover, any subspace of V that contains S must also contain the span of S.<br>	pg 30
What does it mean for a subset S of a vector space V to generate V?	pg 30
1.4 Exercise 1 pg 32	(yes, exercise 1 is included in core concepts on purpose)<br><br>answer in back of book
What does <b>linearly dependent mean?</b>	pg 36
Is the empty set linearly dependent? Prove your answer.	pg 37-36
Is a set containing a single vector linearly independent? Why or why not?	TRICK QUESTION: The answer is sometimes.<br>pg 37
Let <i>u</i> and <i>v</i> be distinct vectors in a vector space V. Show that {u,v} is linearly dependent if and only if u or v is a multiple of the other.	pg 41 exercise 9
pg 40 exercise 1	answer is in the back
Give the definition of a basis.	pg 43
Let V be a vector space and <$>\beta = \{\vec{u}_1, \vec{u}_2, ..., \vec{u}_n\}</$> be a subset of V. <br><br>Prove <$>\beta</$> is a basis for V if and only if each <$$>\vec{v} \epsilon V</$$> can be expressed in the form <br><$$>\vec{v}={a_1}{u_1}+{a_2}{u_2}+...+{a_n}{u_n}</$$><br>for unique scalars <$>a_1,a_2,...a_n</$>	page 43
Prove Theorem 1.9 pg 44	<br>
State and prove the replacement theorem.	pg 45
Let V be a vector space. Why does every basis for V contain the same number of vectors?	Cor 1. pg 46
Let V be a vector space. Give the definition of dim(V), the dimension of the vector space V.	pg 46-47
Let V be a vector space with dimension n.<br><br>Prove any finite generating set for V contains at least n vectors, and a generating set for V that contains exactly n vectors is a basis for V.<br>	pg 48
Let V be a vector space with dimension n.<br><br>Prove any linearly independent subset of V that contains exactly n vectors is a basis for V.	pg 48
Let V be a vector space with dimension n.<br><br>Why can every linearly independent subset of V can be extended to a basis for V?	pg 48
Let W be a subspace of a finite-dimensional vector space V. <br><br>Prove that W is finite-dimensional and dim(W) <= dim(V). Moreover, if dim(W)=dim(V), then V=W.<br>	pg 50
pg 53 exercise 1.<br>(yes, exercise 1 is included in core concepts on purpose)<br>	answer in back of book
Give the definition of a linear transformation.	pg 65
Give the definition of the null space of a linear transform.	pg 67
Give the definition of the range of a linear transform.	pg 67
Give the definitions of nullity and rank.	pg 69
State and prove the dimension theorem.	pg 70
Prove theorem 2.4 (pg 71)	<br>
Prove theorem 2.5 (pg 71)	<br>
<latex>~\\<br>Let $T : P_2(R) \to P_3(R)$ be the linear transformation defined by<br>$$ T(f(x)) = 2f'(x) + \int_0^x 3 f(t)~\mathit{dt}$$<br>Is $T$ one-to-one?<br></latex><br>	pg 71-72
Do example 12 (pg 72)	<br>
Do example 13 (pg 72)	<br>
Prove theorem 2.6 (pg 72-73)	<br>
Give the definition of an ordered basis.	pg 79
Give the definition of the coordinate vector of <$$>\vec{x} \epsilon V</$$> relative to an ordered basis <$>\beta</$> for a vector space V.	pg 80
Give the definition of the matrix representation of linear transform T : V -> W in the ordered bases <$>\beta</$> and <$>\gamma</$> of V and W respectively.	pg 80
Explain the notations <$>[T]_\beta</$> and <$>[T]_{\beta}^{\gamma}</$>. 	pg 80
Prove thm 2.7 (pg 82)	<br>
What does <$$>\cal{L}(V,W)</$$> denote? What about <$$>\cal{L}(V)?</$$>	 pg 82
Prove thm 2.8<br>(pg 82-83)	<br>
Prove thm 2.9	pg 86
Prove thm 2.10 a. <br>(pg 87)	<br>
Prove thm 2.10 b. <br>(pg 87)	<br>
Prove thm 2.10 c. <br>(pg 87)	<br>
Prove thm 2.10 d. <br>(pg 87)	<br>
What is the motivation for the definition of the matrix product? Derive the matrix product from this motivation.	pg 87
Express (AB)<sup>t</sup> in terms of A<sup>t</sup> and B<sup>t</sup>.<br><br>Prove your answer is correct.	pg 88
Prove Thm 2.12 a<br>pg 89	<br>
Prove Thm 2.12 b<br>pg 89	<br>
Prove Thm 2.12 c<br>pg 89	<br>
Prove Thm 2.12 d<br>pg 89	<br>
Let V and W be vector spaces, and let T : V → W be linear and invertible. <br><br>Prove T<sup>-1</sup> is linear.	pg 100 Thm 2.17
What does it mean for a matrix to be invertible? 	An nxn matrix A is invertible iff there exists a matrix B such that AB=BA=I. pg 100 
Let T be an invertible linear transformation from V to W. <br><br>Prove V is finite-dimensional iff W is finite-dimensional, and that dim(V)=dim(W) in that case.	pg 101<br>
Let V and W be finite-dimensional vector spaces with ordered bases β and γ, respectively. Let T : V → Wbe linear.<br><br>Prove that T is invertible iff <$>[T]_{\beta}^{\gamma}</$> is invertible. Furthermore, prove <$>[T^{-1}]_{\beta}^{\gamma}=([T]_{\beta}^{\gamma})^{-1}</$>	chpt 2.4
Give the definition of a <b>Change of coordinate matrix</b>. 	pg 112
Give the definition of a linear operator.	pg 112
prove pg 112 thm 2.23	<br>
Let A ϵ M<sub>nxn</sub>(F), and let γ be an ordered basis for F<sup>n</sup>. <br><br>Prove [L<sub>A</sub>]<sub>γ</sub> = Q<sup>-1</sup>AQ, where Q is the n x n matrix whose jth column is the jth vector of γ. 	pg 115
What does it mean for two matrices to be similar?	pg 115
pg 116, exercise 1<br>	<br>
pg 116, exercise 1	<br>
Give the definition of an elementary row operation.<br>Give the definition of an elementary column operation.<br>	pg 148
Give the definition of an elementary matrix.	pg 149
Let a ϵ M<sub>n x n</sub>(F), and suppose that B is obtained from A by performing an elementary row operation.<br><br>Prove there exists an m x m elementary matrix E such that B = EA. 	pg 150
Suppose E is an elementary m x m matrix and A is an m x n matrix. Explain the matrix EA in terms of elementary operations performed on A.<br>	pg 150
Prove that elementary matrices are invertible, and the inverse of an elementary matrix is an elementary matrix of the same type.<br>	pg 150
pg 151, exercise 1	<br>
Give the definition of the <b>rank</b> of a matrix.	pg 152
Let T : V → W be a linear transformation between finite-dimensional vector spaces, and let β and γ be ordered bases for V and W, respectively.<br><br>Prove <$$>rank(T)=rank([T]_{\beta}^{\gamma}).</$$>	pg 152
Let A be an m x n matrix. If P and Q are invertibele m x m and n x n matrices, respectively, then prove: <br>-rank(AQ) = rank(A)<br>-rank(PA) = rank(A)<br>-rank(PAQ) = rank(A)	pg 153
Prove that elementary row and column operations on a matrix are rank-preserving.<br>	pg 153
Prove that the rank of a matrix equals the maximum number of its linearly independent columns; that is, the rank of a matrix is the dimension of the subspace generated by its columns.	pg 153-154
Prove Theorem 3.6 on page 155	pg 155
Prove corollary 1 on pg 158	pg 158
Prove Corollary 2 on page 158	pg 158
Prove theorem 3.7 on page 159	pg 159
What are the kernel and image of a linear transformation?	pg 69
Let A and B be m x n and m x p matrices, respectively.<br>What is (A | B)?	pg 161
pg 165 exercise 1<br>	<br>
Exercise 1.2 1.)	pg 12
Exercise 1.2 11.)	pg 15
Chpt 1.2 Exercise 13.	pg 15
Chpt 1.2 Exercise 14	pg 15
Chpt 1.2 Exercise 17	No. <$$>1\vec{x} \neq \vec{x}\mbox{ (VS 5)}</$$><br>pg 15
Chpt 1.2 Exercise 18	pg 15
Chpt 1.2 Exercise 19.	pg 16
Chpt 1.2 Exercise 20	pg 16<br><br>This is like example 5. I'd like to know why example 5 doesn't apply to sequences with an infinite number of non-zero entries. I think I was able to prove that it does... must have made a mistake.
Chpt 1.2 Exercise 21	pg 16
1.3 exercise 12 <br>pg 21	<br>
1.3 exercise 15<br>pg 21	<br>
1.3 exercise 1<br>pg 20	<br>
1.3 exercise 17<br>pg 21	<br>
1.3 exercise 18<br>pg 21	<br>
1.3 exercise 19<br>pg 21	<br>
1.3 exercise 20<br>pg 21	My answer: Checked 0 times<br><br>Proof by induction:<br>I.H. The sum from i to k of a<sub>i</sub>w<sub>i</sub> is an element of W.<br><br>Base case: Since w<sub>1</sub> is in W, and W is closed under scalar multiplication, a<sub>1</sub>w<sub>1</sub> is in W.<br><br>Inductive step: Suppose the sum from i to k-1 of a<sub>i</sub>w<sub>i</sub> is an element of W. Prove the same is true for the sum from i to k.
1.3 exercise 23<br>pg 22	<br>
1.3 exercise 25<br>pg 22	<br>
1.3 exercise 28<br>pg 23	<br>
1.3 exercise 28<br>pg 23	<br>
1.3 exercise 29<br>pg 23	<br>
1.3 exercise 30<br>pg 23	<br>
1.4 exercise 7<br>pg 34	<br>
1.4 exercise 8<br>pg 34	<br>
1.4 exercise 11<br>pg 34	<br>
1.4 exercise 12<br>pg 34	<br>
1.4 exercise 13<br>pg 34	<br>
1.4 exercise 14<br>pg 34	<br>
1.4 exercise 15<br>pg 35	<br>
1.4 exercise 16<br>pg 35	<br>
1.4 exercise 17<br>pg 35	<br>
exercise 9 pg 41<br>	<br>
ex 14 pg 42	<br>
ex 15 pg 42	<br>
ex 16 pg 42	<br>
ex. 11 pg 55	<br>
ex. 12 pg 55	<br>
ex 20 pg 56	<br>
ex 21 pg 56	<br>
ex 22 pg 56	<br>
ex 26 pg 57	<br>
ex 29 a <br>pg 57	<br>
ex 29 b<br>pg 57	<br>
ex 31 a<br>pg 57	<br>
ex 31 b<br>pg 57	<br>
ex 33 a&b<br>pg 58	<br>
ex 34 a&b<br>pg 58	<br>
ex 12 pg 75	<br>
ex 13 pg 75	<br>
ex 14 pg 75	<br>
ex 17 pg 76	<br>
ex 18 pg 75	<br>
ex 19 pg 75	<br>
ex 21 pg 75	<br>
ex 26 pg 76	<br>
ex 27 pg 76	<br>
ex 28 pg 76	<br>
ex 29 pg 76	<br>
ex 30 pg 76	<br>
ex 31 pg 76	<br>
ex 32 pg 78	<br>
ex 33 pg 76	<br>
ex 34 pg 78	<br>
ex 35 pg 78	<br>
ex 36 pg 78	<br>
ex 37 pg 78	<br>
ex 39 pg 78	<br>
ex 40 pg 79	<br>
ex 3 pg 84	<br>
ex 8 pg 85	<br>
ex 10 pg 85	<br>
ex 11 pg 85	<br>
ex 13 pg 86	<br>
ex 14 pg 86	<br>
ex 15 pg 86	<br>
ex 16 pg 86	<br>
pg 97 ex 9	<br>
pg 97 ex 11	<br>
pg 97 ex 12	<br>
pg 97 ex 13	<br>
pg 98 ex 14	<br>
pg 98 ex 15	<br>
pg 98 ex 16	<br>
pg 98 ex 17	<br>
pg 98 ex 19	<br>
pg 98 ex 20	<br>
pg 99 ex 21	<br>
pg 99 ex 22	<br>
pg 107 ex 5	<br>
pg 107 ex 6	<br>
pg 107 ex 7	<br>
pg 107 ex 9	<br>
pg 107 ex 10	<br>
pg 107 ex 13	<br>
pg 107 ex 14	<br>
pg 108 ex 15	<br>
pg 108 ex 16	<br>
pg 108 ex 17	<br>
pg 108 ex 20	<br>
pg 108 ex 24	<br>
pg 109 ex 25	<br>
pg 117 ex 8	<br>
pg 118 ex 9	<br>
pg 118 ex 10	<br>
pg 118 ex 11	<br>
pg 118 ex 13	<br>
pg 118 ex 14	<br>
pg 151 ex 5	<br>
pg 151 ex 4	<br>
pg 151 ex 6	<br>
pg 152 ex 8	<br>
pg 152 ex 9	<br>
pg 152 ex 10	<br>
pg 152 ex 11	<br>
pg 152 ex 12	<br>
pg 167 ex 8	<br>
pg 167 ex 11	<br>
pg 167 ex 12	<br>
pg 167 ex 14	<br>
pg 167 ex 15	<br>
pg 167 ex 17	<br>
pg 167 ex 18	<br>
pg 167 ex 19	<br>
pg 167 ex 21	<br>
pg 166 exercise 5	<br>
pg 166 exercise 3	<br>
pg 167 exercise 8	<br>
pg 167 exercise 11	<br>
pg 167 exercise 12	<br>
pg 167 exercise 14	<br>
pg 168 exercise 15	<br>
pg 168 exercise 17	<br>
pg 168 exercise 18	<br>
pg 168 exercise 19	<br>
pg 168 exercise 20	<br>
pg 168 exercise 22	<br>
pg 42 prb 2	<br>
pg 42 prb 5	<br>
pg 42 prb 7	<br>
kunze pg 47<br>prb 1	<br>
kunze pg 47<br>prb 2	<br>
kunze pg 47<br>prb 3	<br>
kunze pg 48<br>prb 5	<br>
kunze pg 48<br>prb 6	<br>
kunze pg 48<br>prb 7	<br>
kunze pg 48<br>prb 8	<br>
kunze pg 48<br>prb 9	<br>
kunze pg 56<br>prb 1	<br>
kunze pg 56<br>prb 7	<br>
kunze pg 57<br>prb 8	<br>
kunze pg 57<br>prb 9	<br>
kunze pg 57<br>prb 10	<br>
kunze pg 57<br>prb 11	<br>
kunze pg 57<br>prb 14	<br>
Kunze pg 63<br>prb 4	<br>
Kunze pg 63<br>prb 6	<br>
Kunze pg 74<br>prb 1	<br>
Kunze pg 74<br>prb 2	<br>
Kunze pg 74<br>prb 4	<br>
Kunze pg 74<br>prb 7	<br>
Kunze pg 81<br>prb 1	<br>
Kunze pg 81<br>prb 2	<br>
Kunze pg 81<br>prb 4	<br>
Kunze pg 81<br>prb 7	<br>
Kunze pg 81<br>prb 9	<br>
Kunze pg 81<br>prb 12	<br>
Kunze pg 82<br>prb 13	<br>
Kunze pg 91<br>prb 2	<br>
Kunze pg 91<br>prb 5	<br>
Kunze pg 91<br>prb 6	<br>
Kunze pg 92<br>prb 7	<br>
Kunze pg 91<br>prb 8	<br>
Kunze pg 91<br>prb 9	<br>
Kunze pg 91<br>prb 10	<br>
Kunze pg 91<br>prb 11	<br>
Kunze pg 91<br>prb 12	<br>
Kunze pg 94<br>prb 1	<br>
Kunze pg 94<br>prb 2	<br>
Kunze pg 94<br>prb 3	<br>
Kunze pg 94<br>prb 6	<br>
Kunze pg 94<br>prb 7	<br>
List several standard applicative functors in Haskell.<br>List the typeclasses and operators required for applicative functors.<br>List all laws of applicative functors.<br>Show that one of the standard applicative functors obeys the applicative functor laws.<br>	Typeclasses: applicative functors must be functors (duh)<br><br>Operators for functor f:<br>pure : a -> f a -- a functor in a minimal context<br><*> : f (a -> b) -> f a -> f b -- "applies a function" at the functor level<br><br>Applicative functors:<br><br>Maybe<br>List<br>Function<br>IO<br>ZipList<br><br>Laws:<br><br>pure f <*> x = fmap f x<br>pure id <*> v = v<br>pure (.) <*> u <*> v <*> w = u <*> (v <*> w)<br>pure f <*> pure x = pure (f x)<br>u <*> pure y = pure ($ y) <*> u<br><br>Learn you a haskell "Functors, Applicative Functors, and Monoids"<br><br><br><br><br><br>
What is a functor? What operators a required of a functor?<br>What common haskell types are functors?<br>What are the functor laws?<br><br>Choose a common haskell functor and show that it obeys the functor laws.<br>	Functor operators:<br>there is only one<br>fmap : (a -> b) -> f a -> f b -- takes item out of box, applies function, reboxes result.<br><br>haskell functors<br><br>Maybe<br>List<br>IO<br>Function<br><br>Functor laws<br>fmap id = id<br>fmap (f . g) x = (fmap f (fmap g x)) <br><br>Learn You A Haskell: functors, applicative functors, and monoids<br><br><br><br><br>
Describe the purpose and usage of Haskell's newtype construct.<br>	LYAHFGG Functors, etc. pg 26/27
Suppose we want to make Pair a functor instance, such that fmap maps the first component of the pair. How would we accomplish this?	use newtype (of course, a more in-depth description is wanted when answering these flash cards)<br><br>see LYAHFGG Functors etc. pg 28<br>
data CoolBool = CoolBool { getCoolBool :: Bool }<br>newtype CoolBool2 = CoolBool { getCoolBool2 :: Bool }<br><br>are these types different in any way, behaviorally?<br>	yes. matching a term of type CoolBool forces evaluation, because it doesn't know that there is only one variant<br><br>LYAHFGG Functors, etc. pg 20
Describe the operators of the Monoid typeclass, standard types that are instance of Monoid, and the Monoid laws. Show how a common Monoid instance of your choice obeys the monoid laws.<br><br><br>	A monoid is like a group, only its elements do not need to have inverses!<br><br>class Monoid m where  <br>    mempty :: m  <br>    mappend :: m -> m -> m  <br>    mconcat :: [m] -> m  <br>    mconcat = foldr mappend mempty  <br><br>mempty is the identity element of the monoid<br>mappend is the group operation<br>mconcat mappends all of the elements in the list, as its default implementation suggests<br><br>Common Instances of Monoid:<br>-Lists<br>-Orderings (EQ,LT,GT)<br>-Num has two newtype Monoid instances: Product and Sum. (Num a => Sum a), (Num a => Product a).<br>-Booleans have two newtype Monoid instances: Any and All<br>-Maybe is a monoid instance only when its type parameter is a monoid instance.<br>-First is a newtype of Maybe that is a monoid instance even when its type parameter is not a Monoid instance.<br><br>LYAHFGG Functors, etc. pg 33<br><br><br><br><br><br><br>
Explain the relation between the monoid and foldable type classes.	If the elements of a container have a monoid type, then foldr and foldl are the same thing, in which case a foldMap operator can be implemented in order to implement the foldl and foldr automatically:<br><br>foldMap :: (Monoid m, Foldable t) => (a -> m) -> t a -> m  <br><br>pg 44, Functors, etc.<br>
Suppose foldMap is implemented for some type T Int. How do we test if any integer that a (T Int) value contains is equal to 5?<br>	LYAHFGG Functors,etc. , pg 45/46
Give the implementations of >>= and return for the Maybe monad.	pg 6, LYAH Fist Full of Monads<br>
Translate from do notation to usages of the >>= operator:<br><br>foo :: Maybe String  <br>foo =  do   <br>    x <- Just 3  <br>    y <- Just "!"  <br>    Just (show x ++ y)  <br><br><br>	LYAH Fist Full of Monads pg 14<br>
Give the default implementation of Monad's >> operator.<br>	pg 12, LYAH Fist Full of Monads<br>
Give the implementations of >>= and return for the <i>list</i> monad instance.<br>	LYAH Fist Full of Monads, pg 18<br>
Name some common Haskell types that are Monad instances. Describe the Monad operators. What is a monad anyway?	Common monads: Maybe, List<br><br>LYAH Fist Full of Monads, pg 18,19,20<br>
Give the definition of the MonadPlus type class.	class  Monad m => MonadPlus m  where   <br>    mzero :: m a      <br>    mplus :: m a -> m a -> m a<br><br>LYAH Fist Full of Monads pg 20,21<br>
Give the list implementation of the MonadPlus type class.<br>	instance  MonadPlus []  where   <br>    mzero = []  <br>    mplus = (++) <br><br>LYAH Fist full of Monads pg 21<br>
Describe the purpose of the guard function. Give its type and implementation.<br>	guard :: (MonadPlus m) => Bool -> m ()  <br>guard True = return ()  <br>guard False = mzero  <br><br>guard example:<br>sevensOnly :: [Int]  <br>sevensOnly =  do   <br>    x <- [1..50]  <br>    guard ('7' `elem` show x)  <br>    return x  <br><br>LYAH Fist Full of Monads pg 21<br>
How would you use the list monad to determine if a knight can reach a position in three moves?<br>	moveKnight :: KnightPos -> [KnightPos]  <br>moveKnight (c,r) =  do   <br>    (c',r') <- [(c+2,r-1),(c+2,r+1),(c-2,r-1),(c-2,r+1)  <br>               ,(c+1,r-2),(c+1,r+2),(c-1,r-2),(c-1,r+2)  <br>               ]  <br>    guard (c' `elem` [1..8] && r' `elem` [1..8])  <br>    return (c',r')  <br><br>LYAH Fist full of monads pg 23<br>
Describe the monad laws. Show how one common instance of Monad obeys the monad laws.<br>	LYAH Fist full of monads pg 25-27<br><br>Left Identity:<br>(return x >>= f)  =  (f x)<br><br>Right Identity:<br>(m >>= return) =  m<br><br>Associativity:<br>((m >>= f) >>= g) = (m >>= (\x -> f x >>= g))<br><br>
Give the definition of the <i>length</i> of a finite chain.<br>	pg 26
Give the definition of the <i>length</i> of a lattice.<br>	pg 26
What does it mean for a lattice to satisfy the <i>ascending chain condition (ACC)</i>? 	pg 26
Do lattices with no infinite chains necessarily have finite length?	No. Look at rightmost figure 2.9. <br>pdf pg 26<br>
Consider the following statement:<br><br>An ordered set P satisfies (ACC) if and only if every non-empty subset A of P has a maximal element.<br><br>Prove or give a counterexample.<br>	true. pdf pg 27.<br><br>
Consider the following statement:<br><br>An ordered set P satisfies (ACC) if and only if some non-empty subset A of P has a maximal element.<br><br>Prove or give a counterexample.<br>	IMPOSTOR. pdf pg 27
What can be said of an ordered set which satisfies both the (ACC) and the (DCC)?<br>	It has no infinite chains. See theorem 2.40 pdf pg 52.<br><br><br><br>
Consider the following statement:<br><br>An ordered set P has no infinite chains if and only if it satisfies both (ACC) and (DCC).<br><br>Prove or give a counterexample.<br>	true. pdf pg 27<br>
Consider the following statement:<br><br>An ordered set P has no infinite chains if and only if it satisfies (ACC).<br><br>Prove or give a counterexample.<br>	IMPOSTOR. pdf pg 27<br>
Consider the following statement:<br><br>If P satisfies (ACC), then for every non-empty subset A of P there exists a finite subset F of A such that ⋁A = ⋁F.<br><br>Prove or give a counterexample.<br><br>	true. pdf pg 27.<br>
Consider the following statement:<br><br>If P satisfies (DCC), then for every non-empty subset A of P there exists a finite subset F of A such that ⋁A = ⋁F.<br><br>Prove or give a counterexample.<br><br>	IMPOSTOR. Consider the topped natural numbers. pdf pg 27
Consider the following statement:<br><br>If P has a bottom element and satisfies (ACC), then P is complete.<br><br>Prove or give a counterexample.	true. pdf pg 27.<br>
Consider the following statement:<br><br>Let P be a lattice. If P has a top element and satisfies (ACC), then P is complete.<br><br>Prove or give a counterexample.	IMPOSTOR:<br><br>Consider the chain of real numbers: { 1/2<sup>n</sup> | n is a natural number}.<br>This satisfies the ACC, yet it does not contain the meet of the entire set (0), and therefore is not complete.<br><br>pdf pg 27<br>
Consider the following statement:<br><br>Let P be a lattice. If P has no infinite chains, P is complete.<br><br>Prove or give a counterexample.<br>	True. Pdf pg 27<br>
Let L be a lattice. What does it mean for an element x ∈ L to be join irreducible?	pdf pg 27
If L is a lattice, then what do J(L) and M(L) denote?	The join-irreducible and meet-irreducible elements of L, respectively.<br><br>mstudy pg 27<br>
If Q and P are ordered sets such that Q ⊆ P, what does it mean for Q to be join-dense in P?<br>	mstudy pg 27
Join-irreducible elements of finite lattices can easily be identified. How is this done?	An element of a finite lattice is join-irreducible iff it has exactly one lower cover. These are easy to spot in Hasse diagrams.<br><br>mstudy pg 27/28<br>
In the lattice &< <b>N</b><sub>0</sub>; lcm, gcd &>, which elements are join irreducible?	note: I think the book is wrong about r: it should be in <b>N</b><sub>0</sub><br><br>mstudy pg 28
Which elements of a powerset lattice P(X) are join-irreducible?	All singleton sets {x}.<br><br>mstudy pg 28
What is the lattice-theoretic equivalent of insisting that 1 is not a prime number?	insisting that 0 (or Bot) is not join-irreducible.<br><br>mstudy pg 28
Let L be a lattice satisfying (DCC). Consider the following statement:<br><br>Suppose a,b ∈ L and a ≰ b. Then there exists x ∈ J(L) such that x ≤ a and x ≰ b.<br><br>Prove or give a counterexample.	true<br><br>mstudy pg 28<br>
Let L be a lattice satisfying (DCC). Consider the following statement:<br><br>Suppose a,b ∈ L and a ≰ b. Then there exists x ∈ J(L) such that x ≰ a and x ≤ b.<br><br>Prove or give a counterexample.	IMPOSTOR <br><br>mstudy pg 28<br>
Let L be a lattice satisfying (DCC). Consider the following statement:<br><br>a = ⋁{ x ∈ J(L) | x ≤ a } for all a ∈ L.<br><br>Prove or give a counterexample.<br><br><br>	true. mstudy pg 28<br>
Let L be a lattice. Consider the following statement:<br><br>If L satisfies (DCC), then J(L) and, more generally, any subset Q which contains J(L) is join-dense in L.<br><br>Prove or give a counterexample.	true. mstudy pg 28.<br>
Let L be a lattice. Consider the following statement:<br><br>If L satisfies (ACC) and Q is join-dense in L, then, for each a ∈ L, there exists a finite subset F of Q such that a = ⋁F.<br><br>Prove or give a counterexample.	true. mstudy pg 28.<br>
Let L be a lattice. Consider the following statement:<br><br>If L has no infinite chains, then for each a ∈ L, there exists a finite subset F of J(L) such that a = ⋁F.<br><br>Prove or give a counterexample.	true. mstudy pg 28.<br>
Let L be a lattice. Consider the following statement:<br><br>If L has no infinite chains, then Q is join-dense in L if and only if J(L) ⊆ Q.<br><br>Prove or give a counterexample.	true. mstudy pg 28<br>
Let L be a lattice. Consider the following statement:<br><br>If L has no infinite chains, then Q is join-dense in L if and only if J(L) = Q.<br><br>Prove or give a counterexample.	IMPOSTOR.<br><br>mstudy pg 28<br>
Let L be a lattice and a,b,c ∈ L. Consider the following statement:<br><br>a∧(b∨c)≥(a∧b)∨(a∧c)<br><br>Prove or give a counterexample.	true. mstudy pg 43.<br>
Let L be a lattice and a,b,c ∈ L. Consider the following statement:<br><br>a∧(b∨c)≤(a∧b)∨(a∧c)<br><br>Prove or give a counterexample.	IMPOSTOR!<br>mstudy pg 43<br>
Let L be a lattice and a,b,c ∈ L. Consider the following statement:<br><br>a ≥ c ⇒ a∧(b∨c) ≥ (a∧b)∨c<br><br>Prove or give a counterexample.<br>	true. mstudy pg 43.
Let L be a lattice and a,b,c ∈ L. Consider the following statement:<br><br>a ≥ c ⇒ a∧(b∨c) ≤ (a∧b)∨c<br><br>Prove or give a counterexample.<br>	IMPOSTOR!<br>mstudy pg 43<br>
Let L be a lattice and a,b,c ∈ L. Consider the following statement:<br><br>(a∧b)∨(b∧c)∨(c∧a) ≤ (a∨b)∧(b∨c)∧(c∨a)<br><br>Prove or give a counterexample.<br>	true. mstudy pg 43
Let L be a lattice and a,b,c ∈ L. Consider the following statement:<br><br>(a∧b)∨(b∧c)∨(c∧a) ≥ (a∨b)∧(b∨c)∧(c∨a)<br><br>Prove or give a counterexample.<br>	IMPOSTOR. M<sub>3</sub> is a counterexample.<br><br>Changing geq to leq is true due to the minimax theorem. An alternative explanation is in the book.<br><br>mstudy pg 43.<br>
Let L be a lattice. Consider the following statement:<br><br>The following are equivalent:<br>(i)   ∀a,b,c ∈ L, a ≥ c ⇒ a∧(b∨c)=(a∧b)∨c<br>(ii)  ∀a,b,c ∈ L, a ≥ c ⇒ a∧(b∨c)=(a∧b)∨(a∧c)<br>(iii) ∀p,q,r ∈ L, p∧(q∨(p∧r))=(p∧q)∨(p∧r)<br><br>Prove or give a counterexample.<br>	true. mstudy pg 43
Let L be a lattice. Consider the following statement:<br><br>The following are equivalent:<br>(i)   ∀a,b,c ∈ L, a∧(b∨c)=(a∧b)∨c<br>(ii)  ∀a,b,c ∈ L, a ≥ c ⇒ a∧(b∨c)=(a∧b)∨(a∧c)<br>(iii) ∀p,q,r ∈ L, p∧(q∨(p∧r))=(p∧q)∨(p∧r)<br><br>Prove or give a counterexample.<br>	IMPOSTOR.<br>mstudy pg 43<br>
Let L be a lattice. Consider the following statement:<br><br>The following are equivalent:<br>(i)  ∀a,b,c ∈ L. a∧(b∨c)=(a∧b)∨(a∧c)<br>(ii) ∀p,q,r ∈ L. p∨(q∧r)=(p∨q)∧(p∨r)<br><br>Prove or give a counterexample.	true. mstudy pg 43<br>
What does it mean for a lattice to be <i>distributive</i>?<br>	mstudy pg 44<br>
What does it mean for a lattice to be <i>modular</i>?	mstudy pg 44.<br>
Consider the following statement:<br><br>Any distributive lattice is modular.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 44 remark 2.<br>
Consider the following statement:<br><br>Any modular lattice is distributive.<br><br>Prove or give a counterexample.<br>	IMPOSTOR. <b>M</b><sub>3</sub> is a good counterexample to this.<br><br>mstudy pg 44<br>
Let L be a lattice and a,b,c ∈ L. Consider the following statement:<br><br>If a∧(b∨c)=(a∧b)∨(a∧c) then a∨(b∧c)=(a∨b)∧(a∨c).<br><br>Prove or give a counterexample.<br><br><br>	IMPOSTOR!<br>mstudy pg 44<br>See remark 4 
Consider the following statement:<br><br>Any lattice of sets is distributive.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 44.
Consider the following statement:<br><br>Any chain is distributive.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 44
Consider the following statement:<br><br>The lattice &< <b>N</b><sub>0</sub>;lcm,gcd &> is distributive.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 44
Consider the following statement:<br><br>If G is a group, then the lattice of normal subgroups of G, N-Sub G, is modular.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 44<br>
Consider the following statement:<br><br>If G is a group, then the lattice of normal subgroups of G, N-Sub G, is distributive.<br><br>Prove or give a counterexample.<br>	IMPOSTOR. there should be a counterexample. can you find one?<br><br>mstudy pg 44
Draw the lattice <b>M</b><sub>3</sub>. Is it modular? Distributive? Prove/show your answer.<br>	mstudy pg 44<br>
Draw the lattice <b>N</b><sub>5</sub>. Is it modular? Distributive? Prove/show your answer.<br>	mstudy pg 44<br>
Consider the following statement:<br><br>If a lattice L is modular (distributive), then every sublattice of L is modular (distributive).<br><br>Prove or give a counterexample.<br>	true. mstudy pg 45.<br>
Consider the following statement:<br><br>If L and K are modular (distributive), then L × K is modular (distributive).<br><br>Prove or give a counterexample.<br>	true mstudy pg 44
Consider the following statement:<br><br>If L is modular and K is distributive, then L × K is modular.<br><br>Prove or give a counterexample.<br>	this is true. note that distributive ==> modular, and modular x modular = modular.<br><br>mstudy pg 45<br>
Consider the following statement:<br><br>If L is modular (distributive) and K is the image of L under a homomorphism, then K is modular (distributive).<br><br>Prove or give a counterexample.<br>	true. mstudy pg 44.<br>
Consider the following statement:<br><br>If a lattice is isomorphic to a sublattice of a product of distributive (modular) lattices, it is distributive (modular).<br><br>Prove or give a counterexample.<br>	mstudy pg 45<br>
State the M<sub>3</sub>-N<sub>5</sub> theorem.<br>	mstudy pg 45<br>
Consider the following statement:<br><br>if N<sub>5</sub> ↣ L then L is non-modular.<br><br>Prove or give a counterexample.<br>	true. N5 is known to be non-modular, and section 4.7 explains how homomorphisms preserve modularity. If L were modular, then the isomorphism from L to N5 would witness N5's modularity. N5 is not modular, though, so L cannot be modular.<br><br>mstudy pg 45<br>
Consider the following statement:<br><br>If N5 ↣ L then L is non-distributive.<br><br>Prove or give a counterexample.<br>	true. all distributive lattices are modular. If L were distributive, the isomorphism between L and N5 would witness N5's distributivity (see section 4.7), which would imply that N5 is modular (and it isn't). <br><br>mstudy pg 45<br><br>
Consider the following statement:<br><br>If M<sub>3</sub> ↣ L then L is non-distributive.<br><br>Prove or give a counterexample.<br><br>	true. If L were distributive then the isomorphism between L and M<sub>3</sub> would witness M<sub>3</sub>'s distributivity (see section 4.7). M<sub>3</sub> is not distributive, though.<br><br>mstudy pg 45
Consider the following statement:<br><br>If M<sub>3</sub> ↣ L then L is non-modular.<br><br>Prove or give a counterexample.<br>	IMPOSTOR.<br><br>mstudy pg 45
Consider the following statement:<br><br>If L is non-distributive then N<sub>5</sub> ↣ L or M<sub>3</sub> ↣ L.<br><br>Prove or give a counterexample.<br>	true.<br><br>If L is non-distributive then it may or may not be modular. If it is non-modular, then N<sub>5</sub> ↣ L. Otherwise M<sub>3</sub> ↣ L. This is explained in mstudy pg 46.<br><br>mstudy pg 46<br><br>
Consider the following statement:<br><br>If L is non-modular then N<sub>5</sub> ↣ L.<br><br>Prove or give a counterexample.<br><br>	true.<br><br>mstudy pg 46<br>
Explain the following notation:<br><br><$$>S[\gamma](t_1,t_2)=\int_{t_1}^{t_2} F[\gamma]</$$>	mstudy pg 458<br>
Explain the following equation:<br><br><$$>\cal{F}[\gamma]=\cal{L} \circ T[\gamma]</$$>	SICM pg 458 (1.2) / pg 7
State the principle of stationary action.<br>	mstudy pg 460
Solve ex. 1.1 pg 9	mstudy pg 461
What is a particle?	An object with mass and position but no internal structure.<br><br>mstudy pg 461 footnote 17<br><br><br>
What is a <i>configuration </i> of a particle system? What is a <i>configuration space</i>?<br>	A configuration of a particle system is a tuple of the positions of all constituent particles.<br><br>The set of all configurations of the system that can be assumed is called the configuration space of the system.<br><br>mstudy pg 461/462
What are the <i>degrees of freedom</i> of a configuration space?<br>	Also called the <i>dimension</i> of the configuration space. <br><br>It is the smallest number of parameters that have to be given to completely specify a configuration.<br><br>mstudy pg 462
How many degrees of freedom exist in a system of two point particles constrained to be a constant distance apart in 3d space?	Five. Give three rectangular coordinates for the first one, and then pitch and yaw to describe the position of the second on a sphere surrounding the first.<br><br>mstudy pg 462
How many degrees of freedom does a mid-air juggling pin have?	6 - three for position and three for orientation<br><br>mstudy pg 462
Solve exercise 1.2, mstudy pg 463	<br>
Must the number of generalized coordinates be the same as the dimension of the configuration space? Why or why not?	mstudy pg 464<br>
What do the χ and χ<sup>i</sup> functions represent in Sussman and Wisdom?<br>	χ is a map from elements of a configuration space into n-tuples of generalized coordinates (which are real numbers)<br><br>χ<sup>i</sup> maps an element of a configuration space to its ith generalized coordinate<br><br>mstudy pg 464, bottom paragraph
What is the difference between <i>configuration</i> paths and coordinate paths?<br>	<br>mstudy pg 465 (make sure to take a look at footnote 21)<br>
Exercise 1.3, mstudy pg 466	mstudy pg 
Do configuration spaces necessarily consist of tuples of real numbers?<br>	footnotes 21 and 23 suggest not<br><br>however, footnote 21 suggests that configuration spaces must be metric spaces<br><br>mstudy pg 465/466<br><br>
Are generalized coordinates necessarily tuples of real numbers?	yes. bottom paragraph of mstudy pg 464
Give the definitions of these notations:<br><br><$$>L_{\chi}</$$><br><$$>S_{\chi}[q](t_1,t_2) </$$>	mstudy pg 467<br>
Consider the following statement:<br><br><$$>S[\gamma](t_1,t_2)=S_{\chi}[\chi \circ \gamma](t_1,t_2)</$$><br><br>Prove or give a counterexample.<br>	mstudy pg 467
In what way are Lagrangians robust against changes in the underlying coordinate system?<br>	mstudy pg 467
Types can be read as sets or relations. Explain the two approaches.<br>	pdf pg 409<br><br>
For relations <b>A</b> : A ⇔ A', and <b>B</b> : B ⇔ B', how do we define the relation A × B?<br>	pdf pg 409
For a relation <b>A</b> : A ⇔ A', how do we define the relation <b>A</b>*?	pdf pg 410
For any relations <b>A</b> : A ⇔ A' and <b>B</b> : B ⇔ B', how do we define the relation <b>A</b> → <b>B</b>?	pdf pg 410
If χ is a relation, how do we define the relation ∀χ. <b>F</b>(χ)?<br><br>	pdf pg 410
State the parametricity theorem.<br>	pdf pg 410
Derive a "free" theorem for the type ∀X. X* → X*.<br><br>	pdf pg 410
In the special case where the relation a is a function, what can be said of the relation a*? why?<br>	it's the map function<br><br>pdf pg 410
In the special case in which a and b are functions, what can be said of the relation a → b? why?<br><br>	(f,f') ∈ a → b is equivalent to f' ∘ a = b ∘ f<br><br>pg 410<br>
Consider the following statement:<br><br>In the special case the a and b are functions, the relation a → b is a function.<br><br>Prove or give a counterexample.<br>	it seems that if (f,f') and (f,g') are both elements, f' and g' must be observationally equivalent. however, the book says no. Maybe this is because they can have different structures?<br><br><br>there should be a counterexample pdf pg 410<br>
In what way can the type ∀X. (A → A) → X be considered isomorphic to A?<br>	mstudy pg 413
Give the definition of a <i>type model</i>.<br>	mstudy pg 414
<$$> \textrm{If T is a type and } \overline{A} \textrm{ is an environment, what does [[T]]}\overline{A}\textrm{ denote?}</$$>	mstudy pg 414<br><br>note that in ∀F, the function F from U to U is specified using lambda notation
For each type A in U, D<sub>A</sub> denotes the set of representatives of values of A. How does this work? Why doesn't it denote the actual set of values of A?<br>	mstudy pg 415
<$$>\textrm{What does it mean for }\overline{A},\overline{a}\textrm{ to be environments respecting }\overline{X},\overline{x}?</$$>	pg 415
<$$>\textrm{Give the definition of the value of t in the environments }\overline{A}\textrm{ and }\overline{a}</$$>	mstudy pg 415
Give the definition of a <i>frame</i>.<br><br>	<br>pg 415<br>
Give the definition of an <i>environment model</i>.<br>	pg 415<br>
<$$>\textrm{What does }\overline{X},\overline{x} \models~t:T\textrm{ mean?}</$$>	mstudy pg 415<br>
State the "soundness of types" proposition.	pg 415<br>
Why is helpful for contracts to be first-class values?	mstudy pg 423, section 2.4<br>
What are <i>stateful contracts</i>? Why are they important.	mstudy pg 423 section 2.5<br>
Explain λ<sup>CON</sup>'s expression forms contract(e) and e ⟼ e.<br>	mstudy pg 424
Explain λ<sup>CON</sup>'s flatp, pred, dom, rng, and blame expression forms.<br>	mstudy pg 424<br>
Give λ<sup>CON</sup>'s contract typing rules.<br>	pg 425, top part of fig 7<br>
Explain λ<sup>CON</sup>'s expression form e<sup>e,x,x</sup>.<br>	mstudy pg 425<br>
In λ<sup>CON</sup>, do programmers explicitly write obligations, or are they part of an internal language? In the former case, how are they written? In the latter case, how are they generated?	mstudy pg 425, bottom two paragraphs
λ<sup>CON</sup> only contains obligation values of the form V<sup>V⟼V,x,x</sup>. Why only function contracts? Can't non-functions be given obligations?	answer: they can. but such obligations are checked immediately via a reduction, and therefore are not values.<br><br>mstudy pg 426, figure 8<br>
Explain λ<sup>CON</sup>'s <i>hoc</i> reduction rule.	mstudy pg 426<br>
Explain the purpose and implementation of the <$>\overline{wrap}</$> function of λ<sup>CON</sup>.<br>	mstudy pg 427 (and 426 figure 9)<br>
State the type soundness for λ<sup>CON</sup>.<br>	mstudy pdf pg 428
Explain the difference between E, E<sub>fw</sub>, and E<sub>fh</sub>. What are they used to prove regarding λ<sup>CON</sup>?<br>	mstudy pg 428
Give the typing and reduction rules for dependent contracts in λ<sup>CON</sup>.<br>	mstudy pdf pg 429
Computationally, using scmutils, how do we determine whether or not a given trajectory is realizable?<br>	mstudy pg 473/474
Computationally using scmutils, how can we use the variational principal to approximate realizable trajectories?<br>	mstudy pg 474/475<br>
Give the definition for the variation δ<sub>η</sub>f[q] of the function f on the path q.<br>	mstudy pg 479<br>
What do δq and δDq denote?<br>	mstudy pg 480
Explain how the variation δ<sub>n</sub>f[q] may be expressed in terms of a derivative.	mstudy pg 480 (1.22)
Consider the following statement:<br><br>For path-dependent functions f and g,<br>δ<sub>η</sub>(f·g)[q] = δ<sub>η</sub>f[q]·g[q] + f[q]·δ<sub>η</sub>g[q]<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 480, (1.23)
Consider the following statement:<br><br>For path-dependent functions f and g,<br>δ<sub>η</sub>(f + g)[q] = δ<sub>η</sub>f[q] + δ<sub>η</sub>g[q]<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 480 (1.24)<br>TODO: add impostor?
Consider the following statement:<br><br>For path-dependent function f and constant c,<br>δ<sub>η</sub>(c·f)[q] = c·δ<sub>η</sub>f[q]<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 480. (1.25(<br>todo: add impostor?
Let F be a path-independent function and g be a path-dependent function.<br>Consider the following statement:<br><br>δ<sub>η</sub>h[q] = (DF ∘ g[q])·δ<sub>η</sub>g[q]<br><br>where h[q] = F ∘ g[q]<br><br>Prove or give a counterexample.<br>	true. mstudy pg 480.<br><br>todo: add counterexample<br>
Let f be a path-dependent function. Consider the following statement:<br><br>Dδ<sub>η</sub>f[q] = δ<sub>η</sub>g[q]<br><br>where g[q] = D(f[q])<br><br>Prove or give a counterexample.<br>	mstudy pg 480
If a path-dependent function f is stationary on a path q, what can be said of the variations of f on q?<br>	δ<sub>η</sub>f[q] = 0<br><br>mstudy pg 480/481<br>
What are the first three components of δ<sub>η</sub>Γ[q] ?<br>	mstudy pg 482
What is a harmonic oscillator?<br><br>The Langrangian for a harmonic oscillator is <br>L(t,x,v)=(1/2)mv<sup>2</sup> - (1/2)kx<sup>2</sup><br><br>What are the lagrange equations in general?<br>What do the lagrange equations tell us about the harmonic oscillator?	pg 483/484
Give the full syntax of types and expressions for λ<sub>→</sub><sup>?</sup>.<br>	mstudy pg 959
Should the following program be accepted or rejected by λ<sub>→</sub><sup>?</sup>'s type checker? Why or why not?<br><br>((λ (x : number) (succ x)) #t)	reject. duh.<br><br>mstudy pg 959
Should the following program be accepted or rejected by λ<sub>→</sub><sup>?</sup>'s type checker? Why or why not?<br><br>((λ (x) (succ x)) #t)	Accept. Because bool is consistent with ?. int is also consistent with ?.<br><br>mstudy pg 959<br>
What does it mean for two partial functions to be <i>consistent</i>? <br>How is this relevant to gradual typing?<br>	mstudy pg  960<br>
Trees can be represented as partial functions from _________ to ________.<br><br>Fill in the blanks.	mstudy pg 960
Give the four judgment rules for type consistency in λ<sub>→</sub><sup>?</sup>.	mstudy pg 960<br>
Is consistency an equality relation? Is it an order relation? Why or why not?	Consistency is not an equality relation because it is not transistive.<br>It is not an order relation because it is symmetric.<br><br>mstudy pg 960
Give the typing rules for λ<sub>→</sub><sup>?</sup>.<br>	mstudy pg 960
Is λ<sub>→</sub><sup>?</sup> less expressive than the untyped lambda calculus? Why or why not?<br><br>	no. we can translate from λ to λ<sub>→</sub><sup>?</sup>.<br>mstudy pg 960<br>
How do fully-annotated λ<sub>→</sub><sup>?</sup> terms and their types relate to λ<sub>→</sub> terms and their types?	pg 960
What is the ⊑ relation on partial functions, and how do its properties compare with <:? Why not use ⊑ instead of ~ for consistency?<br>	pg 961 (bottom right paragraph)<br>
Give the typing rules for extending λ<sub>→</sub><sup>?</sup> with references.<br><br>	mstudy pg 962<br>
Do reference types have a compatibility rule for consistency, in which τ ~ σ => ref τ ~ ref σ?<br>Justify this rule or give a counterexample showing why it is unsound.<br>	pg 962
The runtime semantics for λ<sub>→</sub><sup>?</sup> are defined in two steps. What are these two steps?	mstudy pg 962<br>
What does the syntactic form <τ> e denote?<br>	mstudy pg 962
What do judgments of the form Γ ⊢ e ⇒ e' : τ denote?<br><br>Give the rules for var, const, and lambda	pg 962
What do judgments of the form Γ ⊢ e ⇒ e' : τ denote?<br><br>Give the three rules for applications.<br><br>	mstudy pg 963
Give the TCast typing rule for λ<sub>→</sub><sup>⟨τ⟩</sup>	mstudy pg 963
What lemmas do we need to prove about cast insertion and cast insertion's effect on fully annotated lambda terms?<br><br>	mstudy pg 963<br><br>lemmas 3 and 4<br>
Explain the differences between values, simple values, errors, and results in λ<sub>→</sub><sup>⟨τ⟩</sup>.<br><br>	pg 964<br><br>make sure you understand the role of simple values: <?> s<br>
Give the casting evaluation rules of λ<sub>→</sub><sup>⟨τ⟩</sup>	pg 965
Give the functions and constants evaluation rules of λ<sub>→</sub><sup>⟨τ⟩</sup>	mstudy pg 965
Give λ<sub>→</sub><sup>⟨τ⟩</sup>'s evaluation rules for errors.<br>	mstudy pg 965
Perform cast insertion and evaluation on the following term:<br><br>((λ (x) (succ x)) #t)	mstudy pg 964<br>
Perform cast insertion and evaluation on the following term<br><br>((λ (f : ? → number) (f 1))<br>(λ (x : number) (succ x)))<br>	mstudy pg 964<br>
State the "soundness of evaluation" lemma for λ<sub>→</sub><sup>?</sup>.<br><br><br>	mstudy pg 966<br>
D&P Exercise 4.2, mstudy pg 53 (left page)	<br>
Give the definition of a boolean lattice.<br>	mstudy pg 47<br>
Let L be a Boolean lattice. Consider the following statement:<br><br>0' = 1 and 1' = 0<br><br>Prove or give a counterexample.<br>	mstudy pg 47
Let L be a Boolean lattice. Consider the following statement:<br><br>a'' = a     for all a ∈ L<br><br>Prove or give a counterexample.<br>	mstudy pg 47
Let L be a Boolean lattice. Consider the following statement:<br><br>de Morgan's laws hold:   <br><br>for all a,b ∈ L, <br><br>(a ∨ b)' = a' ∧ b'<br>and (a ∧ b)' = a' ∨ b'<br><br>Prove or give a counterexample.<br>	mstudy pg 47
Let L be a boolean lattice. Consider the following statement:<br><br>a ∧ b = (a' ∨ b')' <br>and <br>a ∨ b = (a' ∧ b')'<br><br>for all a,b ∈ L.<br><br>Prove or give a counterexample.	mstudy pg 47<br>
Let L be a boolean lattice. Consider the following statement:<br><br>a ∧ b' = 0    if and only if    a ≤ b for all a,b ∈ L.<br><br>Prov or give a counterexample.<br><br>	mstudy pg 47 (right pane, lemma 4.15)
Let L be a boolean lattice. Consider the following statement:<br><br>a ∧ b' = 0    if and only if    a = b <br><br>for all a,b ∈ L.<br><br>Prov or give a counterexample.<br><br>	IMPOSTOR<br><br>mstudy pg 47 (right pane, lemma 4.15)
Give the definition of a boolean algebra.<br><br>	mstudy pg 48<br>
Let f : B → C, where B and C are Boolean algebras. Consider the following statement:<br><br>Assume f is a lattice homomorphism. Then the following are equivalent:<br><br>(a) f(0) = 0 and f(1) = 1<br>(b) f(a') = (f(a))' for all a ∈ B.<br><br>Prove or give a counterexample.<br> 	mstudy pg 48<br>
Let f : B → C, where B and C are Boolean algebras. Consider the following statement:<br><br>If f preserves ' then f preserves ∨ if and only if f preserves ∧.<br><br>Prove or give a counterexample.<br>	mstudy pg 48 (left page)<br><br>TODO: add impostor?<br>
<br>Let X be a set. Consider the following collection:<br><br>{ A ⊆ X | A is finite or X \ A is finite }<br><br>Is this collection a boolean algebra? Why or why not?<br>	of course it is you dodo. mstudy pg 48 (right page)
Let x,y ∈ R<sup>n</sup> and a ∈ R<br><br>Consider the following statement:<br><br>|x| ≥ 0, and |x| = 0 iff x = 0<br><br>Prove or give a counterexample.<br>	ms pg 993
Let x,y ∈ R<sup>n</sup> and a ∈ R<br><br>Consider the following statement:<br><br><$$>|\sum_{i=1}^nx^iy^i| \leq |x| \cdot |y|</$$><br>and equality holds iff x and y are linearly dependent<br><br>Prove or give a counterexample.<br>	pg 993<br>
Let x,y ∈ R<sup>n</sup> and a ∈ R<br><br>Consider the following statement:<br><br>|x + y| ≤ |x| + |y|<br><br>Prove or give a counterexample.<br>	pg 993
Let x,y ∈ R<sup>n</sup> and a ∈ R<br><br>Consider the following statement:<br><br>|ax| ≤ |a|·|x|<br><br>Prove or give a counterexample.<br>	ms pg 993<br>
Let x, x<sub>1</sub>, x<sub>2</sub> and y, y<sub>1</sub>,y<sub>2</sub> be vectors in R<sup>n</sup> and a ∈ R.<br><br>Consider the following statement:<br><br>⟨x,x⟩ ≥ 0, and ⟨x,x⟩ = 0 iff x = 0<br><br>Prove or give a counterexample.<br>	pg 993<br>
State and prove the polarization identity for the inner product on R<sup>N</sup>.<br><br>	ms pg 994
prb 1-1 <br><br>ms pg 995	<br>
prb 1-2<br><br>ms pg 995	<br>
prb 1-3<br><br>ms pg 995	<br>
prb 1-4<br><br>ms pg 995	<br>
prb 1-5<br><br>ms pg 995	<br>
prb 1-6<br><br>ms pg 995	<br>
prb 1-7<br><br>ms pg 995	<br>
prb 1-8<br><br>ms pg 995	<br>
prb 1-9<br><br>ms pg 996	<br>
prb 1-10<br><br>ms pg 996	<br>
prb 1-11<br><br>ms pg 996	<br>
prb 1-12<br><br>ms pg 996	<br>
prb 1-13<br><br>ms pg 996	<br>
Give the definition of a <i>closed rectangle</i> in R<sup>n</sup>. Also, give the definition of an <i>open rectangle<i> in R<sup>n</sup>.<br>	mstudy pg 996
What does it mean for a set to be open?	mstudy pg 996
What does it mean for a set to be closed?	mstudy pg 996
If A ⊆ R<sup>n</sup>, give the definition of the <i>interior</i>, <i>exterior</i>, and <i>boundary</i> of A.<br>	mstudy pg 997
Give the definition of an <i>open cover</i>.	ms pg 998
What does it mean for a set in R<sup>n</sup> to be <i>compact</i>?	ms pg 998
Consider the following statement:<br><br>The closed interval [a,b] is compact.<br><br>Prove or give a counterexample.<br>	true. pg 998
Consider the following statement:<br><br>The closed interval (a,b) is compact.<br><br>Prove or give a counterexample.<br>	IMPOSTOR<br><br>pg 998
Consider the following statement:<br><br>If B is compact and O is an open cover of {x} × B, then there is an open set U ⊆ R<sup>n</sup> containing x such that U × B is covered by a finite number of sets in O.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 999.<br><br>TODO: add impostor<br>
Consider the following statement: <br><br>If A ⊆ R<sup>n</sup> and B ⊆ R<sup>n</sup> are compact, then A × B ⊆ R<sup>n+m</sup> is compact.<br><br>Prove or give a counterexample.<br>	ms pg 1000<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>A<sub>1</sub> × ... × A<sub>k</sub> is compact if each A<sub>i</sub> is. In particular, a closed rectangle is compact.<br><br>Prove or give a counterexample.<br>	ms pg 1000<br>TODO: add impostor<br>
Consider the following statement:<br><br>A closed bounded subset of R<sup>n</sup> is compact.<br><br>Prove or give a counterexample.<br>	ms pg 1001<br>TODO: add impostor<br>
What is the difference between latent and manifest contracts?	ms pg 1138
What is the manifest analogue of latent function contracts?	casts between function types<br><br>ms pg 1138
What does ⟨R<sub>1</sub> → R<sub>2</sub> ⇒ S<sub>1</sub> → S<sub>2</sub>⟩<sup>l</sup> f mean? Why have only one blame label?	ms pg 1139, top-left paragraph
Explain the difference between lax and picky contract checking.	ms pg 1139 (bottom left)<br>
Explain and draw the axis of blame.	ms pg 1139 figure 1
What is an "abusive" contract? How are these relevant to the axis of blame?<br>	ms pg 1139 (right col)
Give the term typing rules of λ<sub>C</sub>.	mstudy pg 1140
In λ<sub>c</sub>, what is the operational behavior and meaning of the contract term ⟨c⟩<sup>l,l'</sup>?	ms pg 1140 (make sure to mention both E_CCheck and E_CDecomp)<br>
Give the operational semanics of λ<sub>C</sub>.	ms pg 1140
Give the contract typing rules for λ<sub>C</sub>.<br>	ms pg 1140
Give the syntax for λ<sub>H</sub>.	ms pg 1141
Give the operational semantics for λ<sub>H</sub>.	ms pg 1141<br>
Give typing rules for λ<sub>H<sub>.	ms pg 1142
Give subtyping rules for λ<sub>H</sub>.	ms pg 1142
Give the ⊢ s<sub>1</sub> ⊃ s<sub>2</sub> rule for λ<sub>H</sub>. What is the purpose of this rule?	ms pg 1142
Give the type well-formedness rules for λ<sub>H</sub>.<br>	pg 1142<br>
Why is checking the full internal language for λ<sub>H</sub> undecidable?	they claim that removing active active checks recovers decidability, but this doesn't take T-Sub into account. But I understand what they are saying. Statically, we can ensure that T-Sub isn't need by including casts in the right places.<br><br>ms pg 1141 (right above "the language λ<sub>H</sub>")
In one sentence, what are the functions φ and ψ?<br>	pg 1142 (bottom-right)<br>
How does Φ translate the contract: ⟨ {x:Int | nonzero x} ↦ {y:Int | pos y} ⟩<sup>l,l'</sup> ?	ms pg 1142/1143<br>
What is "bulletproofing", and why is it overkill for base types?	pg 1142 (bottom-right)<br>
Both Φ and Ψ preserve behavior in the strong sense. What is meant by this?	pg 1143, right above "the dependent languages"<br>
What changes are necessary to contract & context syntax and operational semantics for going from normal λ<sub>C</sub> to dependent?	pg 1143, figure 9<br>
What changes are necessary to typing rules for going from normal λ<sub>C</sub> to dependent?	pg 1143, figure 9<br><br>
Why are the soundness proof between Greenberg's paper and Knowles's paper fundamentally different?<br>	footnote on pg 1143<br>
Give the changes needed for type syntax and operational semantics to adapt λ<sub>H</sub> from non-dependent to dependent function types.<br>	<br>ms pg 1144, figure 10
Give the changes needed for tping rules to adapt λ<sub>H</sub> from non-dependent to dependent function types.<br>	pg 1144, figure 10
What changes are needed to the implication rule to adapt λ<sub>H</sub> from non-dependent to dependent refinements?<br>	pg 1144<br>
Give the changes needed for type well-fromedness rules to adapt λ<sub>H</sub> from non-dependent to dependent function types.	pg 1144, figure 10<br>
Give the changes needed for subtyping rules to adapt λ<sub>H</sub> from non-dependent to dependent function types.	ms pg 1144, figure 10
Give the two closing substitution formation rules for dependent λ<sub>H</sub>.<br>	pg 1144, figure 10<br>
Give the denotational semantics for types and kinds of dependent λ<sub>H</sub>.<br>	pg 1144, figure 11
Give the three semantics judgments for dependent λ<sub>H</sub>, including their definitions. Explain the need for these.<br>	ms pg 1144<br>
Explain the asymmetry for dependent λ<sub>H</sub>'s cast decomposition operational semantics between codomain types. 	pg 1144, bottom-left paragraph
State the strong normalization theorem for dependent λ<sub>H</sub>.<br><br>	ms pg 1144<br>
State the <i>semantics type soundness</i> theorem.<br>	pg 1145<br>
What useful result do we get when we combine syntactic type soundness with strong normalization?	ms pg 1145 (right above <b>exact translations</b>)<br>
What does {x:B | t} ~<sup>l,l'</sup> {x:B | s} : B mean?<br>	It means (t,s) a member of the term correspondence logical relation at base-type B.<br><br>pg 1145 figure 12<br><br>
Why does Φ need to translate <i>derivations</i> of well-formedness and well-typedness rather than translating types and terms directly?<br><br>	pg 1145, section 5.1<br>
Why are abusive contracts well-typed in λ<sub>C</sub>, but their naive translations into λ<sub>H</sub> ill-typed? What can be done to solve this?	pg 1145, top of left column<br>
Why can't we have ty<sub>H</sub>(sqrt) = x:{x:Float| x >= 0} -> {y:Float| |y*y - x| < eps}?<br>	pg 1145, right column
What are the <i>result correspondence</i> and <i>term correspondence</i> relations for? Give their definitions.<br>	ms pg 1145, figure 12<br><br>
What is the contract/type correspondence for? Give its definition.<br>	ms pg 1145, figure 13<br>
What does the Γ ⊨ δ semantic judgment denote? Give its definition.<br> 	pg 1145, figure 13
Give the term translations for Φ.	ms pg 1146, fig 14<br>
Give the type translations for Φ.	ms pg 1146, figure 14
Give the context translations for Φ.	ms pg 1146, figure 14
Give the term translations for ψ.	ms pg 1146, figure 15<br>
Give the type-to-contract translations for ψ.	ms pg 1146<br>
What is the contract/cast correspondence? Give its definition.	ms pg 1146, figure 16 (note that it is incorrectly labeled as a contract / type correspondence)<br>
State (and prove?) the behavioral correspondence theorem for Φ.	pg 1146, thm 5.1
State (and prove?) type preservation for Φ.<br>	ms pg 1146, thm 5.2<br>
State and prove the type preservation theorem for Φ.	<br>
State (and prove?) behavioral correspondence for ψ.	ms pg 1146, thm 5.3<br>
State and prove type preservation for ψ.<br>	ms pg 1146<br>
Give the logical relation for the blame-inexact correspondence for Φ from lax λ<sub>C</sub>.<br>	pg 1147, figure 17<br>
Give the logical relation for the blame inexact correspondence for Ψ into picky λ<sub>C</sub>.<br><br>	pg 1147, figure 18
State and explain the extra casts lemma.<br><br>	ms pg 1147
State and explain the inexact behavioral correspondence for Φ.<br>	pg 1147, thm 6.2
State inexact type preservation for Φ.	ms pg 1147, thm 6.3
Under the following definitions:<br><br>c = f :(x :{x :Int | true} → {y:Int | nonzero y}) → {z :Int | f 0 = 0}<br><br>S<sub>1</sub> = x :{x :Int | true} → {y:Int | nonzero y}<br><br>S = Φ(∅ ⊢<sup>l,l</sup><sub>c</sub>   c : (Int → Int) → Int) <br>= f :S<sub>1</sub> → {z :Int | ( ⟨S<sub>1</sub> ⇒ ⌈S<sub>1</sub>⌉⟩<sup>l</sup> f ) 0 = 0}.<br><br>What is the difference in operational semantics between ⟨c⟩<sup>l,l'</sup> (λf. 0) (λx. 0)<br>and the operational semantics of its translation under Φ?<br>	pg 1147, top of right column<br>TODO: add other example just below<br>
State the extra contracts lemma.<br>	ms pg 1147, lemma 6.4 (bottom-right)
State the inexact behavioral correspondence theorem for Ψ.<br>	ms pg 1147, thm 6.5<br>
State the inexact type preservation theorem for Ψ.<br>	ms pg 1147, thm 6.6
Give an example of a λ<sub>H</sub> term reducing to a value when its translation by Ψ reduces to blame.<br> 	ms pg 1148 (top-left, above "restricted calculi")<br>
Give the definition of a <i>topological space</i>.<br>	mstudy pg 138<br>
Give the definition of a <i>topology</i>.	mstudy pg 138<br>
Give the general topological definition of an <i>open set</i>.<br>	mstudy pg 138
Give an example from R<sup>1</sup> demonstrating why the definition of topological spaces requires closure only under finite intersections.<br>	mstudy pg 138
What is the general topological definition of a <i>closed set</i>?<br>	a set is closed iff it is the complement of an open set<br><br>mstudy pg 138<br>
What is the general topological definition of a <i>connected set</i>?<br>	mstudy pg 139<br>
What is the general topological definition of a <i>connected</i> set?	a set X is connected if its only clopen subsets are the empty set and X itself.<br>mstudy pg 139<br>
What is the definition of a <i>subspace</i> of a topological space?<br>	mstudy pg 139 (left)
If T is a topology on a set X, what does it mean for a family S of subsets of X to be a <i>basis</i> for T? What does it mean for a family S of subsets of X to be a <i>subbasis</i> for T?	mstudy pg 139 (left)
What does it mean, in the general topological sense, for a function to be <i>continuous</i>?<br>	mstudy pg 139
What is a homeomorphism?	mstudy pg 139 (left)<br>
What does it mean for a topological space to be <i>Hausdorff</i>?	remember the mnemonic "housed off"<br>mstudy pg 139 (left)
If Y is a subset of a topological space, what does it mean for Y to be <i>compact</i>?<br>	mstudy pg 139
Let (X;T) be a compact Hausdorff space.<br><br>Consider the following statement:<br><br>A subset Y of X is compact if and only if it is closed.<br><br>Prove or give a counterexample.	true. mstudy pg 139(right) Lemma A7 (i)<br><br>TODO: add impostor<br><br>
Let (X; T) be a compact Hausdorff space. Let f : X → X' be a continuous map, where (X';T') is any topological space.<br><br>Consider the following statement:<br><br>f(X) is a compact subset of X'.<br><br>Prove or give a counterexample.<br>	yo this is actually pretty tough and isn't even contained in the text<br><br>Wait... maybe it's not that tough. Here is an answer I came up with on the train:<br><br>Let O be an open cover of f(X).<br>f-1(O) is an open cover of X.<br>there is therefore a finite subcover M of f-1(O)<br>f(M) is therefore a finite subcover of O<br><br>true. mstudy pg 139 (bottom right) <br>Lemma A7 (ii)<br><br>TODO: add impostor<br>
Let (X; T) be a compact Hausdorff space. Let f : X → X' be a continuous map, where (X';T') is any topological space.<br><br>Consider the following statement:<br><br>If (X'; T') is a Hausdorff and f : X → X' is bijective, then f is a homeomorphism.<br><br>Prove or give a counterexample.<br>	true mstudy pg 139 (bottom right)<br>Lemma A7 (ii)<br><br>TODO: add impostor<br>
Let (X; T) be a compact Hausdorff space. Let V be a closed subset of X and {x}∩V=∅.<br><br>Consider the following statement.<br><br>There exist disjoint open sets W<sub>1</sub> and W<sub>2</sub> such that x ∈ W<sub>1</sub> and V ⊆ W<sub>2</sub>.<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 139 (bottom right)<br>lemma A8 (i)<br><br>TODO: add impostor.<br>
Let (X; T) be a compact Hausdorff space.<br><br>Consider the following statement.<br><br>Let V<sub>1</sub> and V<sub>2</sub> be disjoint subsets of X. Then there exist disjoint open sets U<sub>1</sub> and U<sub>2</sub> such that V<sub>i</sub> ⊆ U<sub>i</sub> for i = 1,2.<br><br>Prove or give a counterexample.	true. mstudy pg 139 (bottom right)<br>lemma A8 (ii)<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>Let (X;T) be a compact Hausdorff space. Then the following conditions are equivalent:<br>i.) X is finite<br>ii.) every subset of X is open (that is, T is discrete)<br>iii.) every subset of X is clopen<br><br>Prove or give a counterexample.	true. mstudy pg 140<br>lemma A9<br><br>TODO: add impostor<br>
Let (X;T) be a topological space and S a subbasis for T.<br><br>Consider the following statement:<br><br>X is compact if every open cover of X by members of S has a finite subcover.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 140<br>Lemma A10<br><br>TODO: add impostor
What topped intersection structure does topology's closure operator have an intimate connection to and why?<br>	mstudy pdf pg 73<br>
Let P be an poset. Give the definition of a <i>closure</i> operator on P.<br>	pdf pg 73 (bottom right)
What does it mean for an element of a poset to be closed?	mstudy pdf pg 74 (top left)
If P is a poset, what does P<sub>c</sub> denote?<br>	The set of all closed elements of P.<br><br>mstudy pdf pg 74 (top left)
If P = ⟨P(X), ⊆⟩ for some set X, what does it mean for C to be a closure <i>on</i> X?<br>	it means C : P(X) → P(X)<br>pdf pg 74
Let c be a closure on a  poset P.<br><br>Consider the following statement:<br><br>P<sub>c</sub> = {c(x) | x ∈ P} and P<sub>c</sub> contains the top element of P when it exists.<br><br>Prove or give a counterexample.	true. mstudy pg 74 (left). Proposition 7.2<br><br>TODO: add counterexample.<br>
Let c be a closure operator on a complete lattice P.<br><br>Consider the following statement:<br><br>For any x ∈ P, <br><$$>c(x) = \bigwedge_P\{y \in P_{c} | x \leq y \}</$$><br><br>Prove or give a counterexample.	true. mstudy pg 74 (left). Proposition 7.2 (ii) (a)<br><br>TODO: add impostor<br>
Let c be a closure operator on a complete lattice P. Consider the following statement:<br><br>P<sub>c</sub> is a complete lattice, under the order inherited from P, such that for every subset S of P<sub>c</sub>,<br><$$>\bigwedge_{P_c}S = \bigwedge_{P}S~~\mbox{and}~~\bigvee_{P_c}S = c(\bigvee_{P}S)</$$><br><br>Prove or give a counterexample.	true. mstudy pg 74. prop 7.2 (ii) (b)<br><br>TODO: add impostor<br>
Let C be a closure operator on a set X. Consider the following statement:<br><br>The family L<sub>C</sub> = { A ⊆ X | C(A) = A } of closed subsets of X is a topped ∩-structure and so forms a complete lattice, ordered by inclusion.<br><br>Prove or give a counterexample.<br>	true. mstudy pdf pg 74 (right). theorem 7.3<br><br>TODO: add impostor<br>
Give a topped ∩-structure on X, how do we define the closure operator C<sub>L</sub> on X?<br>	true. mstudy pg 74. bottom of theorem 7.3.<br><br>TODO: add impostor<br>
Describe the relationship between the topped ∩-structure L<sub>C</sub> and the closure operator C<sub>L</sub>.<br>	mstudy pdf pg 74 (right). remark 7.4<br>
Give three examples of topped intersection structures and their corresponding closure operators.<br>	mstudy pdf pg 74/75 (example 7.5)<br>
Let G be a group and H = {H<sub>i</sub>}<sub>i ∈ I</sub> be a non-empty family of subgroups of G with the property that, for each i<sub>1</sub>, i<sub>2</sub> ∈ I, there exists k ∈ I such that H<sub>i<sub>1</sub></sub> ∪ H<sub>i<sub>2</sub></sub> ⊆ H<sub>k</sub>.<br><br>Consider the following statement:<br><br>Define H := ∪H<sub>i ∈ I</sub>. Then H is a subgroup.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 75 (left). example 7.6<br><br>TODO: add impostor<br>
What does it mean for a non-empty subset S of a poset P to be <i>directed</i>?<br>	mstudy pg 75 (bottom left/top right)<br>
What is the difference between the ⨆ and ⋁ notations for joins?<br><br>	mstudy pdf pg 75.<br>
Give three examples of directed subsets of posets.	mstudy pg 75, examples 7.8<br><br>
What is a directed union?	mstudy pg 75 (bottom right)<br>
Consider the following statement:<br><br>Define the subset D = {A<sub>i</sub>}<sub>i ∈ I</sub> of P(X) to be directed. Let Y = {y<sub>1</sub>,...,y<sub>n</sub>} be a finite subset of ∪A<sub>i</sub>. Then there exists A<sub>k</sub> ∈ D such that Y ⊆ A<sub>k</sub>.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 76 (above definition 7.10)<br><br>TODO: add impostor<br>
What does it mean for a family L of P(X) to be <i>closed under directed unions</i>?	mstudy pg 76. definition 7.10.<br>(ones that aren't probably involve infinite directed families)<br>
What is an algebraic ∩-structure?<br>	mstudy pdf pg 76. definition 7.10<br>
What does it mean for a closure operator C on a set X to be algebraic?<br>	mstudy pg 76<br>
Let C be aclosure operator on a set X. Consider the following statement:<br><br><br>If for all A ⊆ X, C(A) ⊆ ∪{C(B) | B ⊆ A and B is finite}<br><br>then C is an <i>algebraic</i> closure operator<br><br>Prove or give a counterexample.	mstudy pg 76 (bottom left)<br><br>see side note after definition 7.12<br>
What is the closure operator corresponding to the ∩-structure Sub G? Is this closure operator algebraic? Why or why not?<br><br>	mstudy pdf pg 76 (right). example 7.13
Let C be a closure operator on a set X and let L<sub>C</sub> be the associated topped ∩-structure. Consider the following statement:<br><br>The following are equivalent:<br>(i) C is an algebraic closure operator<br>(ii) for every directed family {A<sub>i</sub>}<sub>i ∈ I</sub> of subsets of X,<br><$$>C(\bigcup_{i \in I} A_i) = \bigcup_{i \in I} C(A_i)</$$><br>(iii) L<sub>C</sub> is an algebraic ∩-structure.<br><br>Prove or give a counterexample.	mstudy pdf pg 76 (right). Theorem 7.14.<br><br>TODO: add impostor<br>
If L is a complete lattice and k ∈ L, what does it mean for k to be <i>finite</i>?<br>	mstudy pdf pg 152. definition 7.15 (i)<br>
If L is a complete lattice and k ∈ L, what does it mean for k to be <i>compact</i>?<br>	mstudy pg 77. Definition 7.15 (ii)<br><br>
Consider the following statement:<br><br>Let L be a complete lattice. Then F(L) = K(L). Further, k<sub>1</sub> ∨ k<sub>2</sub> ∈ F(L) whenever k<sub>1</sub> and k<sub>2</sub> ∈ F(L).<br><br>Prove or give a counterexample.<br><br><br>	true. mstudy pg 77. Lemma 7.16<br><br>TODO: add impostor<br>
For each complete lattice L, give the set F(L) (i.e. the set of finite elements of L)<br>(choose three. you don't have to do all)<br><br>P(X)     - the powerset of X<br>O(P)    - the downsets of poset P<br>Sub G - the subgroups of G<br>Sub V  - the subspaces of vector space V<br>[0,1]     - the closed interval of real numbers [0,1] using numeric comparison as an order<br><br><br>	mstudy pdf pg 77(right side). table 7.1
What does it mean for a complete lattice L to be <i>algebraic</i>?<br>	mstudy pg 77 (bottom right), definition 7.18<br>
Let C be an algebraic closure operator on X and L<sub>C</sub> the associated topped algebraic ∩-structure.<br><br>Consider the following statement:<br><br>L<sub>C</sub> is an algebraic lattice in which an element A is finite (equivalently, compact) if and only if A = C(Y) for some finite set Y ⊆ X.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 77 (bottom right). Lemma 7.19<br>
Consider the following statement:<br><br>Let L be a topped algebraic ∩-structure. Then L is an algebraic lattice.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 78 (left). theorem 7.20 (i)<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>Let L be an algebraic lattice and define D<sub>a</sub> := { k ∈ K(L) | k ≤ a } for each a ∈ L. Then L := { D<sub>a</sub> | a ∈ L } is a topped algebraic ∩-structure isomorphic to L.<br><br>Prove or give a counterexample.<br>	true. mstudy pdf pg 78 (left). Theorem 7.20<br><br>TODO: add impostor.
Give three examples of algebraic lattices.<br>	mstudy pg 78 (top right)<br>
In concept analysis, what intuitively is a concept?	mstudy pg 33(right)<br>
How can an order be defined on the concepts of a context?	mstudy page 34 (left)<br>
Give the formal definition of a context as a triple.	mstudy pg 34 (left)<br>
If (G,M,I) is a context, g ∈ G, and m ∈ M, what does gIm denote?	mstudy page 34 top/left
If (G,M,I) is a context, A ⊆ G and B ⊆ M, what do A' and B' denote?<br>	mstudy pg 34<br>
Give the formal definition of a <i>concept</i> of a context (G,M,I).	mstudy pg 34 (right)
Let (G,M,I) be a context.<br><br>Consider the following statement:<br><br>a subset A of G is the extent of some concept iff A'' = A<br><br>prove or give a counterexample<br>	true mstudy pg 34 (r)<br><br>TODO: add impostor<br>
If (G,M,I) is a context, what does B(G,M,I) denote?<br>	mstudy pg 34 (right)<br>
Describe the computer science idea of a non-determinstic transition system in the language of formal concept analysis.<br>	mstudy pg 34 (right) (above 3.4)<br><br>
Let (A<sub>1</sub>, B<sub>1</sub>) and (A<sub>2</sub>,B<sub>2</sub>) be concepts. <br><br>Consider the following statement:<br><br>A<sub>1</sub> ⊆ A<sub>2</sub> iff B<sub>1</sub> ⊇ B<sub>2</sub><br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 34 (right)<br>
In concept analysis, if (G,M,I) is a context, what do B<sub>G</sub> and B<sub>M</sub> denote?<br>	mstudy pg 34 (top left)<br>
Let (G,M,I) be a context and let A ⊆ G and B ⊆ M.<br><br>Consider the following statement:<br><br>A ⊆ A'' and B ⊆ B''<br><br>Prove or give a counterexample.	mstudy pg 34 (lemma 3.5)<br>
Let (G,M,I) be a context and let A ⊆ G and B ⊆ M.<br><br>Consider the following statement:<br><br>A ⊇ A'' and B ⊇ B''<br><br>Prove or give a counterexample.	IMPOSTOR!<br><br>mstudy pg 34 (lemma 3.5)<br>
Let (G,M,I) be a context and let A<sub>1</sub>, A<sub>2</sub> ⊆ G and B<sub>1</sub>,B<sub>2</sub> ⊆ M.<br><br>Consider the following statement:<br><br>A<sub>1</sub> ⊆ A<sub>2</sub> ⇒ A<sub>1</sub>' ⊇ A<sub>2</sub>'<br>and<br>B<sub>1</sub> ⊆ B<sub>2</sub> ⇒ B<sub>1</sub>' ⊇ B<sub>2</sub>'<br><br>Prove or give a counterexample.<br>	mstudy pg 35 (lemma 3.5) P2<br>
Let (G,M,I) be a context and let A<sub>1</sub>, A<sub>2</sub> ⊆ G and B<sub>1</sub>,B<sub>2</sub> ⊆ M.<br><br>Consider the following statement:<br><br>A<sub>1</sub> ⊆ A<sub>2</sub> ⇒ A<sub>1</sub>' ⊇ A<sub>2</sub>'<br>and<br>B<sub>1</sub> ⊇ B<sub>2</sub> ⇒ B<sub>1</sub>' ⊇ B<sub>2</sub>'<br><br>Prove or give a counterexample.<br>	IMPOSTOR!<br><br>mstudy pg 34 (lemma 3.4 P2)<br>
Let (G,M,I) be a context, A ⊆ G and B ⊆ M.<br><br>Consider the following statement:<br><br>A' = A''' and B = B'''<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 34 (lemma 4.5 P3)<br>
Let (G,M,I) be a context, A ⊆ G and B ⊆ M.<br><br>Consider the following statement:<br><br>A = A'' and B = B''<br><br>Prove or give a counterexample.<br>	IMPOSTOR!<br><br>mstudy pg 35 (lemma 3.5 P3)<br>
Let (G,M,I) be a context, A<sub>j</sub> ⊆ G, and B<sub>j</sub> ⊆ M.<br><br>Consider the following statement:<br><br><$$>(\bigcup_{j \in J} A_{j})' = \bigcap_{j \in J}A'_{j}~~\mbox{and}~~(\bigcup_{j \in J} B_j)' = \bigcap_{j \in J} B'_{j}</$$><br><br>Prove or give a counterexample.	true. mstudy pg 35 (lemma 3.5)<br> <br>TODO: add impostor<br>
Let (G,M,I) be a context and let A ⊆ G, B ⊆ M.<br><br>Consider the following statement:<br><br>A ⊆ B' iff A' ⊇ B<br><br>Prove or give a counterexample.	true. mstudy pg 35 (lemma 3.5 P5)<br><br>TODO: add impostor<br>
Let (G,M,I) be a context. Then ⟨B(G,M,I); ≤⟩ is a complete lattice.<br><br>Given expressions for its meet and join. Prove that it is a complete lattice.<br><br><br>	mstudy pg 35 (right). Proposition 3.6<br>
In concept analysis, what is an <i>attribute extent</i>?<br>	mstudy pg 36 (top left)<br>
With respect to a context (G,M,I), what are the mappings γ and μ in concept analysis? What is their relation to I?<br><br>Prove your answer.<br><br>	mstudy pg 36 (left)<br>
Let (G,M,I) be a context and L=B(G,M,I) the associated complete lattice of concepts. <br><br>Define γ(g) = ({g}'', {g}') and μ(m) = ({m}', {m}'')<br><br>Consider the following statement:<br><br>The mappings γ : G → L and μ : M → L are such that the set γ(G) is join-dense in L, the set μ(M) is meet-dense in L, and gIm is equivalent to γ(G) ≤ μ(m) for each g ∈ G and m ∈ M.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 36. theorem 3.8<br><br>TODO: add impostor<br>
Let L be a complete lattice, let G and M be sets and assume that there exist mappings γ : G → L and  μ : M → L such that γ(G) is join-dense in L and μ(M) is meet-dense in L. Define I by gIm ⇔ γ(g) = μ(m) for all g ∈ G and m ∈ M. <br><br>Consider the following statement:<br><br>L is isomorphic to B(G,M,I).<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 36 (right)<br><br>TODO: add counterexample<br>
What is the fundamental theorem of concept analysis?<br>	mstudy pg 36 (theorems 3.8 and 3.9)<br>
Suppose we have a complete lattice L. We know of no other properties of L. L is isomorphic to at least one concept lattice. Explain why this is so.<br>	L ≅ B(L,L,≤)<br><br>This follows from the fundamental theorem of concept lattices. Specifically, theorem 3.9, letting μ and γ both be the identity map.<br><br>mstudy pg 37<br>
Consider the complete lattice P(X). Are there concept lattices that are isomorphic to P(X) besides B(L,L,≤)?<br><br>Is there one in which G=X and M=X?<br>Is there one in which G=X and M=P(X)?<br><br>In what ways are thes more or less compelling than B(L,L,≤)?<br><br>	mstudy pg 37 (right side, example 2)<br><br>
Is M<sub>n</sub> isomorphic to some concept lattice? Which one?	mstudy pg 37 (right side)<br>example 3<br>
Given an ordered set P, can we find a concept lattice that is isomorphic to O(P)?<br>	mstudy pg 37 (right side, example 4)<br><br>
Consider the following statement:<br><br>the set of all open sets in R<sup>k</sup> is a topped intersection structure.<br><br>Prove or disprove.	IMPOSTOR<br><br>open sets are not closed under intersection
What is a Galois connection?	pg 78 (right)
Give two examples of Galois connections.<br>	mstudy pg 79 (7.24)<br>
How do preconditions and postconditions manifest in the formalsm of non-deterministic-programs-as-concept-lattices?<br>	mstudy pg 80 (left page)<br>
What is a <i>predicate transformer</i> and how does it fit into the framework of lattice theory and Galois connections?<br>	mstudy pg 80 (wp and R<sub>·</sub> are polar maps)<br>
Consider the following statement:<br><br>(<sup>▹</sup>, <sup>◃</sup>) is a Galois connection iff (<sup>◃</sup>,<sup>▹</sup>) is<br><br>Prove or give a counterexample.	true. mstudy pdf pg 80 (top right)<br>
Assume (▹,◃) is a Galois connection between posets P and Q. Let p ∈ P and q ∈ Q.<br><br>Consider the following statement:<br><br>p ≤ p<sup>▹◃</sup> and q<sup>◃ ▹</sup> ≤ q<br><br>Prove or give a counterexample.	true. mstudy pg 80. lemma 7.26 (Gal1)<br>
Assume (▹,◃) is a Galois connection between posets P and Q. Let p<sub>1</sub>,p<sub>2</sub> ∈ P and q<sub>1</sub>,q<sub>2</sub> ∈ Q.<br><br>Consider the following statement:<br><br>p<sub>1</sub> ≤ p<sub>2</sub> ⇒ p<sub>1</sub><sup>▹</sup> ≤ p<sub>2</sub><sup>▹</sup> <br><br>and <br><br>q<sub>1</sub> ≤ q<sub>2</sub> ⇒ q<sub>1</sub><sup>◃</sup> ≤ q<sub>2</sub><sup>◃</sup><br><br>Prove or give a counterexample.	true. mstudy pg 80. lemma 7.26 (Gal2)<br><br>TODO: add impostor<br>
Assume (▹,◃) is a Galois connection between posets P and Q. Let p ∈ P and q ∈ Q.<br><br>Consider the following statement:<br><br>p<sup>▹</sup> = p<sup>▹◃ ▹</sup><br><br>and<br><br>q<sup>◃</sup> = q<sup>◃ ▹◃</sup><br><br>Prove or give a counterexample.<br>	mstudy pg 80 (right side) Lemma 7.26 (Gal3)<br><br>TODO: add impostor
<br>Let P and Q be posets and ▹ : P  → Q and ◃ : Q → P be maps betweeen them. <br><br>Consider the following statment:<br><br>If for all p,p<sub>1</sub>,p<sub>2</sub> ∈ P and all q,q<sub>1</sub>,q<sub>2</sub> ∈ Q,<br><br>p ≤ p<sup>▹◃</sup>, q ≤ q<sup>◃ ▹</sup>,<br>p<sub>1</sub> ≤ p<sub>2</sub> ⇒ p<sub>1</sub><sup>▹</sup> ≤ p<sub>2</sub><sup>▹</sup>, and<br>q<sub>1</sub> ≤ q<sub>2</sub> ⇒ q<sub>1</sub><sup>◃</sup> ≤ q<sub>2</sub><sup>◃</sup><br><br>Then (▹,◃) is a Galois connection. <br><br>Prove or give a counterexample.<br><br> <br><br>	Impostor! should be q ≥ q<sup>◃ ▹</sup>.<br><br>mstudy pg 80 (right)<br>
List the three basic properties of Galois connections.<br>	mstudy pg 80 (right page)<br>
Let (▹,◃) be a Galois connection between ordered sets P and Q<sup>∂</sup>.<br><br>Consider the following statement:<br><br>These maps<br>▹◃  : P  → P<br>◃ ▹ : Q → Q<br>are closure operators<br><br>Prove or give a counterexample.<br>	mstudy pg 81. 7.27 (i)<br>
Let (▹,◃) be a Galois connection between ordered sets P and Q<sup>∂</sup>.<br><br>Consider the following statement:<br><br>Let <br>P<sub>c</sub> := { p ∈ P | p<sup>▹◃</sup>=p }<br>and<br>Q<sub>k</sub> := { q ∈ Q | q<sup>◃ ▹</sup>=q }<br><br>Then <br><sup>▹</sup> : P<sub>c</sub> → Q<sub>k</sub><sup>∂</sup> and <br>and<br><sup>◃</sup> :  Q<sub>k</sub><sup>∂</sup> → P<sub>c</sub> <br><br>are mutually inverse isomorphisms<br> <br>Prove or give a counterexample.	mstudy pg 81 (7.27)<br><br>NOTE: Q<sup>∂</sup> is used rather than Q for part (i)<br><br>TODO: add impostor<br>
Let (▹, ◃) be a Galois connection. Consider the following statement:<br><br>▹ preserves existing joins, and<br>◃ preserves existing meets<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 81 (right page). proposition 7.31<br>
Let (▹, ◃) be a Galois connection. Consider the following statement:<br><br>▹ preserves existing meets, and<br>◃ preserves existing joins<br><br>Prove or give a counterexample.<br><br>	IMPOSTOR!<br><br>mstudy pg 81 (right page) <br>proposition 7.31<br>
Let P and Q be ordered sets and φ : P → Q an order preserving map.<br><br>Consider the following statement:<br><br>The following are equivalent:<br><br>(i)  there exists an order-preserving map φ<sup>♯</sup> such that both <br>φ<sup>♯</sup>∘φ ≥ id<sub>P</sub> and φ∘φ<sup>♯</sup> ≤ id<sub>Q</sub> <br>(note that the above map comparisons are pointwise: ∀x∈P. φ<sup>♯</sup>∘φ(x) ≥ x, etc.)<br><br>(ii) for each q ∈ Q there exists a (necessarily unique) s ∈ P such that φ<sup>-1</sup>(↓q) =↓s.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 81 (bottom right). lemma 7.32<br><br>TODO: add impostor<br>
Let P and Q be ordered sets and φ : P → Q a map. Assume P is a complete lattice.<br><br>Consider the following statement:<br><br>φ preserves arbitrary joins if and only if φ possesses an upper adjoint φ<sup>♯</sup> (that is, (φ,φ<sup>♯</sup>) is a Galois Connection)<br><br>Prove or give a counterexample.<br>	mstudy pg 82 (left page). prop 7.34 (i)<br>
Let P and Q be ordered sets and φ : P → Q a map. Assume Q is a complete lattice.<br><br>Consider the following statement:<br><br>φ preserves arbitrary meets if and only if φ possesses an lower adjoint φ<sup>♭</sup> (that is, (φ<sup>♭</sup>,φ) is a Galois Connection)<br><br>Prove or give a counterexample.<br>	true. mstudy pg 82 (bottom left). prop 7.34 (ii)<br><br><br>TODO: add impostor<br>
What is a <i>Type 2 Turing Machine</i>? Give both the definitions of a type-2 turing machine's structure and semantics.<br><br>	mstudy pg 1155<br>
What does it mean for a function to be type-2 computable? What does it mean for a sequence to be computable?<br><br>	note: a sequence is just a sequence of elements of the alphabet<br><br>mstudy pg 1156<br>
What is the <i>Generalized Church-Turing Thesis</i>?<br>	mstudy pg 1157<br>
Draw a flowchart for a type-2 turing machine that computes the function f described in example 2 on pg 1158.<br>	mstudy pg 1159<br>
Is the problem of dividing a real number by 3 computable? Why or why not?<br><br>	mstudy pg 1159 example 3<br>
Is the problem of multiplying real numbers by 3 computable? Why or why not?<br>	mstudy pg 1159/1160 example 4<br>
Let Σ := {0,1} and define f :⊆ Σ<sup>ω</sup> → Σ<sup>*</sup> by<br><br>f(p) := <br>  0 if p = 0<sup>ω</sup><br>  1 otherwise<br><br>Is f computable? Why or why not?<br>      	mstudy pg 1160 example 5<br>
How does the power of type-2 turing machines with 1-way output compare to that of type-2 turing machines with 2-way output?<br><br>	mstudy pg 1160 (see paragraph above example 5)<br>
Let Σ := {0,1} and define f :⊆ Σ<sup>ω</sup> → Σ<sup>*</sup> by<br>f(0<sup>ω</sup>)    := div<br>f(0<sup>i</sup>1p) := 0<sup>i</sup> for all i ∈ ω and p ∈ Σ<sup>ω</sup><br><br>Does this function have a computable proper extension? If so, give the extension along with a recognizer. Otherwise, explain why no such extension exists.<br><br><br>	nope<br>mstudy pg 1161, example 6 
What is the <i>finiteness property</i> for computable functions?<br>	mstudy pg 1161
What is the <i>Cantor topology</i> on Σ<sup>ω</sup>? What is the <i>Cantor space over Σ</i>?<br>	mstudy pg 1161<br>definition 2.4<br>
What is the <i>discrete topology</i> over Σ<sup>ω</sup>?<br>	mstudy pg 1161<br>definition 2.4<br>
When is a set U⊆Σ<sup>ω</sup> τ<sub>d</sub>-open?	mstudy pg 1161 near bottom
How can the Cantor topology τ<sub>d</sub> be generated from a metric space? What is the point set, and what is the metric function?	mstudy pg 1161 near bottom
Consider the following statement:<br><br>Every computable function f :⊆ Y<sub>1</sub> × ... × Y<sub>K → Y<sub>0</sub> is continuous.<br><br>Prove or give a counterexample.<br>	(note that the product topology is used for the input, where the discrete topology is used for finite components of the input and the Cantor topology is used for infinite components)<br><br>true. mstudy pg 1162<br>
Consider the following statement:<br><br>All continuous functions are computable.<br><br>Prove or give a counterexample.<br>	COUNTEREXAMPLE.<br><br>mstudy pg 1162, example 7<br>
Let f :⊆ Y<sub>1</sub> → Y<sub>2</sub> and g :⊆ Y<sub>2</sub> Y<sub>3</sub> (Y<sub>1</sub>,Y<sub>2</sub>,Y<sub>3</sub> ∈ {Σ<sup>*</sup>, Σ<sup>ω</sup>}) be computable.<br><br>Consider the following statement:<br><br>If (Y<sub>2</sub>,Y<sub>3</sub>) ≠ (Σ<sup>ω</sup>, Σ<sup>*</sup>), then gf is computable.<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 1163<br>
Let f :⊆ Y<sub>1</sub> → Y<sub>2</sub> and g :⊆ Y<sub>2</sub> Y<sub>3</sub> (Y<sub>1</sub>,Y<sub>2</sub>,Y<sub>3</sub> ∈ {Σ<sup>*</sup>, Σ<sup>ω</sup>}) be computable.<br><br>Consider the following statement:<br><br>If (Y<sub>2</sub>,Y<sub>3</sub>) = (Σ<sup>ω</sup>, Σ<sup>*</sup>), then gf has a computable extension h such that dom(gf) ∩ dom(f) = dom(h) ∩ dom(f).<br><br>Prove or give a counterexample.<br><br>	true, mstudy pg 1163<br>
Let f :⊆ Y<sub>1</sub> → Y<sub>2</sub> and g :⊆ Y<sub>2</sub> Y<sub>3</sub> (Y<sub>1</sub>,Y<sub>2</sub>,Y<sub>3</sub> ∈ {Σ<sup>*</sup>, Σ<sup>ω</sup>}) be computable.<br><br>Consider the following statement:<br><br>If (Y<sub>2</sub>,Y<sub>3</sub>) = (Σ<sup>ω</sup>, Σ<sup>*</sup>), then gf is computable.<br><br>Prove or give a counterexample.<br><br>	IMPOSTOR.<br><br>mstudy pg 1163, thm 2.6<br>
In computable analysis, what is a <i>computable element</i>?<br>	A word y is a computable element iff the 0-place function f : {()} → Y<sub>0</sub> with f() = y is computable.<br><br>mstudy pg 1156<br>
In computable analysis, what does it mean for a set X ⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> to be <i>recursively enumerable</i> (r. e.)?	mstudy pg 1163/1164<br>def 2.7 (1)<br>
Let U ⊆ W ⊆ Y<sub>1</sub> × ... × Y<sub>k</sub>.<br><br>What does it mean for U to be r.e. in W?<br>	mstudy pg 1163/1164<br>def 2.7 (2)<br>
Let U ⊆ W ⊆ Y<sub>1</sub> × ... × Y<sub>k</sub>.<br><br>What does it mean for U to be <i>recursive (or decidable)</i> in W?<br>	mstudy pg 1163/1164 <br>def 2.7 (3)<br>
Under what conditions is a set X ⊆ Σ<sup>ω</sup> recursively enumerable?<br>	X = AΣ<sup>ω</sup> for some r.e. (even some recursive) subset A ⊆ Σ<sup>*</sup><br><br>mstudy pg 1164 
Consider the following statement:<br><br>U is recursive in W iff there is a computable function f :⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> → Σ<sup>*</sup> with W  ⊆ dom(f) and U = f<sup>-1</sup>{ε} ∩ W.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1164.
Consider the following statement:<br><br>U is recursive in Σ<sup>ω</sup> iff U = AΣ<sup>ω</sup> for some finite set A ⊆ Σ<sup>*</sup>.<br><br>Prove or give a counterexample.<br>	mstudy pg 1164<br>
Give the definition, from computable analysis, of a <i>naming system</i> of a set M.<br>	mstudy pg 1164, def 2.8 (see paragraph above def 2.8 for motivating info)<br>
Let functions γ :⊆ Y → M and γ' :⊆ Y' → M' with Y,Y' ∈ {Σ<sup>*</sup>, Σ<sup>ω</sup>}. What does it mean for γ to be reducible to γ'? What does it mean for γ and γ' to be equivalent?<br><br>What does it mean for γ to be topologically reducible to γ'? What does it mean for γ and γ' to be topologically equivalent?<br>	mstudy pg 1164, def 2.8 (2)<br>
Let ν<sub>1</sub> and ν<sub>2</sub> be notations of Σ<sup>*</sup>.<br>Let A ⊆ Σ<sup>*</sup> be r.e. and not recursive. <br>Define ν<sub>1</sub>(w) = w for all w ∈ Σ<sup>*</sup>.<br><br>Define ν<sub>2</sub>(0w) = w if w ∈ A,<br> ν<sub>2</sub>(1w) = w if ¬(w ∈ A)<br>and  ν<sub>2</sub>(x) = div otherwise<br><br>Consider the following statement:<br><br>ν<sub>2</sub> ≤ ν<sub>1</sub><br><br>Prove or give a counterexample.<br> 	mstudy pg 1165<br>
Let ν<sub>1</sub> and ν<sub>2</sub> be notations of Σ<sup>*</sup>.<br>Let A ⊆ Σ<sup>*</sup> be r.e. and not recursive. <br>Define ν<sub>1</sub>(w) = w for all w ∈ Σ<sup>*</sup>.<br><br>Define ν<sub>2</sub>(0w) = w if w ∈ A,<br> ν<sub>2</sub>(1w) = w if ¬(w ∈ A)<br>and  ν<sub>2</sub>(x) = div otherwise<br><br>Consider the following statement:<br><br>ν<sub>1</sub> ≤ ν<sub>2</sub><br><br>Prove or give a disprove.	false! mstudy  pg 1165<br>
What does the acronym CPO stand for? <br>What does it mean for a poset to be a <i>CPO</i>?<br><br>	<br>mstudy pg 88 (right)<br>
What does it mean for an ordered set to be a <i>pre-CPO</i>?<br>	mstudy pg 88 (right)<br>
Consider the following statement:<br><br>Any poset satisfying (ACC) is a pre-CPO.<br><br>Prove or give a counterexample.	<br>true mstudy pg 88, example 8.2 (1)<br>
Consider the following statement:<br><br>Any poset satisfying (DCC) is a pre-CPO.<br><br>Prove or give a counterexample.	IMPOSTOR<br><br>mstudy pg 88 (right) example 8.2 (1)<br>
Consider the following statement:<br><br>Any complete lattice is a CPO.<br><br>Prove or give a counterexample.	<br>true. mstudy pg 89 top/left<br>
Consider the following statement:<br><br>Any algebraic ∩-structure is a CPO.<br><br>Prove or give a counterexample.	<br>true. mstudy pg 89 (top/left).<br>
Let P be a CPO. What is a <i>sub-CPO</i> of P?<br>	mstudy pg 89 (left). def 8.3
Consider the poset X = {S ⊆ N | S is finite or S = N} under the inclusion order.<br><br>Is X a CPO? Is it a sub-CPO of P(N)?<br>	mstudy pg 89 (left) section 8.3<br><br>
If P and Q are posets, each with a ⊥ element, then their disjoint union fails to have a ⊥. Name and define two union-like operators that produce a poset with ⊥ from two input posets which both have ⊥s.<br>	mstudy pg 89 (8.4)<br>
Let P and Q be CPOs and let S be a set<br><br>Consider the following statement:<br><br>Each of P ⊕<sub>⊥</sub> Q,  and P ⊕<sub>∨</sub> Q, and P × Q are CPOs.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 89 (right)<br>
Let P be a CPO and let S be a set.<br><br>Consider the following statement:<br><br>The power (S → P) of P is a CPO in which directed joins are calculated pointwise. More precisely, if {φ<sub>i</sub>}<sub>i ∈ I</sub> is a directed subset of (S → P), then, for each s in S, the set {φ<sub>i</sub>(s)}<sub>i ∈ I</sub> is a directed subset of P and (⨆<sub>i∈I</sub>φ<sub>i</sub>)(s) = ⨆<sub>i∈I</sub> φ<sub>i</sub>(s).<br><br>Prove or give a counterexample.<br>	true. mstudy pg 89 (right) lemma 8.5 (ii)<br>
What is the analogy of a calculus' <i>limit</i> in lattice theory?<br>	Both meets and joins could be considered analogous, but join is the canonical choice.<br>This is described on mstudy pg 89 (right) in section 8.6.<br>
If P and Q are pre-CPOs, what does it mean for a map φ : P → Q to be <i>continuous</i>?<br>	mstudy pg 89 (right) section 8.6<br>
If P and Q are CPOs and φ : P → Q is a continuous map, is it necessary that φ(⊥<sub>P</sub>) = ⊥<sub>Q</sub>?<br><br>	no, because the empty set is not directed by the definition of directed<br><br>mstudy pg 89 (right), section 8.6<br>
What does it mean for a continuous map to be <i>strict</i>?<br>	It means that it maps between CPOs P and Q, and φ(⊥<sub>P</sub>)=⊥<sub>Q</sub>.<br><br>mstudy pg 89<br>
Let P and Q be CPOs and φ a map from P to Q. Suppose D is a directed subset of P and φ is order-preserving.<br><br>Consider the following statement:<br><br>φ(D) is a directed subset of Q and ⨆φ(D) ≤ φ(⨆D)<br><br>Prove or give a counterexample.<br><br><br> <br><br>	mstudy pg 89/90 (lemma 8.7 (i))<br>
Let P and Q be CPOs and φ an order-preserving map from P to Q. <br><br>Consider the following statement:<br><br>For any ascending chain x<sub>0</sub> ≤ x<sub>1</sub> ≤ ... in P,<br>⨆<sub>n ≥ 0</sub> φ(x<sub>n</sub>) ≤ φ( ⨆<sub>n ≥ 0</sub> x<sub>n</sub>)<br>φ(D) is a directed subset of Q and ⨆φ(D) ≤ φ(⨆D)<br><br>Prove or give a counterexample.<br>	true. mstudy pg 89/90 (lemma 8.7 (i))<br>
Let P and Q be CPOs and φ a map from P to Q. <br><br>Consider the following statement:<br><br>If φ(D) is directed and ⨆φ(D) ≤ φ(⨆D) for every directed set D in P, then φ is order preserving.<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 90 (top/left) lemma 8.7 (ii)<br>
Consider the following statement:<br><br>Every continuous map between CPOs is order preserving.<br><br>Prove or give a counterexample.<br>	true.<br><br>this is a straightforward corollary of lemma 8.7 (ii) on mstudy pg 90.<br>
Consider the following statement:<br><br>Every order-preserving map between CPOs is continuous.<br><br>Prove or give a counterexample.<br>	IMPOSTOR.<br><br>This may have been confused for the true statement "every continuous map between CPOs is order preserving".<br><br>See example 8.8 (1) on mstudy pg 90 for a counterexample.<br><br>Here's another example. f : N union {infty} -> {0,1}<br>f(n) = 0 for all natural numbers 0<br>f(infty) = 1<br><br>
Let S be an ordered set and E ⊆ S. What does it mean for E to be <i>bounded above</i>?<br>	There is some element of S which greater or equal to every element of E. Doy.<br><br>pg 1242
Let S be an ordered set and E ⊆ S.<br><br>Give the definitions of sup E and inf E.<br>	sup E is:<br><br>an α ∈ S such that<br>(i) α is an upper bound of E<br>(ii) If γ < α then γ is not an upper bound of E.<br> <br>inf E is similar<br><br>pg 1243
What does it mean for an ordered set S to have the least-upper-bound property?<br>	If E ⊆ S, E is not empty, and E is bounded above, then sup E exists in S.<br><br>pg 1243
Consider the following statement:<br><br>Suppose S is an ordered set with the least-upper-bound property, B ⊆ S, B is not empty, and B is bounded below. Let L be the set of all lower bounds of B. Then α = sup L exists in S, and α = inf B. In particular, inf B exists in S.<br><br>Prove or give a counterexample.<br>	true. pg 1244<br><br>TODO: add impostor
Give the definition of a field. (Bonus points for the abstract algebra version.)<br><br><br>	mstudy pg 1244/1245<br>
Give the definition of an <i>ordered field</i>.	A field F which is also an <i>ordered set</i> such that<br><br>(i) x + y < x + z if x,y,z ∈ F and y < z<br>(ii) xy > 0 if x ∈ F, y ∈ F, x > 0, and y > 0<br><br>pg 1246, def 1.17
Let F be an ordered field and x,y,z ∈ F. Consider the following statement:<br><br>If x > 0 and y < z then xy < xz.<br><br>Prove or give a counterexample.	pdf pg 17<br>true pg 1247, prop 1.18
Let F be an ordered field and x,y,z ∈ F. Consider the following statement:<br><br>If x > 0, then -x < 0, and vice versa.<br><br>Prove or give a counterexample.	true. pg 1247, prop 1.18<br><br>todo: ADD IMPOSTOR
Let F be an ordered field and x,y,z ∈ F. Consider the following statement:<br><br>If 0 < x < y then 0 < 1/y < 1/x.<br><br>Prove or give a counterexample.	pg 127, prop 1.18<br><br>todo: ADD AN IMPOSTOR
Consider the following statement:<br><br>If x ∈ R, y ∈ R, and x > 0, then there is a positive integer n such that nx > y.<br><br>Prove or give a counterexample.<br>	true. Thm 1.20 a.) pg 1248<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>If x ∈ R, y ∈ R, and x < y, then there exists a p ∈ Q such that x < p < y.<br><br>Prove or give a counterexample.<br>	true. thm 1.20 b) , pg 1248<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>If a and b are positive real numbers and n is a positive integer, then<br><br>(ab)<sup>1/n</sup> = a<sup>1/n</sup>b<sup>1/n</sup><br><br>Prove or give a counterexample.	true. pg 1250.<br><br>TODO: add impostor
Give the definition of the extended real number system.	pg 1250/1251
Give the definition of the complex numbers. You know they're a field, but prove three field properties of complex numbers just for fun. Also, prove i<sup>2</sup>=-1 -- should be trivial.<br>	pg 1251,1252,1253
Consider the following statement:<br><br>Every infinite subset of a countable set is countable.<br><br>Prove or give a counterexample.<br>	<br>true.  Thm 2.8, pg 1265.<br><br>TODO: add impostor
Consider the following statement:<br><br>Let {E<sub>n</sub>}, n = 1, 2, 3, ..., be a sequence of countable sets, and put <br><$$>S = \bigcup_{n=1}^{\infty}E_n</$$><br>Then S is countable.<br><br>Prove or give a counterexample.<br>	true pdf pg 1268, thm 2.12<br>TODO: add impostor<br>
Let A be a countable set, and let B<sub>n</sub> be the set of all n-tuples (a<sub>1</sub>,...,a<sub>n</sub>), where a<sub>k</sub> ∈ A (k = 1,...,n), and the elements a<sub>1</sub>,...,a<sub>n</sub> need not be distinct. Then B<sub>n</sub> is countable.	pdf pg 1268
Consider the following statement:<br><br>The set of all rational numbers is countable.<br><br>Prove or give a counterexample.	pg 1269
Consider the following statement:<br><br>Let A be the set of all sequences whose elements are the digits 0 and 1. This set A is uncountable.<br><br>Prove or give a counterexample.	true. thm 2.14, pg 1269<br><br>TODO: add impostor<br>
Give the definition of a <i>metric space</i>. 	A set X, whose elements we shall call <i>points</i>, is said to be a <i>metric space</i> if with any two points p and q of X there is associated a real number d(p,q), called the distance from p to q, such that<br><br>(a) d(p,q) > 0 if p ≠ q; d(p, p)  0;<br>(b) d(p,q) = d(q,p)<br>(c) d(p,q) ≤ d(p,r) + d(r, q), for any r ∈ X<br><br>pg 1269
What does it mean for a subset of R<sup>k</sup> to be convex?	pdf pg 1270, near bottom<br>
Give the definition of a <i>neighbordhood</i> of a point.	A neighborhood of p is a set N<sub>r</sub>(p) consisting of all q such that d(p,q) < r, for some r > 0. The number r is called the radius of N<sub>r</sub>(p).<br><br>pg 1271
Give the definition of a limit point of E, where E is a subset of a metric space.	(b) pdf pg 1271
Give the definition of an <i>isolated</i> point of E, where E is a subset of a metric space.	(c) pg 1271
If E is a subset of a metric space, what does it mean for E to be <i>closed</i>?	every limit point of E is a point of E.<br><br>(d) pg 1271
What does it mean for a point p to be an <i>interior</i> point of E, where E is a subset of a metric space?	There is a neighborhood N of p such that N is a subset of E.<br>(e) pg 1271
Let E be a subset of a metric space. What does it mean for E to be <i>open</i>?	every point of E is an interior point of E<br><br>pg 1271, (f)
Let E be a subset of a metric space. What does it mean for E to be <i>perfect</i>?<br>	E is closed and every point of E is a limit point of E.
Let E be a subset of a metric space X. What does it mean for E to be <i>bounded</i>?	there is a real number M and a point q ∈  X such that d(p,q) < M for al p ∈ E.<br>pg 1271, i
Let E be a subset of a metric space X. What does it mean for E to be dense in X?	E is dense in X if every point of X is a limit point of E, or a point of E (or both).<br><br>pg 1271, (j)
Consider the following statement:<br><br>If p is a limit point of a set E, then every neighborhood of p contains infinitely many points of E.<br><br>Prove or give a counterexample.	true. pg 1271<br><br>TODO: add impostor
Prove Thm 2.22, pg 1272	<br>
Consider the following statement:<br><br>A set E is open if and only if its complement is closed.<br><br>Prove or give a counterexample.	true. thm 2.23, pg 1273<br><br>TODO: add impostor
Consider the following statement:<br><br>For any collection {G<sub>α</sub>} of open sets ∪<sub>α</sub>G<sub>α</sub> is open.<br><br>Prove or give a counterexample.	true. pdf pg 1273<br>
Consider the following statement:<br><br>For any collection {F<sub>α</sub>} of closed sets, ∩<sub>α</sub>F<sub>α</sub> is closed.<br><br>Prove or give a counterexample.<br>	true. pg 1273, thm 2.24 b
Consider the following statement:<br><br>For any collection {F<sub>α</sub>} of closed sets ∩<sub>α</sub>F<sub>α</sub> is closed.<br><br>Prove or give a counterexample.	TODO: add impostor<br><br>true<br>pdf pg 1273
Consider the following statement:<br><br>For any finite collection F<sub>1</sub>,...,F<sub>n</sub> of closed sets,  <$>\bigcup_{i=1}^{n}F_{i}</$> is closed. <br><br>Prove or give a counterexample.<br><br><br><br><br><br>	pdf pg 1273<br><br>TODO: add impostor<br>
Prove thm 2.27, pg 1274<br>	<br>
Prove Thm 2.28, pg 1274	<br>
Suppose E ⊆ Y ⊆ X, where X is a metric space. What does it mean for E to be open relative to Y?<br>	<br>E is open relative to Y if to each p ∈ E there is associated an r > 0 such that q ∈ E whenever d(p,q)<r and q ∈ Y.<br><br>remark 2.29, pg 1274
Suppose Y ⊆ X. <br><br>Consider the following statement:<br><br>A subset E of Y is open relative to Y if and only if E = Y ∩ G for some open subset G of X.<br><br>Prove or give a counterexample.	true. pg 1275<br><br>TODO: add impostor
Let E be a subset of a metric space X. What is an <i>open cover</i> of E?	A collection {G<sub>α</sub>} of open subsets of X such that E ⊆ ∪<sub>α</sub>G<sub>α</sub>.<br><br>pg 1275
What does it mean for a subset K of a metric space X to be <i>compact</i>?	A subset K of a metric space X is compact iff every open cover of K contains a finite subcover.<br><br>pg 1275
Give the definition of a <i>compact set</i>.	A subset K of a metric space X is said to be compact if every open cover of K contains a finite subcover.<br><br>pg 1275
Consider the following statement:<br><br>Suppose K ⊆ Y ⊆ X. Then K is compact relative to X if and only if K is compact relative to Y.<br><br>Prove or give a counterexample.<br><br>	True. thm 2.33, pg 37<br>pdf pg 1276<br><br>TODO: add impostor
Consider the following statement:<br><br>Compact subsets of metric spaces are closed.<br><br>Prove or give a counterexample.	true, thm 2.34, pg 1276<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>Closed subsets of compact sets are compact.<br><br>Prove or give a counterexample.<br>	true. thm 2.35, pg 1276<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>If F is closed and K is compact, then F ∩ K is compact.<br><br>Prove or give a counterexample.	true, pg 38<br>pdf pg 47<br>
Consider the following statement:<br><br>If {K<sub>α</sub>} is a collection of compact subsets of a metric space X such that the intersection of every finite subcollction of {K<sub>α</sub>} is nonempty, then ∩K<sub>α</sub> is nonempty.<br><br>prove or give a counterexample<br>	<br>true. thm 2.36, pg 1277<br><br>TODO: add impostor
Consider the following statement.<br><br>If E is an infinite subset of a compact set K, then E has a limit point in K.<br><br>Prove or give a counterexample.	true, thm 2.37, pg 38<br>pdf pg 47<br><br>
Consider the following statement:<br><br>If {I<sub>n</sub>} is a sequence of intervals in R<sup>1</sup>, such that I<sub>n</sub> ⊇ I<sub>n-1</sub> (n = 1, 2, 3, ....), then ∩<sup>∞</sup><sub>1</sub>I<sub>n</sub> is not empty.<br><br>Prove or give a counterexample.<br><br>	<br>true. thm 2.38, pg 1277<br><br><br>
Consider the following statement:<br><br>Let k be a positive integer. If {I<sub>n</sub>} is a sequence of k-cells such that I<sub>n</sub> ⊇ I<sub>n+1</sub>(n = 1,2,3, ...), then ∩<sub>1</sub><sup>∞</sup>I<sub>n</sub> is not empty.<br><br>Prove or give a counterexample.<br>	true. pg 1277<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>every k-cell is compact<br><br>prove or give a counterexample<br>	true. pg 1278<br><br>TODO: add impostor
Consider the following statement:<br><br>If a set E in R<sup>k</sup> has one of the following three properties, then it has the other two:<br><br>(a) E is closed and bounded<br>(b) E is compact<br>(c) Every infinite subset of E has a limit point in E<br><br>Prove or give a counterexample.<br>	true, mstudy pg 1279, thm 2.41<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>Every bounded infinite subset of R<sup>k</sup> has a limit point in R<sup>k</sup>.<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 1279, Thm 2.42<br><br><br>TODO: add impostor<br>
Consider the following statement:<br><br>Let P be a nonempty perfect set in R<sup>k</sup>. Then P is uncountable.<br><br>Prove or give a counterexample.<br>	true. thm 2.43, mstudy pg 1280<br><br>TODO: add impostor<br>
What does it mean for two subsets A and B of a metric space X to be <i>separated</i>? 	def 2.45, mstudy pg 1281
If X is a metric space, what does it mean for E ⊆ X to be <i>connected</i>?	E is <i>not</i> a union of two nonempty separated sets.<br><br>def 2.45, mstudy pg 1281
Consider the following statement:<br><br>A subset E of the real line R<sup>1</sup> is connected if and only if it has the following property: If x ∈ E, y ∈ E, and x < z < y, then z ∈ E.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1281<br><br>TODO: add a impostor<br>
What does it mean for a sequence {p<sub>n</sub>} in a metric space to <i>converge</i>?<br>	A sequence {p<sub>n</sub>} in a metric space X converges if there is a point p ∈ X with the following property: For every ε > 0 there is an integer N such that n ≥ N implies that d(p<sub>n</sub>,p) < ε. (Here d denotes the distance in X.)<br><br>In this case, we also say that{p<sub>n</sub>} converges to p, or that p is the limit of {p<sub>n</sub>}, and we write p<sub>n</sub>→p, or lim<sub>n→∞</sub>p<sub>n</sub>=p.<br><br>If {p<sub>n</sub>} does not coverge, it is said to <i>diverge</i>.<br><br>mstudy pg 1286<br>
Give the definition of the <i>range</i> of {p<sub>n</sub>}.	The set of all points p<sub>n</sub> (n = 1,2,3,...).<br><br>mstudy pg 1287
What does it mean for a sequence {p<sub>n</sub>} to be bounded?	It means that its range (i.e. the set of all of its points) is bounded.<br><br>mstudy pg 1287
Let {p<sub>n</sub>} be a sequence in a metric space X. <br><br>Consider the following statement:<br><br>{p<sub>n</sub>} converges to p ϵ X if and only if every neighborhood of p contains p<sub>n</sub> for all but finitely many n.<br><br>Prove or give a counterexample.<br>	true. pg 1287<br><br>
Let {p<sub>n</sub>} be a sequence in a metric space X. <br><br>Consider the following statement:<br><br>If p ϵ X, p' ϵ X, and if {p<sub>n</sub>} converges to p and to p', then p' = p.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1287.  them 3.2 b.<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>If E ⊆ X and if p is a limit point of E, then there is a sequence {p<sub>n</sub>} in E such that p = lim<sub>n→∞</sub>(p<sub>n</sub>).<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1287, thm 3.2 pt c.<br><br>TODO: add impostor<br>
Suppose {s<sub>n</sub>}, {t<sub>n</sub>} are complex sequences, and lim<sub>n→∞</sub>s<sub>n</sub> = s, lim<sub>n→∞</sub>t<sub>n</sub> = t. <br><br>Consider the followng statement:<br><br>lim<sub>n→∞</sub>(s<sub>n</sub> + t<sub>n</sub>) = s + t<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1288, thm 3.3, pg 49
Suppose {s<sub>n</sub>}, {t<sub>n</sub>} are complex sequences, and lim<sub>n→∞</sub>s<sub>n</sub> = s, lim<sub>n→∞</sub>t<sub>n</sub> = t. <br><br>Consider the followng statement:<br><br>lim<sub>n→∞</sub> c·s<sub>n</sub> = c·s, and lim<sub>n→∞</sub> (c + s<sub>n</sub>) = c + s, for any c;<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1288, thm 3.3, pt (b)<br><br>TODO: add impostor<br>
Suppose {s<sub>n</sub>}, {t<sub>n</sub>} are complex sequences, and lim<sub>n→∞</sub>s<sub>n</sub> = s, lim<sub>n→∞</sub>t<sub>n</sub> = t. <br><br>Consider the followng statement:<br><br>lim<sub>n→∞</sub>s<sub>n</sub>t<sub>n</sub>=st;<br><br>Prove or give a counterexample.<br>	true. thm 3.3 pt c, pg 1288.<br><br>TODO: add impostor<br>
Suppose {s<sub>n</sub>}, {t<sub>n</sub>} are complex sequences, and lim<sub>n→∞</sub>s<sub>n</sub> = s, lim<sub>n→∞</sub>t<sub>n</sub> = t. <br><br>Consider the followng statement:<br><br>lim<sub>n→∞</sub> (1/s<sub>n</sub>) = 1/s, provided s<sub>n</sub> ≠ 0 (n = 1, 2, 3, ...), and s ≠ 0.<br><br>Prove or give a counterexample.<br>	true. pg 1288, thm 3.3, (d).<br><br>TODO: add impostor<br>
Prove Thm 3.4, pg 1289<br>	<br>
Give the definition of a <i>subsequence</i> of a sequence.	Given a sequence {p<sub>n</sub>}, consider a sequence {n<sub>k</sub>} of positive integers, such that n<sub>1</sub> < n<sub>2</sub> < n<sub>3</sub> <  ⋯. Then the sequence {p<sub>n<sub>i</sub></sub>} is called a <i>subsequence</i> of {p<sub>n</sub>}. If {p<sub>n<sub>i</sub></sub>} converges, its imit is called a subsequential limit of {p<sub>n</sub>}.<br><br>pg 1290
What is a <i>subsequential limit</i> of a sequence?	Given a sequence {p<sub>n</sub>}, consider a sequence {n<sub>k</sub>} of positive integers, such that n<sub>1</sub> < n<sub>2</sub> < n<sub>3</sub> <  ⋯. Then the sequence {p<sub>n<sub>i</sub></sub>} is called a <i>subsequence</i> of {p<sub>n</sub>}. If {p<sub>n<sub>i</sub></sub>} converges, its imit is called a subsequential limit of {p<sub>n</sub>}.<br><br>pg 1290<br>
Prove thm 3.6 (a)<br><br>pg 1290<br>	<br>
Consider the following statement:<br><br>Every bounded sequence in R<sup>K</sup> contains a convergent subsequence.<br><br>Prove or give a counterexample.	true. pg 1290, thm 3.6 (b)<br>
Consider the following statement:<br><br>The subsequential limits of a sequence {P<sub>n</sub>} in a metric space X form a closed subset of X.<br><br>Prove or give a counterexample.	true. Thm 3.7, mstudy pg 1291<br>
Give the definition of <i>Cauchy sequence</i>	A sequence {p<sub>n</sub>} in a metric space X is said to be a <i>Cauchy sequence</i> if for every ε > 0 there is an integer N such that d(p<sub>n</sub>, p<sub>m</sub>) < ε if n ≥ N, and m ≥ N.<br><br>pg 1201
Let E be a nonempty subset of a metric space X. Give the definition of the <i>diameter</i> of E.<br>	Let E be a nonempty subset of a metric space X, and let S be the set of all real numbers of the form d(p,q), with p ϵ E and q ϵ E. The sup of S is called the <i>diameter</i> of E.<br><br>pg 1291,def 3.9
Prove Thm 3.10 a, pg 1292	<br>
Prove Thm 3.10 b.), pg 1292<br>	<br>
Consider the following statement:<br><br>In any metric space X, every convergent sequence is a Cauchy sequence.<br><br>Prove or give a counterexample.<br>	true. thm 3.11, pdf pg 1292
Consider the following statement:<br><br>If X is a compact metric space and if {p<sub>n</sub>} is a Cauchy sequence in X, then {p<sub>n</sub>} converges to some point in X.<br><br>Prove or give a counterexample.<br>	True. thm 3.11 b, pdf pg 1292<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>In R<sup>k</sup>, every Cauchy sequence converges.<br><br>Prove or give a counterexample.<br>	true. thm 3.11 (c), pg 1292<br><br>TODO: add impostor
What does it mean for a metric space X to be <i>complete</i>? 	Every Cauchy sequence in X converges.<br><br>def 3.12, pg 1293<br>
What does it mean for a sequence {s<sub>n</sub>} of real numbers to be <i>monotonically increasing</i>? <i>Monotonically decreasing</i>?<br>	1.) s<sub>n</sub> ≤ s<sub>n+1</sub> (n = 1,2,3,⋯)<br>2.) s<sub>n</sub> ≥ s<sub>n+1</sub> (n = 1,2,3,⋯)<br><br>def 3.13, pg 1294
Consider the following statement:<br><br>Suppose {s<sub>n</sub>} is monotonic. Then {s<sub>n</sub>} converges if and only if it is bounded.<br><br>Prove or give a counterexample.<br>	true. thm 3.14, pg 1294.<br><br>TODO: add impostor<br>
Let s<sub>n</sub> be a sequence of real numbers.<br><br>What does "s → + ∞" mean?<br>What about "s → - ∞"?	1.) For every real M there is an integer N such that n ≥ N implies s<sub>n</sub> ≥ M.<br><br>2.) For every real M there is an integer N such that n ≥ N implies s<sub>n</sub> ≤ M.<br><br>def 3.15, pg 1294<br>
<br>Give the definition of lim sup<sub>n → ∞</sub> s<sub>n</sub>.<br><br><br>Give the definition of lim inf<sub>n → ∞</sub> s<sub>n</sub>.	lim sup: the supremum of all subsequential limits of s<sub>n</sub>. <br>lim inf: the infimum of all subsequential limits of s<sub>n</sub>. <br><br>def 3.16, pg 1295
Consider the following statement:<br><br>Let {s<sub>n</sub>} be a sequence of real numbers. Let E be the set of all subsequential limits of {s<sub>n</sub>} and let s* be its lim sup.<br><br>s* ϵ E.<br><br>Prove or give a counterexample.<br>	true. thm 3.17 a. pg 1295
Consider the following statement:<br><br>Let {s<sub>n</sub>} be a sequence of real numbers. Let E be the set of all subsequential limits of {s<sub>n</sub>} and let s* be its lim sup.<br><br>If x > s*, there is an integer N such that n ≥ N implie s<sub>n</sub> < x.<br><br>Prove or give a counterexample.<br>	true. thm 3.17 b, pdf 1295<br><br>TODO: add impostor<br>
Let {p<sub>n</sub>} be a sequence in a metric space X. <br><br>Consider the following statement:<br><br>p ϵ X is a limit point of {p<sub>n</sub>} if and only if every neighborhood of p contains p<sub>n</sub> for all but finitely many n.<br><br>Prove or give a counterexample.<br>	impostor of theorem on pg 1287.<br><br>counterexample: a sequence which has one subsequence converging to 0 and another subsequence converging to 1.<br>
Consider the following statement:<br><br>The subsequential limits of a sequence {P<sub>n</sub>} in a metric space X form a open subset of X.<br><br>Prove or give a counterexample.	impostor! of thm 3.7, pg 1291<br><br>Unless {Pn} has no subsequential limits, this is not true.<br>Consider the constant sequence, for example.<br><br>
Consider the following statement:<br><br>If F is open and K is compact, then F ∩ K is compact.<br><br>Prove or give a counterexample.	IMPOSTOR!<br>of a theorem on pg 1277. This would be true if F were closed.<br>
Consider the following statement:<br><br>For any collection {F<sub>α</sub>} of closed sets,  ∪<sub>α</sub>F<sub>α</sub> is closed.<br><br>Prove or give a counterexample.<br>	impostor!<br><br>thm 2.24 (b), mstudy pg 1273<br>
Consider the following statement:<br><br>If p > 0, then <$>lim_{n \rightarrow \infty}{\frac{1}{n^p}}=0</$><br><br>Prove or give a counterexample.<br>	pdf pg 1296<br>TODO: add impostor
Consider the following statement:<br><br>If p > 0, then <$>lim_{n \rightarrow \infty}{\sqrt[n]{p}}=1}</$><br><br>Prove or give a counterexample.	true. pdf pg 1296<br>TODO: add impostor<br>
Consider the following statement:<br><br>If p > 0 and α is real, then <$>lim_{n \rightarrow \infty}\frac{n^\alpha}{(1+p)^n}=0</$><br><br>	pdf pg 1296<br>TODO: add counterexample.
Consider the following statement:<br><br>If |x| < 1, then <$>lim_{n \rightarrow \infty}x^n = 0</$><br><br>Prove or give a counterexample.<br>	pdf pg 1296<br>TODO: add impostor
Consider the following statement:<br><br>Σa<sub>n</sub> converges if and only if for every ε > 0 there is an integer N such that<br><$$>|\sum_{k=n}^{m}a_k| \leq \epsilon</$$><br>for all m ≥ n ≥ N.<br><br>Prove or give a counterexample.	IMPOSTOR: this is based on the cauchy covergence criterion, but that applies to R<sup>k</sup>, and not necessarily other metric spaces.<br><br>pdf pg 1298, thm 3.22<br>This is the cauchy convergence criterion for series convergence.<br>
Consider the following statement:<br><br>If Σa<sub>n</sub> converges, then lim<sub>n→∞</sub> a<sub>n</sub> = 0.<br><br>Prove or give a counterexample.	true. pdf pg 1299<br>TODO: add impostor<br>
Consider the following statement:<br><br>A series of nonnegative terms converges if and only if its partial sums form a bounded sequence.<br><br>Prove or give a counterexample.<br>	true<br>pdf pg 1299, thm 3.24<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>If |a<sub>n</sub>|  ≤ c<sub>n</sub> for n ≥ N<sub>0</sub>, where N<sub>0</sub> is some fixed integer, and if Σc<sub>n</sub> converges, then Σa<sub>n</sub> converges.<br><br>Prove or give a counterexample.<br><br>	true.<br>pdf pg 1299, theorem 3.25 a<br><br>TODO: add impostor
Consider the following statement:<br><br>If a<sub>n</sub> ≥ d<sub>n</sub> ≥ 0 for n ≥ N<sub>0</sub> and if Σd<sub>n</sub> diverges, then Σa<sub>n</sub> diverges.<br><br>Prove or give a counterexample.	true. pdf pg 1299, thm 3.25 b<br><br>TODO: add impostor<br>
Consider this series:<br><br><$$>\sum_{k=0}^{\infty}x^k</$$><br><br>Under what conditions does it converge? When it converges, what can be said about the value it converges to?<br>Prove your answer.<br>	pdf pg 1300, theorem 3.26<br>
Consider the following statement:<br><br>Suppose a<sub>1</sub> ≥ a<sub>2</sub> ≥ a<sub>3</sub> ≥ ... ≥ 0. Then the series <$>\sum_{n=1}^{\infty}a_n</$> converges if and only if the series<br><br><$$>\sum_{k=0}^{\infty}2^k a_{2^k} = a_1 + 2{a_2} + 4{a_4} + 8{a_8} + ...</$$><br><br>converges.<br><br>Prove or give a counterexample.<br>	true. pdf pg 1300.<br>TODO: add impostor<br>
Consider the following statement:<br><br><$>\sum \frac{1}{n^p}</$> converges if p > 1 and diverges if p ≤ 1.<br><br>Prove or give a counterexample.<br>	true. pdf pg 1301, thm 3.28<br><br>TODO: add impostor<br>
Give the definition of e as an infinite series. Prove the convergence of this series.<br><br>	pdf pg 1302<br>
Let Σa<sub>n</sub> be a series. Let α = <$>\limsup_{n \rightarrow \infty}{\sqrt[n]{|a_n|}}</$><br><br>Consider the following statement:<br><br>if α < 1, then Σa<sub>n</sub> converges<br>if α > 1, then Σa<sub>n</sub> diverges<br><br>Prove or give a counterexample.<br>	true. this is the ROOT TEST. pdf pg 1304, thm 3.33<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>The series Σa<sub>n</sub> converges if <$>\limsup_{n \rightarrow \infty}{|\frac{a_{n+1}}{a_n}| < 1</$><br><br>Prove or give a counterexample.	true. this is called the ratio test.<br><br>pdf pg 1305. thm 3.34. pt a.<br><br>TODO: add impostor
Consider the following statement:<br><br>The series Σa<sub>n</sub> diverges if <$>|\frac{a_{n+1}}{a_n}|</$> ≥ 1 for all n ≥ n<sub>0</sub>, where n<sub>0</sub> is some fixed integer.<br><br>Prove or give a counterexample.<br>	true. this is called the ratio test.<br><br>pdf pg 1305. thm 3.34 b.<br><br>TODO: add impostor<br>
What is a power series? What is the <i>circle of convergence</i> of a power series?<br>	pdf pg 1308
Consider the following statement:<br><br>Given the power series Σc<sub>n</sub>z<sup>n</sup>, put<br><$$>\alpha = \limsup_{n \rightarrow \infty}\sqrt[n]{|c_n|}</$$><br><$$>R = \frac{1}{\alpha}</$$><br><br>Then Σc<sub>n</sub>z<sup>n</sup> converges if |z| < R, and diverges if |z| > R.<br><br>Prove or give a counterexample.	true. pdf pg 1308. thm 3.39<br><br>TODO: add a counterexample
Find the convergence radius of the series Σn<sup>n</sup>z<sup>n</sup>.<br><br>Also, find the convergence radius of the series <$>\sum \frac{z^n}{n!}</$>.<br><br><br><br>	pdf pg 1308/1309
Find the convergence radius of the series Σz<sup>n</sup>. What happens if |z| is equal to the convergence radius?<br><br>Find the convergence radius of the series <$>\frac{z^n}{n}</$>. What happens to the series when |z| is equal to the convergence radius?	pdf pg 1309, (c) and (d) near top<br>note that z does not always diverge/converge when |z| = 1.<br>
What is the convergence radius of the series <$>\sum \frac{z^n}{n^2}</$>? What happens when |z| is equal to the convergence radius?<br>	this was not obvious to me. The first thing to notice is that when taking the nth rooth of 1/n^2, the root should intuitively drown out the n^2 as n goes to infinity. If n is greater than 1, then 1/n^2 is less than one. Taking the nth root of a quantity that is less than one should therefore yield a quantity that is closer to 1 than the expression inside the root.<br><br>This intuitive argument suggests that α = 1, and therefore R = 1.<br><br>We must prove that α = 1, however, rather than using an intuitive argument. I found no lemmas to help with this, so I carried out the proof manually.<br><br>First note that the elements of the sequence are bounded above by 1.<br><br>Then, for any  0 < ε < 1, we can take n > 1 / sqrt(1 - ε). This will guarantee that the nth root of (1/n^2) is within distance ε of 1. kewl.<br> <br>pdf pg 1309.<br>
Explain how "summation by parts" works. State and prove the key theorem that enables it. What is it used for?	pdf pg 1309
Suppose<br>(a) the partial sums A<sub>n</sub> of Σa<sub>n</sub> form a bounded sequence<br>(b) b<sub>0</sub> ≥ b<sub>1</sub> ≥ b<sub>2</sub> ≥ ...<br>(c) <$>\lim_{n \rightarrow \infty}b_n=0</$><br><br>Consider the following statement:<br><br>Σa<sub>n</sub>b<sub>n</sub> converges<br><br>Prove or give a counterexample.	true. pdf pg 1309<br><br>TODO: add impostor<br>
What is an alternating series? State and prove the key theorem behind the concept of alternating series.<br>	pdf pg 1310. theorem 3.43.<br>
Suppose the radius of convergence of Σc<sub>n</sub>z<sup>n</sup> is 1, and suppose c<sub>0</sub> ≥ c<sub>1</sub> ≥ c<sub>2</sub> ≥ ..., lim<sub>n→∞</sub> c<sub>n</sub> = 0. <br><br>Consider the following statement:<br><br>Σc<sub>n</sub>z<sup>n</sup> converges at every point on the circle |z| = 1, except possibly at z = 1.<br><br>Prove or give a counterexample.	true. pdf pg 1310.<br><br>TODO: add a counterexample.<br>
What does it mean for a series to be absolutely convergent? What is the significance of absolute convergence?	pdf pg 1310/1311
Consider the following statement:<br><br>If Σa<sub>n</sub> converges absolutely, then Σa<sub>n</sub> converges.<br><br>Prove or give a counterexample.<br>	true. pdf pg 1310/1311. <br><br>TODO: add impostor<br>
Give an example of a series that converges non-absolutely.	pdf pg 1311. remark 3.46<br>
Consider the following statement:<br><br>If Σa<sub>n</sub>=A, and Σb<sub>n</sub> = B, then Σ(a<sub>n</sub>+b<sub>n</sub>) = A + B, and Σca<sub>n</sub> = cA, for any fixed c.<br><br>Prove or give a counterexample.	true. pdf pg 1311.<br><br>TODO: add impostor<br>
Give the definition of the "Cauchy product" of two series. Explain the motivation behind this product.<br>	pdf pg 1312, definition 3.48<br>
Consider the following statement:<br><br>If {I<sub>n</sub>} is a sequence of closed intervals in R<sup>1</sup>, such that I<sub>n</sub> ⊇ I<sub>n+1</sub> (n = 1, 2, 3, ....), then ∩<sup>∞</sup><sub>1</sub>I<sub>n</sub> is not empty.<br><br>Prove or give a counterexample.<br><br>	true. <br>pdf pg 1277, 2.38<br>
Why are Cauchy sequences so important?	Their definition does not explicitly involve the limit of convergence. Therefore, they enable us to decide whether or not a given sequence converges without knowledge of the limit to which it converges.<br><br>See note on pdf pg 1292
Consider the following statement:<br><br>Let f be defined on [a,b]. If f is differentiable at a point x ∈ [a,b], then f is continuous at x.<br><br>Prove or give a counterexample.	As t → x, we have, by Theorem 4.4,<br><br><$$>f(t)-f(x)=\frac{f(t)-f(x)}{t-x} \cdot (t-x) \rightarrow f'(x) \cdot 0 = 0</$$><br>that's the proof.<br><br>pg 1343, thm 5.2
Give the definition of the derivative of a function f.<br>	For any x ∈ [a,b] form the quotient <br><$$>\phi(t)=\frac{f(t)-f(x)}{t-x}</$$><br>and define <br><$$>f'(x)=\lim_{t \rightarrow x}\phi(t),</$$><br>f' is called the derivative of f.<br>def 5.1, pg 1342<br>
Consider the following statement.<br><br>Suppose f and g are defined on [a,b] and are differentiable at a<br>point x ∈ [a,b]. Then f+g is differentiable at x and (f+g)'(x) = f'(x)+g'(x).<br><br>Prove or give a counterexample.	true. pg 1343, thm 5.3 (a)
Consider the following statement:<br><br>Suppose f and g are defined on [a,b] and are differentiable at a point x ∈ [a,b]. Then fg is differentiable at x and (f+g)'(x)=f'(x)+g'(x).<br><br>Prove or give a counterexample.<br>	true. follows directly from the fact that the limit of a function sum is the sum of the limits.<br><br>pg 1343, thm 5.3 (a)
Consider the following statement:<br><br>Suppose f and g are defined on [a,b] and are differentiable at a point x ∈ [a,b]. Then (fg)'(x)=f'(x)g(x)+f(x)g'(x).<br><br>Prove or give a counterexample.<br><br>	True.<br><br>Let h = fg. Then h(t)-h(x)=f(t)[g(t)-g(x)]+g(x)[f(t)-f(x)]. If we divide this by t-x and note that f(t)→f(x) as t→x (theorem 5.2), (b) follows.<br><br>thm 5.3 (b), pg 1343
Consider the following statement:<br><br>Suppose f and g are defined on [a,b] and are differentiable at a point x ∈ [a,b]. Then (fg)'(x)=f'(x)g'(x)<br><br>Prove or give a counterexample.<br>	IMPOSTOR!<br><br>thm 5.3 (b), pg 1343
<br>Suppose f and g are defined on [a,b], are differentiable at a point x ∈ [a,b]. Is (f/g) necessarily differentiable at x? If so, is there a formula for the derivative?	it's differentiable if g(x)≠0. the formula is (f/g)'(x) = (g(x)f'(x)-g'(x)f(x))/g<sup>2</sup>x.<br><br>thm 5.3 (c), pg 1343
Let f and t be to continuous functions such that h(t) = g(f(t)).<br><br>Is h necessarily differentiable at x? If not, what are the conditions of differentiability? Is there a formula for the derivative of h? If so, prove it.	thm 5.5, pg 1344
Let f be a real function defined on a metric space X. What is a <i>local maximum</i> of f?<br>	<br>A point p ∈ X such that there exists δ>0 such that f(q) ≤ f(p) for all q ∈ X with d(p,q)<δ.<br><br>def 5.7, pg 1346
Consider the following statement:<br><br>Let f be defined on [a,b]; if f has a local maximum at a point x ∈ (a,b), and if f'(x) exists, then f'(x) = 0.<br><br>Prove or give a counterexample.<br>	true. thm 5.8, pg 1346
Consider the following statement:<br><br>Let f be defined on [a,b]; if f has a local maximum at a point x ∈ [a,b], and if f'(x) exists, then f'(x) = 0.<br><br>Prove or give a counterexample.	IMPOSTOR. putting x in [a,b] allows montonic functions. replacing the second occurrence of [a,b] with (a,b) results in a correct statement.<br><br>thm 5.8, pg 1346
State and prove the generalized mean value theorem.	If f and g are continuous real functions on [a,b] which are differentiable in (a,b), then there is a point x ∈ (a,b) at which<br>[f(b)-f(a)]g'(x)=[g(b)-g(a)]f'(x)<br><br>Proof outline: Let h(t) = [f(b)-f(a)]g(t)-[g(b)-g(a)]f(t). h is continuous on [a,b] and differentiable on (a,b). Show that h'(x)=0 for some x in (a,b). <br><br>proof on pg 1346, thm 5.9
Consider the following statement:<br><br>If f is a real continuous function on [a,b] which is differentiable in (a,b), then there is a point x ∈ (a,b) at which<br>f(b)-f(a)=(b-a)f'(x)<br><br>Prove or give a counterexample.<br> 	true. this is the mean value theorem. pg 1347, thm 5.10.
Consider the following statement:<br><br>If f is a real continuous function on (a,b) which is differentiable in (a,b), then there is a point x ∈ (a,b) at which<br>f(b)-f(a)=(b-a)f'(x)<br><br>Prove or give a counterexample.	IMPOSTOR. of the mean value theorem, thm 5.10, pg 1347
Consider the following statements:<br><br>(a) If f'(x) ≥ 0 for all x ∈ (a,b), then f is monotonically increasing.<br>(b) If f'(x)=0 for all x ∈ (a,b), then f is constant.<br>(c) If f'(x) ≤ 0 for all x ∈ (a,b), then f is monotonically decreasing.<br><br>Prove or give a counterexample.	true. these are all direct results of the mean value theorem.<br><br>pg 1347, thm 5.11
Consider the following statements:<br><br>Suppose f is a real differentiable function on [a,b] and suppose f'(a) < λ < f'(b). Then there is a point x ∈ (a,b) such that f'(x) = λ.<br><br>Prove or give a counterexample.<br> <br>	Put g(t)=f(t)-λt. Then g'(a) < 0, so that g(t<sub>1</sub>) < g(a) for some t<sub>1</sub> ∈ (a,b), and g'(b) >0, so that g(t<sub>2</sub>) < g(b) for some t<sub>2</sub> ∈ (a,b). Hence g attains its minimum on [a,b] (Theorem 4.16) at some point x such that a < x< b. By theorem 5.8, g'(x)=0. Hence f'(x)=λ.<br><br>pg 1347, thm 5.12
<br>prove every k-cell is compact<br><br>DO NOT use the fact that k-cells are closed and bounded; the reason for this is that this could be used to prove the Heine-Borel theorem.	pg 1347
State and prove L'Hospital's rule.<br>	<br>I think the proof in Rudin is crazy weird. Big Spivak pg 202 has a better proof.<br><br>pg 1348<br>
State and prove Taylor's theorem.	big spivak might have a better proof<br>pg 1349<br>
Consider the following statement:<br><br>Let <b>f</b> be a continuous mapping of [a,b] into R<sup>k</sup> and <b>f</b> is differentiable in (a,b). Then there exists x ∈ (a, b) such that <br>|<b>f</b>(b)-<b>f</b>(a)| ≤ (b-a)|<b>f</b>'(x)|.<br><br>Prove or give a counterexample.	true. thm 5.19. pg 1352
Consider the following statement:<br><br>Let <b>f</b> be a continuous mapping of [a,b] into R<sup>k</sup> and <b>f</b> is differentiable in (a,b). Then there exists x ∈ (a, b) such that <br><b>f</b>(b)-<b>f</b>(a) = (b-a)<b>f</b>'(x).<br><br>Prove or give a counterexample.	IMPOSTOR! Example 5.17, pg 1351 is a counterexample. Correct version on pg 113.<br>
Let [a,b] be an interval on R. Give the defintion of a <i>partition</i> P of [a,b].<br>	A finite set of points x<sub>0</sub>, x<sub>1</sub>, ... , x<sub>n</sub> such that a = x<sub>0</sub> ≤ x<sub>1</sub> ≤ ... ≤ x<sub>n-1</sub> ≤ x<sub>n</sub> = b.<br><br><br>pg 1359
<br>What is the definition of the notation U(P,f)?<br>L(P,f)?<br>	If f is a bounded real function defined on [a,b] and P is a partition of [a,b], then <br><$$>U(P,f) = \sum_{i=1}^{n}M_i\Delta x_i</$$><br>and<br><$$>L(P,f) = \sum_{i=1}^{n}m_i\Delta x_i</$$><br><br>They're called upper and lower sums.<br>pg 1360<br><br>
What are the definitions of the following notations?:<br><br><$$> \underline{\int_a^b} f\ dx </$$><br>and<br><$$> \overline{\int_a^b} f\ dx </$$>	<br><$$> \underline{\int_a^b} f\ dx = sup( L(P,f) )</$$><br><$$> \overline{\int_a^b} f\ dx = inf( U(P,f) )</$$><br><br>They are called upper and lower Riemann integrals.<br><br>pg 1360
What does it mean for a bounded real function f to be Riemann integrable on an interval [a,b]?<br>	<br>Its upper and lower integrals on [a,b] are equal.<br><br>pg 1360
Give the definitions of the notations U(P,f,α) and L(P,f,α).	If f is a bounded real function defined on [a,b],P is a partition of [a,b], α is a monotonically increasing function on [a,b],<br>and <br>Δα<sub>i</sub> = α(x<sub>i</sub>)-α(x<sub>i-1</sub>).<br><br><$$>U(P,f,\alpha) = \sum_{i=1}^{n}M_i\Delta \alpha_i</$$><br>and<br><$$>L(P,f,\alpha) = \sum_{i=1}^{n}m_i\Delta \alpha_i</$$><br><br>pg 1361
What are the definitions of the following notations?:<br><br><$$> \underline{\int_a^b} f\ d\alpha </$$><br>and<br><$$> \overline{\int_a^b} f\ d\alpha </$$>	<br><$$> \underline{\int_a^b} f\ d\alpha = sup( L(P,f,\alpha) )</$$><br><$$> \overline{\int_a^b} f\ d\alpha = inf( U(P,f,\alpha) )</$$><br><br>They are called upper and lower Riemann-Stieltjes integrals.<br><br>pg 1361
What does 𝓡 represent? 𝓡(α)?<br>  	𝓡 is the set of all Riemann-integrable functions. 𝓡(α) is the set of all functions which are Riemann-Stieltjes integrable with respect to α.<br><br>pg 1360, 1361  
Give the definition of<br><$$>\int_a^b f\ dx</$$>	It's used to represent the value of the left and right integrals when the two values are equal.<br><br>pg 1360
What does it mean for a partition P<sup>*</sup> to be a refinement of another partition P?	P* ⊇ P. <br><br>pg 1362
Given two partitions P<sub>1</sub> and P<sub>2</sub>, what is the definition of the <i>common refinement</i> of P<sub>1</sub> and P<sub>2</sub>.<br>	P<sub>1</sub> ∪ P<sub>2</sub><br><br>pg 1362
Consider the following statement:<br><br>If P* is a refinement of P, then L(P,f,α) ≤ L(P*,f,α) and U(P*,f,α)≤U(P,f,α).<br><br>Prove or give a counterexample.<br>	true. pg 1362<br>
Consider the following statement:<br><br>If P* is a refinement of P, then L(P*,f,α) ≤ L(P,f,α) and U(P,f,α)≤U(P*,f,α).<br><br>Prove or give a counterexample.<br>	IMPOSTOR! of thm 6.4, pg 1362
Consider the following statement:<br><br><$$> \underline{ \int_a^b } f\ d\alpha \leq \overline{ \int_a^b\ } f\ d\alpha } </$$><br><br>Prove or give a counterexample.<br>	true. thm 6.5, pg 1363<br>
Consider the following statement:<br><br><$$> \underline{ \int_a^b } f\ d\alpha < \overline{ \int_a^b\ } f\ d\alpha } </$$><br><br>Prove or give a counterexample.	should be a counterexample. the less than should be less or equal.<br><br>thm 6.5, pg 1363
Consider the following statement:<br><br>f ∈ 𝓡 on [a,b] if and only if for every ε > 0 there exists a partition P such that U(P,f,α)-L(P,f,α) < ε.<br><br>Prove or give a counterexample.<br> 	true. pg 1363, thm 6.6<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>i.) U(P,f,α)-L(P,f,α) < ε.<br><br>If (i) holds for some P and some ε, then (i) holds (with the same ε) for every refinement of P.<br><br>Prove or give a counterexample.	thm 6.7 (a), pg 1364<br>
Consider the following statement:<br><br>i.) U(P,f,α)-L(P,f,α) < ε.<br><br>If (i) holds for P = {x<sub>0</sub>,...,x<sub>n</sub>} and if s<sub>i</sub>, t<sub>i</sub> are arbitrary points in [x<sub>i-1</sub>,x<sub>i</sub>], then <br><br><$$> | \sum_{i=1}^{n}f(s_i)-f(t_i)|\Delta\alpha_i < \epsilon</$$><br><br>Prove or give a counterexample.	true. thm 6.7 (b), pg 1364<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>i.) U(P,f,α)-L(P,f,α) < ε.<br><br>If (i) holds for P = {x<sub>0</sub>,...,x<sub>n</sub>} and if s<sub>i</sub>, t<sub>i</sub> are arbitrary points in [x<sub>i-1</sub>,x<sub>i</sub>], and f ∈ 𝓡.<br><br><$$> | \sum_{i=1}^{n}f(t_i)\ \Delta\alpha_i - \int_a^b f\ d\alpha | < \epsilon</$$><br><br>Prove or give a counterexample. 	true. thm 6.7 (c), pg 1364
Consider the following statement:<br><br>If f is continuous on [a,b] then f ∈ 𝓡 on [a,b].<br><br>Prove or give a counterexample. 	true. thm 6.8, pg 1364<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>If f is monotonic on [a,b] and α is continuous on [a,b], then f ∈ 𝓡(α). (We still assume, of course, that α is monotonic.) <br><br>Prove or give a counterexample. 	thm 6.9, pg 1365<br><br>TODO: add impostor<br>
Consider the following statement:<br><br>Suppose f is bounded on [a,b], f has finitely many points of discontinuity on [a,b], and α is continuous at every point at which f is discontinuous. Then f ∈ 𝓡(α).<br><br>Prove or give a counterexample. 	true. thm 6.10, pg 1365/1366
Consider the following statement:<br><br>Suppose f ∈ 𝓡(α) on [a,b], m ≤ f ≤ M, φ is continuous on [m, M], and h(x) = φ(f(x)) on [a,b]. Then h ∈ 𝓡(α) on [a,b].<br><br>Prove or give a counterexample.    	true. thm 6.11, pg 1366<br><br>TODO: add impostor
<br>Consider the following statement:<br><br>Let f ∈ 𝓡 on [a,b]. For a ≤ x ≤ b, put<br><br><$$>F(x) = \int_{a}^{x}f(t)\ dt</$$><br><br>Then F is continuous on [a,b]; furthermore, if f is continuous at a point x<sub>0</sub> of [a, b], then F is differentiable at x<sub>0</sub>, and F'(x<sub>0</sub>)=f(x<sub>0</sub>).<br><br><br>Prove or give a counterexample.<br> 	true. pg 1372, thm 6.20<br><br>TODO: add impostor<br>
<br><br>Consider the following statement:<br><br>If f ∈ 𝓡 on [a,b] and if there is a differentiable function F on [a,b] such that F' = f, then<br><br><$$> \int_{a}^{b} f(x)\ dx = F(b)-F(a) </$$> <br><br>Prove or give a counterexample. 	true. fundamental theorem of calculus. pg 1373.<br><br>todo: add impostor<br>
Consider the following statement:<br><br>Suppose F and G are differentiable functions on [a,b], F' = f ∈ 𝓡, and G' = g ∈ 𝓡. Then<br><br><$$>\int_{a}^{b} F(x)g(x)dx = F(b)G(b) - F(a)G(a) - \int_{a}^{b}f(x)G(x)dx</$$><br><br>Prove or give a counterexample.      	thm 6.22, pg 1373.<br><br>todo: add impostor<br>
<br>Let P and Q be posets and ▹ : P  → Q and ◃ : Q → P be maps betweeen them. <br><br>Consider the following statment:<br><br>If for all p,p<sub>1</sub>,p<sub>2</sub> ∈ P and all q,q<sub>1</sub>,q<sub>2</sub> ∈ Q,<br><br>p ≤ p<sup>▹◃</sup>, q ≥ q<sup>◃ ▹</sup>,<br>p<sub>1</sub> ≤ p<sub>2</sub> ⇒ p<sub>1</sub><sup>▹</sup> ≤ p<sub>2</sub><sup>▹</sup>, and<br>q<sub>1</sub> ≤ q<sub>2</sub> ⇒ q<sub>1</sub><sup>◃</sup> ≤ q<sub>2</sub><sup>◃</sup><br><br>Then (▹,◃) is a Galois connection. <br><br>Prove or give a counterexample.<br><br> 	true. mstudy pg 80
Let P and Q be pre-CPOs. Consider the following statement:<br><br>[P → Q] is a pre-CPO and is a CPO whenever Q is  a CPO. Directed joins [P → Q] are calculated pointwise.<br><br>Prove or give a counterexample.	true. mstudy pg 8.9. TODO: add a counterexample.<br>
What is the difference between a CPO and a completely inductive poset?	trick question: there is no difference.<br><br>however, there is usually a difference in the way they are formulated:<br><br>-a completely inductive poset is defined as a poset in which every chain has a least upper bound.<br><br>mstudy pg 90, thm 8.11<br><br>
Let S be a nonempty set. How can we define a order-isomorphism between the partial maps on S, S ⊸→ S, and the total maps on S → S<sub>⊥</sub>?<br>	mstudy pg 91, lemma 8.12<br>
What is a pre-fixpoint? What is a post-fixpoint?	mstudy pg 92<br>def 8.14<br>
Let P be a CPO, let F be an order-preserving self-map on P, and define α := ⊔<sub>n≥0</sub>F<sup>n</sup>(⊥).<br><br>Consider the following statement:<br><br>if α ∈ fix(F), then α = μ(F)<br><br>Prove or give a counterexample.<br>	mstudy pg 92<br>
Let P be a CPO, let F be an order-preserving self-map on P, and define α := ⊔<sub>n≥0</sub>F<sup>n</sup>(⊥).<br><br>Consider the following statement:<br><br>μ(F) exists and <br>α = μ(F)<br><br>Prove or give a counterexample.<br>	IMPOSTOR!<br><br>this would be true if F were continuous<br><br>mstudy pg 92, thm 8.15<br>
Let P be a CPO, let F be a continuous order-preserving self-map on P, and define α := ⊔<sub>n≥0</sub>F<sup>n</sup>(⊥). <br><br>Consider the following statement:<br><br>μ(F) exists and <br>α = μ(F)<br><br>Prove or give a counterexample.<br>	true. mstudy pg 92, thm 8.15<br>
Example 2, mstudy pg 93<br>I should transcribe this in more detail (i.e. find the least fixpoint of this function)<br><br>	<br>
Let P be an ordered set and let F be an order-preserving self-map on P. Assume that  F possesses a least pre-fixpoint μ<sub>*</sub>(F). <br><br>Consider the following statement:<br><br>F has a least fixpoint, μ(F), which satisfies<br>F(x) ≤ x = μ(F) ≤ x<br><br>Prove or give a counterexample.<br>	true. mstudy pg 94, thm 8.20<br>TODO: add impostor<br>
Let P be a complete lattice and let F be an order-preserving self-map on P. <br><br>Consider the following statement:<br><br>F has a least fixpoint, μ(F), which satisfies<br>F(x) ≤ x = μ(F) ≤ x<br><br>Prove or give a counterexample.<br>	true. mstudy pg 94<br>
Let P be a lattice and let F be an order-preserving self-map on P. <br><br>Consider the following statement:<br><br>F has a least fixpoint, μ(F), which satisfies<br>F(x) ≤ x = μ(F) ≤ x<br><br>Prove or give a counterexample.<br>	IMPOSTOR (would be true if P were a complete lattice)<br><br>mstudy pg 94, thm 8.20
What is <b>the induction rule</b> in the language of CPOs and fixpoints?<br>	mstudy pg 94<br>
What does it mean for a self-map on an ordered set to be <i>increasing</i>?	mstudy pg 94<br>
Let P be a CPO. Consider the following statement:<br><br>The increasing order-preserving self-maps on P have a common fixpoint.<br><br>Prove or give a counterexample.<br>	mstudy pg 94
Let P be a CPO and let F : P → P be order-preserving. Consider the following statement: <br><br>F has a least fixpoint.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 94 (right) theorem 8.22<br>
Let P be a CPO and let F be an increasing self-map on P. Consider the following statement:<br><br>F has a minimal fixpoint.<br><br>True or false<br>	true. mstudy pg 95, thm 8.23<br>
Let P be a poset. Consider the following statement:<br><br>If P is a lattice and every order-preserving map F : P → P has a fixpoint, then P is a complete lattice.<br><br>True or false.	true. mstudy pg 95 right, thm 82.5
Let P be a poset. Consider the following statement:<br><br>If every order-preserving map F : P → P has a least fixpoint, then P is a CPO.<br><br>True or false.<br><br><br>	true. mstudy pg 95<br>
Let F be an order-preserving self-map on a n ordered set P. Consider the following statement:<br><br>If P is a complete lattice, then so is fix(F).<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 95.<br><br><br>
Let F be an order-preserving self-map on a n ordered set P. Consider the following statement:<br><br>If P is a CPO, then so is fix(F).<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 95 r, prop 8.26<br>
What is a Type-2 Turing machine?	pg 2095 / 2096<br>def 2.1.1
What does it mean in computable analysis for a function to be computable?	pg 2096<br>Def 2.1.2<br>
Which words w ∈ Σ* are computable?<br>Which sequences p ∈ Σ<sup>ω</sup> are computable?<br>When is a tuple (y<sub>1</sub>,...,y<sub>k</sub>) with y<sub>i</sub> ∈ Σ* or y<sub>i</sub> ∈ Σ<sup>ω</sup> computable?<br>	pg 2098<br>Def 2.1.3<br>
What does it mean for a mathematical object in computable analysis to be a "computable element"?<br>	pg 2098<br>def 2.1.3<br>
Give three examples of computable functions.<br>	pg 2098
Let M be a type-2 machine with k input tapes. Let T<sub>M</sub> be the set of all (u<sub>1</sub>,...,u<sub>k</sub>,0<sup>m</sup>,v) with u<sub>1</sub>,...,u<sub>k</sub>,v  ∈ Σ* and m ∈ <b>N</b> such that on any input (y<sub>1</sub>,...,y<sub>k</sub>) with u<sub>i</sub> being a prefix of y<sub>i</sub> in m steps, M writes v on the output tape.<br><br>Consider the following statement:<br>T<sub>M</sub> is recursive.<br><br>prove or give a counterexample.	True. Note: recursive == decidable.<br><br>mstudy pg 2100<br>TODO: add impostor (possible by removing 0^m component?)<br><br>
Consider the following statement:<br><br><br>the existence of a computable function producing an infinite string output can be reduced to the existence of a computable function producing a finite output.<br><br>Prove or give a counterexample.<br>	true. pg 2100. Lemma 2.1.6<br>
How do we encode a tuple of finite strings into a single finite string?<br><br>	pg 2100. def 2.1.7<br>
How do we encode a finite tuple of infinite strings into a single infinite string?<br><br>	pg 2100. Def 2.1.7, 4th listed example.
A function h<sub>∗</sub> can sometimes be obtained from a function h.<br>What are the restrictions needed on h for h<sub>∗</sub> to make sense?<br>Why is h<sub>∗</sub> useful?<br>	pg 2101/2102<br>What it is: Definition 2.1.10 (1)<br>Why it is useful: Lemma 2.1.11<br>
What does it mean for a function h : Σ* → Σ* to be monotone?<br><br>	pg 2101. def 2.1.10 (2)<br><br>monotonicity is with respect to prefix by default:<br>It means that u ⊑ v, h(u) ⊑ h(v).<br><br>If u is a prefix of v then h(u) is a prefix of h(v).<br>
For certain functions h, we can obtain a related function h<sub>ω</sub>.<br>How is h<sub>ω</sub> defined and what restrictions must h satisfy for it to make sense?<br>How is it useful?<br>	What it is: pg 2101. Def 2.1.10 (2)<br>How it's useful: pg 2101 Lemma 2.1.11<br><br>note that p<sub><i</sub> is the length-i prefix of p.<br>
State and prove the monotonicity rule for fixpoint calculation.<br>	mstudy pdf pg 96<br>
State and prove the <i>rolling rule</i> for fixpoint calculation.<br>	pdf pg 96
State and prove the <i>fusion rule</i> for fixpoint calculation. Why it called the fusion rule?<br>	pg 96 (right), definition 8.30
State and prove the <i>exchange rule</i> for fixpoint calculation.<br>	mstudy pg 97
State and prove <i>the principle of fixpoint induction for continuous maps</i>.<br>	mstudy pg 97<br>
Let k,n ∈ <b>N</b> amd X<sub>1</sub>,...,X<sub>k</sub>,Y<sub>1</sub>,...,Y<sub>n</sub>,Z ∈ {Σ*,Σ<sup>ω</sup>}. <br><br>Let g<sub>i</sub> :⊆ X<sub>1</sub> × ... X<sub>k</sub> → Y<sub>i</sub> and<br>f :⊆ Y<sub>1</sub> × ... × Y<sub>n</sub> → Z<br><br>(for i = 1,...,n) be computable functions. What can then be said about the computability of<br>f ∘(g<sub>1</sub>,...,g<sub>n</sub>) :⊆ X<sub>1</sub>  × ... × X<sub>k</sub> → Z.<br><br>Prove your answer.<br><br>	mstudy pg 2102 <br>thm 2.1.12<br>
Consider the following statement:<br><br>Every computable function maps computable elements to computable elements.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 2104.<br>
Describe the <i>primitive recursion</i> theorem in computable analysis. What are the applications of this theorem? Can you prove this theorem?<br><br><br>	mstudy pg 2104/2105<br>
mstudy pg 2106 Problem 1<br>	<br>
mstudy pg 2106 <br>Problem 6<br>	<br>
mstudy pg 2106 <br>Problem 8<br><br>	<br>
mstudy pg 2107 <br>problem 10<br>	<br>
mstudy pg 2107 <br>problem 14<br>	<br>
What is the <i>Finiteness Property</i> (FP) in computable analysis?<br>	mstudy pg 2108<br>
Give the definitions of <i>topology</i> and <i>topological space</i>.<br>	mstudy pg 2108<br>
What is a <i>base</i> of a topology?	mstudy pg 2108<br>
What is a subbase of a topology?	mstudy pg 2108<br>
What does it mean for a function between topological spaces to be <i>continuous</i>?<br>	mstudy pg 2109
What does it mean for a function to be (τ,τ')-continuous?<br>	mstudy pg 2109<br>
What does it mean for a function f : M → M' to be continuous at x, where M and M' are topological spaces and x ∈ M?<br> 	mstudy pg 2109<br>
If τ is a topology on M and D ⊆ M, what does τ|<sub>D</sub> denote?<br>	mstudy pg 2109<br>
What is a G<sub>δ</sub>-set?<br>	mstudy pg 2109<br>
If (M,τ) is a topological space, what does it mean for a set X ⊆ M to be <i>dense</i>?<br>	mstudy pg 2109
What is the discrete topology on a set M?<br>	mstudy pg 2109
If (M<sub>i</sub>,τ<sub>i</sub>)<sub>i ∈ I</sub> is a family of topological spaces, what is the <i>product space</i> of this family?<br>	mstudy pg 2109<br>
What is a psuedometric space? What is a metric space?	mstudy pg 2109
If d is a psuedometric, give the definition of the <i>topology generated by the psuedometric d</i>.<br>	mstudy pg 2109
Give the definition of the <i>discrete topology on Σ<sup>*</sup></i>.	mstudy pg 2110
Give the definition of the <i>Cantor topology on Σ<sup>ω</sup></i>.	mstudy pg 2110
What family of sets is used as the canonical base of τ<sub>*</sub>? τ<sub>ω</sub>?	mstudy pg 2110
What is the canonical base on Y = Y<sub>1</sub>× ... ×Y<sub>k</sub> (where Y<sub>i</sub> ∈ {Σ*,Σ<sup>ω</sup>})?<br>	mstudy pg 2110
Explain how Σ<sup>ω</sup> and its canonical base can be considered in terms of infinite trees.<br>	mstudy pg 2110/2111
Consider the following statement:<br><br>Every computable string function f :⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> is continuous.<br><br>Prove or give a counterexample.<br>	mstudy pg 2111
Consider the following statement:<br><br>Every continuous string function f :⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> is computable.<br><br>Prove or give a counterexample.<br>	IMPOSTOR<br><br>pg 2111<br>
Let Y = Y<sub>1</sub> × ... × Y<sub>k</sub>. Consider the following statement:<br><br>If f ⊆: Y → Σ<sup>ω</sup> is computable, then dom(f) is open.<br><br>Prove or give a counterexample.<br><br>	IMPOSTOR pg 2112<br>
Let Y = Y<sub>1</sub> × ... × Y<sub>k</sub>. Consider the following statement:<br><br>If f ⊆: Y → Σ<sup>ω</sup> is computable, then dom(f) is a G<sub>δ</sup>-set.<br><br>Prove or give a counterexample.<br>	true. pg 2112<br>
Let Y = Y<sub>1</sub> × ... × Y<sub>k</sub>. Consider the following statement:<br><br>If f ⊆: Y → Σ* is computable, then dom(f) is open.<br><br>Prove or give a counterexample.<br>	true pg 2112<br>
Give the metric on Σ<sup>ω</sup> which generates the Cantor topology. Prove your answer.<br><br>	pg 2112, lemma 2.5.2<br><br>
Consider the following statement: Σ<sup>ω</sup> is a compact set with respect to the Cantor topology. Prove or give a counterexample.<br>	true. pg 2112. lemma 2.2.5.<br>
Consider the following statement:<br><br>For any w∈Σ*, wΣ<sup>ω</sup> is closed with respect to the standard "Cantor" metric on Σ<sup>ω</sup>.<br><br>Prove or give a counterexample.<br>	It is, because its complement is open. But note that it is both closed and open. It is clopen.<br><br>mstudy pg 2113 (top)<br>
What does it mean for a string function to be decidable?	Its characteristic function is computable.<br><br>mstudy pg 2113<br>
Consider the following statement:<br><br>A subset X ⊆ Σ<sup>ω</sup> is clopen, iff it is decidable, iff X = AΣ<sup>ω</sup> for some finite set A ⊆ Σ*.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 2113, thm 2.2.6<br>
Consider the following statement:<br><br>A (total) function f : Σ<sup>ω</sup> → Σ* is continuous, iff it is computable, iff there are pairs (u<sub>1</sub>,v<sub>1</sub>),...,(u<sub>k</sub>,v<sub>k</sub>) ∈  Σ* × Σ* such that {u<sub>1</sub>,...,u<sub>k</sub>} is prefix-free, Σ<sup>ω</sup> = u<sub>1</sub>Σ<sup>ω</sup> ∪ ... ∪ u<sub>k</sub>Σ<sup>ω</sup> and f[u<sub>i</sub>Σ<sup>ω</sup>] = {v<sub>i</sub>} for all i.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 2113<br>TODO: add impostor<br>
mstudy pg 2113, exercise 1<br>	<br>
mstudy pg 2113, exercise 3<br><br>	<br>
mstudy 2113, exercise 4 or 5 (choose one)<br><br>	<br>
mstudy 2113, exercise 8 or 9 (choose one)	<br>
mstudy 2113, exercise 10 or 11 (choose one)	<br>
Let X and Y be metric spaces; suppose E ⊆ X, f maps E into Y, and p is a limit point of E. <br> <br>What does the notation f(x) → q as x → p mean?	pg 1332
Let X and Y be metric spaces; suppose E ⊆ X, f maps E into Y, and p is a limit point of E. <br><br>Consider the following statement:<br><br><$$>lim_{x \rightarrow p}f(x) = q</$$><br><br>if and only if<br><br><$$>lim_{n \rightarrow \infty}f(p_n) = q</$$><br><br>for every sequence {p<sub>n</sub>} in E such that<br>p<sub>n</sub>≠p and {p<sub>n</sub>} → p<br><br>Prove or give a counterexample.<br>	true pg 1323<br>TODO: add impostor<br>
Consider the following statement:<br><br>If f has a limit at p, this limit is unique.<br><br>Prove or give a counterexample.<br>	mstudy pg 1323<br>
Suppose X and Y are metric spaces, E ⊆ X, p ∈ E, and f maps E into Y.<br><br>What does it mean for f to be <i>continuous</i> at p? What does it mean for f to be continuous on E?<br><br>	mstudy pg 1324 def 4.5<br>
If p is an isolated point, when is a function continuous at p?	always. top of pg 1325<br>
Suppose X and Y are metric spaces, E ⊆ X, p is a limit point of E, and f maps E into Y. Consider the following statement:<br><br>f is continuous at p if and only if lim<sub>x→p</sub>f(x)=f(p)<br><br>Prove or give a counterexample.<br><br><br>	mstudy pg 1325<br>TODO: impostor, maybe?<br>
Suppose X, Y, and Z are metrix spaces, E ⊆ X, f maps E into Y, g maps the range of f, f(E), into Z, and h is the mapping of E into Z defined by<br><br>h(x) = g(f(x))   (x ∈ E)<br><br>Consider the following statement:<br><br>If f is continuous at a point p ∈ E and if g is continuous at the point f(p), then h is continuous at p.<br><br>Prove or give a counterexample.	true mstudy pg 1325, thm 4.7<br>TODO: add impostor?<br>
If f : Y -> Z and g : X -> Y are two functions on metric spaces X, Y, and Z, when is f ∘ g continuous at a point p ∈ X?<br>	pg 1325, thm 4.7<br>
Consider the following statement:<br><br>A mapping f of a metric space X into a metric space Y is continuous on X if and only if f<sup>-1</sup>(V) is open in X for every open set V in Y.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1325.<br>
Consider the following statement:<br><br>A mapping f of a metric space X into a metric space Y is continuous on X if and only if for any open set V ⊆ f(X), all sets W ⊆ X such that f(W) = V are open.<br><br>Prove or give a counterexample.<br>	IMPOSTOR!<br>Constant functions serve as good counterexamples to this.<br><br>mstudy pg 1325, thm 4.8<br>
Consider the following statement:<br><br>A mapping f of a metric space X into a metric space Y is continuous if and only if f<sup>-1</sup>(C) is closed in X for every closed set C in Y.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1326<br>
Let f<sub>1</sub>,...,f<sub>k</sub> be real functions on a metric space X, and let <b>f</b> be the mapping of X into R<sup>k</sup> defined by<br><br><b>f</b>(x) = (f<sub>1</sub>(x),...,f<sub>k</sub>(x))          (x ∈ X)<br><br>Consider the following statement:<br><br><b>f</b> is continuous if and only if each of the functions f<sub>1</sub>,...,f<sub>k</sub> is continuous.<br><br>Prove or give a counterexample.<br><br><br>	true. mstudy pg 1326.<br>TODO: add impostor?<br>
Consider the following statement:<br><br>If <b>f</b> and <b>g</b> are continuous mappings of X into R<sup>k</sup>, then <b>f</b>+<b>g</b> and <b>f</b>·<b>g</b> (dot product) are continuous on X.<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 1326, thm 4.10 (b)<br>TODO: impostor?<br>
Consider the following statement:<br><br>Every rational function in x<sub>1</sub>,...,x<sub>k</sub> is continuous on R<sup>k</sup> wherever the denominator is different from zero.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1327, examples 4.11<br>TODO: impostor?
Suppose f is a continuous mapping of a compact metric space X into a metric space Y.<br><br>Consider the following statement:<br><br>f(X) is compact.<br><br>Prove or give a counterexample.	true. mstudy pg 1328 thm 4.14<br>TODO: impostor?<br>
Consider the following statement:<br><br>If <b>f</b> is a continuous mapping of a compact metric space X into R<sup>k</sup>, then <b>f</b> is bounded.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1328<br>TODO: impostor?<br>
Let f be a continuous real function on a compact metric space X, and<br><$$>M = sup_{p \in X}f(p),\ \ \ m = inf_{p \in X}f(p)</$$><br>Consider the following statement:<br><br>There exist points p, q ∈ X such that f(p) = M and f(q) = m.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1328<br>theorem 4.16<br>TODO: impostor?<br>
What does it mean for a non-empty subset of an ordered set P to be <i>consistent</i>?<br>	pg 101 (right)<br>
What is the difference between directed sets and consistent sets?	mstudy pg 101 (r) remark 9.2
What is a <i>complete semilattice</i>?	mstudy pg 101/102
Let P be a CPO. Consider the following statement:<br><br>The following are equivalent:<br><br>-P is <i>consistently complete</i>, that is ⋁S exists for every consistent set S in P<br>-⋁S exists whenever S<sup>u</sup> ≠∅<br>-⋀S exists whenever S ≠ ∅<br>-P⊕1 is a complete lattice<br><br>Prove or give a counterexample	mstudy pg 102, lemma 9.4<br>TODO: add impostor<br>
What does it mean for an element k of a CPO P to be <i>finite</i>?<br>	mstudy pg 102, definition 9.5
Give three examples of finite elements of CPOs.<br>	mstudy pg 102, example 9.6
What is a <i>domain</i>?	mstudy pg 102, 9.7.<br><br>Note that it is a <i>complete semilattice</i> in which every element is the join of its finite approximations.<br>
Consider the following statement:<br><br>All algebraic ⋂-structures are domains. <br><br>Prove or give a counterexample.<br>	true. mstudy pg 102, thm 9.9<br>TODO: counterexample?
Let L be a domain and define D<sub>a</sub> := { k ∈ F(L) | k ≤ a } for each a ∈ L. <br><br>Consider the following statement:<br><br>Then LL := { D<sub>a</sub> | a ∈ L } is an algebraic ∩-structure isomorphic to L.<br><br>Prove or give a counterexample.<br>	true msutidy pg 102, thm 9.8 ii<br>TODO: impostor?<br>
Give three examples of domains that are not algebraic lattices.<br>	mstudy pg 102, ex 9.9<br>
How can we intuitively characterize continuous maps between domains?	mstudy pg 102 (r) 9.10<br><br>Continuous maps between domains are determined entirely by their effect on finite elements.<br>
Let P and Q be domains and φ : P → Q be order-preserving.<br><br>Consider the following statement:<br><br>The following are equivalent:<br>- φ is continuous<br>- φ(x) = ⨆{ φ(k) | k ∈ F(P) and k ≤ x } for each x ∈ P.<br>- D<sub>φ(x)</sub> ⊆ φ(D<sub>x</sub>) for all x ∈ P.<br><br>Prove or give a counterexample.	true. mstudy pg 102. prop 9.11<br>TODO: add impostor<br>
Let P and Q be domains.<br><br>Consider the following statement:<br><br>[P → Q] (the continuous maps from P to q)  is isomorphic to <br>⟨F(P)  → Q⟩ (the order-preserving maps from F(P) to Q.<br><br>Prove or give a counterexamlple.<br>	true. mstudy pg 102. prop 9.11.<br><br>TODO: impostor?
What is a <i>notation</i>? What is a <i>representation</i>? What is a <i>naming system</i>?<br>	mstudy pg 2114, def 2.3.1<br><br>
Consider arbitrary functions γ :⊆ Y → M and γ' :⊆ Y' → M' with Y,Y*  ∈ {Σ<sup>*</sup>, Σ<sup>ω</sup>}.<br><br>What does it mean for a function f :⊆ Y  → Y' to reduce γ to γ'?<br>	mstudy pg 2115. def 2.3.2 (1)<br>
Consider arbitrary functions γ :⊆ Y → M and γ' :⊆ Y' → M' with Y,Y*  ∈ {Σ<sup>*</sup>, Σ<sup>ω</sup>}.<br><br>What does γ ≤ γ' mean?<br>What does γ ≤<sub>t</sub> γ' mean?	mstudy pg 2115<br>
Consider arbitrary functions γ :⊆ Y → M and γ' :⊆ Y' → M' with Y,Y*  ∈ {Σ<sup>*</sup>, Σ<sup>ω</sup>}.<br><br>What does γ ≡ γ' mean? What does γ ≡<sub>t</sub> γ' mean?<br>	mstudy pg 2115, def 2.3.2 (4,5)<br>
Consider the relations ≤ and ≤<sub>t</sub> on nameing systems. Consider the following statement:<br><br>≤ and ≤<sub>t</sub> are pre-orders<br><br>Prove or give a counterexample.<br>	true. mstudy pg 2115, below def 2.3.2<br>
Consider the relations ≤ and ≤<sub>t</sub> on naming systems. Consider the following statement:<br><br>≤ is a partial order on naming systems.<br> <br>Prove or give a counterexample.<br>	IMPOSTOR! it is only a preorder<br>mstudy pg 2115, below def 2.3.2<br>
What does it mean for a naming system γ to be <i>richer</i> than a naming system γ'?<br>	mstudy pg 2115<br>
State the definitions of the <i>general</i> utm and stm properties.<br>	mstudy pg 2115, def 2.3.3<br>
What is the <i>standard notation</i> ξ<sup>ab</sup> for computable functions from Σ<sup>a</sup> to Σ<sup>b</sup>, where a,b ∈ {*,ω}?<br><br><br><br><br><br>	mstudy pg 2116, def 2.3.4<br><br>
Consider the following statement:<br><br>For all a,b ∈ {∗,ω}, utm(ξ<sup>ab</sup>) and smn(ξ<sup>ab</sup>)<br><br>Prove or give a counterexample.<br>	mstudy pg 2116<br>
Consider the following statement:<br><br>The set of continuous functions f : Σ* → Σ<sup>b</sup> has a representation for all b ∈ {∗,ω}.<br><br>Prove or disprove.<br>	true. mstudy pg 2116<br>
Consider the following statement:<br><br>The set of continuous functions f : Σ<sup>ω</sup> → Σ<sup>b</sup> has a representation for all b ∈ {∗,ω}.<br><br>Prove or disprove.<br>	IMPOSTOR. mstudy pg 2116, below thm 2.3.5<br><br>
How are the sets F<sup>∗∗</sup>,F<sup>∗ω</sup>,F<sup>ω∗</sup>, and F<sup>ωω</sup> defined, and why?<br>	mstudy pg 2116, def 2.3.6<br>
Consider the follow statement:<br><br>F<sup>ω∗</sup> = {h<sub>∗</sub> | h :⊆ Σ* → Σ* has a prefix-free domain}<br><br>true or false?<br><br><br>	true. mstudy pg 2117<br>
Consider the follow statement:<br><br>F<sup>ωω</sup> = {h<sub>ω</sub> | h : Σ* → Σ* is monotone}<br><br>true or false?<br><br><br>	true. mstudy pg 2117. thm 2.3.7 (2)<br>
Consider the following statement:<br><br>Every continuous partial function f :⊆ Σ<sup>ω</sup> → Σ<sup>∗</sup> has an extension in F<sup>ω∗</sup>.<br><br>Prove or give a counterexample.<br><br><br>	true. mstudy pg 2117<br>
Consider the following statement:<br><br>Every continuous partial function f :⊆ Σ<sup>ω</sup> → Σ<sup>ω</sup> has an extension in F<sup>ωω</sup>.<br><br>True or false.<br><br><br><br>	true. mstudy pg 2117.<br>
Consider the following statement:<br><br>h<sub>∗</sub> ∈ F<sup>ω∗</sup> for every h :⊆ Σ<sup>∗</sup> → Σ<sup>∗</sup>.<br><br>Prove or give a counterexample.	true. mstudy pg 2117 (proof 1, below thm 2.3.8)<br>
Consider the following statement:<br><br>If f :⊆ Σ<sup>ω</sup> → Σ<sup>∗</sup> is continuous, then h<sub>∗</sub> extends f for some h :⊆ Σ<sup>∗</sup> → Σ<sup>∗</sup> with prefix-free domain.<br><br>Prove or give a counterexample.	true. mstudy pg 2117.<br>TODO: add impostor<br>
Consider the following statement:<br><br>If V ⊆ dom(h<sub>∗</sub>) is open, then the restriction of h<sub>∗</sub> to V is equal to g<sub>∗</sub> for some function g :⊆ Σ<sup>∗</sup> → Σ<sup>∗</sup>.<br><br>Prove or give a counterexample.<br><br>	mstudy pg 2117, proof 3 below thm 2.3.8<br>TODO: add impostor<br>
Consider the following statement:<br><br>h<sub>ω</sub> ∈ F<sup>ωω</sup> for every monotone function h : Σ<sup>∗</sup> → Σ<sup>∗</sup>.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 2118, proof 4.) near top<br>TODO: add impostor<br>
Consider the following statement:<br><br>If f :⊆ Σ<sup>ω</sup> → Σ<sup>ω</sup> is continuous, then h<sub>ω</sub> extends f for some monotone function h : Σ<sup>∗</sup> → Σ<sup>∗</sup>.<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 2118, proof 5.)<br>TODO: add impostor<br>
Let h : Σ<sup>∗</sup> → Σ<sup>∗</sup> be a monotone function.<br><br>Consider the following statement:<br><br>If G ⊆ dom(h<sub>ω</sub>) is a G<sub>δ</sub>-set, then the restriction of h<sub>ω</sub> to G is equal to g<sub>ω</sub> for some monotone function g : Σ<sup>∗</sup> → Σ<sup>∗</sup>.<br><br>Prove or give a counterexample.<br><br>	NOTE: Properties 4, 5, and 6 together imply thm 2.3.7.2 and 2.3.8.2<br><br>true. mstudy pg 2118, proof 6.)<br>TODO: add impostor<br>
Does interval arithmetic with exact real endpoints form a field?<br>	No. Interval arithmetic is not distributive--it is subdistributive.<br>It also does not have additive or multiplicative inverses.<br><br>pg 2408/2409<br>
Does additive cancellation hold for exact interval arithmetic? What about multiplicative cancellation?<br><br>Prove your answer.<br>	1.) yes<br><br>2.) no<br>-write out the formulas for interval multiplication XZ and YZ in terms of min and max.<br>-note that if Z = [-1,1] then these formulas are essentially sign agnostic<br>-hence, if X = [1,2] and Y = [-2,-1], then XZ = YZ, but XZ ≠ YZ<br><br>pg 2410<br>
In interval analysis, what is a <i>symmetric</i> interval?	mstudy pg 2410<br>
What is the <i>subdistributivity</i> property of exact interval arithmetic?<br> 	mstudy pg 2409<br>
What nice properties do symmetric intervals have that intervals lack in general?<br>	mstudy pg 2411<br>
Are there any common situations in which multiplication can be distributed over addition in interval arithmetic?	yes. Multiplication can be distributed over addition whenever the summands all have the same sign.<br><br>X(Y + Z) = XY + XZ <br>provided that YZ > 0.<br>(YZ > 0 means that the left endpoint of the interval YZ is greater than 0)<br><br>mstudy pg 2410
In a complex interval arithmetic calculation, it is unlikely that intermediate results will ever be symmetric. Why, then, is the concept of a symmetric interval still useful?	Answer: any interval can be represented as symmetric interval plus a degenerate one (i.e. a translated symmetric interval).<br><br>mstudy pg 2410, exercise 4.6<br>
Define the <i>inclusion isotonicity</i> property of interval arithmetic.<br>	mstudy pg 2411<br>
In exact interval arithmetic, how do we define interval operations for unary functions, which, like e^x, are monotonic?<br>	mstudy pg 2416<br>
What does it mean for an interval-valued function to be an <i>extension</i> of a real-valued function?	mstudy pg 2419, def 5.2
Let g : M<sub>1</sub> → M<sub>2</sub> be a mapping between sets M<sub>1</sub> and M<sub>2</sub>, and denote by S(M<sub>1</sub>) and S(M<sub>2</sub>) the families of subsets of M<sub>1</sub> and M<sub>2</sub>, respectively. <br><br>Give the definition of the <i>united extension</i> of g.<br>	mstudy pg 2415, def 5.1.<br>
Why is the term <i>united</i> used to describe <i>united extensions</i>?<br>	see footnote 16 on pg 2415
Solve exercise 5.2, pg 2417<br>	<br>
Solve exercise 5.4, pg 2417<br>	<br>
Consider the following statement:<br><br>Formulas that are equivalent in ordinary real-number arithmetic always give rise to equivalent interval arithmetic extensions.<br><br>Prove or give a counterexample.	IMPOSTOR!<br>pg 2420, 2421<br>
Do exercise 5.7 on page 2421<br>	<br>
Do exercise 5.8 on pg 2422	<br>
What is the <i>interval extension</i> of a multi-argument real-arithmetic function?	pg 2422, def 5.3<br>
What is <i>inclusion isotonicity</i> for n-argument interval functions?<br>	pg 2423<br>
Give the definition of <i>rational interval function</i>	pg 2423, def 5.5<br>
Consider the following statement:<br><br>All rational interval functions are inclusion isotonic.<br><br>Prove or give a counter-example.<br>	pg 2424, lemma 5.1<br>
State and prove the <i>fundamental theorem of interval analysis</i>.	mstudy pg 2424<br>
Suppose f is a continuous 1-1 mapping of a compact metric space X onto a metrix space Y. Consider the following statement:<br><br>The inverse mapping f<sup>-1</sup> defined on Y by f<sup>-1</sup>(f(x)) = x<br>is a continuous mapping of Y onto X.<br><br>Prove or give a counterexample.<br>	true mstudy pg 1329<br>
Suppose f is a continuous 1-1 mapping of a metric space X onto a metrix space Y. Consider the following statement:<br><br>The inverse mapping f<sup>-1</sup> defined on Y by f<sup>-1</sup>(f(x)) = x<br>is a continuous mapping of Y onto X.<br><br>Prove or give a counterexample.<br>	IMPOSTOR. if X is compact it would be true. pg 1329<br>
What does it mean for a mapping f : X -> Y to be <i>uniformly continuous</i> on X.<br>	mstudy pg 1329, def 4.18<br>
Let f be a continuous mapping of a compact metric space X into a metric space Y.<br><br>Consider the following statement:<br><br>f is uniformly continuous on X<br><br>Prove or give a counterexample.<br><br>	true. mstudy pg 1330.<br>
Let f be continuous a mapping of a metric space X into a metric space Y.<br><br>Consider the following statement:<br><br>f is uniformly continuous on X<br><br>Prove or give a counterexample.<br>	IMPOSTOR. this would be true if X were compact. mstudy pg  1330.
Let E be a noncompact set in R<sup>1</sup>. Consider the following statement:<br><br>there exists a continuous function on E which is not bounded.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1330.<br>
Let E be a noncompact set in R<sup>1</sup>. Consider the following statement:<br><br>there exists a continuous and bounded function on E which has no maximum<br><br>Prove or give a counterexample.<br>	true mstudy pg 1330, thm 4.20 (b)<br>TODO: add impostor<br>
Let E be a bounded, noncompact set in R<sup>1</sup>. Consider the following statement:<br><br>there exists a continuous function on E which is not uniformly continuous.<br><br>Prove or disprove.<br>	true. mstudy gp 1331<br>
Let E be a noncompact set in R<sup>1</sup>. Consider the following statement:<br><br>there exists a continuous function on E which is not uniformly continuous.<br><br>Prove or disprove.<br>	IMPOSTOR. would be true if E were bounded.<br><br>mstudy pg 1331 (c) near top<br>
Let f be a continuous mapping of a metric space X into a metric space Y, and let E be a connected subset of X. Consider the following statement:<br><br>f(E) is connected<br><br>Prove or give a counterexample.<br>	true. mstudy pg 1332, thm 4.22<br>
Let f be a continuous real function on the interval [a,b]. Consider the following statement:<br><br>If f(a) < f(b) and if c is a number such that f(a) < c < f(b), then there exists a point x ∈ [a,b] such that f(x) = c.<br><br>Prove or disprove.<br>	true. mstudy pg 1332. <br><br>
Suppose that f is a function such that for any interval (a,b) with f(a) < f(b), and any c ∈ (f(a),f(b)), there exists an x ∈ (a,b) such that f(x) = c. Consider the following statement:<br><br>f is continuous.<br><br>Prove or disprove.<br>	IMPOSTOR. see example 4.27 d on page 1334.<br>
Give the formal definition behind these notations:<br><br>f(x+) = q<br>f(x-) = q<br>	mstudy pg 1333, def 4.25<br>
Give the definition of <i>discontinuity of the first kind</i>.<br>Give the definition of <i>discontinuity of the second kind</i>.<br>	mstudy pg 1333, def 4.26<br>
There are two ways in which a function can have a <i>discontinuity of the first kind</i> describe both of these scenarios.<br>	mstudy pg 1333, below def 4.26<br>
Let f be monotonically increasing on (a,b). Then what can be said about the relation between f(x-), f(x), and f(x+)?<br>	mstudy pg 1334, thm 4.29<br>
Let f be monotonically increasing on (a,b).  Let a < x < y < b.<br><br>Then what can be said about the relation between f(x+) and f(y-)?<br><br><br>	mstudy pg 1334, thm 4.29 (26)
Consider the following statement:<br><br>Montonic functions have no discontinuities of the second kind.<br><br>Prove or disprove.	mstudy pg 1335<br>
Let f be montonically increasing on (a,b). Consider the following statement: <br><br>f(x+) and f(x-) exist for every point on (a,b)<br><br>Prove or disprove.<br>	true. mstudy pg 1134, thm 4.29.<br>
Let f be monotonic on (a,b). Consider the following statement:<br><br>The set of points of (a,b) at which f is discontinuous is at most countable.<br><br>Prove or disprove.<br>	true. mstudy pg 1335.<br>
Let (a,b) be a real interval. For any countable subset E of (a,b), can we construct a function f that is monotonic on (a,b) and discontinuous at every point of E? If so, provide directions for constructing such a function. Otherwise, prove your answer.<br>	it's possible. pg 1336, remark 4.31<br>
What is the <i>natural interval extension</i> of a real rational function?	pg 2424<br>
Consider the following statement:<br><br>If F is a rational interval function and an interval extension of f, then<br><br>f(X<sub>1</sub>,...,X<sub>n</sub>) ⊆ F(X<sub>1</sub>,...,X<sub>n</sub>)<br><br>Prove or disprove<br>	true. pg 2424
What is the best algebraic form for evaluating interval polynomial expressions?	nested form. pg 2425<br>
Do exercise 5.11, pg 2426<br>	<br>
Do exercise 5.12, pg 2426<br>	<br>
Exercise 5.13, pg 2426<br>	<br>
Suppose F(X) is a natural interval extension of a real rational function f(x), and suppose we can evaluate F(X<sub>0</sub>) for some interval X<sub>0</sub> without encountering a division by an interval containing zero. What can be said about the range of f(x) for x in X<sub>0</sub>?<br>	pg 2426 "a further property of natural extensions"<br>
Give the definition of the standard metric function on real-endpoint intervals.<br>	pg 2429
Do exercise 6.1, pg 2429<br>	<br>
Do exercise 6.2, pg 2429<br>	<br>
Do exercise 6.3, pg 2429<br>	<br>
What is an <i>isometry</i>?<br>What does "the real line is isometrically embedded in the space of intervals" mean?<br><br>	mstudy pg 2429 (near bottom)<br><br>
Do exercise 6.4, pg 2430<br>	<br>
What doe it mean for an interval extension F to be <i>Lipschitz</i> in X<sub>0</sub>?<br>	mstudy pg 2430, def 6.1<br>
Let F be a natural interval extension of a real rational function with F(X) defined for X ⊆ X<sub>0</sub>, and where X and X<sub>0</sub> are intervals or n-dimensional interval vectors.<br><br>Consider the following statement:<br><br>F is Lipschitz in X<sub>0</sub><br><br>Prove or give a counterexample.<br>	mstudy pg 2430/2431<br>
Let f be a real-valued function that satisfies an ordinary Lipschitz condition on X<sub>0</sub>: |f(x) - f(y)| ≤ L|x - y| for x, y ∈ X<sub>0</sub><br><br>Consider the following statement:<br><br>The united extension of f is a Lipschitz interval extension in X<sub>0</sub><br><br>Prove or disprove.<br>	true mstudy pg 2431, lemma 6.2<br>
Let F and G be inclusion isotonic interval extensions with F Lipschitz in Y<sub>0</sub>, G Lipschitz in X<sub>0</sub>, and G(X<sub>0</sub>) ⊆ Y<sub>0</sub>.<br><br>Consider the following statment:<br><br>The composition H(X)=F(G(X)) is Lipschitz in X<sub>0</sub> and is inclusion isotonic.<br><br>Prove or disprove.<br><br>	mstudy pg 2431<br>todo: impostor?<br>
What is a <i>uniform subdivision</i> of an interval vector?<br>	mstudy pg 2432, def 6.2<br><br>
Let F(X) be an inclusion isotonic, Lipschitz, interval extension for X ⊆ X<sub>0</sub>.<br>What is a <i>refinement</i> of F over X?<br>	mstudy pg 2432, def 6.3<br>
Consider the following statement:<br><br>If X and Y are intervals such that X ⊆ Y, then there is an interval E with E<sub>lo</sub> ≤ 0 ≤ E<sub>hi</sub> such that Y = X + E and w(Y) = w(X) + w(E).<br><br>Prove or disprove.<br> 	true. mstudy pg 2432.<br>
What is the <i>excess width</i> of an interval extension?<br>	mstudy pg 2432, def 6.4<br>
Let F(X) be an inclusion isotonic, Lipschitz, interval extension for X ⊆ X<sub>0</sub>.<br><br>Consider the following statement:<br><br>The excess width of a refinement F<sub>(N)</sub>(X) is of order (1 / N), i.e.<br><br>F<sub>N</sub>(X) = f(X<sub>1</sub>,...,X<sub>n</sub>) + E<sub>N</sub><br><br>where w(E<sub>N</sub>) ≤ K·w(X)/N for some constant K<br><br>prove or disprove<br><br>	pg 2432<br>
Consider the following statement:<br><br>Every nested interval sequence {X<sub>k</sub>} converges and has the limit <$>\cap_{k=1}^{\infty}X_K</$>.<br><br>Prove or disprove.<br>	true. mstudy pg 2432.<br>todo: add impostor?<br>
Suppose {X<sub>k</sub>} is such that there is a real number x ∈ X</sub>k</sub> for all k. Define {Y<sub>k</sub>} by Y<sub>1</sub>=X<sub>1</sub> and Y<sub>k+1</sub> = X<sub>k+1</sub> ∩ Y<sub>k</sub> for k = 1,2,...<br><br>Consider the folowing statement:<br><br>Y<sub>k</sub> is nested with limit Y, and<br>x ∈ Y  ⊆ Y<sub>k</sub> for all k.<br><br>Prove or disprove.<br>	<br>interval analysis pg 2435, lemma 6.5<br>todo: impostor?<br><br>
What does it mean for an interval sequence {X<sub>k</sub>} to have <i>finite convergence</i>?	mstudy pg 2435, def 6.6<br>
Read Example 6.6, pg 2436	<br>
If we convert a normal numerical program to one in which all floating-point values have been replaced with intervals, do we need handle if statements differently at all? Explain.<br>	yes. pg 2439.<br>
What does FC<sub>n</sub>(X<sub>0</sub>) denote?	pg 2441
What is a <i>code list</i>? (also called <i>computational graphs</i>)	pg 2442 near top<br>
What is the downside to using uniform refinement to improve the precision of interval arithmetic?<br>	it's super slow... see pg 2442 near bottom<br>
Prove thm 6.2 pg 2443<br>	<br>
Do exercise 6.9, pg 2444<br>	<br>
Let g ∈ F<sup>ab</sup> and f ∈ F<sup>bc</sup> where a,b,c ∈ {∗, ω}. <br><br>Consider the following statement.<br><br>If b = ω and c = ∗, then f ∘ g has an extension d ∈ F<sup>a∗</sup> with dom(d) ∩ dom(g) = dom(f ∘ g), otherwise f ∘ g ∈ F<sup>ac</sup>.<br><br>Prove or disprove.<br>	true. mstudy pg 2118, thm 2.3.9.<br>TODO: add impostor<br><br>
Give the definition of the standard representations of the sets F<sup>ab</sup>, where a,b ∈ {∗, ω}. Explain the rationale behind this definition.<br><br>	mstudy pg 2119, def 2.3.10<br>
Consider the following statement:<br><br>For all a, b ∈ {∗, ω}, η<sup>ab</sup> is a representation of F<sup>ab</sup><br><br>Prove or disprove.	true. mstudy pg 2119, lemma 2.3.11<br>TODO: add impostor?<br>
Consider the following statement:<br><br>A function f :⊆ Σ<sup>a</sup> → Σ<sup>b</sup> is computable, iff f = η<sup>ab</sup><sub>p</sub> for some computable p ∈ Σ<sub>ω</sub>.<br><br>Prove or disprove.<br>	mstudy pg 2120, lemma 2.3.12<br>todo: add impostor?<br>
Consider the following statement:<br><br>For each a,b ∈ {∗, ω}, we have utm(η<sup>ab</sup>) and smn(η<sup>ab</sup>).<br><br>Prove or disprove.<br>	mstudy pg 2120. lemma 2.3.13<br>todo: add impostor?<br> 
Let β and γ be notations of a set G<sup>ab</sup> of functions f :⊆ Σ<sup>a</sup> → Σ<sup>b</sup>.<br><br>Consider the following statement:<br><br>( β ≤ γ and utm(γ) ) ⇒ utm(β)<br><br>Prove or disprove.<br><br><br>	true. mstudy pg 2121 thm 2.3.14<br>TODO: add impostor<br>
Let β and γ be notations of a set G<sup>ab</sup> of functions f :⊆ Σ<sup>a</sup> → Σ<sup>b</sup>.<br><br>Consider the following statement:<br><br>( smn(β) and β ≤ γ ) ⇒ smn(β)<br><br>Prove or disprove.<br><br><br>	true mstudy pg 2121. thm 2.3.14, pt 2<br>todo: add impostor?<br> 
Let β and γ be notations of a set G<sup>ab</sup> of functions f :⊆ Σ<sup>a</sup> → Σ<sup>b</sup>.<br><br>Consider the following statement:<br><br>( utm(β) and smn(γ) ) ⇒ β ≤ γ<br><br>Prove or disprove.<br><br>	pg 2121. thm 2.3.14, part 3<br>todo: add impostor?<br><br>
Let β, γ, and  δ be notations of a set G<sup>ab</sup> of functions f :⊆ Σ<sup>a</sup> → Σ<sup>b</sup> with utm(δ) and smn(δ).<br><br>Consider the following statement:<br><br>( utm(β) ) ⇒ β ≤ δ<br><br>Prove or disprove.<br><br>	true. mstudy pg 2121, thm 2.3.14, part 4.<br>todo: add impostor?<br><br><br><br>
Let β and  δ be notations of a set G<sup>ab</sup> of functions f :⊆ Σ<sup>a</sup> → Σ<sup>b</sup> with utm(δ) and smn(δ).<br><br>Consider the following statement:<br><br>smn(β) ⇒ δ ≤ β<br><br>Prove or disprove.<br><br>	true. mstudy pg 2121, thm 2.3.14 part 5<br>todo: add impostor?<br>
Let γ and  δ be notations of a set G<sup>ab</sup> of functions f :⊆ Σ<sup>a</sup> → Σ<sup>b</sup> with utm(δ) and smn(δ).<br><br>Consider the following statement:<br><br>( utm(γ) and smn(γ) ) ⇔ ( γ ≡ δ )<br><br>Prove or disprove.<br><br>	true. mstudy pg 2121.<br>todo: add impostor?<br><br>
What does it mean for a set A ⊆ Σ* to be recursive?<br>	pg 2124
What does it mean for a set A ⊆ Σ* to be recursively enumerable?<br>	mstudy pg 2124
Consider the following statement:<br><br>A set A is recursive iff it is r.e. and its complement is r.e.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 2124<br>
Let X ⊆ Z ⊆ Y := Y<sub>1</sub> × ... Y<sub>k</sub>.<br><br>What does it mean for X to be <i>recursively enumerable open</i> in Z?<br><br>	pg 2142
Let X ⊆ Z ⊆ Y := Y<sub>1</sub> × ... Y<sub>k</sub>.<br><br>What does it mean for X to be <i>decidable</i> in Z?<br><br>	mstudy pg 2124<br>
Consider the following statement:<br><br>If X is r.e. open in Z then X is open in Z.<br><br>Prove or disprove.	true mstudy pg 2125<br>
Consider the following statement:<br><br>If X is decidable in Z then X is clopen in Z.<br><br>Prove or disprove.	true. mstudy pg 2125.<br>TODO: add impostor<br>
Consider the following statement:<br><br>X is clopen in Z, iff there is a continuous function f :⊆ Y → Σ* with f(z) = 1 when z ∈ X, and f(z) = 0 when z ∈ Z \ X.<br><br>Prove or disprove.<br>	true. mstudy pg 2125. thm 2.4.3 (1)<br>TODO: add impostor
Consider the following statement:<br><br>X is decidable in Z iff there is a computable function f :⊆ Y → Σ* with f(z) = 1 when z ∈ X, and f(z) = 0, if z ∈ Z \ X.<br><br>Prove or disprove.<br><br>	true. mstudy pg 2125. thm 2.4.3 (2)<br>TODO: add impostor<br>
Consider the set X = { p ∈ Σ<sup>ω</sup> | p ≠ 0<sup>ω</sup> }.<br>Is X r.e. open? Is X decidable?	mstudy pg 2126, example 2.4.4 (2)<br>
Let < > be the tupling function. Consider the following statement. <br><br>A set X ⊆ Y<sub>1</sub> × ... Y<sub>k</sub> is r.e. open iff <X> is r.e. open.<br><br>Prove or disprove.<br>	true. mstudy pg 2126 (there is no proof there unfortunately)<br>TODO: add impostor<br>
Let X<sub>1</sub>,X<sub>2</sub>,Z ⊆ Y<sub>1</sub> × ... × Y<sub>k</sub>,with X<sub>1</sub>,X<sub>2</sub> ⊆ Z.<br><br>Consider the following statement:<br><br>If X<sub>1</sub> and X<sub>2</sub> are r.e. open in Z, then X<sub>1</sub> ∩ X<sub>2</sub> and X<sub>1</sub> ∪ X<sub>2</sub> are r.e. open in Z.<br><br>Prove or disprove.<br>	true. mstudy pg 2126, thm 2.4.5 (1)<br>todo: add impostor<br>
Let X<sub>1</sub>,X<sub>2</sub>,Z ⊆ Y<sub>1</sub> × ... × Y<sub>k</sub>,with X<sub>1</sub>,X<sub>2</sub> ⊆ Z.<br><br>Consider the following statement:<br><br>If X<sub>1</sub> and X<sub>2</sub> are decidable in Z, then X<sub>1</sub> ∩ X<sub>2</sub>, X<sub>1</sub> ∪ X<sub>2</sub>, and Z \ X are decidable in Z.<br><br>Prove or disprove.<br>	true. mstudy pg 2126. thm 2.4.5 (2)<br>todo: add impostor<br>
Let f :⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> → Y<sub>0</sub> and U,W ⊆ Y<sub>0</sub>.<br><br>Consider the following statement:<br><br>If f is computable and U is r.e. open (decidable) in W, then f<sup>-1</sup>[U] is r.e. open (decidable) in f<sup>-1</sup>[W].<br><br>Prove or disprove.<br>	true mstudy .pg 2126. them 2.4.5 (3).<br>todo: add impostor, separate parenthesized version.<br>
Let f :⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> → Y<sub>0</sub> and U,W ⊆ Y<sub>0</sub>.<br><br>Consider the following statement:<br><br>If f is computable, U is r.e. open, and f<sup>-1</sup>[W] is r.e. open, then f<sup>-1</sup>[U] is r.e. open.<br><br>Prove or disprove.<br>	true. mstudy pg 2127. cor 2.4.6 (1)<br>todo : add impostor<br>
Let f :⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> → Y<sub>0</sub> and U,W ⊆ Y<sub>0</sub>.<br><br>Consider the following statement:<br><br>If f is a total computable function and U is r.e. open (decidable), then f<sup>-1</sup> is r.e. open (decidable).<br><br>Prove or disprove.<br>	true. mstudy pg 2127. cor 2.4.6<br>todo: add impostor<br>
Let X ⊆ Y := Y<sub>1</sub> × ... × Y<sub>k</sub>. Consider the following statement:<br><br>The following properties are equivalent:<br>1. X is r.e. open<br>2. X = A∘Y for some r.e. set A ⊆ (Σ*)<sup>k</sup><br>3. X is open and {y ∈ (Σ*)<sup>k</sup> | y∘Y ⊆ X} is r.e.<br><br>Prove or give a counterexample.<br>	true. mstudy pg 2127. thm 2.4.7.<br>todo: add impostor<br>
What does it mean for a set X ⊆ Y = Y<sub>1</sub> × ... × Y<sub>k</sub> to be r.e.?<br><br>	mstudy pg 2128, def 2.4.9<br>
What does it mean for a set X ⊆ Y = Y<sub>1</sub> × ... × Y<sub>k</sub> to be <i>co-r.e.</i>?<br>	mstudy pg 2128, def 2.4.9<br>
What does it mean for a set X ⊆ Y = Y<sub>1</sub> × ... × Y<sub>k</sub> to be <i>recursive</i>?<br>	mstudy pg 2128, def 2.4.9<br>
Consider the following statement:<br><br>The recursive open subsets of Y := Y<sub>1</sub> × ... × Y<sub>k</sub> are <b>not</b> closed under union.<br><br>Prove or disprove.<br>	true. mstudy pg 2128, lemma 2.4.10<br>impostor has been added<br><br>
Consider the following statement:<br><br>The recursive open subsets of Y := Y<sub>1</sub> × ... × Y<sub>k</sub> are closed under union.<br><br>Prove or disprove.<br>	IMPOSTOR. mstudy pg 2128, lemma 2.4.10.<br>
Let X ⊆ Y := Y<sub>1</sub> × ... × Y<sub>k</sub>. Consider the following statment.<br><br>The following properties are equivalent:<br>1. X is r.e. open<br>2. There is some decidable set V ⊆ Y × Σ* such that X = {y ∈ Y | (∃u ∈ Σ*)(y,u) ∈ V}.<br>3. There is some r.e. open set V ⊆ Y × Σ* such that X = {y ∈ Y | (∃u ∈ Σ*)(y,u) ∈ V}.<br><br>Prove or disprove.<br><br>	true. mstudy pg 2129, thm 2.4.11.<br>todo: add counterexample.<br>
Consider the following statement: <br><br>Every decidable set X ⊆ Y<sub>1</sub> × ... × Y<sub>k</sub> is recursive. <br><br>Prove or disprove.	true. mstudy pg 2129.<br>todo: add impostor<br>
Consider the following statement:<br><br>There are decidable sets X ⊆ Y<sub>1</sub> × ... × Y<sub>k</sub>  which are not recursive. <br><br>Prove or disprove.<br><br><br>	IMPOSTOR. <br>mstudy pg 2129. <br><br>
Define the various type of dataflow nodes in C&C's abstract interpretation paper: "entries", "tests", "junction", "assignment", "exit".<br>	pg 2601, 2602
Give the logical type of the set of program states used in C&C's abstract interpretation paper.<br>	Arcs<sup>0</sup> x Env<br>pg 2602<br>
Give the definition of the <i>n-state</i> function used in C&C's abstract interpretation paper.	pg 2602 (bottom right)<br>
How is the set I-states, of initial states defined in C&C's abstract interpretation paper?	pg 2602 (bottom right)<br>
How do C&C define a <i>computation sequence</i> in their abstract interpretation paper?<br>	pg 2603 (top left)<br>
How do C&C define the "initial-to-final" state transition function in their abstract interpretation paper?<br>	pg 2603 (top-left)<br>
In C&C's abstract interpretation paper, if q is a program point (arc), then what does Cq denote?<br>	pg 2603 (left)
How is the <i>context vector</i> defined in C&C's abstract interpretation paper?<br>	mstudy pg 2603
In C&C's abstract interpretation paper, what is the <i>n-context</i> function used for? How is it defined?	pg 2603<br>
In C&C's abstract interpretation paper, what is the F-Cont function? How is it defined?	pg 2603 (top-right)<br>
How do we define the lattice join of two context vectors?<br>	pg 2603 (r)
How do we define the lattice order relation of two context vectors?<br>	pg 2603 (r)
Does the F-Cont function have fixpoints? Why?	pg 2603 (r)
How can the context vector <$>\underline{Cv}</$> be defined as a fixpoint?	pg 2603 (r)
Give the definition of an <i>abstract interpretation</i> of a program P.<br>	pg 2603 (bottom right)<br>
What is an <i>abstract context vector</i>, and why do the set of abstract context vectors form a complete lattice?	pg 2603/2604<br><br>Note that A-Cont is the set of abstract contexts and A-Cont with a wavy hat is the set of abstract context vectors.<br>
Give the definition of the <$>\underline{Int}</$> component of an abstract interpretation.<br>	pg 2604(l)<br>
Give a formula which describes how <$>\underline{Int}</$> is order preserving.<br>	pg 2604 (l)<br>
How can we characterize the abstract context vector resulting from the abstract interpretation I of a program P?<br>	by a fixpoint equation. <br>pg 2604 (bot left), right above section 5.2, and inside section 5.2 as well.<br><br>
How is <$>\widetilde{Int}</$> defined? Is it order-preserving? If so, why?	pg 2604 (left)
What is the purpose of defining joins ∪ and meets ∩ for abstract contexts?<br>	Not to deal with path convergence; that is a coincidence. It's to ensure the existence of extreme fixpoints.<br><br>pg 2604 (bot left)<br>
Give the definition of <i>accumulating semantics</i> as an abstract interpretation.	pg 2604, example 5.3.1<br>
In data-flow analysis, what is an "available expression"?	pg 2604 (r)<br>
Give the interpretation of basic nodes using <i>available expressions sets</i> as abstract contexts.<br>	(read the parenthesized text below the definition of avail: I'm not sure the psuedo-code makes any sense)<br><br>pg 2604 (r)<br>
Explain the difference between <i>syntactic</i> and <i>semantic</i> abstract interpretations.<br>	pg 2605<br>
What are the <$>\tilde{\alpha}</$> and <$>\tilde{\gamma}</$> functions, and what constraints are placed on these functions?<br>	note: the constraints we want here are 6.0-6.5<br>pg 2605<br>
Explain how the <i>overapproximation</i> property of the abstraction function α can be written as a local property rather than a global one.<br>	pg 2605 (top right)
Draw and annotate a commutative diagram describing the relationship between interpreting a command concretely and abstractly.<br>	pg 2605<br>
What does it mean for an interpretation I to be a <i>refinement</i> of another interpretation <$>\overline{I}</$>. What is the opposite of refinement?<br>	<br>pg 2605 (right)<br>
If I and I' are interpretations, what does I < (α ,γ) I' mean?<br>	pg 2605(r)
What makes the <i>accumulating semantics</i> interpretation I<sub>SS</sub> such a special interpretation?<br>	pg 2605 (right)<br>
Explain the interpretation I<sub>DS</sub>, for the deductive semantics of programs.<br>	pg 2605/2606.<br>
What does <$>R_{\vec{t}}</$> denote?	pg 2618 (r)<br>
How can we use parametricity to express the invariance of a transformation across changes in origin?<br>	pg 2518 (r)
Consider the following statement:<br><br>Changes in origin form an Abelian group.<br><br>Prove or disprove.<br>	true. not actually proven in paper, but it's straightforward. pg 2618 (r)<br>
Give the definitions of the index erasure and relational interpretations of vec⟨e⟩.<br>	pg  2619 (l)<br>
Give the definitions of the index erasure and relational interpretations of ∀x:T<sub>2</sub>.A<br>	pg 2619 (l)<br>
What is the type of the <i>affine combination</i> operator? What is the type of <i>vector addition</i>? Which of these operators is invariant under change of origin? Why?	pg 2619 (l)<br>
What are the types of the negate and subtraction operators for 2d vectors?<br>	pg 2619 (l,r)<br><br>
What is the type of the <i>offset</i> operator, which returns the vector offset between two points? (In Gallier's language, this would be point subtraction).<br>	pg 2619 (r)<br>
Give the erasure and relational semantics of vec<B,t>.	pg 2620
Give types for affComb (of 2 vecs), (+), negate, 0, and (*) (scalar times vector), where vec⟨B,E⟩ is used for 2d vectors.<br><br>	pg 2620
Give the type of the dot product operator.<br>	pg 2620
Give the types of cross product, absolute value, and determinant.<br>	pg 2620<br>
Give the type and implementation of a function that computes the area of a triangle. Also, give a specialized version in which the endpoints of the triangle are expressed in an orthogonal basis.<br>	pg 2620<br>
What does the type real<e> represent? What are the types of the operators and special constants defined on it?<br>	pg 2620 (l) fig 2.<br>
Is the ≤ (α,β) relation comparing levels of abstraction a poset? Is it a preorder? Why?	pg 2606<br>
If I and I' are abstract interpretations, then what does I ≡ I' mean?<br>	pg 2606 (r)
Consider the following statement:<br><br>(I ≡ (β)I') ⇔ (β is an isomorphism between algebras I and I')<br><br>Prove or disprove.<br><br><br><br>	pg 2606<br>
Describe how a program with one integer variable can be abstracted by an interpretation whose contexts form a complete lattice of integer intervals. Explain how the interval abstraction can further be abstracted into a sign & literal interpretation.<br><br>	pg 2607 (l)<br>
Consider the following statement:<br><br>If equivalent intepretations of a program are identified, and if we restrict only to interpretations which abstract accumulating semantics, this set of interpretations I forms a lattice.<br><br>Prove or disprove.	true. pg 2606 (r).<br>
Consider the following statement:<br><br>The set of interpretations I of a program forms a lattice.<br><br>Prove or disprove.	IMPOSTOR.<br><br>When multiple equivalent interpretations are taken into account, this does not hold, since the underlying set isn't even a poset (can you give a concrete example of equivalent interpretations?)<br><br>When interpretations that do not abstract accumulating semantics are taken into account, this does not hold (because there isn't a bottom element?).<br><br>pg 2606 (r)<br>
Draw a Hasse diagram for a lattice of various interpretations of programs having one integer variable.<br>	pg 2607 (r)<br>
How can abstract interpretation be performed when the least fixpoint of F-Cont is unreachable?<br>	pg 2608 (top-right, sec 9., sec 9.1)<br>
When the least fixpoint of an abstract interpretation's Int function is unreachable, we can instead look for an upper bound of the least fixpoint. Why is this useful?<br>	pg 2608, section 9.1<br>
What criteria constrain an <i>increasing approximate interpretation function</i> of a given abstract interpretation I?<br>	pg 2608 (r) 9.1.1.1, 9.1.1.2<br>
Suppose that we have an <i>increasing approximate interpretation function</i> A-Int for an abstract interpretation I. Given an algorithm for computing an increasing approximation sequence from A-Int and the interpretation function Int of I.<br><br>What useful properties does this sequence have? Prove your answer. 	pg 2608 (r), 2609 (l)<br>
Let (q,r) ∈ Arcs<sup>2</sup>. What does it mean for the context associated with q to be dependent upon the context associated with r?<br>	pg 2609<br>
In a forward system of equations the context associated to q may only depend on the contexts ____________.<br>	pg 2609 (l)<br>
In a system of equations <$>\underline{Cv} = \underline{\widetilde{Int}}(Cv)</$>, what is a cycle?<br>	pg 2609 (l)<br>
Suppose the existence of an infinite, strictly increasing Kleene sequence. Why might such a sequence exist?	answer: cycles<br>pg 2609 (l)<br>
What is the purpose of a widening operator ▽? Give the type signature of widening operators, as well as the logical constraints imposed on them.<br>	pg 2609 (l), 9.1.3.2, 9.1.3.3<br><br>
Give the definition of the set W-Arcs of widening arcs. 	pg 2609 (l)<br>
How can a widening operator ▽ be used to define an <i>increasing approximation interpretation</i>? Prove your answer.	mstudy pg 2609 (l)<br><br>
Here is a program:<br><br><i><br>begin<br><br>x := 1<br>while x <= 100:<br>  x := x + 1<br><br>end<br></i><br><br>Suppose we abstract x using integer intervals. What can go wrong with this abstract interpretation, and how do we solve it?<br>	pg 2609/2610, example 9.2: Bounds of Integer Variables<br><br>
Do Exercise 2.4.5, pg 2129<br><br>	<br>
Do Exercise 2.4.6, pg 2129<br><br>	<br>
Do Exercise 2.4.7, pg 2129<br><br>	<br>
Do Exercise 2.4.10, pg 2130<br>	<br>
Do Exercise 2.4.11, pg 2130<br><br><br>	<br>
Consider the following statement:<br><br>All naming systems must be total functions.<br><br>True or false?	false. pg 2132.<br>
Consider the following statement:<br><br>All naming systems must be 1-1 functions.<br><br>True or false?	False. pg 2132.<br>
Explain the notation and definition for rational number used by Weirauch.<br>	pg 2132, def 3.1.2, 4<br>
Give the definition of the <i>enumeration</i> representation of sets of natural numbers.<br>	pg 2132. def 3.1.2 - 5 (see sticky note)
Give the definition of the <i>characteristic function</i> representation of sets of natural numbers.<br>	pg 2132, def 3.1.2 - 6.<br>
Let Δ ⊆Σ. Give the definition of the <i>enumeration representation</i> of 2<sup>Δ*</sup>.<br>	pg 2132, def 3.1.2 - 7.<br><br>
Let γ :⊆ Y → M be a naming system, and let x ∈ M.<br><br>What does it mean for the element x to be <i>γ-computable</i>?<br><br>	pg 2132, def 3.1.3 1.)<br>
Let γ :⊆ Y → M be a naming system and X ⊆ M.<br><br>What does it mean for X to be γ-open?<br>What does it mean for X to be γ-clopen?<br>What does it mean for X to be γ-r.e.?<br>What does it mean for X to be γ-decidable?<br><br><br>	pg 2133, def 3.1.3 - 2.<br><br>
Let γ :⊆ Y → M be a naming system and X ⊆ M.<br><br>What is the <i>final topology</i> of γ on M?<br>	pg 2132, def 3.1.3 - 2.<br><br>
Let γ :⊆ Y → M and γ<sub>0</sub> :⊆ Y<sub>0</sub> → M<sub>0</sub> be naming systems and f :⊆ M → M<sub>0</sub> be a function.<br><br>What is a (γ, γ<sub>0</sub>)-realization of f?<br>What does it mean for f to be (γ, γ<sub>0</sub>)-continuous?<br><br><br><br>	pg 2133, def 3.1.3 - 3.<br><br>
Let γ :⊆ Y → M and γ<sub>0</sub> :⊆ Y<sub>0</sub> → M<sub>0</sub> be naming systems and F :⊆ M ⇉ M<sub>0</sub> be a function.<br><br>What is a (γ, γ<sub>0</sub>)-realization of F?<br>What does it mean for F to be (γ, γ<sub>0</sub>)-continuous?<br><br><br><br>	pg 2133. def 3.1.3 -4.<br>
Let γ :⊆ Y → M and γ<sub>0</sub> :⊆ Y<sub>0</sub> → M<sub>0</sub> be naming systems and F :⊆ M ⇉ M<sub>0</sub> be a function.<br><br>What is a <i>choice function</i> for F?<br>	pg 2133, def 3.1.3 - 5.<br><br>
Consider the following statement:<br><br>If <i>Δ ⊢ A ≡ B type</i> then ⌊A⌋ = ⌊B⌋.<br><br>Prove or disprove.<br><br><br><br><br>	pg 2623, lemma 1-1<br>
Consider the following statement:<br><br>If <i>Δ' ⊢ A type</i> and <i>Δ ⊢ σ ⇒ Δ'</i>, then ⌊σ* A⌋ = ⌊A⌋.<br><br>Prove or disprove.<br>	pg 2623. lemma 1-2.<br>
Give the inductive definition of the index erasure interpretation of types.<br>	pg 2623 "Interpretation of Types"<br>
Give the index-erasure interpretation of well-indexed type contexts.<br>	pg 2623 "Interpretation of Terms"<br>
Give the index-erasure interpretation of well-typed terms.	pg 2623 "Interpretation of Terms"<br>
What does it mean for two terms to be <i>contextually equivalent</i> in algebraically indexed type semantics?<br>	pg 2623 (r), "Contextual Equivalence"<br>
What does it mean for two well-indexed types to be isomorphic?	pg 2623, "Type Isomorphisms"<br>
Consider the following statement:<br><br>Isomorphism of well-indexed types is a congruence with respect to type formation.<br><br>Prove or disprove.<br>	pg  2623 "Type Isomorphism"<br>
What is an <i>index environment</i> ρ?	pg 2623 "The Relational Interpretation of Types"<br>
Regarding algebraically indexed types, what is the definition of a <i>model</i>?<br>	pg 2624 "Models"<br>
How are index environments and index expressions interpreted under a model?<br>	pg 2624 "models"<br>
Regarding algebraically indexed types, what does it mean for a model to be sound?	pg 2624, "Models"<br><br>
Given ρ ∈ [[Δ]] and substitution Δ ⊢ σ ⇒ Δ', what is the definition of the composed index environment ρ∘σ?<br>	pg 2624, "Models"<br>
How are the relational interpretations of primitive types defined?<br>	pg 2624<br>
Give the inductive definition of the relational interpretation of types. How are the operators <$>\widehat{+}</$>, <$>\widehat{\rightarrow}</$>, and <$>\widehat{\times}</$> on binary relations defined?<br>	pg 2624, "Relational Interpretation of Types"<br>
Consider the following statement:<br><br>If <i>Δ ⊢ A ≡ B type</i>, then [[A]] = [[B]]<br><br>Prove or disprove.<br>	true. pg 2624, lemma 2-1<br>
Consider the following statement:<br><br>If <i>Δ' ⊢ A type</i> then for all <i>Δ ⊢ σ ⇒ Δ'</i> and ρ ∈ [[Δ]],<br>[[σ* A]]<sub>ρ</sub> = [[A]](ρ ∘ σ).<br><br>Prove or disprove.<br>	pg 2624, lemma 2-2.<br><br>
How is the relational interpretation of typing contexts defined?<br><br>State the <i>abstraction theorem</i> (hint: it utilizes the relational interpretation of typing contexts).<br>	pg 2624, "The Abstraction Theorem"<br>
Once an upper bound on the least fixpoint of Cv has been obtained via an ascending approximation sequence, is there anything that can be done to obtain a <i>better</i> approximation? What?<br>	Yes, a decreasing approximation sequence can be used. <br>pg 2610, sec 9.3<br>
Give the two criteria for an interpretation D-Int of a decreasing sequence. How can D-Int be used to define a truncated decreasing sequence (i.e. give the n<sup>th</sup> element s<sub>n</sub>). What desirable properties does the truncated decreasing sequence have?<br>	pg 2611, below 9.3.2.3<br><br>
What two creiteria must a narrowing operator Δ meet?<br>What is the purpose of narrowing operators?<br>	pg 2611, section 9.3.4<br>1.) see 9.3.4.2 and 9.3.4.3<br>2.) in order to construct D-Int 9.3.4.4<br><br>
Define an interpretation operator for a truncated decreasing sequence, D-Int, by using a narrowing operator Δ.<br>	pg 2611. 9.3.4.4.<br>
How would we define a narrowing operator Δ for extended integer intervals?<br>	pg 2611, example 9.4<br>
Consider the following statement:<br><br>The ascending approximation sequence and the truncated decreasing sequence are duals.<br><br>Prove or disprove.<br>	IMPOSTOR<br>pg 2612 (2nd pargraph on right.)<br>
Let γ :⊆ Y → M be a naming system.<br><br>Is τ<sub>γ</sub>, the final topology on γ, actually a topology?<br><br>Why or why not?<br>	pg 2133
A (γ,γ<sub>0</sub>)-realization g of a function f must be "(γ,γ<sub>0</sub>)-extensional" on dom(f∘γ). What does "(γ,γ<sub>0</sub>)-extensional" mean, and why is this the case?<br>	pg 2134<br>
Consider the following statement:<br><br>The real number π ∈ <b>R</b> is ρ<sub>b,10</sub>-computable, where ρ<sub>b,10</sub> is the representation of real numbers by infinite decimal fractions.<br><br>Prove or disprove.<br>	true. pg 2134-1<br>
Consider the following statement:<br><br>A tuple (x<sub>1</sub>, ..., x<sub>k</sub>) is (γ<sub>1</sub>,...,γ<sub>k</sub>)-computable, iff x<sub>i</sub> is γ<sub>i</sub>-computable for 1 ≤ i ≤ k.<br><br>Prove or disprove.<br>	true. pg 2134-2<br>
What is a <i>sequence</i>? What does it mean for a sequence to be γ-computable?<br>	pg 2134-3<br>
Consider the following statement:<br><br>Let N,Z,and Q be the sets of natural numbers, integers, and rationals.<br><br>The sets {0}, N, Z and {a ∈ Q | a > 0} are ν<sub>Q</sub>-decidable.<br><br>Prove or disprove.<br>	true. pg 2135-5.<br>TODO: add impostor<br>
Let Q be the set of rationals.<br><br>Consider the following statement:<br><br>The set { (a,b) ∈ Q<sup>2</sup> | a < b } is ( ν<sub>Q</sub>, ν<sub>Q</sub> )-decidable.<br><br>Prove or disprove.<br>	true. pg 2135-5.<br>TODO: add a counterexample.<br>
What does it mean for a set to be En-computable? What does it mean for a set to be Cf-computable?<br><br>Can we characterize the properties En-computable and Cf-computable purely in terms of recursion theory?<br>	pg 2135-6<br><br>note: En and Cf are representations on sets of naturals defined on pg 2132<br>
Let N be the set of naturals, Z the integers, and Q the rationals.<br><br>Consider the following statement:<br><br>ν<sub>N</sub> ≤ ν<sub>Z</sub> ≤ ν<sub>Q</sub><br><br>Prove or disprove.<br>	true. pg 2135-7.<br>TODO: add impostor!<br>
Let N be the set of natural numbers.<br><br>Consider the following statement:<br><br>Addition is (ν<sub>N</sub>,ν<sub>N</sub>,ν<sub>N</sub>)-computable.<br><br>Prove or disprove.<br>	true. mstudy pg 2135-8.<br>
Let Q be the set of rationals.<br><br>Consider the following statement:<br><br>Inversion is (ν<sub>Q</sub>,ν<sub>Q</sub>)-computable.<br><br>Prove or disprove.<br>	true. pg 2135-8.<br>TODO: add impostor?<br>
What is a <b>category</b>?	pg 2660
Explain the category <b>Sets</b> of sets and functions. Also, explain the category <b>Sets<sub>fin</sub></b>.<br><br>	pg 2661
Consider the following "Category".<br><br>Objects : <br>sets<br><br>Arrows: <br>functions f : A → B such that  f<sup>-1</sup>(b) has at most  two elements.<br><br>Is this a category? Why or why not?<br>	I don't think so. Let A = {1,2,3,4}, let g : A -> A be defined such that g(1) = 1, g(2) = 1, g(3) = 2, and g(4) = 2.<br><br>Then g is in the "category", but g ∘ g is not. Therefore, it cannot be a category.<br><br>pg 2661/2662<br>
Explain the category <b>Pos</b> of posets and monotone functions.<br>	pg 2662 (item 3, rolls over to 2663)<br>
What, intuitively, is a <i>concrete category</i>? How do concrete categories differ from abstract categories?<br>	pg 2663 (item 4)<br>
Explain the category <b>Rel</b> of binary relations.<br>	pg 2663<br>
How can matrix multiplication be abstracted as a category?<br>	this is a weird example, but whatever. when he says "unit matrices", does he mean "square matrices? this means that objects do not have unique identity arrows, which I guess is allowable. oh.. I think I see: any n x n matrix could have been chosen as the identity arrow, and he choses the unit matrix.<br><br><br>pg 2663 (bottom of point 4)<br>
Draw diagrams for the categories <b>1</b>, <b>2</b>, <b>3</b>, and <b>0</b>.<br>	pg 2663/2664<br>
When constructing a category by drawing a diagram, what care must be taken if one wishes to avoid constructing an infinite category?<br>	(avoid loops)<br>pg 2664<br>
What is a <b>functor</b>? Provide a definition.<br>	pg 2664/2663<br>
What is the category <b>Cat</b>? Provide a definition.<br>	pg 2665<br>
Any pre-order can be regarded as a category. Explain how this is so.<br>	pg 2665 (point 7)<br>
Any poset can be considered a category. Explain how this is so.	any pre-order can be considered a category, and posets are pre-orders<br>pg 2665/2666<br>
How can monotone maps on posets be positioned into the framework of category theory?<br>	pg 2666, near top<br>
Every deductive system of logic has an associated <i>category of proofs</i>. Explain.	pg 2666
Explain how every typed functional programming language has an associated category.<br>	pg 2666 (11, near bottom)<br>
Let X be an arbitrary set. What is the category <b>Dis</b>(X)? Provide a definition.<br>	pg 2667<br>
How can a monoid be considered a category?<br>	pg 2667 (point 13)<br>
What is the category <b>Mon</b> of monoids? Provide a definition.	pg 2667, near bottom<br>
What is the category theoretic definition of an <i>isomorphism</i>?<br>	pg 2668
What is the category theoretic definition of a <i>group</i>?	pg 2668<br>
Let f<sub>1</sub>,...,f<sub>k</sub> be real functions on [a, b] and let <b>f</b>=(f<sub>1</sub>,...,f<sub>k</sub>) be the corresponding mapping of [a, b] into R<sup>k</sup>. If α increases monotonically on [a, b], what does <b>f</b> ∈ 𝓡(α) mean? How is <$>\int_{a}^{b}\textbf{f} d\alpha</$> defined?<br><br>  	pg 1374<br><br>
What is a <i>curve</i> in R<sup>k</sup>. Give the definition.	pg 1375
What is an <i>arc</i> in R<sup>k</sup>. Give the definition.	pg 1375<br>
What does it mean for a curve in R<sup>k</sup> to be <i>closed</i>?<br>	pg 1375<br>
What does it mean for a curve in R<sup>k</sup> to be <i>rectifiable</i>?	pg 1375<br>
What does it mean for a sequence {f<sub>n</sub>} to converge to a function f?<br>	pg 1382<br>
If {f<sub>n</sub>} is a sequence of functions, what does Σf<sub>n</sub> denote?<br>	pg 1383
To ask whether the limit of a sequence of continuous functions is continuous is the same as to ask whether _________________.<br>	pg 1383<br>
Consider the following "double sequence":<br><br>s<sub>m,n</sub> = m / (m + n)<br><br>Does <$$>lim_{n \rightarrow \infty} lim_{m \rightarrow \infty} s_{m,n} = lim_{m \rightarrow \infty} lim_{n \rightarrow \infty} s_{m,n}</$$>?	no. pg 1383/1384<br>
Consider the following statement:<br><br>A convergent series of continuous functions is continuous.<br><br>Prove or disprove.<br><br>	FALSE. pg 1384<br>
If <$>f_n(x) = \frac{sin(nx)}{\sqrt{n}}</$>, what can be said about the functions that the sequences {f<sub>n</sub>} and {f'<sub>n</sub>} converge to?<br>	pg 1385<br>
If E is a set, what does it mean for a sequence of functions {f<sub>n</sub>} to <i>converge uniformly</i> on E to a function f?<br>	pg 1386<br>
What is the difference between uniform convergence and pointwise convergence for a sequence of functions {f<sub>n</sub>}?<br>	pg 1386, below def 7.7<br>
If E is a set, and {f<sub>n</sub>} is a sequence of functions, what does it mean for the series Σf<sub>n</sub> to converge uniformly on E?	pg 1386, right above thm 7.8
State and prove the Cauchy criterion for the uniform convergence of a sequence of functions {f<sub>n</sub>}.<br>	pg 1386, thm 7.8<br>
Suppose<br><br><$>lim_{n \rightarrow \infty}f_n(x) = f(x)</$><br><br>and define M<sub>n</sub> such that<br><br><$>M_n = sup_{x \in E} |f_n(x) - f(x)|</$><br><br>Consider the following statement.<br><br>f<sub>n</sub> → f uniformly on E if and only if M<sub>n</sub> → 0 as n → ∞.<br><br>Prove or disprove.<br>	true. thm 7.9, pg 1387.<br>
Suppose {f<sub>n</sub>} is a sequence of functions defined on E, and suppose |f<sub>n</sub>(x)| ≤ M<sub>n</sub>. <br><br>Consider the following statement.<br><br>Σf<sub>n</sub> converges uniformly on E if M<sub>n</sub> converges.<br><br>Prove or disprove.<br>	pg 1387, thm 7.10<br>
Suppose f<sub>n</sub> → f uniformly on a set E in a metric space. Let x be a limit point of E, and suppose that <br><$>lim_{t \rightarrow x}f_n(t)=A_n</$><br><br>Consider the following statement:<br><br>{A<sub>n</sub>} converges and <br><$> lim_{t \rightarrow x}f(t) = lim{t \rightarrow \infty}A_n</$><br><br>Prove or disprove.<br><br>	true. thm 7.11 pg 1388<br>TODO: add impostor<br>
Let {f<sub>n</sub>} be a sequence of continuous functions on E.<br><br>Consider the following statement:<br><br>If f<sub>n</sub> → f uniformly on E, then f is continuous on E.<br><br>Prove or disprove.<br>	true. pg 1389, thm 7.12<br>
Let {f<sub>n</sub>} be a sequence of continuous functions on E.<br><br>Consider the following statement:<br><br>If f<sub>n</sub> → f, then f is continuous on E.<br><br>Prove or disprove.<br>	IMPOSTOR. the sequence must converge to f <b>uniformly</b>.<br>thm 7.12, pg 1389.<br>
Consider the following statement:<br><br>If a sequence of continuous functions converges to a continuous function, the convergence must be uniform.<br><br>Prove or disprove.<br>	IMPOSTOR:<br><br>example 7.6 on pg 1385 is an example of this.<br>to see this, apply thm 7.9 (pg 1387).<br><br>
Suppose K is compact, and<br><br>(a) {f<sub>n</sub>} is a sequence of continuous functions on K.<br>(b) {f<sub>n</sub>} converges pointwise to a continuous function on K<br>(c) f<sub>n</sub>(x) ≥ f<sub>n+1</sub>(x) for all x ∈ K, n = 1,2,3, ...<br><br>Consider the following statement:<br><br>f<sub>n</sub> → f uniformly on K.<br><br>Prove or disprove.<br>	true. pg 1389<br><br>TODO: add impostor<br>
If X is a metric space, then what does𝒞(X) denote?<br> 	the set of all complex-valued, continuous, bounded functions with domain X.<br>pg 1389, def 7.14<br><br>
Let X be a metric space with metric d<sub>X</sub>, and f ∈𝒞(X). What is the definition of the <i>supremum norm</i> of f?<br><br><br> 	pg 1389<br>
Let X be a metric space and f,g ∈𝒞(X).<br><br>Consider the following statement:<br><br>|| f + g || ≤ || f || + || g ||<br><br>Prove or disprove.<br> 	pg 1389<br>
If X is a metric space and f, g ∈ 𝒞(X), define the <i>distance</i> between f and g as || f - g ||.<br><br>Consider the following statement:<br><br>The above distance function is a metric, which makes 𝒞(X) into a complete metric space.<br><br>Prove or disprove.<br>  	pg 1390, thm 7.15<br>
Let α be monotonically increasing on [a,b]. Suppose f<sub>n</sub> ∈ 𝓡(α) on [a,b], for n = 1,2,3, ..., and suppose f<sub>n</sub> → f uniformly on [a,b]. <br><br>Consider the following statement:<br><br>f ∈ 𝓡(α) on [a,b], and<br><$>\int_{a}^{b}f d\alpha = lim_{n \rightarrow \infty} \int_a^b f_n d\alpha</$><br><br>Prove or disprove.<br>  	true. mstudy pg 1390<br>TODO: add impostor<br>
Suppose {f<sub>n</sub>} is a sequence of functions, differentiable on [a,b] and such that {f<sub>n</sub>(x<sub>0</sub>)} converges for some point x<sub>0</sub> on [a,b].<br><br>Consider the following statement:<br><br>If {f'<sub>n</sub>} converges uniformly on [a,b], then {f<sub>n</sub>} converges uniformly on [a, b], to a function f, and <br><br><$>f'(x) = lim_{n \rightarrow \infty} f'_n(x)</$> <br><br>for a ≤ x ≤ b.<br><br>Prove or disprove.<br> 	true. pg 1391.<br>TODO: add impostor<br>
Consider the following statement:<br><br>There exists a real continuous function on the real line which is nowhere differentiable.<br><br>Prove or disprove.<br>	true. thm 7.18 pg 1393<br>
What does it mean for a sequence of functions {f<sub>n</sub>} to be <i>pointwise bounded</i>? What about <i>uniformly bounded</i>?<br>	pg 1394, def 7.19<br>
What does it mean for a family 𝔉 of complex functions f defined on a set E in a metric space X to be <i>equicontinuous</i> on E?<br> 	pg 1395, def 7.22<br>
Let {f<sub>n</sub>} be a pointwise bounded sequence of complex functions on a countable set E.<br><br>Consider the following statement:<br><br>{f<sub>n</sub>} has a subsequence {f<sub>n<sub>k</sub></sub>} such that {f<sub>n<sub>k</sub></sub>(x)} converges for every x ∈ E.<br><br>Prove or disprove.<br>	true. pg 1395, thm 7.23<br>TODO: add impostor<br>
What is an <i>analytic function</i>? Provide a definition.	pg 1411<br>
If f(x) is an analytic function, what does it mean for f to be expanded in a power series about a point x=a?<br>	pg 1411<br>
Suppose the series<br><$$> (1) \sum_{n=0}^{\infty}c_n x^n</$$><br>converges for |x| < R, and define<br><$$> f(x) = \sum_{n=0}^{\infty}c_n x^n</$$><br><br>Consider the following statement:<br><br>(1) converges uniformly on [-R + ε, R - ε], no matter which ε > 0 is chosen. The function f is continuous and differentiable in (-R,R), and <br><br><$$>f'(x) = \sum_{i=1}^{\infty}nc_nx^{n-1}\ \ \ (|x| < R)</$$><br><br>Prove or disprove.<br><br>	true. pg 1412<br>TODO: add impostor<br>
Suppose the series<br><$$> (1) \sum_{n=0}^{\infty}c_n x^n</$$><br>converges for |x| < R, and define<br><$$> f(x) = \sum_{n=0}^{\infty}c_n x^n</$$><br><br>Consider the following statement:<br><br>f has derivatives of all orders in (-R, R), which are given by<br><br><$$>f^{k}(x) = \sum_{n=k}^{\infty} n(n-1) \cdots (n-k+1)c_nx^{n-k}</$$><br><br>Prove or disprove.<br>	true. pg 1412<br>TODO: add impostor<br>
Suppose the series<br><$$> (1) \sum_{n=0}^{\infty}c_n x^n</$$><br>converges for |x| < R, and define<br><$$> f(x) = \sum_{n=0}^{\infty}c_n x^n</$$><br><br>Consider the following statement:<br><br>for all k ≥ 0,<br><br><$$>f^{k}(0) = k!c_k</$$><br><br>Prove or disprove.<br>	true. pg 1412.<br>TODO: add impostor<br>
Suppose Σc<sub>n</sub> converges. Let<br><br><$$> f(x) = \sum_{n=0}^{\infty} c_n x^n\ \ \ (-1 < x < 1)</$$><br><br>Consider the following statement:<br><br><$$>lim_{x \rightarrow 1}f(x) = \sum_{n=0}^{\infty}c_n</$$><br><br>Prove or disprove.<br><br><br><br>	true. pg 1413, thm 8.2.<br>TODO: add impostor<br>
Given a double sequence {a<sub>ij</sub>, i = 1, 2, 3, ..., j = 1, 2, 3, ....<br>Suppose that<br><$$>\sum_{j=1}^{\infty} |a_{ij}| = b_i\ \ \ (i = 1, 2, 3, ...)</$$><br>and Σb<sub>i</sub> converges.<br><br>What can be said of<br><$$>\sum_{i=1}^{\infty}\sum_{j=1}^{\infty}a_{ij}</$$><br>Prove your answer.<br>	pg 1414<br>
State and prove Taylor's theorem.<br>	pg 1415, thm 8.4.<br>
Consider the following statement:<br><br>It is possible for two power series converging to the same function in interval (-R, R) to be distinct.<br><br>Prove or disprove.<br>	false. see section above thm 8.5, pg 1416.<br>
Suppose the series Σa<sub>n</sub>x<sup>n</sup> and Σb<sub>n</sub>x<sup>n</sup> converge in the segment S = (-R, R). Let E be the set of all x ∈ S at which<br><br><$$>(1)\ \ \sum_{n=0}^{\infty}a_n x^n = \sum_{n=0}^{\infty}b_n x^n</$$><br><br>Consider the following statement:<br><br>If E has a limit point in S, then a<sub>n</sub>=b<sub>n</sub> for n = 0, 1, 2.<br>Hence, (1) holds for all x ∈ S.<br><br>Prove or disprove.	true. pg 1416, thm 8.5<br>TODO: add impostor<br>
How is the exponential function defined, and how can the preopreties of exponents be derived from this definition?<br>	pg 1417/1418<br>
Let e<sup>x</sup> = <$>sum_{n=0}^{\infty} \frac{x^n}{n!} </$>.<br><br>Consider the following statement:<br><br>e<sup>x</sup> → +∞ as x → +∞, and e<sup>x</sup> → 0 as x → -∞<br><br>Prove or disprove.<br>	true. pg 1419, thm 8.6 (e)<br>
Let e<sup>x</sup> = <$>\sum_{n=0}^{\infty} \frac{x^n}{n!} </$>.<br><br>Consider the following statement:<br><br><$$>lim_{x \rightarrow +\infty}x^n e^{-x} = 0</$$><br><br>for every n.<br><br>Prove or disprove.<br>	true. pg 1419<br>todo: add impostor<br>
What is the definition of the group Aut(X)?<br>	pg 2668
What is a <i>group of permutations</i>, defined in terms of category theory?	pg 2668, near bottom
What is a <i>homomorphism of groups</i>, defined in terms of category theory?	pg 2669, near top.<br>
Prove Cayley's Theorem (Every group G is isomorphic to a group of permutations) using category theory.<br>	pg 2669<br>
Consider the following statement:<br><br>Every category with a set of arrows is isomorphic to one in which the objects are sets and the arrows are functions.<br><br>Prove or disprove.	pg 2669
Consider the following statement:<br><br>The Scott topology is the final topology of En, the enumeration representation of sets of natural numbers.<br><br>Prove or disprove.<br>	true. pg 2135/2136 (11).<br>
Consider naming systems γ :⊆ Y → M and γ<sub>0</sub> :⊆ Y<sub>0</sub> → M<sub>0</sub>.<br><br>Consider the following statement:<br><br>γ ≤ γ<sub>0</sub> (γ ≤<sub>t</sub> γ<sub>0</sub>), iff M ⊆ M<sub>0</sub> and the identical embedding id<sub>M M<sub>0</sub></sub> is (γ ≤<sub>t</sub> γ<sub>0</sub>)-computable (-continuous).<br><br>Prove or disprove.	true. pg 2136. lemma 3.1.5 (1)<br>TODO: add impostor.<br>
Consider naming systems γ :⊆ Y → M and γ<sub>0</sub> :⊆ Y<sub>0</sub> → M<sub>0</sub>.<br><br>Consider the following statement:<br><br>A function f :⊆ M → M<sub>0</sub> is (γ,γ<sub>0</sub>)-computable (-continuous), iff f ∘ γ ≤ γ<sub>0</sub> (f ∘ γ ≤<sub>t</sub> γ<sub>0</sub>)<br><br>Prove or disprove.<br>	true. pg 2136. lemma 3.1.5 (2)<br>
Let γ :⊆ Y → M and γ' :⊆ Y → M' be naming systems.<br><br>Let f :⊆ M → M' be (γ,γ')-computable and let f<sub>a</sub> :⊆ Σ* × M' × M → M' be (id<sub>Σ*</sub>, γ', γ, γ')-computable for each a ∈ Σ.<br><br>Define g :⊆ Σ* × M → M by<br>g(λ,x) = f(x)<br>g(aw,x) = f<sub>a</sub>(w, g(w,x),x)<br><br>for all x ∈ M, a ∈ Σ, w ∈ Σ*.<br><br>Consider the following statement:<br><br>The function g is (id<sub>Σ*</sub>,γ,γ')-computable.<br><br>Prove or disprove.<br><br>	true. pg 2137, thm 3.1.7 (1).<br>Todo: add impostor<br>
Let γ :⊆ Y → M and γ' :⊆ Y → M' be naming systems. Let <b>N</b> denote the natural numbers.<br><br>Let f :⊆ M → M' be (γ,γ')-computable and let f' :⊆ <b>N</b> × M' × M → M' be (ν<sub><b>N</b></sub>, γ', γ, γ')-computable Define g' :⊆ <b>N</b> × M → M' by<br>g'(0,x) = f(x)<br>g'(n+1,x) = f'(n,g'(n,x),x)<br><br>for all x ∈ M, n ∈ <b>N</b>.<br><br>Consider the following statement:<br><br>The function g is (ν<sub><b>N</b></sub>, γ, γ')-computable.<br><br>Prove or disprove.<br>	true. mstudy pg 2137, thm 3.1.7 (2).<br>todo: add impostor.<br>
If <b>C</b> and <b>D</b> are categories, what does <b>C</b> × <b>D</b> denote?<br>	pg 2670/2671<br>
If <b>C</b> is a category, then what does <b>C</b><sup>op</sup> denote?	pg 2671
If <b>C</b> is a category, then what does <b>C</b><sup>→</sup> denote?<br>	pg 2671/2672
If <b>C</b> is a category and C is an object of <b>C</b>, then what does <b>C</b>/C denote? What about C/<b>C</b>?<br>	pg 2672, 2673<br><br>
If g : C → D is any arrow, then there exists a composition functor<br><br>g<sub>*</sub> : <b>C</b>/C → <b>C</b>/D <br><br>How does this functor work?<br>	pg 2672/2673<br>
Explain the functor<br><br><b>C</b>/(-) : <b>C</b> → <b>Cat</b><br><br>Prove that it is actually a functor	pg 2673
How can the coslice category C/<b>C</b> be defined in terms of the slice category <b>C</b>/C and the opp construction?<br>	pg 2673<br>
Give the definition of the category <b>Sets</b><sub>*</sub> of pointed sets.<br><br>	pg 2673<br>
Consider the following statement: <br><br><b>Sets</b><sub>*</sub> ≅ 1/<b>Sets</b><br><br>Prove or disprove.<br>	pg 2673<br><br><br>
Let A be a set. What is the <i>free monoid</i> of A?<br>	pg 2674<br>
What does it mean for a monoid M to be <i>freely generated</i> by a subset A of M?<br>	pg 2674 / 2675<br>
Let A be a set and M(A) be the free monoid on A. Give the definition of the <i>Universal Mapping Property of M(A)</i>.<br><br>	pg 2675<br>
Prove that the monoid A* (operator is concatenation, underlying set is possibly empty sequences of elements of A), has the UMP of M(A).<br>	pg 2675<br>
Let M and N be monoids and functions i : A → |M| and j : A → |N|, each with the UMP of the free monoid on A. (hint: the UMP of the free monoid A is a property M,N, i and j..... not of A! don't think that this is merely saying that A has free forgetful adjunction between Mon, because every set does)<br><br>Consider the following statement:<br><br>There is a unique monoid isomorphism h : M ≌ N such that |h|i = j and |h<sup>-1</sup>|j = i.<br><br>Prove or disprove.<br>	true. pg 2676. prop 1.10<br>TODO: add counterexample.
Let G be a graph. Give the definition of <b>C</b>(G), the free category on G.<br>	pg 2677
Part 1:<br><br>Draw a diagram representing an arbitrary category <b>C</b>, using the following components:<br><br>C<sub>0</sub> - The set of objects<br>C<sub>1</sub> - The set of arrows<br>C<sub>2</sub> - The set of all composable ordered pairs of arrows<br><br>and the following functions between them<br><br>∘,i,cod,dom<br><br>Part 2:<br><br>How do functors apply to this diagram? (hint: including functors into the picture requires a slightly more complex diagram)<br>	pg 2677, near bottom<br>pg 2678<br>
Give the definition of the <i>forgetful functor</i> U : <b>Cat</b> → <b>Graphs</b>.<br><br>	NOTE: U stands for "underlying": it maps a category to its underlying graph.<br><br>the discussion is kind of long, but you'll want to read all of it<br><br>the bottom of page 2677 and the entirety of 2678<br>
Give the definition of the <i>Universal Mapping Property of <b>C</b>(G)</i>.<br>	pg 2679
What does it mean for a category to be <i>small</i>?<br>What does it mean for a category to be <i>large</i>?<br>	pg 2680<br>
What does it mean for a category to be <i>locally small</i>?<br>	pg 2681<br>Definition 1.12<br>
Exercise 1.9.1, pg 2681<br>	<br>
Exercise 1.9.2, pg 2681<br>	<br>
Exercise 1.9.3, pg 2682<br><br>	<br>
Exercise 1.9.4, pg 2682<br><br>	<br>
Exercise 1.9.5, pg 2682<br><br>	<br>
Exercise 1.9.6, pg 2682<br><br>	<br>
Exercise 1.9.7, pg 2682<br><br>	<br>
Exercise 8, pg 2682<br><br>	<br>
Exercise 1.9.9, pg 2682<br><br>	<br>
Exercise 1.9.10, pg 2682<br><br>	<br>
Exercise 1.9.11, pg 2682<br><br>	<br>
Exercise 1.9.12, pg 2683<br><br>	<br>
Exercise 1.9.13, pg 2684<br><br>	<br>
Exercise 1.9.14, pg 2684<br><br>	<br>
Prove theorem 3.1.6 (1) on page 2137<br><br>	<br>
Prove theorem 3.1.6 (2) on page 2137<br><br>	<br>
Prove theorem 3.1.7 (2) on page 2137<br><br>	<br>
Prove theorem 3.1.7 (3) on page 2137<br><br>	<br>
Prove theorem 3.1.8 (1) and (2) on pg 2138<br>	<br>
Prove theorem 3.1.8 (3) and (4) on pg 2138<br>	<br>
Prove theorem 3.1.8 (4) and (5) on pg 2138<br>	<br>
Prove corollary 3.1.9 on page 2139<br>	<br>
pg 2139, exercise 4<br>	<br>
pg 2139, exercise 5<br>	<br>
pg 2139, exercise 6<br>	<br>
pg 2139, exercise 8<br>	<br>
pg 2139, exercise 18<br>	<br>
pg 2139, exercise 21<br>	<br>
pg 2139, exercise 23<br>	<br>
pg 2139, exercise 24	<br>
What is a <i>monomorphism</i>?<br>What is an <i>epimorphism</i>?<br>	pg 2685, def 2.1<br>
Complete the following sentence, and prove your answer:<br><br>A function f : A → B between sets is monic just in case it is __________.<br><br><br><br>	injective.<br>prop 2.2, pg 2682<br>
What does it mean when an arrow is written as f : A ↣ B?<br>	pg 2686, top line
What does it mean when an arrow is written as f : A ↠ B?<br>	pg 2686, top line<br>
How can we characterize monos in the category of monoids?<br>	pg 2686, example 2.3<br>
Consider the following statement:<br><br>In a poset <b>P</b>, every arrow p ≤ q is both monic and epic.<br><br>Prove or disprove.<br>	pg 2686, example 2.4 near bottom<br>
Let N be the set of natural numbers and Z the set of integers.<br><br>Consider the following statement:<br><br>In the category <b>Mon</b> of monoids and monoid homomorphisms, there is a monic homomorphism (N,+) ↣ (Z,+).<br><br>Prove or disprove.<br>	the identity map.<br><br>it has the effect of restricting the function composed to its left to the natural numbers,<br><br>(as a side note, this implies that it is epic, as shown by the book).<br><br>true. pg 2687, example 2.5.<br><br>
Consider the following statement:<br><br>Every iso is both monic and epic.<br><br>Prove or disprove.<br>	pg 2687<br>
What is a <i>split</i> mono?	pg 2688, def 2.7
If e is an arrow, what is a <i>splitting</i> of e?	pg 2688, def 2.7<br>
If s is an arrow, what is a <i>retraction</i> of s?	pg 2688, def 2.7<br><br>
Consider the following statement:<br><br>In <b>Sets</b>, every mono splits.<br><br>Prove or disprove.<br>	IMPOSTOR!<br>almost... monos out of the empty set do not split<br>pg 2688, example 2.8<br>
What does it mean for an object to be <i>projective</i>?<br>	pg 2689
If e : E ↠ X is an epi and f : P → X is an arrow, what does it mean for f to <i>lift across</i> e?<br>	pg 2689<br>
Consider the following statement:<br><br>In any category, any retract of a projective object is also projective.<br><br>Prove or disprove.<br>	<latex><br>If $D$ is a retract of $P$ then there exists $f : P \to D$ and $f_R : D \to P$ such<br>that $f f_R = id_P$.\\~\\<br>Now assume some $j : D \to A$ and some epi $g : E \to A$.<br>Then $jf : P \to A$, and so there exists a $(jf)_g : P \to E$ such that<br>$g \circ (jf)_g = jf$. Then $g \circ (jf)_g \circ f_R = j f f_R = j$, <br>and so we can set $j_g = (jf)_g \circ f_R$.\\~\\<br></latex><br>true. pg 2689.<br>
Let <b>C</b> be a category.<br><br>What does it mean for an object of <b>C</b> to be <i>initial</i>?<br>What does it mean for an object of <b>C</b> to be <i>terminal</i>?<br><br>	pg 2689, def 2.9<br>
An terminal object in <b>C</b> is exactly an initial object in ______________.	C<sup>op</sup> pg 2689, below def 2.9<br>
Consider the following statement:<br><br>Initial (terminal) objects are unique up to isomorphism.<br><br>Prove or disprove.<br>	pg 2689, prop 2.10<br>
In the category <b>Sets</b>, which objects are initial? Which objects are terminal?<br>	pg 2690, item 1<br>
In the category <b>Cat</b>, which objects are initial? Which objects are terminal?	item 2, pg 2690<br>
In the category <b>Groups</b>, which objects are initial? Which objects are final?	pg 2690, item 3<br>
Define the category <b>BA</b> of boolean algebras. <br><br>Which objects are initial? Which objects are final?<br>	<br>pg 2690/2691, item 4<br>
When a poset is considered as a category, what are the initial objects? What are the final objects?	Note that a poset category need not contain initial or final objects.<br><br>pg 2691, item 5<br>
For any category <b>C</b> and any object X in <b>C</b>, what is the terminal object in the slice category <b>C</b>/X? 	pg 2691, item 6<br>
What does it mean for two types σ and τ to be <i>consistent</i>?<br>	pg 2972, definition 1<br>
Describe five important properties of the consistency relation ~.<br>	pg 2972, proposition 1<br>
A gradual type system uses type consistency where a normal type system uses _________.	type equality <br>pg 2972, below prop 1<br>
Give the "method invocation" typing rule.<br>	pg 2972<br>
Here is a Point class:<br><br>class Point {<br>  var x : int = 0<br>  function Point move(dx) { this.x = this.x + dx }<br>}<br><br>Perform cast-insertion on the move method.<br>	pg 2973 (top)<br>
In Siek and Taha's Gradual Types for Objects, what is the difference between <i>type safe</i> and <i>statically type safe</i>?<br>	pg 2973
Give the subtyping rules for Ob<sub><:</sub><sup>?</sup>.<br>	pg 2973<br>
What is the motivation for the <i>consistent subtyping</i> relation? How is it defined?<br>	pg 2974<br>
Give the definition of Siek and Taha's restriction operator.<br>	pg 2974 (bottomish)<br><br>
Consider the following statement:<br><br>The following are equivalent:<br>1. σ ≲ τ<br>2. σ <: σ' and σ' ~ τ for some σ', and<br>3. σ ~ σ'' and σ'' <: τ for some σ''<br><br>Prove or disprove.<br>	true. pg 2974. TODO: add impostor<br><br>
Draw an informal diagram showing the relation between consistency, subtyping, and restriction.<br>	pg 2975<br>
Give the gradual typing rules for Ob<sub><:</sub><sup>?</sup><br>	pg 2977<br>
How is are the syntax and typing rules for the intermediate cast-inserted language defined? (No need for an exhaustive definition, just broad strokes.)<br>	pg 2977<br>
What is the ↼ operator for, and how is it defined?<br>	pg 2978 (bottomish) and 2979<br>
Give the syntax for Typed Lua's first-level type language.<br>	pg 2995<br>
Give the syntax for Typed Lua's second-level type language.<br>	pg 2995<br>
What is the motivation behind <i>projection types</i> in Typed Lua.<br><br>	pg 2995, bottom-rght.<br>
Give BNF for Typed Lua's "special types".<br>	pg 2996, figure 4<br>
What is the purpose of Typed Lua's <i>value</i> type?<br>	pg 2996, left bottomish<br>
Why do const fields not guarantee that the field's value does not change, and what are the ramifications of this?<br>	pg 2996<br>
What are the four kinds of table types in Typed Lua? Describe and compare them.<br>	<br>pg 2996 - right<br><br>Fixed<br>- all other references to this table are fixed or closed<br>- all keys in the table are <i>reflected in the type</i>, and so allows type-safe iteration over k/v pairs.<br>-to ensure that all present fields are represented in the type, we must prohibit width subtyping when a fixed table is on the rhs of the typing judgment<br><br>Closed<br>- Less controlled than fixed. Allows width-subtyping, and so iteration is not type-safe.<br>- May have an external open alias, and multiple other closed aliases.<br><br>Open<br>- All other references are closed.<br>- We can add new fields without having to worry about stomping on existing fields.<br><br>Unique<br>- Guarantees that there are no other references to it<br>- More flexibility in re-interpreting type than open table types. e.g., depth subtyping on immutable fields is allowed.<br>- Along with open and fixed table types, it allows "optional table fields". This is because we know that any field not reflected in the type will produce nil when selected.<br>- Table constructors are the introduction form for unique table types.<br><br>
Tuple types in Typed Lua always end with a <i>variadic type</i>. Explain why this is so and address potential issues.<br><br>	pg 2996 (bottom left / top right)<br>
Give the subtyping rules for Typed Lua's second level types.<br>	pg 2997<br>
Give the (S-TableFCToC), (S-TableUToC), (S-TableOToC) table subtyping rules.<br>	pg 2997<br>
Give the (S-TableUToUOF), (S-TableOToOF), and (S-TableFToF) table subtyping rules.<br> 	pg 2997<br>
Give the field subtyping rules for <:<sub>c</sub>.<br>	pg 2998<br>
Give the field subtyping rules for <:<sub>u</sub>.<br>	pg 2998<br>
Give the field subtyping rules for <:<sub>o</sub>.<br>	pg 2998<br>
Give the subtyping rules for recursive types.<br>	pg 2998<br>
Give the (T-Constructor), (T-NewFieldUnique), and (T-IdRead) table-related typing rules.<br>	pg 3000<br>
Give the (T-IdWrite), (T-IndexIdRead), and (T-IndexExpRead) table-related typing rules.<br>	pg 3000<br>
Give the (T-CoerceClosed), (T-CoerceFixed), (T-Function), and (T-Local) table-related typing rules.<br>	pg 3000<br>
In Typed Lua's type system, what are the<i>merging</i> and <i>joining</i>  metafunctions for? List these functions and give their definitions.<br>	pg 3000<br>
Discuss some of the auxiliary functions for table types, and give their definitions.<br>	pg 3001<br>
Discuss the auxiliary functions for projection types and give their definitions.<br>	pg 3002<br>
In Typed Lua, how do consistency and consistent subtyping interact with union, table, and pair types?<br>	pg 2999, top-left<br><br>
Explain type coercion for the evolution of table types.	pg 3002 (top-left corner)<br>pg 2999 (4th bullet)<br>
Explain the form of Typed Lua's typing judgments for statements.<br>	pg 2999 (above section 5.1)<br>
What does it mean for a table type to be <i>well formed</i>?<br>	pg 3000<br>
Suppose that the variables x and y have type number. Mentally typecheck the following fragment of core typed lua.<br><br>local point : {}<sub>unique</sub> = {} in<br>point["x"] &lt number &gt, point["y"] &lt number &gt = x,y;<br>	pg 3001<br>
Describe the two ways that the types of unique and open tables can be changed.<br>	pg 3001<br><br>way 1: top left<br>way 2: bottom right<br>
What are the purposes of the <i>open</i> and <i>close</i> metafunctions?<br>	pg 3001 (see description of T-IdRead in right column)<br>
Mentally type-check the following fragment of typed lua code:<br><br>local a : {}<sub>unique</sub> = {} in<br>local b : {}<sub>closed</sub> = a in a["x"] &lt string &gt = "foo";<br>	pg 3001 (right column)<br>
What does the Typed Lua type system use the <i>closeall</i> metafunction for?<br>	pg 3002<br>
What does the Typed Lua type system use the <i>closeset</i> metafunction for?<br>	pg 3002<br>
Mentally typecheck the follow core typed lua fragment:<br><br>local a : {}<sub>unique</sub>, b : {}<sub>unique</sub> = {}, {} in<br>~~local f : integer × nil* → integer × nil* =<br>~~~~fun (x : integer) : integer × nil*<br>~~~~~~b = a; return x + 1;<br>~~in<br> ~~~~a["x"] &lt integer &gt = 1 ; ⌊f(a["x"])⌋<sub>0</sub> <br>	pg 3002
What is a <i>masked object type</i>?<br>	pg 3007, section 2.1<br><br>
What is a <i>subclass mask</i>?<br>	pg 3007, (top-rightish)<br>
What is the "*" mask used for?	pg 3007, section 2.2<br>
With masked types, how is mask information propagated across method calls?	pg 307, section 2.2<br>
What does the "{ }" mask mean in masked types?<br>	pg 3007, section 2.2<br>
How does subtyping interact with masked types?<br>	pg 3008 (top of section 2.3)<br><br>
What is a <i>must mask</i>?<br>	pg 3008, section 2.3<br>
What is the default mask effect of a constructor?<br>	pg 3008, fourth paragraph of section 2.3<br><br><br>
How do masked types avoid reasoning about aliasing while still allowing sound object initialization?<br>	pg 3008<br>
Explain how masked types can be helpful for reinitialization.<br>	pg 3008 (right column)<br>
What is a <i>conditional mask</i>?<br>	pg 3008/3009<br>
Describe three ways to remove a conditional mask from a field f.<br>	pg 3009 (bullet point list in right column)<br>
Explain how conditionally masked types interact with subtyping. (right, bottomish)<br>	pg 3009 (right bottomish)<br>
What is the motivation behind <i>abstract masks</i>, and how do they work?<br> 	pg 3010<br>
What is the <i>interpretation</i> of an abstract mask in a given context?<br>	pg 3010<br><br>
What is a <i>mask constraint</i>? What is the motivation behind mask constraints?<br>	pg 3010<br>
How can mask constraints be implemented soundly?<br>	pg 3010, right column<br>
Consider the following statement:<br><br>X ⊆ Σ<sup>ω</sup> there is a recursive subset B ⊆ Σ* such that X = BΣ<sup>ω</sup>.<br><br>Prove or disprove<br><br>	true. pg 2182<br>
What is a <i>multi-valued partial function</i>?<br>What is the <i>source</i>, <i>target</i> and <i>graph</i> of a multi-valued partial function?<br>What is the <i>inverse</i> of a multi-valued partial function? <br>What is the <i>domain</i> of a multi-valued partial function?<br>What is the <i>range</i> of a multi-valued partial function?<br>	pg 2092/2093<br><br>
Let f<sub>i</sub> :⊆ A ⇉ B<sub>i</sub> (i=1,...,k) be multi-valued partial functions. <br>Give the definition of (f<sub>1</sub>,...,f<sub>k</sub>).<br> 	pg 2092<br>
For multi-valued partial functions f :⊆ A ⇉ B and g :⊆ B ⇉ C, how is the composition g ∘ f defined?<br><br>	pg 2092<br>
For a multi-valued function f, what does f|<sub>X</sub> denote?	pg 2092
For a multivalued partial function f, what does f⌋<sub>X</sub> denote?<br>	pg 2092<br>
For a multivalued partial function f, what does f|<sup>X</sup> denote?<br>What does f⌉<sup>X</sup> denote?<br><br>What about <$>f\rbrack_{X}^{Y}</$>?<br>	pg 2092<br>
What does λ represent in computable analysis?<br><br>	pg 2092<br>
Give the definition of <i>effective topological space</i>.<br>	pg 2143<br>
If <b>S</b> is an effective topological space, then what does τ<sub><b>S</b></sub> denote?<br>	pg 2143, def 3.2.1 (2)<br>
Give the definition of <i>computable topological space</i>.<br>	pg 2143
What are <i>atomic properties</i> in effective topological spaces?<br>	pg 2143<br>
Consider the following statement:<br><br>If (M,σ,ν) is an effective topological space then any two elements of M can be distinguished by their atomic properties.<br><br>Prove or disprove<br>	true. pg 2143
Let <b>S</b> be an effective topological space. Consider the following statement:<br><br>τ<b>S</b> has a countable base.<br><br>Prove or disprove.<br>	true. pg 2143.<br>
Let <b>S</b>=(M,σ,ν) be an effective topological space. What is the <i>standard representation</i> δ<sub><b>S</b></sub> of M?<br>	pg 2144, def 3.2.2<br>
What is an "incomplete name"? Why are incomplete names not a significant issue.<br>	pg 2144 (be sure to hove over sticky notes)<br><br>Lemma 3.2.3 is the reason that incomplete names are not a significant issue.<br>
What is a <i>T<sub>0</sub>-space</i>? What is a <i>second countable T<sub>0</sub>-space</i>?<br>	pg 2143 near bottom<br>
Given a notation μ for a countable set M, how can we define a computable topological space for M?	pg 2145, example 1<br>
Give a computable topological space for <b>R</b>, the set of real numbers.<br>	pg 2145, example 2<br>
Give two computable toplogical spaces for 2<sup><b>N</b></sup>, the power set of natural numbers, one which is based on enumeration and the other on a characteristic function.<br>	pg 2145, examples 5 and 6<br>
Give a computable topological space for <b>N</b><sup>ω</sup>, the set of all infinite tuples of natural numbers.<br><br>	pg 2146 (point 7, near top)<br>
Explain why and how computability and approximation are the two key ingredients for computable analysis.<br>	read page 2146<br>
Let <b>S</b>=(M,σ,ν) be a computable topological space. Consider the following statement:<br><br>The representation δ<sub><b>S</b></sub> is (τ<sub>C</sub>, τ<sub><b>S</b></sub>)-continuous.<br><br>Prove or disprove<br>	pg 2147, lemma 3.2.5 (1)<br>TODO: impostor?<br>
Let <b>S</b>=(M,σ,ν) be a computable topological space. Consider the following statement:<br><br>The representation δ<sub><b>S</b></sub> is (τ<sub>C</sub>, τ<sub><b>S</b></sub>)-open.<br><br>Prove or disprove<br>	true. pg 2147, lemma 3.2.5 (2)<br>TODO: impostor?<br>
Let <b>S</b>=(M,σ,ν) be a computable topological space. Consider the following statement:<br><br>τ<sub><b>S</b></sub> is the final topology of δ<sub><b>S</b></sub><br><br>Prove or disprove<br>	true. pg 2147 (3)<br>todo: impostor?<br>
Let <b>S</b>=(M,σ,ν) be a computable topological space. Consider the following statement:<br><br>ζ ≤<sub>t</sub> δ<sub><b>S</b></sub> for all (τ<sub>C</sub>, τ<sub><b>S</b></sub>)-continuous functions ζ :⊆ Σ<sup>ω</sup> → M.<br><br>Prove or disprove<br>	true. pg 2147, lemma 3.2.5 (4)<br>todo: impostor?<br>
Let <b>S</b>=(M,σ,ν) be a computable topological space. Let (M',τ') be a topological space and let H :⊆ M → M' be a function such that H ∘ δ<sub><b>S</b></sub> :⊆ Σ<sup>ω</sup> → M' is (τ<sub>C</sub>,τ')-continuous. Consider the following statement:<br><br>H is (τ<sub><b>S</b></sub>,τ')-continuous. Then H is (τ<sub><b>S</b></sub>,τ')-continuous.<br><br>Prove or disprove<br>	true. pg 2147, lemma 3.2.5 (5)<br>todo: impostor?<br>
Consider the following statement:<br><br>For every second countable T<sub>0</sub>-space (M, τ) there is an effective topological space <b>S</b> = (M, σ, ν) with τ = τ<sub><b>S</b></sub>.<br><br>Prove or disprove.<br>	true. pg 2147, lemma 3.2.6 (1)<br>todo:impostor?<br><br>
Consider the following statement:<br><br>If <b>S</b> = (M,σ,ν) and <b>S'</b> = (M,σ',ν') are effective topological spaces such that τ<sub><b>S</b></sub> = τ<sub><b>S'</b></sub>, then δ<sub><b>S</b></sub> ≡<sub>t</sub> δ<sub><b>S'</b></sub>.<br><br>Prove or disprove.<br>	pg 214. lemma 3.2.6 (2)<br>todo: impostor?<br>
Let (M, τ) be a second countable T<sub>0</sub>-space. What does it mean for a naming system to be admissible w.r.t. τ?<br>	pg 2148, definition 3.2.7 (1)<br>
What does it mean for a naming system to be <i>admissible</i>?<br>	pg 2148, definition 3.2.7 (2)<br>
Prove theorem 3.2.9 on page 2149 (TODO: conver to prove/disprove format)<br><br>	<br>
Prove theorem 3.2.10 on page 2149 (TODO: conver to prove/disprove format)	<br>
Prove theorem 3.2.11 on page 2149 (TODO: conver to prove/disprove format)	<br>
Prove corollary 3.2.12 on page 2151 (TODO: conver to prove/disprove format)	<br>
Prove corollary 3.2.13 on page 2151 (TODO: conver to prove/disprove format)	<br>
Prove theorem 3.2.14 on page 2152 (TODO: conver to prove/disprove format)	<br>
How do the standard representations of effective topological spaces interact with realizations of functions defined upon them?<br><br>	pg 2150, above thm 3.2.11 (Roughly speaking, the function g...)<br><br>
Why are realizations of continuous real-valued functions not necessarily continuous when we use a decimal representation?<br>	pg 2151<br>
Give a computable analysis explanation for why every real-valued function we may reasonably expect to compute is continuous in the high-school calculus sense.<br>	pg 2151<br>
Explain the computable analysis analog to Rice's theorem.<br>	pg 2152
Exercise 3.2.1, pg 2153<br>	<br>
Exercise 3.2.3, pg 2153<br>	<br>
Exercise 3.2.5, pg 2153<br>	<br>
Exercise 3.2.8, pg 2153<br>	<br>
Exercise 3.2.14, pg 2153<br>	<br>
Exercise 3.2.15, pg 2153<br>	<br>
Exercise 3.2.16, pg 2153<br>	<br>
Give the fragment Δ<sub>=μ</sub>, equational rules for the term-level constructs associated with recursive types.<br><br>	pg 3074 (left)<br>
Give the fragment Δ<sub>μ</sub>, the typing and type well-formedness rules for recursive types.<br><br>	pg 3074 (left)<br>
Give a term in Ob<sub>1μ</sub> (first-order typed object calculus with recursive types) that is functionally equivalent to the untyped term [l = ς(x)x].<br>	pg 3074 (top-right)<br><br>
Give the fragment Δ<sub><:X</sub>, the environment well-formedness, type well-formedness, and subtyping rules for type variables (intended to be included with recursive types).<br>	pg 3075 (left)<br>
Give the fragment Δ<sub><:μ</sub>: the well-formedness, subtyping, and typing rules for μ types.<br>	pg 3075
What does it mean for A{X} to be covariant in X?  contravariant? invariant?<br>	pg 3075 (left, top paragraph)<br>
Give the (Sub Rec) rule: subtyping for μ-types. Explain how it determines the variance behavior of recursive types.<br>	pg 3075 (left)<br>
How can we derive an equational rule that can prove the equality of two fold terms even when the types used for folding are different?<br><br>	pg 3075 (right)<br>
Explain (Eq Fold<: Lemma2) on page 3075 right.<br><br>	pg 3075 (right)<br>
What is the "minimum types" property, and how can we show that Ob<sub>1<:</sub> has a limited form of it?<br>	pg 3076-3078
Consider an untyped object that can keep backup copies of itself, for example as an audit trail:<br><br>[retrieve = ς(s<sub>1</sub>)s<sub>1</sub>,<br> backup = ς(s<sub>2</sub>)s<sub>2</sub> s.retrieve ⥢ ς(s<sub>1</sub>)s<sub>2</sub>,<br> (additional attributes)]<br><br>Can we create an equivalent object that is typable with recursive types?<br>	pg 3077 (bottom right) 3078 (top left)<br>
Consider the object-oriented natural numbers described on page 3051. Can we write equivalent terms which are typable using recursive and sum types?<br>	yes. pg 3078.<br><br>
Give all store and stack well-fromedness rules for impς.<br>	pg 3085<br>
Give the reduction rules (Red x), (Red Objects), and (Red Select) for impς.<br>	pg 3085<br>
Give the reduction rules (Red Update), (Red Clone), and (Red Let) for impς.<br>	pg 3085<br>
For the first-order imperative ς calculus, give environment well-formedness rules (Env ∅) and (Env x). Also give (Type Object), the well-formedness rule for object types.<br>	pg 3087 (right)<br>
Give the (Sub Object) subtyping rule for the first-order imperative ς-calculus.<br>	pg 3087 (right)<br>
Give the typing rules (Val Subsumption), (Val x), and (Val Object) for the first-order imperative ς-calculus.<br>	pg 3088
Give the (Val Select), and (Val Update) typing rules for the first-order imperative ς-calculus.	pg 3088
Give the (Val Clone) and (Val Let) rules for the first-order imperative ς-calculus.<br>	pg 3088<br>
Are Self types less or more important an an imperative setting than a functional one. Why?<br>	pg 3088 (right)<br>
Explain the operational and typing behavior of classes in an imperative, first-order typed setting.<br>	pg 3089.<br>
Explain the operational behavior of inheritance in an imperative first-order typed setting.<br>	pg 3089 (left)<br>
Suppose that in the FO typed, imperative ς-calculus, a pre-method of a class is re-assigned after instances (of a derived class) have been instantiated. What is the effect of this?<br>	pg 3089 (right)<br>
Explain the various judment forms involved in store typing for first-order, imperative typed ς-calculus.<br>	pg 3090 (right, "Store Typing")<br>
When typing the first-order, imperative ς-calculus, what is a "method type"? What are method types used for?<br>	bottom left of pg 3090<br>
Give the (Method Type) and (Store Type) rules for first-order, imperative ς-calculus.<br>	pg 3090, bottom right<br>
Give the (Result Object), (Stack ∅), and (Stack x Typing) rules for first-order, imperative ς-calculus.<br>	pg 3091<br>
Give the (Store Typing) rule for first-order, imperative ς-calculus.<br>	pg 3091
Give Δ<sub>∀</sub>, the fragment for well-formedness and typing of universally quantified types.<br>	pg 3103 (left)<br>
Give Δ<sub>=∀</sub>, the fragment for equational rules of terms involving universally quantified types.<br><br>	pg 3101 (left)<br>
Give Δ<sub><:∀</sub>, the fragment for well-formedness, subtyping, and typing of bounded, universally quantified types.<br>	pg 3101 (right)
Give Δ<sub>=<:∀</sub>, the equational rules for the lambda calculus with bounded universal quantifiers.<br>	pg 3101 (right)<br>
Give the (Val Structural Update) rule for object update, and describe:<br>1.) why it is different from normal update<br>2.) why it may be problematic<br>	pg 3102 (left)<br>
Explain the basic ingredients of bounded, existentially quantified types.<br>	pg 3102 (right)<br>
Give the fragment Δ<sub><:∃</sub>, the well-formedness, typing, and subtyping rules for bounded, existentially quantified types.<br><br>	pg 3102 (right)<br><br>
Give the fragment Δ<sub>=<:∃</sub> for equational rules for bounded existentials.<br> 	pg 3103 (left)<br>
How can we encode bounded existential quantifiers in terms of bounded universal quantifiers?<br>	pg 3103 (right)<br>
Give Δ<sub>∃</sub> and  Δ<sub>∃=</sub>. These are in the appendix to A Theory of Objects, which I have not yet scanned. TODO<br>	<br>
Give an inductive definition for variant occurrences over the types of FOb<sub><:μ</sub>. (Object calculus with bounded universal and existential quantifiers, which also includes recursive types)<br><br>	pg 3104<br>
How can we encode a typed λ calculus with variant function types into a typed object calculus with bounded universal and existential quantifiers.<br>	pg 3105 (left and right)<br>
Derive the Self type quantifier ς(X) B in terms of recursive types and bounded existentials.<br>	pg 3106<br>
What is the recursive equation corresponding to a Self type quantifier? What is the subtyping property that its solution must satisfy?<br>	pg 3106 (left)<br><br>
Try to give the best summary possible of the advantages of Self type quantifiers over recursive type quantifiers in three sentences or less.<br>	the "subtyping property" described on pg 3106 (left) should probably be included<br>pg 3106 (left)<br>
What are the elements of the type ς(X) B{X}?	pg 3106 (left)<br>
What does the abbreviation A⦗B⦘ mean (it involves Self types)?<br>	pg 3106 (left)<br>
Explain how to use Self types to type simple storage cells with get and set methods (where set returns the resulting cell).<br><br>	pg 3106 (bottom left / top right)<br>
Explain the <i>wrap</i> and <i>use</i> operators on Self types. Define them as derived forms.<br>	pg 3106<br>
Give Δ<sub>ς</sub>, the fragment for well-formedness, subtyping and typing rules for Self types and their associated term-level constructs.<br>	pg 3107 (left)<br><br>
Give Δ<sub>=ς</sub>, the equational rules for the term-level constructs associated with Self types.<br>	pg 3107 (left)<br>
How are "ς-object" types defined, and why?<br>	pg 3116 (right)<br>
What does the "Self types do not nest" slogan mean?	pg 3117 (left), paragraph 2<br>
If A is a ς-object type, how do we build an element of A? What is meant by the "representation type" of this element?<br>	pg 3117 (left)<br>
Define the selection and update operations on ς-objects, in terms of use, wrap, and normal selection and update operators on regular objects.<br>	pg 3117 (left)<br>
Give Δ<sub>ς+</sub>, the well-formedness, subtyping, and typing rules associated with ς-object types and their associated term-level constructs.<br>	pg 3117 (right)<br>
Give these rules from Δ<sub>ς+=</sub>, the equational rules for term-level constructs associated with ς-object types.<br><br>specifically: (Eq ςObjects) and (Eq Sub ςObject).<br><br>	pg 3117 (right)<br>
Give these rules from Δ<sub>ς+=</sub>, the equational rules for term-level constructs associated with ς-object types.<br><br>specifically: (Eq ςSelect) and (Eq ςUpdate).<br><br>	pg 3117 (right)<br>
Give these rules from Δ<sub>ς+=</sub>, the equational rules for term-level constructs associated with ς-object types.<br><br>specifically: (Eval ςSelect) and (Eval ςUpdate).<br><br>	pg 3118<br>
What can be said about the relation between ς-Object types and width subtyping?<br>	Width subtyping is allowed on ς-object types. This wouldn't be the case, for example, with recursive types.<br><br>pg 3118 (left) paragraph 2<br>
Consider the following statement: <br><br>For a ς-object to be well-typed, its methods must be well-typed for arbitrary choices of a Self type.<br><br>Prove or disprove.<br>	IMPOSTOR<br><br>pg 3118 (left, 3rd paragraph)
Define a movable 1d point object as a ς-object. Explain its typing derivation.<br>	pg 3118 (right)<br>
Define a movable point with backup as a ς-object.	pg 3119 (left, "Backup methods")<br>
Define object-oriented natural numbers in terms of ς-bound self types.<br>	pg 3119 (left, right)<br>
What is a <i>binary method</i>? Explain the difficulties that arise when trying to statically type a binary method.<br>	pg 3120 (left,right)<br>
If A ≡ ς(Self)[l<sub>i</sub> : B<sub>i</sub>{Self<sup>+</sup>}<sup>i ∈ 1 .. n</sup>] is an object type, then what is the type of classes that generate objects of type A? 	pg 3121 (left, top) make sure to read and understand the following paragraph<br>
How can the <i>new</i> field for a class (in the OOP sense) of ς-objects be defined?<br>	pg3121 (left)<br>
Why is defining pre-methods for ς-object classes problematic?<br>	pg 3121 (left)<br>
Describe the "updating from the outside" problem that one encounters when dealing with ς-objects with updatable methods.<br>	pg 3121 (left, right)<br><br>
What is a <i>recoup</i> method, and what does its presence in a ς-object imply about the object that contains it?<br>	pg 3122 (left, right)<br>
How can recoup methods be used to solve the "updating from the outside" problem?	pg 3122 (right)<br>
Name and describe the two <i>structural invariants</i> for structural object types.	pg 3123/3124<br><br>shape invariant described on pg 3124 (right)<br>
What is an <i>ultrafilter</i>? <br>	pg 2691<br>
Consider the following statement:<br><br>A filter F in a boolean algebra B is an ultrafilter just if for all b ∈ B,<br><br>either b ∈ F, or ¬b ∈ F, and not both<br><br>Prove or disprove<br>	true. pg 2691<br>
Any category with a terminal object has a class of arrows called <i>points</i>. What are points?<br>	pg 2692<br>
Let P be an object in the category of posets. How many points does P have?<br><br>	P has one point for each element of its underlying set.<br>pg 2692<br>
Let M be an object in the category of monoids. How many points does M have?<br><br>	It only has 1. See second sticky on pg 2692<br>
Posets are said to "have enough points" to distinguish arrows in the category <b>Pos</b> of posets. On the other hand, monoids do not "have enough points" to distinguish arrows in the category <b>Mon</b> of monoids.<br><br>What is the formal meaning of this informal claim?	pg 2692, examples 1 and 2.<br><br><br>
Explain why the claim in exercise 3 on pg 2692 is true.<br>	<br>=> for each pair of arrows a and b, there is a unique arrow ab, and so ...<br><br><= choose the identity for x
In Glew's system, explain the relation between <i>node labels</i>, <i>labels</i>, and <i>specs</i>.<br>	pg 3180 (top)
Give Glew's definition of the set <i>Tree</i> of <i>binding trees</i>.<br>	pg 3180, definition 3.1<br>
How does Glew define the <i>distance</i> between two binding trees?<br>	pg 3180, definition 3.1<br>
Prove that Glew's metric on trees is an ultrametric, that is:<br><br>d(a,a) = 0<br>d(a,b) = d(b,a), and<br>d(a,c) ≤max(d(a,b),d(b,c))<br> 	top of pag 3181<br>
If n is a natural number, what tree does <b>var<b>(n) denote?<br>	pg 3181, def 3.2<br><br>
If nl is a node label and t<sub>l</sub> is a map from labels(nl) to trees, give the tree denoted by <b>nl</b>(nl, l = t<sub>l</sub>).<br>	pg 3181, def 3.2<br>
Why is the standard definition of <i>regular trees</i> inadequate for second order trees?<br>	pg 3182, top<br>
How is the binding of a path p in a tree t, BIND(t,p), defined?<br>	pg 3182<br>
How is the function VAROF(t,p) defined?<br>	pg 3183, definition 3.4<br><br>
Consider the following statement:<br><br>If t ∈ Tree then: VAROF(t, p) = free(n) if and only if t(p) = in<sub>2</sub>(n + BIND(t, p)).<br><br>Prove or give a counterexample.<br><br>	pg 3183, lemma 3.4 (ii)<br><br>TODO: impostor?<br>
Consider the following statement:<br><br>If t ∈ Tree then: VAROF(t, p) = <b>bound</b>(p', l, n) if and only if t(p) = in<sub>2</sub>(n + BIND(t, p'l → p)), t(p') = in<sub>1</sub>(nl), and 0 ≤ n < BIND(nl, l).<br><br>Prove or disprove.<br>	true. pg 3183, lemma 3.4 (iv)<br><br>TODO: impostor?<br>
How does Glew define the <i>free variables</i> of a tree?<br>	pg 3183, def 3.5<br><br>
How does Glew define the <i>shift</i> of a tree t above m by n, SHIFT(t,m,n)?<br>	pg 3183, def 3.6<br>
Consider the following statement:<br><br>BIND(SHIFT(t, n), p) = BIND(t, p)<br><br>Prove or disprove.<br>	true. pg 3184, lemma 3.5 iii<br><br>todo: impostor?<br>
Consider the following statement:<br><br>If p ∈ dom(t) then either t(p) = in<sub>1</sub>(nl) and SHIFT(t, n)(p) = in<sub>1</sub>(nl), VAROF(t, p) = FREE(i) and VAROF(SHIFT(t, n), p) = FREE(n + i), or VAROF(t, p) = BOUND(p', l, i) and VAROF(SHIFT(t, n), p) = BOUND(p', l, i).<br><br>Prove or disprove.<br>	true. lemma 3.5 (iv)<br><br>todo: impostor?<br><br>
Consider the following statement:<br><br>SHIFT(SHIFT(t, m<sub>1</sub>, n<sub>1</sub>), m<sub>2</sub>, n<sub>2</sub>) = SHIFT(t, m<sub>1</sub>, n<sub>1</sub> + n<sub>2</sub>) if m<sub>1</sub> ≤ m<sub>2</sub> ≤ m<sub>1</sub> + n<sub>1</sub><br><br>prove or disprove.<br><br>	true. pg 3184, lemma 3.5 (vi)<br><br>todo: impostor?<br><br>
Consider the following statement:<br><br>d(SHIFT(t<sub>1</sub>, n), SHIFT(t<sub>2</sub> , n)) = d(t<sub>1</sub>, t<sub>2</sub>)<br><br>Prove or disprove.	true. pg 3184, lemma 3.5 viii<br><br>todo: add impostor?<br>
How does Glew define the <i>subtree</i> of a tree t at path p, SUBTREE(p,t)?<br><br><br>	pg 3185, definition 3.7<br>
Consider the following statement:<br><br>If t ∈ Tree then: VAROF(t, p) = <b>free</b>(n) if and only if SUBTREE(t, p) = <b>var</b>(n + BIND(t, p)).<br><br>Prove or disprove	true. pg 3185, lemma 3.6 (iv)<br>
Consider the following statement:<br><br>If pp' ∈ dom(t) then BIND(SUBTREE(t, p), p') = BIND(t, p → p').<br><br>Prove or disprove.<br>	pg 3185. lemma 4.6 vi<br><br>todo: impostor?<br>
Consider the following statement:<br><br>SUBTREE(SUBTREE(t, p<sub>1</sub>), p<sub>2</sub>) = SUBTREE(t, p<sub>1</sub>, p<sub>2</sub>)<br><br>prove or disprove<br>	true. pg 3185, lemma 3.6 viii<br><br>TODO: impostor?<br><br>
Consider the following statement:<br><br>SUBTREE(<b>nl</b>(nl, l = t<sub>l</sub>), l) = t<sub>l</sub><br><br>prove or disprove<br>	true. pg 3185 lemma 3.6  ix<br><br>todo: impostor?<br>
How does Glew define the <i>capture-avoiding</i> substitution of t<sub>2</sub> for a path p in t<sub>1</sub>, t<sub>1</sub>{p := t<sub>2</sub>}?<br>	pg 3185, defintion 3.8<br><br><br>
What does it mean for a set P of paths in a tree to be incomparable, and how does Glew define the simultaneous substitution of t<sub>i</sub> for p<sub>i</sub> in t, where {p<sub>i</sub> | i ∈ I} is incomparable?<br>	pg 3185, def 3.8<br><br>
How does Glew define the substitution of t<sub>2</sub> for free variable n in t<sub>1</sub>?<br>	pg 3186, top<br><br>
How does Glew define a <i>substitution</i> ρ? <br>How does he define the substitution of ρ in t, t{p}?<br>How does he define the <i>shift</i> of a substitution SHIFT(ρ,n)?<br>	pg 3186, top<br>
How can ordered pairs be defined in terms of sets?<br>	pg 3239<br>
What is a <i>relational structure</i>?	pg 3240<br>
What does the notation f↾c mean?<br>	c is a subset of the domain of f<br>f ↾ c is the restriction of f to c<br>pg 3240<br><br>
What are <i>finite von Neumann ordinals</i>?<br>	pg 3240<br>
How is the <i>disjoint union</i> A+B of two sets A and B defined?<br>	pg 3241<br>
What does it mean for a set A to be transitive?	pg 3242
If A is a set, what is the <i>transitive closure</i> of A?<br>	pg 3242
Exercise 2.1, pg 3242<br>	pg 3242<br>
Exercise 2.2, pg 3242<br>	<br>
Exercise 2.3, pg 3243<br>	<br>
Exercise 2.4, pg 2343<br>	<br>
What is the difference between a class and a set?<br>	pg 3243<br>
Why is the class of all sets large?<br>	pg 3243<br>
Consider the predicate <br><br>x is an ordered pair <a,b> and b = <b>P</b>(A)<br><br>Show that this predicate defines a large class.<br>	pg 3244<br>
Exercise 2.5, pg 3244<br>	<br>
Exercise 2.6, pg 3244<br>	<br>
Consider the following statement:<br><br><b>nl</b>( nl, l = t<sub>l</sub>{P<sub>l</sub> := SHIFT(t, BIND(nl,l))} ) = <b>nl</b>(nl, l = t<sub>l</sub>){{lp | p ∈ P<sub>l</sub>} := t}<br><br>Prove or disprove<br><br>	true. pg 3186<br><br>
Conisder the following statement:<br><br>SHIFT(t<sub>1</sub>{P := t<sub>2</sub>}, m, n) = SHIFT(t<sub>1</sub>,m,n){P := SHIFT(t<sub>2</sub>,m,n)<br><br>Prove or disprove.<br>	true. pg 3186, lemma 3.8 iv<br><br>todo: impostor?<br>
What does it mean for a relation R to be an <i>equivalence</i> of a tree t's subtrees?<br>	pg 3187<br>
If R is a relation on a tree t, and p<sub>1</sub> and p<sub>2</sub> are paths in the tree, how is the EQSTPROP(p<sub>1</sub>,R,p<sub>2</sub>) proposition defined? What is it used for?<br><br><br><br>	EQSTPROP(p<sub>1</sub>,R,p<sub>2</sub>) is true if one of the three conditions is satisfied:<br><br>t(p<sub>1</sub>) = in<sub>1</sub>(nl), t(p<sub>2</sub>) = in<sub>1</sub>(nl), and (p<sub>1</sub>l) R (p<sub>2</sub>l) for all l ∈ LABELS(nl)<br><br>VAROF(t,p<sub>1</sub>) = <b>free</b>(n) and VAROF(t,p<sub>2</sub>) = <b>free</b>(n)<br><br>or<br><br>VAROF(t,p<sub>1</sub>) = <b>bound</b>(p'<sub>1</sub>,l,n), VAROF(t,p<sub>2</sub>) = <b>bound</b>(p'<sub>2</sub>,l,n), and p'<sub>1</sub> R p'<sub>2</sub><br><br>pg 3187<br><br><br><br>
What does it mean for an equivalence R of t's subtrees to be <i>nonoverlapping</i>?<br>	pg 3187, def 3.10<br><br>
What does it mean for a tree t to be <i>regular</i>?<br>	pg 3187, definition 3.10<br>
For t ∈ <i>Tree</i>, what does EQST(t) denote?<br>	pg 3187, def 3.11<br>
Consider the following statement:<br><br>If R is an equivalence of t's subtrees, p<sub>1</sub> R p<sub>2</sub>, and p<sub>1</sub>p ∈ dom(t) then p<sub>2</sub>p ∈ dom(t) and p<sub>1</sub>p R p<sub>2</sub>p.<br><br>prove or disprove<br>	pg 3187 (lemma 3.9 i)<br><br>todo: add impostor?<br>
Consider the following statement:<br><br>If R is an equivalence of t's subtrees, p<sub>1</sub> < p<sub>2</sub>, p<sub>1</sub> R p<sub>2</sub>, and ¬∃p'<sub>1</sub>, p'<sub>2</sub> : p'<sub>1</sub> < p'<sub>2</sub> < p<sub>2</sub> ∧p'<sub>1</sub> R p'<sub>2</sub> then SUBTREE(t,p<sub>2</sub>) = SHIFT(SUBTREE(t,p<sub>1</sub>),BIND(t,p<sub>1</sub> → p<sub>2</sub>)).<br><br>Prove or disprove.<br>	true. pg 3187, lemma 3.9 (ii)<br>
Consider the following statement:<br><br>If p<sub>2</sub> ∈ dom(t), p<sub>1</sub> < p<sub>2</sub>, and SUBTREE(t, p<sub>2</sub>) = SHIFT(SUBTREE(t,p<sub>1</sub>), BIND(t,p<sub>1</sub> → p<sub>2</sub>)) then p<sub>1</sub> EQST(t) p<sub>2</sub>.<br><br>Prove or disprove.<br>	true. pg 3187, lemma 3.9.<br><br>todo: impostor?<br><br>
What is the <i>axiom of extensionality</i>?<br>	pg 3631<br>
Prove, from the axiom of extensionality, that there is only one empty set.	<latex>~\\<br>An empty set is a set such that $\forall x. \neg (x \in A)$. Let $A$ and $B$ be distinct empty sets. Then wlog there is some $x \in A$ such that $\neg (x \in B)$. But $A$ is empty, so $x \not \in A$. $\Rightarrow \Leftarrow$ <br></latex><br><br>pg 3633, exercise 1.2.4<br><br>
Exercise 1.4.1, pg 3635<br>	<br>
What does it mean for a binary relation to be <i>connected</i>?<br>	pg 3639<br>
What does it mean for a poset to be <i>well-founded</i>?<br>	pg 3639 (near bottom)<br><br>
Consider the following statement:<br><br>Let (x, ≤) be a poset. (x, ≤) is well-founded if and only if there is no sequence {a<sub>n</sub>}<sup>∞</sup><sub>n=0</sub> of elements of x such that a<sub>n+1</sub> < a<sub>n</sub> for all n, i.e. no sequence of {a<sub>n</sub>}<sup>∞</sup><sub>n=0</sub> such that a<sub>0</sub> > a<sub>1</sub> > a<sub>2</sub> > ...<br><br>Prove or disprove<br>	pg 3640, lemma 1.5.1<br><br>
Consider the following statement:<br><br>Let (x, ≤) be a poset. Then there is a set y of subsets of x such that (x, ≤) ≅ (y, ⊆).<br><br>Prove or disprove.<br>	true. pg 3640, theorem 1.5.2<br><br>todo: add impostor<br>
What is a toset? What is a woset?	pg 3640<br>
Exercise 1.6.1, pg 3641<br>	<br>
Exercise 1.6.3 (ii), pg 3642<br>	<br>
Exercise 1.6.3 (iii), pg 3642	<br>
Let x<sub>i</sub>, i ∈ I denote a family of sets. What does Π<sub>i ∈ I</sub> x<sub>i</sub> denote? What about x<sup>I</sup>?<br>	pg 3643<br>
What is the cartesian product x<sup>{1}</sup>?<br>	pg 3643<br>
Exercise 1.6.6, pg 3643<br>	<br>
Explain the connection between well-orderings and standard induction on natural numbers.	pg 3644<br>
Consider the following statement:<br><br>Let (X, ≤) be a woset. Let E be a subset of X such that:<br><br>(i)  the smallest element of X is a member of E<br>(ii) for any x ∈ X, if ∀y[y < x → y ∈ E], then x ∈ E.<br><br>Then E = X.<br><br>Prove or disprove.<br>	true. theorem 1.7.1, pg 3645<br><br>todo: impostor?<br>
What does it mean for a function between wosets to be an <i>order isomorphism</i>?<br>	pg 3645<br>
Consider the following statement:<br><br>Let (X, ≤) be a woset, Y ⊆ X, and f : X ≌ Y. Then for all x ∈ X, x ≤ f(x).<br><br>Prove or disprove.<br>	true. Theorem 1.7.2, pg 3645<br>
Consider the following statement:<br><br>Let (X, ≤), (X', ≤') be wosets. If (X, ≤) ≌ (X', ≤'), there is exactly one order-isomorphism f : X ≌ X'.<br><br>Prove or disprove.	true. pg 3646, thm 1.7.3. <br>
Consider the following statement:<br><br>Let (X, ≤), (X', ≤') be tosets. If (X, ≤) ≌ (X', ≤'), there is exactly one order-isomorphism f : X ≌ X'.<br><br>Prove or disprove.	IMPOSTOR. pg 3646, thm 1.7.3.<br>
Let (X, ≤) be a woset, and a ∈ X. What is the <i>segment</i> X<sub>a</sub> of X determined by a?<br>	pg 3464<br>
Consider the following statement:<br><br>Let (X, ≤) be a woset. There is no isomorphism of X onto a segment of X.<br><br>Prove or disprove.<br><br>	true. pg 3646, thm 1.7.4.<br><br>
Consider the following statement:<br><br>Let (X, ≤) be a poset. There is no isomorphism of X onto a segment of X.<br><br>Prove or disprove.<br><br>	IMPOSTOR<br><br>pg 3646, below thm 1.7.4<br>
Consider the following statement:<br><br>Let (X, ≤) be a woset, A = {X<sub>a</sub> | a ∈ X}. Then (X, ≤) ≌ (A, ⊆).<br><br>Prove or disprove<br>	true. pg 3646, thm 1.7.5<br><br>todo: add impostor?<br>
Give the definition of an <i>ordinal</i>.<br>	pg 3646, near bottom<br>
Exercise 1.7.1, pg 3646<br>	<br>
Consider the following statement:<br><br>Let (X, ≤) be an ordinal. Then for x, y ∈ X, we have<br><br>x < y ↔ X<sub>x</sub> ⊂ X<sub>y</sub> ↔ x ⊂ y.<br><br>Prove or disprove.<br>	true. pg 3647.<br><br>todo: impostor?<br>
Consider the following statement:<br><br>Let X be an ordinal. If a ∈ X, then X<sub>a</sub> is an ordinal.<br><br>Prove or disprove.<br>	true. pg 3647, thm 1.7.6<br><br>todo: impostor?<br>
Consider the following statement:<br><br>Let X be an ordinal. Let Y ⊂ X. If Y is an ordinal, then Y = X<sub>A</sub> for some a ∈ X.<br><br>Prove or disprove.<br>	true. pg 3647, thm 1.7.7<br><br>todo: impostor?<br>
Consider the following statement:<br><br>If X,Y are ordinals, then X ∩ Y is an ordinal.<br><br>Prove or disprove.<br>	true. pg 3647<br><br>todo: impostor?<br>
Consider the following statment:<br><br>Let X,Y be ordinals. If X ≠ Y, then one is a segment of the other.<br><br>Prove or disprove.<br>	true. pg 3648. todo: impostor?<br>
Conside the following statement:<br><br>If X,Y are isomorphic ordinals, then X=Y.<br><br>Prove or disprove.	true. pg 3648, thm 1.7.10.<br><br>todo: impostor?<br>
Consider the following statement:<br><br>Let (X, ≤) be a woset such that for each a ∈ X, X<sub>a</sub> is isomorphic to an ordinal. Then X is isomorphic to an ordinal.<br><br>Prove or disprove.<br>	true. pg 3648, thm 1.7.11<br><br>todo: impostor?<br><br><br>
Consider the following statement.<br><br>Every woset is isomorphic to a unique ordinal.<br><br>Prove or disprove.<br>	true. theorem 1.7.12, pg 3650<br><br>todo: impostor?<br>
If X is a woset, then what does Ord(X) denote?<br>	pg 3650<br>
Why are the orderings ⊂ and ∈ on ordinals identical?<br>	pg 3650.<br>
Why are the ordinals well-ordered by ⊂?	pg 3650, 3651<br>
If α is an ordinal, then what does α + 1 denote?	pg 3652<br>
Define and contrast limit ordinals and successor ordinals.<br>	pg 3652<br>
Give the ordinal-based definition of <i>sequences</i>.	pg 3652, 3653<br>
What does the notation ⟨ x<sub>ξ</sub> | ξ < α ⟩ mean?	pg 3653<br>
How do "real analysis" sequences relate to ordinal-based sequences?<br>	pg 3653<br>
Exercise 1.7.3, pg 3653.<br>	<br>
Exercise 1, pg 3653<br>	<br>
Exercise 2, pg 3654<br>	<br>
Exercise 3, pg 3655<br>	Here is part 1.)<br>Part 2.) is a todo<br><latex>~\\<br>This is asking us to prove that the order topology is the smallest (i.e. coarsest) Hausdorff topology on X. We can do this by showing that for any Hausdorff topology $\mathcal T$ on X, and any basis element $B$ of $\mathcal T$, we have some basis element $A$ of the order topology such that $B \subseteq A$. (see lemma 13.3 on pg 4359 of this pdf)<br><br>We write $\mathcal B$ for some arbitrary basis of an arbitrary Hausdorff toplogy $\mathcal T$ on X. Let $x \in X$ and $B \in \mathcal B$. Then either $B = X$, or there exists a $y \in X - B$.<br><br>\begin{itemize}<br>\item If $B = X$, noting that $X$ is a basis element of the order topology on $X$ since it is the empty intersection of subbasis elements, we see that $B$ is contained in some basis element ($X$) of the basis described in the problem statement.<br><br>\item If $B \neq X$ then there exists some $y \in X - B$. Due to the total ordering on X, either $x < y$ or $y < x$. In the former case, $B$ is contained in the order topology basis element $\{ z \mid z < y \}$. In the latter case, it is contained in $\{ z \mid y < z \}$ <br>\end{itemize}<br><br></latex>
Consider a black-box machine (or process) with one (external) button and one light. The machine performs a certain action only if the button is pressed. And the light goes on only if the machine stops operating (i.e. has reached a null state); in that case, pressing the button has no effect any more. A client on the outside of such a machine cannot directly observe the internal state of the machine, but (s)he can only observe its behaviour via the button and the light. In this simple (but paradigmatic) situation, all that can be observed directly about a particular state of the machine is whether the light is on or not. But a user may iterate this experiment, and record the observations after a change of state caused by pressing the button 1 . In this situation, a user can observe how many times (s)he has to press the button to make the light go on. This may be zero times (if the light is already on), finitely many times, or infinitely many times (if the machine keeps on operating and the light never goes on).<br><br>Describe this machine mathematically in terms of coalgebras.<br>	pg 3826<br>
Let us consider a slightly different machine with two buttons: value and next . Pressing<br>the value button results in some visible indication (or attribute) of the internal state (e.g. on a<br>display), taking values in a dataset A, without affecting the internal state. (Hence pressing value twice consecutively yields the same result.) By pressing the next button the machine moves to another state (the value of which can be inspected again).<br><br>Describe the above machine mathematically in terms of coalgebras.<br>	pg 3827 (ii)<br>
Describe a movable 2d point OOP object mathematically in terms of coalgebras.<br>	pg 3827<br>
Let us consider a slightly different machine with two buttons: value and next . Pressing<br>the value button results in some visible indication (or attribute) of the internal state (e.g. on a<br>display), taking values in a dataset A, without affecting the internal state. (Hence pressing value twice consecutively yields the same result.) By pressing the next button the machine moves to another state (the value of which can be inspected again).<br><br>Describe the above machine in transition system notation.<br>	pg 3828 (iv)<br>
How can a non-deterministic transition system be described in terms of a coalgebra?<br>	pg 3828 (v)<br>
What slogan "______ vs. ______" do we use to distinguish between algebras and coalgebras?<br>	construction vs. observation<br><br>pg 3830<br>
Give two reasons why it is sometimes difficult in practice to distinguish between algebras and coalgebras.<br>	pg 3830<br>
Describe how structural operational semantics is an example of a system that layers algebras and coalgebras.<br>	pg 3830<br>
Explain the basic difference between an inductive definition of a function f and a coinductive definition of a function f.<br>	pg 3831, boxes<br><br>
Define an inductive <i>length</i> function on finite lists, and a coinductive <i>ext<sub>f</sub></i>  function (which applies the function f to every element of its argument list) on infinite lists.	pg 3831<br>
Define ext(f)--a function that applies f to every element of an infinite list--coinductively using transition notation.<br><br><br>	pg 3831<br>
Let <i>odd</i> be a function which, given an infinite list, produces a new infinite list containing every odd element of the input list. Give a coinductive definition of odd, both equationally, and using transition notation.	pg 3831<br>
What is a functorial operation? Show how the standard map function from functional programming is functorial.	pg 3833<br>
Show how the cartesian product is a functorial operation.	pg 3833<br>
Give the definition of the coproduct operation, and explain why it is functorial.<br>	pg 3833<br>
Explain how the operation of taking the powerset of a set can be lifted onto functions, and show that it is a functorial operation.<br>	pg 3834<br>
What does "consider the functor T(X) = X + (C × X)" mean?	pg 3834<br>
Let C be a constant set. What is the constant functorial operation X ↦ C? Also, what is the identity functorial operation X ↦ X?<br>	pg 3834<br>
What is a "polynomial" functor?<br>	pg 3834<br>
Does the category of sets and functions have an initial object? Does it have a terminal object? If so, what are they? If not, prove it.<br><br>	pg 3834
Why are isomorphism between "polynomially constructed" sets important? List a few useful ones.	pg 3834 (bottom)<br>
What is the definition of an <i>algebra</i>?<br>	pg 3835<br>
How can the idea of a group (its operations, but not its equational properties) be expressed as an algebra?	pg 3835<br>
Give the definition of the <i>carrier</i> of an algebra. Also, give the definition of the <i>algebra structure</i> of an algebra.<br>	pg 3835<br>
Describe the zero and successor functions on natural numbers as an algebra.<br>	pg 3835<br>
Describe A-Labeled binary trees as an algebra.<br>	pg 3835<br>
How does an algebra's signature correspond to a functor?<br>	pg 3835<br>
What is the essential role of coproducts with regard to universal algebra?	answer: to combine multiple operations into a single operation.<br><br>pg 3836<br>
Give the definition for <i>homomorphism of algebras</i>.<br>	pg 3836<br>
Consider the following statement: <br><br>algebra maps (<i>homomorphisms</i>) are closed under composition.<br><br>Prove or disprove.<br>	true. pg 3837.<br><br>todo: impostor?<br>
Consider the following statement:<br><br>algebras and algebra homomorphisms form a category.<br><br>Prove or disprove.<br>	true. pg 3837.<br><br>todo: impostor?<br>
What does it mean for an algebra to be <i>initial</i>?<br>	pg 3837<br>
What is a "unique mediating algebra map"?<br>	pg 3837<br>
Prove that the natural numbers with zero and successor functions form an initial algebra for the functor T(X) = 1 + X.<br>	pg 3837/3838<br>
Use initiality to provide an inductive definition for the function f(n)=2<sup>-n</sup> from natural numbers to rationals.	pg 3838<br>
Let T be a functor. Consider the following statement:<br><br>Initial T-algebras, if they exist, are unique, up-to-isomorphism of algebras. That is, if we have two initial algebras <br><br>a  : T(U) → U<br>a' : T(U') → U'<br><br>of T, then there is a unique isomorphism f : U → U' of algebras.<br>	true. pg 3839, lemma 5.5 (i)<br>
Let T be a functor. Consider the following statement:<br><br>The operation of an initial algebra is an isomorphism: if a : T(U) → U is an initial algebra, then a has an inverse a<sup>-1</sup> : U → T(U).<br><br>Prove or disprove. 	true. pg 3839, lemma 5.5 (ii)<br><br>
How is it that initial algebras can be seen as generalizations of the least fixpoints of monotone functions?	pg 3839 (above proof)<br>
What notation is used for initial algebras, and why?<br>	a:T(U) \overset{\cong}{\rightarrow} U<br><br>pg 3840, above example 5.6<br><br>
Give the initial algebra for the functor 1 + (A × X) and prove that it is the initial algebra.<br>	pg 3840<br>
The initial algebra of 1 + (A × X) is the set A* = all finite sequence of elements of A, together with the function 1 → A* given by the empty list nil = (), and the function A × A* → A* which maps an element a ∈ A and a list α = (a<sub>1</sub>, ..., a<sub>n</sub>) ∈ A* to the list cons(a, α) = (a, a<sub>1</sub>, ..., a<sub>n</sub>).<br><br>Use initiality to define a length function on lists.<br>	pg 3841<br>
Let d be a doubling function on lists, e.g. d(1,3,2) = (1,1,3,3,2,2). Prove by "initiality" induction that len(d(α)) = 2·len(α).<br>	pg 3841<br>
Show how the predicate formulation of induction for lists can be derived from the initial algebra formulation.<br>	pg 3843, item 3<br>
Why is the coproduct + considered the dual of the product ×?<br>	pg 3844, near top<br>
Give the definition of <i>coalgebra</i>.<br>	pg 3844, def 6.1<br>
What is the <i>state space</i> of a coalgebras?<br>	pg 3844, def 6.1<br><br><br>
Why is the difference between algebras and coalgebras considered a difference of construction vs. observation?<br>	pg 3844<br>
True or false: A coalgebraic structure can be used to extract all information about its coalgebra's carrier set.<br>	false. pg 3844.<br>
What does it mean for two elements of a coalgebra's carrier set to be bisimilar?<br>	pg 3844<br>
Express the set containing all finite and infinite lists as a coalgebra.<br>	pg 3844, near bottom.<br>
Let A × X be the "infinite list" functor. Describe the concept of a homomorphism between two of its coalgebras using function diagrams.<br>	pg 3845, near top<br><br><br>
Give the definition of <i>homomorphism of coalgebras</i>.<br>	pg 3845, def 6.2 (i)<br><br>
Give the definition of <i>final coalgebra</i>.<br>	pg 3845, def 6.2 (ii)<br>
Discuss the similarities between initiality of algebras and finality of coalgebras.<br>	pg 3845/3846<br>
Consider the functor A × X. Show that the final coalgebra of this functor is the set A<sup><b>N</b></sup> of infinite lists with coalgebra structure <head, tail> : A<sup><b>N</b></sup> → A × A<sup><b>N</b></sup>.<br>	pg 3846<br><br>
In LAST, do our set names form a finite, countably infinite, or uncountably infinite collection? Why?	pg 3658<br>
LAST has two fundamentally different ways to refer to sets. Describe them.<br>	names (constants) and variables<br><br>pg 3658<br><br>
List the eight syntactic forms of the LAST language.<br>	pg 3659<br>
A formula that contains no free variables is called a _________.<br>	sentence.<br><br>pg 3660<br>
Provide the definition of a <i>LAST-describable collection</i>.<br>	pg 3660<br>
Express "x ⊆ y" in LAST.<br>	pg 3662<br>
Express "x = ⋃y" in LAST.<br>	pg 3662<br>
Express "x = {y}" in LAST.	pg 3662<br>
Express "x = {y, z}".<br>	pg 3662<br>
Express "x = (y,z)" in LAST.<br>	pg 3662<br>
Express "x = y ∪ z" in LAST.<br>	pg 3662<br>
Do exercise 2.1.1 on page 3662<br>	<br>
Why does the initial formulation of sets as any collection describable by LAST lead to an inconsistent theory?<br>	pg 3663<br>
What is the solution to the inconsistencies (Russell's paradox) of LAST?<br>	pg 3663/3664<br><br>
To solve Russell's paradox for LAST, we've decided to organize our collections in a hierarchy. What collection do we take as our initial collection (at the bottom of the hierarchy) M<sub>0</sub>?	pg 3664<br>
To solve Russell's paradox for LAST, we've decided to organize our collections in a hierarchy.<br>Which 'sets' of objects from lower levels of the hierarchy do we take as elements of each new level of the hierarchy?<br>	pg 3664/3665<br>
To solve Russell's paradox for LAST, we've decided to organize our collections in a hierarchy.<br>'How far' does the hierarchy extend?<br>	pg 3664
What is the Zermelo hierarchy?<br>	pg 3666<br>
State the motivation and definition of the <i>axiom of subset selection</i>.<br>	pg 3666<br>
Define the axiom of subset selection as a LAST sentence schema.<br>	pg 3666/3667<br>
Zermelo-Fraenkel set theory can be summarized as the thoery of sets with what three assumptions?<br>	pg 3667<br>
Exercise 2.2.1, pg 3667<br>	We can use theorem 1.7.1 (pg 3645) on the ordinals.<br><br>Base case: Since <$>\emptyset</$> has no members, this case holds vacuously.<br><br>Inductive case <$>V_\alpha = P(V_{\alpha-1}):<br>Since <$>y \in V_\alpha</$> we have <$>y \subseteq V_{\alpha - 1}</$>. Since <$>x \in y</$> we have <$>x \in V_{\alpha - 1}</$>. By the IH we have <$>x \subseteq V_{\alpha - 1}</$>.<br>Hence <$>x \in P(V_{\alpha-1}) = V_{\alpha}</$>.<br><br>Inductive case <$>V_\alpha = \bigcup_{\beta < \alpha} V_{\beta}</$>:<br>Since <$>y \in V_\alpha</$>, there exists a <$>\beta < \alpha</$> with <$>y \in V_{\beta}</$>.<br>Applying the IH yields <$>y \subseteq V_{\beta}</$>. Hence <$>y \subseteq V_{\beta} \subseteq \bigcup_{\beta < \alpha} V_{\beta} = V_\alpha</$>.<br><br>
Exercise 2.2.2, pg 3667<br>	see answer to section 2.2.3
Exercise 2.2.3, pg 3667<br>	We apply thm 1.7.1 (pg 3645) on On.<br><br>Base Case: <$>V_0 = \emptyset = \bigcup \emptyset = \bigcup_{\lambda < 0} \mathcal P(V_\lambda)</$><br><br>Case <$>V_\alpha = \mathcal P (V_{\alpha - 1})</$>:<br><br><br>******************<br>Using the result of exercise 2.2.3 makes this much easier to prove.<br>Proving 2.2.3 is fairly trivial:<br>The base case holds vacuously.<br><br>For successors we have <$>x \in V_{\beta-1} \to x \subseteq V_{\beta-1} \to x \in P(V_{\beta-1}) \to x \in V_\beta</$>. We then have <$>V_{\beta-1} \subseteq V_\beta</$> and if <$>\alpha < \beta</$> the IH gives <$>V_\alpha \subseteq V_{\beta-1} \subseteq V_\beta</$>.<br><br>Limits are trivial: <$>V_\beta = \bigcup_{\alpha < \beta} V_\alpha</$> and so <$>V_\alpha \subseteq V_\beta</$> since a union is a superset of each of its components.<br>**********************<br><br>Case <$>V_\alpha = \bigcup_{\beta < \alpha} V_\beta</$>:<br><br><$>x \in V_\alpha \leftrightarrow \exists \beta < \alpha. (x \in V_\beta) \leftrightarrow \exists \beta < \alpha. (x \in \bigcup_{\lambda < \beta} \mathcal P(V_\lambda)) \leftrightarrow \exists \beta < \alpha. (x \in \mathcal P(V_\beta)) \leftrightarrow x \in \bigcup_{\beta < \alpha} P(V_\beta)</$><br><br><br>
Exercise 2.2.4, pg 3667<br>	<br>
Exercise 2.2.5, pg 3667<br>	<br>
Exercise 2.2.6, pg 3667<br>	<br>
State the powerset axiom, and give its motivation.<br>	pg 3668<br>
Write down a sentence of LAST which expresses the power set axiom.<br>	pg 3668, ex 2.3.1<br>
State the axiom of union and give its motivation.<br>	right above exercise 2.3.2, pg 3668<br>
Express the axiom of union in the language LAST.	pg 3668<br>
State and motivate the axiom of replacement.<br>	pg 3669<br>
Exercise 2.3.3, pg 3669<br>	<br>
State and motivate the null set axiom and the axiom of infinity.<br>	pg 3670<br>
Consider the following statement:<br><br>Without the null set axiom, ZF would be insufficient as a basis for set theory. <br><br>Prove or disprove	IMPOSTOR.<br><br>pg 3670, bottom<br>
Express the axiom of infinity and the null set axiom in LAST.<br>	pg 3671, ex 2.3.4<br>
List the nine axioms of Zermelo-Fraenkel set theory.<br>	pg 3671/3672<br>
Exercise 2.3.8, pg 3673<br>	<br>
Exercise 2.3.9, pg 3673<br>	<br>
Motivate and state th axiom of foundation.	pg 3672<br>
Exercise 2.3.6, pg 3672<br>	--><br>First suppose that <$>\in</$> is well-founded.<br><br>For contradiction, assume there exist a set x such that for all <$>a \in x</$>, there<br>exists a <$>v_a \in a</$> such that <$>v_a \in x</$>.<br><br>Let <$>a \in x</$>. By our assumption, there is some <$>v_a \in a</$> such that <$>v_a \in x</$>. Since <$>v_a \in x</$>, we can then apply our assumption again to obtain the existence of a <$>v_{v_a} \in v_a</$> such that <$>v_{v_a} \in x</$>.<br><br>Thus we obtain an infinite sequence <$>a, v_a, v_{v_a}, \ldots</$> where each subsequent item is an element of the previous item, contradicting the well-foundedness of <$>\in</$>.<br><br><--<br>TODO<br><br>
Exercise 2.3.7, pg 3672<br>	We first prove that if <$>V = \bigcup_{\alpha} V_{\alpha}</$> then <$>\in</$> is well-founded.<br><br>To this end, let <$>x \in V</$>. Then there exists an <$>\alpha \in Ord</$> such that <$>x \in V_{\alpha}</$>. We prove by well-founded induction that no infinite chain <$>x \in x_0 \in x_1 \in ... </$> can exist.<br><br>Base case <$>\alpha = 0</$>:<br><$>V_0 = \emptyset</$> and so <$>x \in V_0</$> is contradictory.<br><br>Inductive case <$>\alpha = P(V_{\alpha-1})</$>:<br>Suppose <$>x \in V_{\alpha}</$> For contradiction, assume an infinite chain <$>x \in x_0 \in x_1 \in \ldots</$><br><$>x \subseteq V_{\alpha-1}</$>, and so <$>x_0 \in V_{\alpha-1}</$>. By the IH, there is no infinite chain beginning with <$>x_0</$>, contradicting the assumption that <$>x \in x_0 \in x_1 \in \ldots</$> is an infinite chain.<br><br>Inductive case <$>V_{\alpha} = \bigcup_{\lambda < \alpha}{V_\alpha}</$>:<br>Let <$>x \in V_{\alpha}</$>. Then <$>x \in V_\beta</$> for some <$>\beta < x</$>. The inductive hypothesis then tells us that no infinite chain begins with <$>x</$>.<br><br>TODO:<br>We now prove in the opposite direction that if <$>\in</$> is well-founded, then <$>V = \bigcup{\alpha \in Ord} V_\alpha</$>. Maybe exercise 2.3.6 would be helpful here?<br><br><br><br>---<br><br><br><br>
What is the difference between ZF and ZFC?<br>	pg 3673<br>
Exercise 2.3.9, pg 3673	<br>
Consider the following statement:<br><br>The collection of all sets is a set.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 3674.<br>
Consider the following statement:<br><br>The set of all ordinals is a set.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 3674<br>
Provide the definitions of <i>class</i> and <i>proper class</i>.<br>	pg 3674, near bottom<br>
Exercise 2.4.1, pg 3676	<br>
Exercise 2.4.2, pg 3676	<br>
How can the usage of classes help simplify the statement of the Axiom of Replacement?<br>	pg 3677<br>
What does "classes are abbreviations" mean?	pg 3675-3677<br>
Exercise 2.4.3, pg 3677<br>	<br>
Exercise 2.4.4, pg 3677<br>	<br>
Exercise 2.4.5, pg 3677<br>	<br>
How do we know if the ZFC axioms are sufficient for our needs?<br>	pg 3678, near bottom<br>
Express the construction of the Zermelo hierarchy using a single equation.<br>	pg 3679<br>
State and discuss the axiom of choice.<br>	pg 3684, near bottom<br><br>
Give the alternate version of the axiom of choice, which deals with choice functions rather than choice sets. Prove it equivalent to the standard version.<br>	pg 3685/3686<br>
State Zermelo's well-ordering principle and prove that it is equivalent to the axiom of choice.<br>	pg 3686<br>
Consider the following statement:<br><br>Every set has a correspondence with some ordinal.<br><br>Prove or disprove.	true. pg 3688<br>
State Zorn's lemma.<br>	pg 3688, ZL<br>
Show that the axiom of choice implies Zorn's lemma.	pg 3688<br>
Here is Zorn's lemma:<br><br>If a poset (P, <<sub>P</sub>) has the property that every chain in P has an upper bound in P, then P has a maximal element.<br><br>Here is a variant of Zorn's lemma:<br><br>If (P, ≤<sub>P</sub>) is a poset such that every chain in P has an upper bound in P, then for every p ∈ P there is a q ∈ P such that p ≤<sub>P</sub> q and q is maximal in P.<br><br>Show that the first version implies the second.<br><br>	pg 3688<br>
State the Hasdorff Maximal Principle. <br><br>Here is a variant of Zorn's lemma:<br><br>If (P, ≤<sub>P</sub>) is a poset such that every chain in P has an upper bound in P, then for every p ∈ P, there is a q ∈ P such that p ≤<sub>P</sub> q and q is maximal in P.<br><br>Show that the variant of Zorn's lemma implies the Hausdorff maximal principle.	pg 3689<br>
Exercise 2.7.1, pg 3689<br>	<br>
Exercise 2.7.2, pg 3689<br>	<$>\rightarrow</$><br>Suppose that X is a member of F. Let Y be a finite subset of X. Then <br><$>dom(Y) \subseteq dom(X) \subseteq A</$><br>and<br><$>rng(Y) \subseteq rng(Y) \subseteq B</$><br>Hence <$>Y \in F</$><br><br><$>\leftarrow</$><br>Suppose that X is a set and every finite subset of X is an element of F.<br>First note that X is a function; because every singleton subset of X is in F,<br>every element of X is a pair. Because every doubleton subset of X is a function,<br>X is a function.<br><br>Let <$>v \in dom(X)</$>. Then there exists a finite subset {(v,w)} of X. Hence {(v,w)} is an element of F, and so <$>dom({(v,w)}) = {v} \subseteq A \therefore v \in A</$> . Hence <$>dom(X) \subseteq A</$>. The proof that <$>rng(X) \subseteq B</$> is similar.<br><br><br><br><br>
Exercise 2.7.3, pg 3690<br>	<br>
What does it mean for a set to have <i>finite character</i>?<br>	pg 3689, near bottom, above exercises<br><br>
State Tukey's lemma. <br><br>Here is a variant of the axiom of choice:<br><br>A choice function for F is a function f : F → ⋃F such that for each X ∈ F, f(X) ∈ X.<br>Every set of nonempty sets has a choice function.<br><br>Prove that Tukey's lemma implies the variant of the axiom of choice.<br>	pg 3690<br>
<br>Here is the Hausdorff Maximal Principle:<br><br>If (P, ≤<sub>P</sub>) is a poset, then every chain in P can be extended to a maximal chain.<br><br>Here is Tukey's Lemma:<br><br>Every set of finite chatacter has an element that is maximal with respect to inclusion.<br><br>Prove that the Hausdorff Maximal Principle implies Tukey's lemma.<br><br>	pg 3690/3691<br>
Which axiom of ZF set theory rules out the possibility of self-referential sets and why?<br>	pg 3772, top paragraph<br>
What is ZFCA, and how is it different from ZFC?<br>	pg 3773
Explain how sets can be depicted as directed graphs.<br>	pg 3773/3774<br>
When depicting sets as graphs, what is the difference between a hollow node and a filled node?<br>	pg 3775, near bottom, second to last paragraph<br>
There can be multiple ways to depict a set as a graph. Give two graphs corresponding to the ordinal 2.<br>	pg 3776, near top<br>second version is near top of pg 3775<br><br>
What is the set Ω? Why are there infinitely many graphs which depict Ω?<br>	pg 3777<br>
draw a graph depicting a = {b,c}, b = {Zermelo, Fraenkel, c}, c = {Hilbert, Fraenkel, b}.<br>	pg 3778<br>
What does it mean for a directed graph to be <i>pointed</i>?<br>	pg 3779<br>
Why do the two sets a = {Zermelo, a} and b = {Zermelo, b} pose a problem for non-well-founded set theory? What is the solution to this dillema?<br>	pg 3779, 3780<br>
Informally paraphrase the anti-foundation axiom in intuitive terms.<br>	pg 3780, "every graph depicts one set"<br>
What is ZFCA<sup>-</sup>?	pg 3781<br>
What is a <i>tagging</i> of a pointed graph in ZFCA<sup>-</sup>?<br>	pg 3781<br>
Let G be a pointed graph and t a tagging of G. What is a <i>decoration</i> of G with respect to t?<br>	pg 3781<br>
What does it mean for a graph to be <i>well-founded</i>?<br>	pg 3781<br>
State and prove the collapsing lemma.<br>	pg 3781/3782<br>
Let x be a possibly non-well-founded set. What is a <i>picture</i> of x?<br>	pg 3782<br>
Give three pictures of the set a = {a, Zermelo}, two of which are finite and one of which is infinite.<br>	pg 3782<br>
Consider the following statement: <br><br>Every (possibly non-well-founded) set can be pictured by a tree.<br><br>Prove or disprove.<br>	true. pg 3782, lemma 7.2.2<br>
What is the <i>unfolding</i> of a pointed graph G?<br>	pg 3782, bottom of the proof of lemma 7.2.2<br>
Consider the following statement:<br><br>For any (possibly non-well-founded) set x, there is a unique tree that pictures x.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 3783, fig 7.9<br><br><br>
What is a <i>universe</i> for a theory of sets?	pg 3783<br>
How are the universes for ZFCA abd ZFCA<sup>-</sup>+AFA related?<br>	pg 3783, thm 7.2.3<br>
What is a set equation? What is a system of set equations?<br><br>	pg 3786
What is a <i>solution</i> to a system of set equations?<br>	pg 3786/3787<br><br>
State the solution lemma.<br>	pg 3787<br>
Give an inductive definition of the ordinals.	pg 3788<br>
Define the ordinals as the least fixpoint of a monotone set-based (i.e. continuous) operator.	pg 3788<br>
Give a brief, handwavy overview of the techique for defining a coalgebra map by finality.<br>	pg 3846<br>
Describe the connection between final coalgebras and observable behavior.	pg 3846, second to last paragraph<br>
Use the finality of (A<sup><b>N</b></sup>, [head,tail]) to define the constant sequence const<sub>a</sub>(n) = a. (hint: define const<sub>a</sub> as a function from 1 to A<sup><b>N</b></sup>.	pg 3846<br>
Use the finality of (A<sup><b>N</b></sup>, [head,tail]) to define the function <i>from</i> : <b>N</b> →  <b>N<sup>N</sup></b>, where from(n) = (n, n+1, n+2, ...). (hint: this is a special case where A = <b>N</b>)<br><br>	pg 3847<br>
Use the finality of (A<sup><b>N</b></sup>, [head,tail]) to define the <i>merge</i> function from A<sup><b>N</b></sup> × A<sup><b>N</b></sup> → A<sup><b>N</b></sup>, where <i>merge</i>([a<sub>1</sub>,a<sub>2</sub>,...], [b<sub>1</sub>,b<sub>2</sub>,...]) = [a<sub>1</sub>, b<sub>1</sub>, a<sub>2</sub>, b<sub>2</sub>, ...].	pg 3847<br>
Use the finality of (A<sup>N</sup>, [head,tail]) to define the <i>odd</i> function, where odd([a<sub>1</sub>,a<sub>2</sub>,...]) = [a<sub>1</sub>,a<sub>3</sub>,a<sub>5</sub>, ...].<br><br>	pg 3847<br>
Use the finality of (A<sup>N</sup>,[head,tail]) to prove that for all α ∈ A<sup>N</sup>, merge(odd(α),even(α))=α.<br>	pg 3847<br>
Consider the following statement:<br><br>Final coalgebras, if they exist, are uniquely determined up-to-isomorphism.<br><br>Prove or disprove.<br><br>	true. pg 3848, lemma 6.4 (i)<br>
Consider the following statement:<br><br>The final coalgebra of a functor, if it exists, is unique.<br><br>Prove or disprove.<br><br>	IMPOSTOR (it is unqiue up-to-isomorphism, not quite the same thing)<br><br>pg 3848<br>
Consider the following statement:<br><br>A final coalgebra W → T(W) is a fixed point of the functor T.<br><br>Prove or disprove.<br><br>	true. lemma 6.4 (ii)<br>
Finality has two components: existence and uniqueness. How are each of these components relevant to coinduction?	pg 3849<br>
Let F be a invertible monotone function. What does it mean for x ϵ U to be F-supported? What does it mean for an F-supported element to be F-ground?	def 21.5.3 pg 291
Let X be the set of all finite and infinite trees.<br><br>Define S : 2<sup>UxU</sup>→2<sup>UxU</sup> by the following.<br><br>S(R) =<br>{(T,Top) | T ϵ <i>T</i>}<br>U {(S<sub>1</sub> x S<sub>2</sub>, T<sub>1</sub> x T<sub>2</sub>) | (S<sub>1</sub>,T<sub>1</sub>), (S<sub>2</sub>,T<sub>2</sub>) ϵ R}<br>U {(S<sub>1</sub> → S<sub>2</sub>, T<sub>1</sub> → T<sub>2</sub>) | (T<sub>1</sub>,S<sub>1</sub>), (S<sub>2</sub>,T<sub>2</sub>) ϵ R}<br><br>Consider the following statement<br>νS is transitive<br><br>Prove or give a counterexample.	Thm 21.3.7
Exercise 20.2.1	<br>
Exercise 20.2.2	<br>
Explain the difference between Curry-style and Church-style lanuage definitions.<br>	tapl section 9.6
What does it mean for a term in the untyped lambda calculus to be typable?	Don't forget... THE TERM CAN BE TYPABLE IN ANY CONTEXT.<br><br>tapl definition 9.5.3
State the Progress property of a term in the simply typed lambda calculus.	see theorem 9.3.5
State the canonical forms lemma for the simply typed lambda calculus.	see lemma 9.3.4
If R is a binary relation on set S, what does R* denote?	the reflexive transitive closure.<br><br>tapl chm section 2.2.5
Consider this grammar for a simple language:<br>t ::= true | false | if t then t else t | 0 | succ t | pred t | iszero t<br><br>Express the same language:<br>1. Inductively<br>2. By inference rule schemas<br>3. Concretely	tapl chm 3.2
TAPL Exercise 3.2.4	59439<br>tapl_solutions pdf pg 1
tapl exercise 3.2.5	answer in book. I consider this too easy to copy into here. it is an inductive proof.
Let T be the smallest set such that<br><$>1.\ \{true,\ false,\ 0\}\ \subseteq\ T;</$><br><$>2.\ if\ t_1\ \epsilon\ T,\ then\ \{succ\ t_1,\ pred\ t_1,\ iszero\ t_1\}\ \subseteq\ T;</$><br><$>3.\ if\ t_1\ \epsilon\ T,\ t_2\ \epsilon\ T,\ and\ t_3\ \epsilon\ T,\ then\ "if\ t_1\ then\ t_2\ else\ t_3"\ \epsilon\ T.</$><br><br>Let S be the set defined as follows:<br><$>S = \bigcup\limits_i S_i</$><br>where<br><$>S_0 = \emptyset</$><br><$>S_{i+1}\ =\ \{true,\ false,\ 0\}\ \cup\ \{succ\ t_1,\ pred\ t_1,\ iszero\ t_1\ |\ t_1\ \epsilon\ S_i\} \cup\ \{if\ t_1\ then\ t_2\ else\ t_3\ |\ t_1,t_2,t_3\ \epsilon\ S_i\}</$><br><br>Prove T=S	tapl section 3.2
List and explain the three different types of induction on terms.	tapl section 3.3
Explain the three different approaches to formalizing semantics. Give the pros and cons of each. Which is currently the most popular?	tapl chm section 3.4
Give the definition for an *instance* of an inference rule. 	An instance of an inference rule is the result of the following process:<br><br>-Start with the inference rule<br>-For each metavariable in the rule, replace all occurences of that metavariable with the same term.<br><br>tapl chm section 3.5
What does it mean for an inference rule to be satisfied by a relation?	For each instance of the rule, either the conclusion is in the relation or one of the premises is not.<br><br>For example, if the conclusion of a rule is 2<1, that rule is not satisfied by < (the standard less than operator). If one of the premises is not in the relation, the conclusion doesn't matter, because we have started with false premises. <br><br>tapl section 3.5
Explain the "induction on derivations" method of proof.<br>	If, for each derivation D, given P(C) for all immediate subderivations C we can show P(D), then P(D) holds for all D.<br><br>take a look at the proof of theorem 3.5.4 in tapl to see it in action.
Define what it means for a term to be in *normal form*	tapl definition 3.5.6
tapl exercise 3.5.10	<br>
Define preorder, partial order, and total order.	tapl chm section 2.2
Suppose <$>\leq</$> is a partial order on a set S and s and t are elements of S. What does it mean for <$>j \epsilon S</$> to be a join of s and t?	tapl chm section 2.2.3
If R is a binary relation on set S, define the transitive closure of R. Define the reflexive closure of R as well.	tapl section 2.2.5<br>Reflexive:<br><$$>R' = R \cup \{(s,s) : s \epsilon S\}</$$><br>(The chm has a typo in exercise 2.2.6, if you were wondering.)<br><br>Transitive:<br>See ex 2.2.7 (like 2.2.6, this has a typo)<br><br><br>
<$>\mbox{Suppose we have a preorder }\leq\mbox{ on set S. Define a decreasing chain in }\leq.</$>	tapl chm section 2.2.9
What is a well founded set?	tapl chm section 2.2.10
tapl exercise 3.5.16	From the book:<br><br>Let us use the metavariable t to range over the new set of terms extended with wrong (including all terms with wrong as a subphrase), and g to range over the original set of "good" terms that do not involve wrong. Write <$>t \stackrel{w}{\rightarrow} t'</$> for the new evaluation relation augmented with wrong transitions, and <$>g \stackrel{o}{\rightarrow} g'</$> for the original form of evalutation. Now, the claim that the two treatments agree can be formulated precisely as follows: any (original) term whose evaluation gets stuck in the original semantics will evaluate to wrong in the new semantics, and vice versa.<br><br>Holy crap... you will just need the book for the rest of this answer, because it is two pages.
tapl exercise 3.5.17	see tapl_solutions.pdf
Explain the difference between bound and unbound variables in the lambda calculus.	tapl chm section 5.1
What does <$>(\lambda x.\ t_{12})\ t_2 \rightarrow\ [x\ \mapsto\ t_2]t_{12}\ </$> mean in the lambda calculus? What is its significance?  	It is the application operator<br>see tapl chm 5.1, "Operational Semantics"
In the lambda calculus, what is a redex? Give the general form of a redex.	tapl chm 5.1, "operational semantics"
What is full beta-reduction?	tapl chm 5.1, "Operational Semantics"
In the lambda calculus, what is <i>normal order</i> evaluation strategy? 	tapl chm 5.1, "Operational Semantics"
Explain the call-by-value strategy for evaluating the lambda calculus.	tapl chm 5.1, "Operational Semantics"
Explain the call-by-name strategy for evaluating the lambda calculus.<br><br>Evaluate "id (id (λz. id z))" to a normal form using call-by-name.<br>	tapl chm 5.1, "Operational Semantics"
Give the definitions of the Church booleans, tru and fls.	tapl chm 5.2, "Church Booleans"
test is a function such that test b v w = v if b is tru and w if b is fls. write test using lambda terms.	tapl chm 5.2 "Church Booleans"
<i>and</i> is a function such that, given two arguments x and y, supposing x and y are either tru or fls, returns tru if x and y are both tru, but returns false if either x, y, or both are fls.<br><br>Write and using lambda terms.<br>	tapl chm 5.2, "Church Booleans"
tapl chm exercise 5.2.1	answer is in the back of the book, I could copy it here, but this is a one-star problem, so that shouldn't be necessary.
Explain how to use lambda abstractions to encode pairs of values. Give definitions for these three functions:<br><br>pair : a function that, given two values, returns a pair containing those values.<br><br>fst : a function that, given a pair, returns the first value in the pair.<br><br>snd : a function that, given a pair, returns the second value in the pair.<br> 	tapl chm 5.2, "Pairs"
Give the definition of the church numerals <$>c_0, c_1, c_2, etc.</$>	tapl chm 5.2, "Church Numerals"
tapl chm exercise 5.2.2	pass (s z) in for z... a better answer is in the book, but really, this should be easy.
Write a definition of the scc (successor) function for Church numerals. <br><br>scc must satisfy this equation for all church numerals: <$>scc\ c_{n}\ =\ c_{n+1}</$> <br><br>(There are multiple possible answers of course.)	tapl chm 5.2, "Church Numerals"
define the function <i>plus</i>, which takes two church numerals and returns the church numeral representing the sum of the arguments.	tapl chm 5.2, "Church Numerals"
write the definition of times, a function which takes two church numerals, and returns a function which is the church numeral representing the product of its arguments.	tapl chm 5.2, "Church Numerals"
tapl chm exercise 5.2.3	<$>times = \lambda m.\ \lambda n.\ \lambda s.\ m\ (n\ s)\ z</$><br>Or, more compactly:<br><$>times = \lambda m.\ \lambda n.\ \lambda s.\ m\ (n\ s)</$> 
tapl chm exercise 5.2.4	More than one way to do it:<br><$>power = \lambda m.\ \lambda n.\ m\ (times\ n)\ c_1</$><br><$>power = \lambda m.\ \lambda n.\ m\ n</$>
Given the definition for the iszro function, which takes a church numeral and returns tru if that numeral is zero, and fls otherwise.	tapl chm 5.2, "Church Numerals"
Give the definition of prd, a function which, given a church numeral, returns the church numeral representing the number that is one less than the argument. If the argument is 0, prd returns 0.	tapl chm 5.2, "Church Numerals"
tapl chm exercise 5.2.5	<$>subtract = \lambda m.\ \lambda n.\ n\ prd\ m</$>
tapl chm exercise 5.2.6	Evalutating <$>prd\ c_n</$> takes O(n) steps, since prd uses n to construct a sequence of n pairs of numbers and then  selects the first component of the last pair of the sequence.<br>
tapl chm exercise 5.2.7	Here's a simple one:<br><br><$>equal = \lambda m. \lambda n.\ and\ (iszro\ (m\ prd\ n))\ (iszro\ (n\ prd\ m))</$>
tapl chm exercise 5.2.8	From the book: here is one possible solution:<br><br><$>nil = pair tru tru</$><br><$>cons = \lambda h.\ \lambda t.\ \lambda c. \lambda n.\ c\ h\ (t\ c\ n)</$><br><$>head = \lambda l.\ l\ (\lambda h.\lambda t.h)\ fls</$><br><$>tail = \lambda l.\ fst\ (l\ (\lambda x.\ \lambda p.\ pair\ (snd\ p)\ (cons\ x\ (snd\ p)))\ (pair\ nil\ nil))</$><br><$>isnil = \lambda l.\ l\ (\lambda h.\lambda t. fls)\ tru</$><br><br>here is a rather different approach:<br><$>nil = pair tru tru</$><br><$>cons = \lambda h.\ \lambda t.\ pair\ fls\ (pair\ h\ t)</$><br><$>head = \lambda z.\ fst\ (snd\ z)</$><br><$>tail = \lambda z.\ snd\ (snd\ z)</$><br><$>isnil = fst</$><br> 
What is the motivation for using primitive booleans and numerals rather than Church booleans and numerals?	tapl 5.1, "Enriching the Calculus"
What does it mean for a lambda term to diverge?	tapl 5.2, "Recursion"
tapl exercise 5.2.9	We used if rather than test to prevent both branches of the conditional always being evaluated, which would make factorial diverge. To prevent this divergence when using test, we need to protect both branches by wrapping them in dummy lambda-abstractions. Since abstractions are values, our call-by-value evaluation strategy does not look underneath them, but instead passes them verbatim to test, which chooses one and passes it back. We then apply the whole test expression to a dummy argument, say <$>c_0</$>, to force evaluation of the chose branch.
tapl exercise 5.2.10	<br>
tapl exercise 5.2.11	Solution:<br><br><$>\lambda f.\ \lambda l.\ test\ (isnil\ l)\ (\lambda x.\ c_0)\ (\lambda x.\ (plus\ (head\ l)\ (f (tail l))))\  c_0</$><br><br><$>sumlist = fix ff</$><br><$>l = cons\ c_2\ (cons\ c_3\ (cons\ c_4\ nil))</$><br><$>equal\ (sumlist\ l) c_9</$><br><br>A list-summing function can also, of course, be written without using fix:<br><br><$>sumlist'\ =\ \lambda l.\ l\ plus\ c_0</$><br><$>equal (sumlist\ l)\ c_9</$>
What is the <i>fixed-point combinator</i>? What is it used for?	tapl chm 5.2, "Recursion"
Give the inductive definition of a lambda term.	tapl 5.2, "syntax"
Give an inductive definition for the set of variables appearing free in a lambda term.	tapl 5.2, "Syntax"
tapl exercise 5.3.3	<br>
tapl exercise 5.3.6	<br>
tapl exercise 5.3.7	<br>
tapl exercise 5.3.8	<br>
tapl exercise 6.1.1	in the book.. TO DO: copy to here... even though this is really easy
Give an inductive definition for the terms <$>\{T_0,\ T_1,\ T_2,\ ...\}</$> where <$>T_i</$> is the set of i-terms, i.e. the set of terms with at most i free variables. 	tapl definition 6.1.2
What is a "naming context"? (hint: it has something to do with de Bruijn indices)	tapl chm 6.1.3
tapl 6.1.4	Let <$>T_{i,j}</$> be the set of all terms with at most i free variables having depth j.<br><br><$>T_{i,0}=\emptyset</$>  <br><$>T_{i,j>0}=\mathbb{Z}_i\ \cup\ \{\lambda.t_1\ :\ t_{1}\ \epsilon\ T_{i+1,j-1}\}\ \cup\ \{t_1\ t_2\ :\ t_1,\ t_2\ \epsilon\ T_{i,j-1}\}</$><br><$>T_i = \bigcup_{j \geq 0}T_{i,j}</$><br><br>One thing that confused me initially is that <$>T{i,j}</$> depends on <$>T{i+1,j-1}</$>. Since the first index increases, aren't we going to set of a chain reaction, causing infinitely many new sets to be computed for (i,j) pairs? No. The reason is that j decreases until it gets to 0, the base case.<br>
tapl exercise 6.1.5	ERRATA ALERT (taken from pierce's official errata):<br>the subscripts in the third clauses should be just "Gamma", not "Gamma,x"<br><br>tapl_soloutions pg 11
must any special cares be taken when doing on a subs	<br>
When using de Bruijn indices, must any special cares be taken when doing substitution on a lambda abstraction? Explain.	tapl chm 6.2
Given the notation and definition for a d-place shift of a term t above cutoff c. What is shifting used for? 	tapl chm definition 6.2.1
What is <$>\uparrow^2(\lambda.\lambda.1\ (0\ 2))</$>?<br><br>What is <$>\uparrow^2(\lambda.\ 0\ 1\ (\lambda.\ 0\ 1\ 2))?</$>	tapl exercise 6.2.2 answer in back
Show that if t is an n-term, then <$>\uparrow_c^d(t)</$> is an (n+d)-term.	tapl chm 6.2.3 (no answer provided)
Give the definition for substitution on lambda terms using de Bruijn indices.<br>	tapl chm definition 6.2.4
tapl chm exercise 6.2.5	tapl_solutions pdf pg 11<br><br><$>[0\ \mapsto\ 1](0\ (\lambda.\lambda.2)) = 1(\lambda.\lambda.3)\ i.e.\ a(\lambda x.\ \lambda y.\ a)</$><br><br><$>[0\ \mapsto\ 1\ (\lambda.2)](0\ (\lambda.1)) = (1\ (\lambda.2)) (\lambda.(2\ (\lambda.3)))</$><br><$>i.e., (a\ (\lambda z.a)) (\lambda x. (a (\lambda z.a)))</$><br>
tapl chm exercise 6.2.6	<br>
tapl chm exercise 6.2.8	If <$>\Gamma</$> is a naming context, write <$>\Gamma(x)\ </$> for the index of x in <$>\Gamma</$>, counting from the right. Now, the property that we want is that <br><br><$>removenames_{\Gamma}([x\ \mapsto\ s]t) = [\Gamma(x)\ \mapsto\ removenames_{\Gamma}(s)](removenames_{\Gamma}(t))</$><br><br>The proof proceeds by induction on t, using Definitions 5.3.5 and 6.2.4, some simple calculations, and some easy lemmas about removenames and the other basic operations on terms. Convention 5.3.4 plays a crucial role in the abstraction case.
What is the result of <$>(\lambda.t_{12})\ v_2</$>, assuming t_12 and v_2 are lambda terms represented namelessly?	tapl chm section 6.3 (E-AppAbs)
tapl chm exercise 6.3.1	The only way an index could become negative would be if the variable numbered 0 actually occurred anywhere in the term we shift. But this cannot happen, since we've just performed a substitution for variable 0 (and since the term that we substituted for variable 0 was already shifted up, so it obviously cannot contain any instances of variable number 0).<br>
tapl chm exercise 6.3.2	<br>
Safety is the most basic property of type systems. Give its definition.	tapl chm section 8.3
tapl 8.3.6	<br>
tapl exercise 8.3.7	<br>
tapl exercise 8.3.8	<br>
What is the difference between explicitly-typed and implicitly-typed languages?<br>	tapl chm section 9.2
What is a typing context?	tapl chm section 9.2
In the simply typed lambda calculus, give the rule for typing abstractions.	tapl chm section 9.2 (T-Abs)
In the simply-typed lambda calculus, give the rule for typing variables.	tapl chm section 9.2 (T-Var)
In the simply-typed lambda calculus, give the rule for typing applications.	tapl chm section 9.2 (T-APP)
In the simply-typed lambda calculus, give the rule for typing if statements.	tapl chm section 9.2 (T-IF)
tapl chm exercise 9.2.2	<br>
tapl chm exercise 9.2.3	From the book:<br>One such context is<br><$>\Gamma = f:Bool\ \rightarrow\ Bool\ \rightarrow\ Bool,\ x:Bool,\ y:Bool.</$><br><br>In general, any context of the form <br><$>\Gamma\ =\ f:S \rightarrow T \rightarrow Bool, x:S, y:T</$><br>where S and T are arbitrary types, will do the job. This sort of reasoning is central to the type reconstruction algorithm developed in chapter 22.
the "Inversion of the Typing Relation" lemma can be useful for proving properties of the simply typed lambda calculus. It consists of many parts, can you name some of them?	tapl chm Lemma 9.3.1
tapl exercise 9.3.2	tapl solutions pg 13
Is it possible for a term in the simply typed lambda calculus to have more than one type? Why or why not?	a term may have only one type <br>see theorem 9.3.3, uniqueness of types
The preservation of types under substitution lemma is the following:<br><br><$>If\ \Gamma,\ x:S\ \vdash\ t:T\ and\ \Gamma\ \vdash\ s:S,\ then\ \Gamma \vdash[x\ \mapsto\ s]t:T</$><br><br>Prove this for the following cases:<br>t = λy:T2.t1,<br>t = t1 t2<br>t = if t1 then t2 else t3	<br>
State the preservation property of the simply typed lambda calculus.	theorem 9.3.9
tapl exercise 9.3.10	<br>
What is an introduction rule? What is an elimination rule? Give an example of an introduction rule and an example of an elimination rule from the simply typed lambda calculus.	tapl 9.4 introduction
tapl exercise 9.4.1	<br>
Explain the Curry-Howard correspondence.	tapl 9.4
give the definition of the "erase" function for the simply typed lambda calculus.	tapl definition 9.5.1
Extend the simply typed lambda calculus to include sequencing.<br>Prove sequencing is a derived form.<br>	tapl 11.3
What is an "external language"? What is one used for?	See 11.3<br>Thoerem 11.3.1
What is an elaboration function? What is one used for?	See 11.3<br>Thoerem 11.3.1
Why are derived forms useful?	11.3<br>They allow us to extend the language syntax without complicating the core language about which theorems such as type safety must be proved.
Do exercise 11.3.2	see tapl_solutions
Give the syntax for type ascription as deduction rules.<br>Give an elaboration for type ascription, and prove it is a derived form (exercise 11.4.1)<br>	tapl 11.4
Give syntactic extensions to the simply-typed lambda calculus for let expressions. Can let expressions be made a derived form?	11.5
Exercise 11.5.2	see tapl_solutions
Give syntactic extensions, as well as typing and evaluation rules for tuples. 	11.7-11.6
Give syntactic extensions, typing rules, and evaluation rules, for records.	11.7-11.8
Exercise 11.8.2	<br>
What is a variant? Give syntactic extensions, typing, and evaluation rules for variants.	11.9-11.10
Why would someone make a variant type with only a single label?	section 11.10, heading "Single-Field Variants"
Give syntactic extensions to the STLC as well as, typing, and evaluation rules for lists.	section 11.12
exercise 11.12.1	see tapl_solutions
exercise 11.12.2	see tapl_solutions
What is the result of the following code?<br><br>r = ref 5;<br>q = r;<br>q := 82;<br>!r<br><br>	82<br><br>tapl 13.1, "References and Aliasing"
Exercise 13.1.1	tapl_solutions
How would you implement an array using the simply typed lambda calculus with references, booleans, and naturals?<br>	13.1 "References to Compound Types"
Exercise 13.1.2	<br>
Exercise 13.1.3	<br>
In TAPL, what is the definition of a <b>store</b>?	section 13.3
In PL theory, what is an <i>intermediate language</i>? How are they relevant to the semantics of references?	section 13.3
Exercise 13.3.1	<br>
Exercise 13.4.1	<br>
Give the syntax, as well as the evaluation and typing rules for<br>λ<sub>→</sub> with Unit and references.	13.5
Give the evaluation rules and typing rule for "fix" in the simply typed lambda calculus.<br>	Section 11.11
Define equal, plus, times, and factorial using fix.<br><br>	Exercise 11.11.1
Give the elaboration for letrec as a derived form of the simply typed lambda calculus with fix and let.<br>	letrec x : T<sub>1</sub> = t<sub>1</sub> in t<sub>2</sub>  <br>becomes<br>let x = fix (λx : T<sub>1</sub> . t<sub>1</sub>) in t<sub>2</sub><br><br>section 11.11.1
Give the syntactic forms, evaluation rules, and typing rules associated with raising and catching value-carrying exceptions.	Chapter 14: Exceptions<br><br>Bottom of the introduction page<br><br>dead tree pg 175
Draw a derivation showing that {x : Nat, y : Nat, z: Nat} is a subtype of {y : Nat}.<br>	exercise 15.2.1 tapl_solutions
Exercise 15.2.2	in solutions
Exercise 15.2.3	in solutions
Exercise 15.2.4	<br>
Exercise 15.2.5	<br>
Give the relevant syntactic forms, subtyping rules, and typing rules for the simply typed lambda calculus with records, arrows, and subtyping.<br><br>Only rules related to subtyping need be given. 	chm - Chapter 15 header as well as 15.2<br>deadtree - all are on pages 186 and 187
What is the point of having a Top type?	chm section 15.4<br>deadtree 191
What is the "Bot" type? Explain the motivations for adding such a type as well as the complications that it introduces. 	section 15.4
Give and explain the typing rule for upcasting.<br>Give and explain the typing rule for downcasting.	Bonus points if you give the evaluation rule for downcasting.<br><br>section 15.5
Give the syntactic forms, typing rules, and subtyping rules for variants.<br>	section 15.5
Give the subtyping rules for references	section 15.5
Give the subtyping rules for references with sources and sinks.	section 15.5 "References Again"
Exercise 16.1.2	<br>
Exercise 16.1.3	<br>
Give the definition for the algorithmic subtyping relation on the lambda calculus with arrow types and record types.	section 16-2
Suppose we are create an algorithmic relation (like typing for example), based on a non-algorithmic relation. What two theorems would we have to prove to see that it is useful?<br>	[Soundness and Completeness]<br>[Termination]<br>16-2
Give the definition of an algorithmic typing relation for the lambda calculus with arrow and record types.	16-2
Exercise 16.2.3	<br>
Exercise 16.2.5	<br>
Suppose we want to prove completeness for an algorithmic typing relation.<br><br>This would amount to proving that a term has type T under a certain context iff the algorithmic typing relation gives the term type T. Right? Wrong. Explain why this is.<br>	See thm 16.2.5
Exercise 16.2.6	<br>
What is the <i>join</i> of a pair of types S and T? What is the concept of a <i>join</i> used for?	16.3.1
Exercise 16.3.2	<br>
Exercise 16.3.3	<br>
Exercise 16.3.4	<br>
If the set U is the universal set, what does it mean for a function F : 2<sup>U</sup>→2<sup>U</sup> to be monotone?	definition 21.1.1<br>
Let X be a subset of U.<br><br>If F : 2<sup>U</sup> → 2<sup>U</sup> is a monotone function, what does it mean for X to be F-closed?	definition 21.1.2
Let X be a subset of U.<br><br>If F : 2<sup>U</sup> → 2<sup>U</sup> is a monotone function, what does it mean for X to be F-consistent?	F(X) is a superset of X.<br>def 21.1.2
Let X be a subset of U.<br><br>If F : 2<sup>U</sup> → 2<sup>U</sup> is a monotone function, what does it mean for X to be a fixed point of F?	def 21.1.2
Let X be a subset of U. Let F : 2<sup>U</sup> → 2<sup>U</sup> be a monotone function.<br><br>Consider the following statement:<br><br>The intersection of all F-closed sets is the least fixed point of F.<br><br>Prove or give a counterexample.	thm 21.1.4
Let X be a subset of U. Let F : 2<sup>U</sup> → 2<sup>U</sup> be a monotone function.<br><br>Consider the following statement:<br><br>The union of all F-closed sets is the least fixed point of F.<br><br>Prove or give a counterexample.	IMPOSTOR<br><br>see thm 21.1.4
Let X be a subset of U. Let F : 2<sup>U</sup> → 2<sup>U</sup> be a monotone function.<br><br>Consider the following statement:<br><br>The union of all F-consistent sets is the greatest fixed point of F.<br><br>Prove or give a counterexample.	thm 21.1.4
Let X be a subset of U. Let F : 2<sup>U</sup> → 2<sup>U</sup> be a monotone function.<br><br>Consider the following statement:<br><br>The intersection of all F-consistent sets is the greatest fixed point of F.<br><br>Prove or give a counterexample.	IMPOSTOR<br><br>see thm 21.1.4
Exercise 21.1.7	<br>
State the principle of induction in terms of monotone sets.<br><br>Do <i>not</i> frame induction on natural numbers in terms of monotone functions; instead, give the more general form of induction.	cor 21.1.8
State the principle of coinduction in terms of monotone functions.<br>	cor 21.1.8
Exercise 21.1.9	<br>
Give the definition of a <i>tree type</i> which includes the three type constructors →, ˟, and Top.<br>	def 21.2.1
Exercise 21.2.2	<br>
Express the subtype relation on finite tree types using concepts of monotone functions.	def 21.3.1
Express the subtype relation on all tree types (which includes both finite and infinite trees) using monotone function concepts. 	def 21.3.2
Exercise 21.3.3	<br>
Exercise 21.3.4	<br>
Let F ϵ 2<sup>UxU</sup> → 2<sup>UxU</sup> be a monotone function.<br><br>Consider the following statement:<br><br><$$>\mbox{If }TR(F(R)) \subseteq F(TR(R))\mbox{ for any R} \subseteq U \times U\mbox{, then }\upsilon F \mbox{ is transitive.}</$$><br>Prove or give a counterexample.	lemma 21.3.6
Give the definition of an invertible monotone function.	def 21.5.1
Let F be an invertible monotone function. Let x ϵ U. Give the definition of support<sub>F</sub>(x).	beneath def 21.5.1 pg 290
Let F be a monotone invertible function and let X ϵ 2<sup>U</sup>. Give the definition of support<sub>F</sub>(X).	below def 21.5.1, pg 291
Exercise 21.5.2	<br>
Exercise 21.5.4	<br>
Give a simple recursive function that calculates whether or not an element is in the gfp of a monotone, invertible, finite-state generating function.<br>	def 21.5.5 pg 292
exercise 21.5.6 	see tapl_solutions for answer
<br>Let F be an invertible generating function. Consider the following statement:<br><br><$$>X \subseteq F(Y) iff support_F(X)\downarrow and support_F(x) \subseteq Y.<$$><br><br>Prove or give a counterexample.	lemma 21.5.7, pg 293
<br>Let F be an invertible generating function. Consider the following statement:<br><br><$$>Y \subseteq F(X) iff support_F(X)\downarrow and support_F(x) \subseteq Y.<$$><br><br>Prove or give a counterexample.	impostor<br><br>see lemma 21.5.7
Let F be an invertible generating function. Consider the following statement:<br><br>Suppose P is a fixed point of F. Then <br><$$>X \subseteq P\mbox{ iff }support_F(X)\downarrow\mbox{ and } support_F(X) \subseteq P.</$$><br><br>Prove or give a counterexample.	lemma 21.5.8, pg 293
Let F be an invertible, finite-state generating function, and let <br><$$>gfp(X) = \begin{tabular}[t]{l}<br>if\ support(X)\uparrow,\ then\ false<br>\\<br>else\ if\ support(X)\ \subseteq\ X, then\ true<br>\\<br>else\ gfp(support(X)\ \cup\ X)<br>\end{tabular}</$$><br><br>Consider the following statement:<br><br><$$>\mbox{If}\ gfp_F(X)\ =\ \mbox{true,}\ \mbox{then}\ X\ \subseteq\ \nu F</$$><br><br>Prove or give a countexample.<br>	thm 21.5.9, pg 293
Let F be an invertible generating function. What does it mean for F to be finite-state?	defs 21.5.11 and 21.5.10
exercise 21.5.13, pg 21.5.13	<br>
Let F be an invertible, finite-state generating function, and let <br><$$>gfp(X) = \begin{tabular}[t]{l}<br>if\ support(X)\uparrow,\ then\ false<br>\\<br>else\ if\ support(X)\ \subseteq\ X, then\ true<br>\\<br>else\ gfp(support(X)\ \cup\ X)<br>\end{tabular}</$$><br><br>Evaluating this recursive function involves a lot of redundant computations. Identify what these redundant computations are, and propose a revised function which avoids them.<br><br>	Each non-top-level recursive call gets passed support(X) U X. It then computes support( support(X) U X ) = support( support(X) ) U support(X). support(X) was already computed in the caller! We should be able to reuse this somehow. The solution is to generalize to two inputs sets: one whose support has already been computed and one whose support has not yet been computed. See def 21.6.1, pg 295.
What does it mean for a tree type to be regular?	def 21.7.2
<$$>\mbox{Let }\frak{T}\mbox{ be the set of all finite and infinite tree types.}</$$><br><br><$$>\mbox{Let}\ S(R)=\begin{tabular}[t]{l}<br>\{(T,Top) \mid\ T\ \epsilon\ \frak{T}\ \}\\<br>\cup\ \{(S_1 \times S_2, T_1 \times T_2)\ \mid\ (S_1, T_1), (S_2, T_2)\ \epsilon\ R\}\\<br>\cup\ \{(S_1 \rightarrow S_2, T_1 \rightarrow T_2) \mid (T_1,S_1), (S_2,T_2)\ \epsilon\ R\}<br></$$><br><br>Consider the following statement:<br><br>The restriction S<sub>r</sub> of the generating function S to regular tree types is finite state.<br><br>Prove or give a counterexample.	prop 21.7.4<br>pg 299
What is a raw μ-type? What does it mean for a raw μ-type to be contractive?	def 21.8.1, 21.8.2<br>pg 299,300
Give the definition of an inductive function which converts from closed μ-types to tree types.	def 21.8.3, pg 300
Exercise 21.8.5	<br>
Give the syntactic forms and typing rules that must be added to STLC to obtain System F.	pg 343, Fig 23-1
Write a "double" function in System F, which takes a function as an argument, and returns the function composed with itself.	pg 344, sec 23.4
Exercise 23.4.5	I got:<br>λX. λa:CBool. λb:CBool. (a [X] tru [X] fls [X]) (b [X] tru [X] fls[X]) (fls [X])
Ex 23.4.6	<br>
Ex 23.4.7	<br>
Ex 23.4.8	<br>
Ex 23.4.9	<br>
Ex 23.4.10	<br>
Ex 23.4.11	<br>
Ex 23.4.12	<br>
Ex 23.5.1	<br>
Proof 23.5.2	<br>
Ex 23.6.3	<br>
Ex 23.7.1	<br>
Give the syntax, evaluation, typing, type equivalence, and kinding rules for λ<sub>ω</sub>.<br>	pg 446, fig 29-1
List the three classes of expressions in λ<sub>ω</sub>.<br>	pg 443
There are three classes of expressions in λ<sub>ω</sub>: types, kinds, and terms. The types can be divided into two categories. Explain these categories.	Ans: those that classify terms and those that do not.<br>pg 443, section 29.1
Give an example of a type expression of kind * which includes a type operator of a higher kind as a subphrase.	pg 443, section 29.1
Exercise 29.1.1	<br>
Exercise 29.1.2	<br>
What does "Πx:S.T" denote?	atapl pg 46
"The result type of a function with a Π-type can vary according to the argument supplied"<br><br>disprove or give an example	This is true.<br><br>This is a bit tricky, though, because there is no way to introduce functions with Π-types in λLF; they must start out in the context.<br><br>atapl pg 46
Suppose "Vector n" is the type denoting n-element vectors whose elements are of type "data". How would we denote the type of init, a function taking a nat (for length) and a data value, and returning a vector having the supplied length whose elements are all equal to the supplied value?	atapl pg 46
Explain the differences between dependent and universal types.	pdf pg 46
Express the type S → T as a Π-type. 	atapl pg 47
atapl exercise 2.1.1	<br>
atapl exercise 2.1.2	<br>
atapl exercise 2.1.3	<br>
atapl exercise 2.1.4	<br>
Give the syntax, well kindness, and kinding rules for λLF.	atapl pdf pg 66
Give the typing and kind equivalence rules for λLF.	pg 51-52
Give the type equivalence and term equivalence rules for λLF.	atapl pg 52-53
Prove lemma 2.3.1 for typing judgments only. (Will the proof for any other judgement system be significantly different?)	atapl pg 55
Prove lemma 2.3.2 for type equivalence.	atapl pg 55,52
Prove lemma 2.3.2 for kinding judgements, assuming all other judgment systems can be proven.	atapl pg 55, 51
Prove Lemma 2.3.3 part 1.	atapl pg 55
Prove lemma 2.3.3 part 2.	atapl pg 55
prove lemma 2.3.3 part 3.	<br>
prove lemma 2.3.3 part 4.	atapl pg 55
prove lemma 2.3.3 part 5<br>atapl pg 55,51,52	<br>
Consider the coalgebra functor <$>\overline{\mathbb N} \longrightarrow 1 + \overline{\mathbb N}</$>. The final coalgebra for this functor is the set {1, 2, 3, ...} ∪ ∞, equipped with a structure which is best called predecessor, because it sends<br><br>0 ↦ κ(*)<br>n + 1 ↦ κ'(n)<br>∞ ↦ κ'(∞)<br><br>What is the defining property of this coalgebra?	pg 3849, near bottom<br><br>
Consider the coalgebra functor <$>\overline{\mathbb N} \longrightarrow 1 + \overline{\mathbb N}</$>. The final coalgebra for this functor is the set {1, 2, 3, ...} ∪ ∞, equipped with a structure which is best called predecessor, because it sends<br><br>0 ↦ κ(*)<br>n + 1 ↦ κ'(n)<br>∞ ↦ κ'(∞)<br><br>Now consider the function <$>f : \overline{N} \times \overline{N} \rightarrow 1 + (\overline N \times \overline N)</$> defined by<br><br>f(x, y) =<br> κ(*)         if pred(x) = pred(y) = κ(*)<br> κ'(⟨x', y⟩) if pred(x) = κ'(x')<br> κ'(⟨x, y'⟩) if pred(x) = κ(*), pred(y) = κ'(y')<br><br>Describe the coalgebra map from <$>\overline N</$> to <$>\overline N \times \overline N</$>, which must be unique due to finality.<br><br>	pg 3850<br>
Describe the coalgebra functor T(X) = list(A × X).<br><br>	pg 3850, near bottom<br><br>
Let T be the functor T(X) = list(A × X). T-coalgebras t : X → list(A × X) represent trees with labels from A. For an arbitrary T-coalgebra t : X → list(A × X), define the two classical traversal "algorithms" for breadth-first search and depth-first search, yielding functions bf(t) : X → A<sup>∞</sup> and df(t) : X → A<sup>∞</sup>.<br><br> 	pg 3851, near top<br>
What is a bisimulation?<br><br>Let merge(a,b) be a function which takes two infinite lists, and returns a list which alternates elements of its arguments: a<sub>1</sub>,b<sub>1</sub>,a<sub>2</sub>,b<sub>2</sub>,...<br><br>Let odd(a) be a function which yields odd elements of an infinite list.<br>Let even(a) be a function which yields even elements of an infinite list.<br><br>Use bisimulation to prove merge(odd(a), even(a)) = a.<br><br>	pg 3852<br>
Let (X, A, →<sub>X</sub>) and (Y, A, →<sub>Y</sub>) be two labeled transition systems with the same set A of labels. How can these two systems be viewed as coalgebras, and what is the significance of a coalgebra map between them?<br>	pg 3853, top half.<br>
Explain the well-known notion of bisimulation for transition systems. Explan the connection between bisimulation and coalgebra maps.<br>	pg 385, bottom half<br><br>
Let T be a functor, and c : U → T(U) a T-coalgebra. What is a <i>bisimulation</i> on U?<br> 	pg 3855, def 7.2<br>
Give the general formulation of the coinduction proof principle, and also its (simple) proof.<br>	pg 3855, thm 7.3<br>
Every bisimulation on a ______ is contained in the equality relation.	terminal coalgebra<br><br>pg 3856<br>
Every ___________ relation on an initial algebra contains the equality relation.<br>	congruence<br><br>pg 3856
Prove the coinductive proof principle for the special case of the final coalgebra ⟨A<sup>N</sup>,[head,tail]) of infinite lists.<br>	pg 3852, near bottom<br><br>
What is a <i>mongruence</i> on a coalgebra c : U → T(U)?<br>	pg 3866, near bottom<br>
What is a <i>mongruence</i> on a coalgebra c : U → T(U)?	pg 3866, near bottom
What is an <i>object identifier</i>?<br>	pg 3867, def 3.1<br>
What is an <i>object</i>?<br>	pg 3867, def 3.1<br>
How are values (like integers, booleans, etc.) represented as objects?	pg 3867, example 3.2<br>
What is the primary disadvantage to representing encapsulated objects using existential types, which coalgebras solve?<br>	pg 3867, below example 3.2<br>
What is a <i>class</i>? Describe all three components.<br><br>	pg 3868, def 3.3 (i)<br>
Describe the difference between the <i>attributes</i> and <i>procedures</i> of a class from a coalgebraic perspective.<br>	pg 3868, def 3.3 (i)<br>
What does it mean for an object to <i>belong to</i> a class?<br>	pg 3868, def 3.3 (ii)<br><br>
A class can be viewed as a category whose objects (in the category-theoretic sense) are objects (in the object-oriented sense). Discuss this category more. What are the morphisms? Does this category have a terminal object?<br>	pg 3868, def 3.3 (iii)<br>
What is the difference between public and private methods?<br>	pg 3868, near bottom<br>
What does it mean for two objects to be <i>bisimilar</i>?	pg 3869, definition 3.4<br>
What does it mean for two objects to be <i>identical</i>?<br>	They only differ in their local state.<br><br>pg 3869<br>
Provide the definition of a bank account class BA, which has a balance, and a <i>change</i> method, which adds an integer to the current balance.<br><br>	pg 3870, top<br>
consider the following class definition:<br><br>~~~<br>class: BA<br><br>public methods:<br>* bal : X → <b>Z</b><br>* ch : X × <b>Z</b> → X<br><br>equations:<br>* x.ch(a).bal = x.bal + a<br> <br>creation:<br>* new.bal = 0<br><br>endclass<br>~~~<br><br>Discuss possible methods for implementing this class. Discuss the bisimulations that exist between objects implemented using distinct implementation methods.<br><br>	pg 3870/3871<br><br>
Let A be a fixed set of data elements. We wish to describe a class of buffer objects, which contain an element a ∈ A. The methods that it should have are store(a), to put an element a ∈ A in a buffer, and read to read the content of a buffer.<br><br>we make the following decisions:<br>- what happens when we send the store(a) message to a buffer which is already full? [we choose that nothing will happen]<br>- what happens when we read from an empty buffer? [we choose that the observable outcome will be an error value]<br><br>Provide two buffer classes PR and DR. DR is a destructive-read buffer in which reading an element empties the buffer. PR is a persistent-read buffer in which reading leaves the buffer unchanged, and a separate <i>empty</i> method is provided for clearing out the buffer.<br>	pg 3871, near bottom<br>
See the definitions of the PR class and the DR class on pg 3871.<br>Express the equations of these classes using commutative diagrams.<br><br>Challenge: for PR, try to represent the bottom two equations in the same diagram<br><br>	pg 3871/3872<br>
Give the definition for a class representing a machine that handles coffee and tea requests.<br><br>There are methods coin for inserting a coin, liq for making a choice between coffee and tea, and add to choose whether one wishes the coffee or tea to be black (b), with milk (m), with sugar (s), or both with milk and sugar (ms). The interesting aspect is that we use a fourth private method status to describe the internal state of the machine. The user of objects belonging to this class is not supposed to have access to this method. With this status method we can express how the public methods change the local state. This is a crucial technique in coalgebraic specification. For convenience, we assume that only one type of coin is used.<br>	pg 3873<br>
Give a brief overview of how local operational semantics for an object is modeled.<br>	pg 3874<br>
What can we say about two objects belonging to the same class which have the same public operational semantics?<br>	pg 3874, lemma 4.2<br><br>
Provide the definition for a <i>transition step</i> of an object.<br>	pg 3874<br>
How can an element O(p) of an object p's operational semantics be described explicitly, and why?<br>	pg 3875, lemma 4.4<br>
What does it mean for a set to be <i>transitive</i>?	pg 3694<br>
Consider the following statement:<br><br>A set X is an ordinal if and only if it is transitive and totally ordered by ∈.<br><br>Prove or disprove.<br>	true. pg 3694.
Consider the following statement:<br><br>A set X is an ordinal if and only if it is totally ordered by ∈.<br><br>Prove or disprove.<br>	IMPOSTOR. it must also be transitive.<br>{ 1, 2 } is a counterexample.<br>It is total since 1 < 2, but not transitive, because 0 is an element of 1 but not { 1 , 2 }<br>pg 3694<br>
Consider the following statement:<br><br>If α is an ordinal, then α ∪ {α} is an ordinal.<br><br>Prove or disprove.	true. pg 3695, lemma 3.1.2<br>
Consider the following statement:<br><br>If A is a set of ordinals, then ∪A is an ordinal.<br><br>Prove or disprove.<br>	true. pg 3695, lemma 3.1.3<br>
Let ω be the first limit ordinal. What does ω + ω denote? How can we prove that ω + ω exists?<br>	pg 3695/3696<br>
Given ordinals α and β, what does α+β denote?<br>	pg 3696, section 3.2<br>
Consider the following statement:<br><br>Addition is associative.<br><br>Prove or disprove.<br>	true. pg 3696, bottom<br>
Consider the following statement:<br><br>Ordinal addition is commutative.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 3697, near top.<br>
What is an <i>ordinal sum</i>?	pg 3697, below section 3.3<br>
Given ordinals α and β, what does α·β denote?<br>	pg 3698, near top<br>
Consider the following statement:<br><br>Ordinal multiplication is commutative.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 3698.<br>
Consider the following statement:<br><br>Ordinal multiplication distributes over ordinal addition.<br><br>Prove or disprove.<br>	This is only half of an impostor, because it left-distributes, but doesn't right distribute.<br><br>pg 3698, lemma 3.3.1<br><br>
Consider the following statement:<br><br>Ordinal multiplication is associative.<br><br>Prove or disprove.	true. pg 3698, lemma 3.3.2<br><br>
Read the text above section 3.4 on page 3699<br><br>	pg 3699<br>
Let λ be a limit ordinal and <$>\langle \alpha_{\xi} \mid \xi < \lambda \rangle</$> be a λ-sequence of ordinals. What does <$$>\lim_{\xi < \lambda} \alpha_{\xi} = \alpha</$$> denote?	pg 3699, section 3.4<br>
Let λ be a limit ordinal, and let <$>\langle \alpha_{\xi} \mid \xi < \lambda \rangle</$> be an increasing sequence of ordinals. Consider the following statement:<br><br>This sequence has a (unique) limit, and indeed:<br><br><$$>\lim_{\xi < \lambda} \alpha_{\xi} = \bigcup_{\xi < \lambda} \alpha_{\xi}</$$><br><br>Prove or disprove.<br>	Denote the limit with α.<br><br>Is α an ordinal? To find out, check whether it is transitive and totally ordered. (It is)<br><br><latex>~\\<br>Let $\beta < \alpha$. Then $\beta \subset \alpha_{\zeta}$ for some $\zeta < \lambda$ (because some $\alpha_i$ for $i < \lambda$ must contain an element not in $\beta$ due to the strict inequality, and additionally because the ordinals are totally ordered by inclusion). Let $\mu$ be an ordinal such that $\zeta < \mu < \lambda$. Then $\beta \subset \alpha_{\zeta} \subset \alpha_{\mu} \subseteq \alpha$<br></latex><br><br>pg 3699, lemma 3.4.1
Consider the following statement:<br><br>Let λ, μ be ordinals, and let f : μ → λ be an order-preserving function such that lim<sub>ξ < μ</sub>f(ξ) = λ. Let ⟨α<sub>ξ</sub> | ξ < λ⟩ be an increasing sequence. Then lim<sub>ξ < λ</sub> α<sub>ξ</sub> = lim<sub>ξ < μ</sub> α<sub>f(ξ)</sub>.<br><br>Prove or disprove.<br><br>	Both of these are equal to unions, by lemma 3.4.1. We just need to prove the unions are equal.<br><br>That the right union is contained in the left union is trivial.<br><br>Proving the left union is contained in the right union involves making use of the assumption that the limit is equal to λ (expand out the definition of limits)<br><br>true. lemma 3.4.2. todo: add impostor.<br>
<latex>~\\<br>Let $\lambda$ be a limit ordinal, and let $\langle \alpha_{\xi} \mid \xi < \lambda \rangle$, $\langle \beta_{\zeta} \mid \zeta < \lambda \rangle$ be increasing sequences such that<br>\begin{itemize}<br>\item $(\forall \xi < \lambda) (\exists \zeta < \lambda) (\beta_{\zeta} > \alpha_{\xi})$<br>\item $(\forall \zeta < \lambda) (\exists \xi < \lambda) (\alpha_{\xi} > \beta_{\zeta})$<br>\end{itemize}<br>Consider the following statement:\\~\\<br>$$\lim_{\xi < \lambda} \alpha_{\xi} = \lim_{\zeta < \lambda} \beta_{\zeta}$$<br>Prove or disprove.<br></latex>	true. pg 3700. TODO: add impostor?<br><br><latex>~\\<br>By Lemma 3.4.1 on page 3699, we merely must show that $\bigcup_{\xi < \lambda} \alpha_{\xi} = \bigcup_{\zeta < \lambda} \beta_{\zeta}$. Let $x \in \bigcup_{\xi < \lambda} \alpha_{\xi}$. Then $x \in \alpha_\xi$ for some $\xi < \lambda$. Then by assumption there exists a $\zeta < \lambda$ such that $\alpha_{\xi} < \beta_\zeta$, and so $x \in \beta_\zeta$. Hence $x \in \bigcup_{\zeta < \lambda} \beta_{\zeta}$. The other direction is symmetric.<br></latex>
Prove lemma 3.4.4 on pg 3700<br><br>TODO: transcribe contents of lemma onto card<br>	<br>
Do exercise 3.4.1 on pg 3700<br>	pg 3700<br>
<br><latex>~\\<br>Let $\lambda$ be a limit ordinal, and let $\langle \alpha_{\xi} \mid \xi < \lambda \rangle$ be any $\lambda$-sequence of ordinals. For each $\mu < \lambda$, let<br>$$\sigma_{\mu} = \sum_{\xi < \mu} \alpha_\xi$$<br>Consider the following statement:<br>$$\sum_{\xi < \lambda} \alpha_{\xi} = \lim_{\mu < \lambda} \sigma_{\mu}$$<br>Prove or disprove.<br></latex>	true. lemma 3.4.4, pg 3700
What does the word <i>continuity</i> mean when used in the context of functions on ordinals?	pg 3700, near bottom.<br>
What is a <i>normal function</i>? 	pg 3700, near bottom<br>
Let f : μ → μ be a normal function, and let λ ∈ μ be a limit ordinal. Let ⟨α<sub>ξ</sub> | ξ < λ⟩ be an increasing sequence of ordinals in μ and (lim<sub>ξ<λ</sub>α<sub>ξ</sub>) < μ.<br><br>Consider the following statement:<br><br>f(lim<sub>ξ<λ</sub>α<sub>ξ</sub>) = lim<sub>ξ<λ</sub> f(α<sub>ξ</sub>)<br><br>Prove or disprove.<br>	seems like an immediate consequence of the definition of continuity; normal functions are continuous and therefore continuous at every limit ordinal.<br><br>pg 3701<br>
Let f : On → On be a normal function. What can be said about fixpoints of f and why?<br>	pg 3701, lemma 3.4.7<br>
Let α, β, and γ be ordinals. Consider the following statement:<br>α<sup>β</sup>·α<sup>γ</sup> = α<sup>β·γ</sup>.<br>Prove or disprove.<br>	IMPOSTOR!<br><latex>~\\<br>Should be $\alpha^\beta \cdot \alpha^\gamma = \alpha^{\beta + \gamma}$\\<br>pg 3879<br></latex>
Prove that (α<sup>β</sup>)<sup>γ</sup> = (α<sup>β·γ</sup>).<br>	<latex>~\\<br>pg 3702\\<br>We're going to assume that lemma 3.5.2, directly below has already been proven (we can prove it without 3.5.1, as described in DetailedNotes). The proof then proceeds by transfinite induction.<br><br>\begin{description}<br>\item[0:]~\\<br>$(\alpha^{\beta})^0 = 1 = \alpha^0 = \alpha^{\beta \cdot 0}$<br>\item[successor:]~\\<br>$(\alpha^{\beta})^{\gamma + 1} = (\alpha^{\beta})^{\gamma} \cdot (\alpha^{\beta})<br>= (\alpha^{\beta \cdot \gamma}) \cdot (\alpha^{\beta}) = (\alpha^{\beta \cdot \gamma + \beta})<br>= \alpha^{\beta \cdot (\gamma + 1)}$<br>\item[limit $\lambda$:]~\\<br>todo<br>\end{description}<br><br><br></latex><br>
Let α and β be ordinals. What does α<sup>β</sup> denote?<br>	pg 3702<br>
Let α be a fixed ordinal. Consider the following statement.<br><br>Regarded as functions of β, the functions α+β, α·β, and α<sup>β</sup> are normal functions.<br><br>Prove or disprove.	true, pg 3879, lemma 3.5.2<br>TODO: add impostor<br>
Consider the following statement:<br><br>For any ordinal α, there are arbitrarily large ordinals β, γ, and δ such that:<br>α+β=β, α·γ=γ, and α<sup>δ</sup>=δ.<br><br>Prove or disprove.	true. pg 3702, lemma 3.4.7<br>TODO: add impostor<br>
Exercise 3.5.1, pg 3702<br>	<latex>~\\<br>To prove that $\alpha + \alpha \cdot \omega = \alpha \cdot \omega$, we could show that these two ordinals are isomorphic, and therefore equal. However, it's easier just to use algebraic properties: $\alpha + \alpha \cdot \omega = \alpha \cdot (1 + \omega) = \alpha \cdot \omega$.<br>\\~\\<br>Proving $\alpha \cdot \alpha^\omega = \alpha^\omega$ would be much harded through the use of isomorphisms, but fortunately we can apply algebraic properties here too:<br>$\alpha \cdot \alpha^\omega = \alpha^1 \cdot \alpha ^ \omega = \alpha^{1 + \omega} = \alpha^\omega$.<br></latex>
Exercise 3.5.2, pg 3702/3703<br><br>	It's first helpful to understand intuitively how the provided examples work. <br>For the first example, "adding an ordinal to an infinite sum of itself" should result in an "infinite sum of itself". In the next example, "multiplying an ordinal with an infinite product of itself" should result in an "infinite product of itself".<br><br>Following these examples, what we need is an ordinal that is essentially an infinite exponentiation of <$>\alpha</$>, we choose the limit of the sequence <$>a = \langle \alpha, \alpha^\alpha, \alpha^{\alpha^\alpha}, \alpha^{\alpha^{\alpha^\alpha}}, \ldots \rangle</$>, which must exist due to  lemma 3.4.1 on page 3699.<br><br>We can then apply lemma 3.4.5 on pg 3701, letting <$>\mu = \lim_{\omega} a</$>, letting f be the ordinal exponentiation function, and letting the increasing sequence be a.
Exercise 3.5.3, pg 3703<br>	NOTE: Set theorists say "order preserving" to mean "strictly order preserving"!!! And Devlin doesn't define the notion anywhere. But we can clarify this detail via the web, see: https://planetmath.org/normalordinalfunction<br><br><latex>~\\<br>To show that $n^{\omega} = lim_{k < \omega}~n^k = \omega$, <br>we must prove that for all $\beta < \omega$ there exists some $\alpha < \omega$ such that<br>$\alpha < k < \omega \Rightarrow \beta < n^k < \omega$. We choose $\alpha \doteq \beta$.<br>Since $n^{(-)}$ is normal, it is strictly order preserving. Strictly order preserving functions on ordinals are inflationary by a variation of the proof of theorem 1.7.2, pg 3645 (todo: explain this variation in DetailedNotes). Thus, since $\alpha = \beta$ by definition, $\alpha < k < \omega$ implies $\beta < k < n^k$.\\~\\<br>We must next show that $k < \omega$ implies $n^k < \omega$. This first relies on ordinal multiplication being strictly order preserving in each argument (is this proven in DetailedNotes? if not, prove!). Then, we use the fact that for any finite $n$, $n \cdot \omega = \omega$ (we prove this by demonstrating an order isomorphism between the lhs and rhs) we have $n^{k+1} = n^k \cdot n < n^k \cdot \omega = \omega$ and $n^0 = 1 < \omega$ as base case.<br><br></latex><br>
List the three properties of finite set cardinality	pg 3703
Give the definition of the <i>cardinality</i> of a set. What is a <i>cardinal</i>?<br>	pg 3704<br>
Consider the following statement:<br><br>Every finite ordinal is a cardinal.<br><br>Prove or disprove.<br>	true. pg 3704<br>TODO: add impostor
Consider the following statement:<br><br>ω is a cardinal<br><br>Prove or disprove.<br>	pg 3704, thm 3.6.1<br>TODO: add impostor<br>
Consider the following statement:<br><br>Every infinite cardinal is a limit ordinal.<br><br>Prove or disprove.<br>	pg 3704, thm 3.6.1<br>todo: add impostor<br>
Let X and Y be sets. Consider the following statement:<br><br>|X| ≤ |Y| if and only if there is an injection f : X → Y.<br><br>Prove or disprove.<br>	pg 3705, thm 3.6.2<br>
Let X and Y be sets. Consider the following statement:<br><br>If there are injections i : X → Y and j : Y → X, then there is a bijection f : X ↔ Y<br><br>Prove or disprove.<br>	true. thm 3.6.3, pg 3705<br>todo: add impostor<br>
Let X and Y be non-empty sets. Consider the following statement:<br><br>The following are equivalent:<br>(i)  There is an injection f : X → Y.<br>(ii) There is a surjection g : Y → X.<br><br>Prove or disprove.<br>	true. lemma 3.6.4, pg 3706<br>todo: add impostor<br>
Consider the following statement:<br><br>An ordinal α is a cardinal if and only if for no ordinal β < α is there a surjection f : β → α.<br><br>Prove or disprove.<br>	true. lemma 3.6.5, pg 3707<br>todo: add impostor.<br>
Consider the following statement:<br><br>If κ is a cardinal, then there is a cardinal greater than κ.<br><br>Prove or disprove.<br>	true. lemma 3.6.6, pg 3707<br>todo: add impostor<br>
Do the objects of <b>Cat</b> really encompass <i>all</i> categories, or only a selection of them? How would one justify this definition of <b>Cat</b>?<br>	pg 2680<br><br>"In particular, then, Cat is not an object of itself, which may come as a relief to some readers."<br>
Which of the categories <b>Sets</b>, <b>Pos</b>, <b>Group</b>, and <b>Cat</b> are small? Of those which are not small, which are locally small?	pg 2680/2681<br>
Give the identity axiom and the cut rule, and explain their converse relationship.<br>	pdf pg 38
Give the rules for Gentzen-style classical propositional logic.<br>	tut 1 - pg 14<br>
Give the three structural rules for the sequent calculus.	pdf pg 37
One could say that  "27 x 37 = 999" is true because the two sides, "27 x 37" and "999", denote the same integer.<br><br>This reasoning misses an essential point, though. Explain this point.	pdf pg 9,10
Explain the pros and cons of sense vs. denotation.	pdf pg 10
Explain Tarski's semantic tradition.	pdf pg 12,13<br>This explanation seems kinda weak. I should look these up on wikipedia.
Explain Heyting's semantic tradition.	pdf pg 13
In Heyting semantics, a deduction A on the hypotheses B<sub>1</sub>,...,B<sub>b</sub> can be seen as a function. Explain this function, and give its domain and range.<br>	pdf pg 3898<br>
Give the three fundamental equations involving natural deductions of conjunctions and their projections.<br><br>	pdf pg 3898<br>
Explain how ⇒I is described using Heyting semantics.	pdf pg 3898/3899 (item 4)
Explain ⇒E using Heyting semantics.	pdf pg 3899<br>
Give the syntactic forms and typing rules of the typed lambda calculus with pairs.  (This is the language discussed in girard chpt 3, and corresponds to the (∧, ⇒) fragment of propositional calculus)	pdf pg 3902<br><br>
List the three primary and two secondary equations for the typed lambda calculus with pairs as given by Girard in chapter 3.	pdf pg 3903<br>
What does it mean for a system of equations to be consistent. Can you prove that the system of primary equations for the typed lambda calculus with pairs is consistent?<br>	consistency is mentioned on pdf pg 3903<br><br>as it says, the consistency of typed lambda calculus with pairs is a straightforward consequence of the Church-Rosser property and the weak normalization theorem.
How would you describe what a "type" is to someone? 	pdf pg 3904 has a fantastic discussion of what a type is
In the typed lambda calculus with pairs, what is does it mean for a term to be normal?	pdf pg 3905<br>
In the typed lambda calculus with pairs, what is head-normal form?	pdf pg 3905, near bottom
Explain the Curry-Howard Isomorphism in terms of the typed lambda calculus with pairs.<br>	Don't forget that an isomorphism is more than just a bijection.<br><br>NOTE: awodey says that Curry-Howard is NOT a bijection, but a functor<br><br>The bijection aspect is explained on <br>pdf pg 3906.<br><br>The behavior preservation is explained a bit on pdf pg 3907/3908.... and explored later in the book I presume.
State the Church-Rosser property.	pdf pg 30
Use the Church-Rosser property to prove that a term has at most one normal form.	pdf pg 31
Prove that the lambda calculus with pairs is <i>consistent</i> under the following system of equations<br>π<sup>1</sup>(x,y)=x, <br>π<sup>2</sup>(x,y)=y,<br>(λx<sup>U</sup> . v) u = v[u/x]<br>and the standard properties of equivalence (symm, trans, refl)<br><br> 	pdf pg 31
State the weak normalization theorem. Why is it called the "weak" normilization theorem rather than just the normalization theorem? 	pdf pg 32
Give the definition of the degree of a type.<br>	pdf pg 32
Give the definition of the degree of a redex.<br>	pdf pg 32
Give the definition of the degree of a term.	pdf pg 33
Let x be a variable of type U. Consider the following statement:<br><br>d(t[u/x]) ≤ max(d(t),d(u),∂(U))<br><br>Prove or give a counterexample.<br>	provable<br>pdf pg 33
Let x be a variable of type U. Consider the following statement:<br><br>d(t[u/x]) ≤ max(d(t),d(u))<br><br>Prove or give a counterexample.	counterexample:<br><br>let u = (λa<sup>A</sup>.a, λa<sup>A</sup>.a)<br>let t = π<sup>1</sup>x<br><br>d(u)=d(t)=0<br>d(t[u/x]) = ∂ ( (A→A) x (A→A) ) = 3<br><br>pdf pg 32
Let r be a redex of any type T. Consider the following statement:<br><br>∂(r)>∂(T)<br><br>Prove or give a counterexample.	proof is straightforward<br>pdf pg 33
Consider the following statement:<br><br>If t ⇝ u, then d(u) ≤ d(t).<br><br>Prove or give a counterexample. 	pdf pg 33
Consider the following statement:<br><br>If t ⇝ u, then d(t) ≤ d(u) <br><br>prove or give a counterexample.	there should be a counterexample.<br><br>pdf pg 33
Let r be a redex of maximal degree n in t, and suppose that all the redexes strictly contained in r have degree less than n. <br><br>Consider the following statement:<br><br>If u is obtained from t by converting r to c, then u has strictly fewer redexes of degree n.<br><br>Prove or give a counterexample.	pdf pg 34.<br>note for the second point that "conserve" just means that no new redexes inside r are being created, though some may be destroyed.<br>
Give the definition of <i>strongly normalizable</i>.	pdf pg 34
Prove the weak normalization theorem.	<br>pdf pg 34 -- section 4.3.4, "Proof of the Theorem"
Give the definition of a sequent, along with its naive (denotational) interpretation.<br>	pdf pg 37
In the natural deduction system of Gentzen and Prawitz, a deduction consists in deriving a proposition from a finite number of packets of assumptions.<br><br>Give the precise, mathematical definition of a "packet of assumptions"	A multiset of propositions. Note that Gallier implies all propositions in this multiset must be the same. Hence, it might be more sensible to define a packet of assumptions as a pair (i, p) where i is a positive integer, and p is a proposition.<br><br>Reading the examples on pages 5 and 6 will be helpful. <br><br>gallier tut 1 - pg 4, 5, 6<br>
Give the three rules for implicational logic.	gallier tut 1 - pg 5
In implicational logic, what is a deduction hypothesis, and what does it mean for a hypothesis to get discharged?	gallier tut 1 - pg 5, 4
In the natural deduction system of Gentzen and Prawitz, what is a proof, and how does a proof differ from a deduction?	"In the deduction system of Gentzen and Prawitz, a deduction consists in deriving a proposition from a finite number of packets of assumptions, using some predefined inference rules... a proof is a deduction such that all the assumptions have been discharged."<br><br>gallier tut 1 - pg 4
Show that (┴-elim) can be derived in classical propositional logic.<br>	tut 1 - pg 11
Give the axioms and inference rules for intuitionistic propositional logic.<br>(Natural deduction style)	tut 1 - pg 10,11
How does minimal propositional logic differ from intuitionistic propositional logic?	tut 1, pg 11
How does classical propositional logic differ from minimal propositional logic?	gallier tut 1 - pg 11
Is <br>A⊃¬¬A<br>derivable in minimal propositional logic?<br>What about intuitionistic propostional logic? <br>Is <br>¬¬A⊃A<br>derivable in the aformentioned logics?	tut 1 - pg 11
In which of the logics is (¬A ˅ A) provable in?<br>-Classical propositional logic<br>-Intuitionistic propositional logic<br>-Minimal propositional logic<br>Supply proofs for each logic for which the answer is affirmative.<br>	tut 1 - pg 11,12
Give the rules for the typed λ-calculus λ<sup>→,x,+,┴</sup>.	tut 1, pg 12
N<sub>i</sub><sup>⊃,˄,˅,┴</sup> and<br>λ<sup>→,x,+,┴</sup> have some unpleasant features. List and discuss these.<br>	tut 1 - pg 14
What is the fundamental difference between the formulations of classical propositional logic and intuitionistic propositional logic using Gentzen's sequent calculus?	With classical propositional logic, the right-hand side of the sequent is a multiset of propositions.<br><br>There are two ways to formulate intuitionistic propositional logic:<br>- With ¬, the rhs contains at most one proposition.<br>- With ┴, the rhs contains exactly one proposition.<br><br>gallier tut 1 - pg 15,16
Give the rules for intuitionistic propositional logic (⊃, ˄, ˅, ¬) using sequent calculus. Suppose we remove ¬ from our logic and represent ¬A using A => ┴ instead. Can we then simplify our rules?	pdf pg 15
What is the motivation for requiring the rhs of a sequent to contain exactly one formula rather than at most one formula?	gallier tut 1 - pdf pg 16
Give the rules for G<sub>i</sub><sup>˄,˅,⊃,┴</sup>.<br><br>	tut 1 - pg 16
What does it mean to rectify a deduction? What is the point of rectifying deductions?	Rectifying a deduction is the process of sorting all of the antecedent entries. The function N rectifies as it translates so that the order the resulting antecedent entries are in is well defined (i.e. so that N is a function).<br><br>read a more detailed description at:<br>gallier tut 1 - pg 19-20  <br>
Let P be a proof tree whose last step is:<br>G ├ ┴<br>---------<br>G ├ A<br><br>Give the deduction N(P)	gallier tut 1 - pg 20-21
Let P be a proof tree whose last entry is:<br>A,A,G├ B<br>-------------<br>A,G ├ B<br><br>Give the deduction N(P).	gallier tut 1 - pg 21
Let P be a proof tree whose last step uses the (˄ right) rule.<br><br>Give the natural deduction N(P).<br>	gallier tut 1 - pg 21
Consider the following statement:<br><br>For every proof P in G<sub>i</sub><sup>⊃,˄,˅,┴</sup>,<br>N(P) is in normal form.<br><br>Prove or give a counterexample.	This is true. In order to prove it, we need to consider every root rule for  G<sub>i</sub><sup>⊃,˄,˅,┴</sup> .<br>Only the ones that map to ⊃ elimination could violate normal form. There is one such rule... it is pretty complicated, so I didn't work out the details of why it doesn't violate normal form... TODO?<br> <br>Gallier tut 1 - pg 24
Give the definition of the cut rule (for G<sub>i</sub><sup>⊃,˄,˅,┴,cut</sup>)	gallier tut 1 - pg 25
Given a deduction D of the form:<br><br>D<sub>1</sub><br>G ├ A˄B<br>------------<br>G ├ A<br><br>Give the proof G(D).<br>	gallier tut 1 - pg 26
Given a deduction D with two premises,<br><br>G ├ A ⊃ B<br>the deduction for is called D<sub>1</sub><br><br>and <br>G ├ A<br>the deduction for which is called D<sub>2</sub><br><br>Concluding<br>G├ B<br><br>Give the proof G(D).<br>	gallier tut 1 - pg 27
A leaf in a natural deduction proof can be either <i>dead</i> or <i>alive</i>. What does this mean?	pg 3896<br>
Explain the equation among natural deduction proofs that corresponds to β-reduction.<br>	pg 3900 (also compare this to the semantics for implication elimination given on page 3899)<br>
What does it mean for a proof to be in normal form?<br>	pg 3907<br>
How can we use the concept of generalized elements to test if an arrow is monic?<br>	pg 2693, near top.
In some category <b>C</b>, we want to test if a square commutes.<br><br>(Let f : A → B, g : A → D, α : B → C, β : D → C. Do we have αf = βg?)<br><br>How can we use generalized elements to do this?<br><br>	pg 2693<br>
Here are two posets:<br><br>X = {x ≤ y, x ≤ z}<br>A = {a ≤ b ≤ c}<br><br>How can we use generalized elements to prove that they are not isomorphic in the category <b>Pos</b>?<br><br>	pg 2693/2694<br>
Draw a category theory diagram demonstrating the relation between the tupling and projection operators and the set A, B, and A×B.<br>	pg 2695<br>
In any category <b>C</b>, what is a <i>product diagram</i> for objects A,B ∈ <b>C</b>?<br> 	pg 2695, def 2.15<br>
Explain the "two parts" of the UMP for product diagrams.<br>	pg 2696, top<br>
Consider the following statement:<br><br>Products are unique up to isomorphism.<br><br>Prove or disprove.<br>	pg 2696, prop 2.17<br>
Consider a poset P as a category. Let p, q ∈ P. Describe the characteristics of the category-theoretic product p×q.<br>	pg 2698
What are the components of the simply-typed lambda calculus (Girard-style, with pairs), and how can it be viewed as a category. Does this category have products? Explain.<br><br>	pg 2699<br>
How can the Curry-Howard "isomorphism" be viewed through the lens of category theory?<br>	pg 2699-2702<br><br>
What does it mean for a category to have <i>binary products</i>?<br>	pg 2703<br>
In a category with binary products, what does the notation f × f' mean, where f and f' are arrows?<br>	pg 2702 (section 2.6)<br>
Consider the following statement:<br><br>If a category has binary products, then it has all finite products with two or more factors.<br><br>Prove or disprove.<br>	pg 2703<br>
In category-theoretic terms, what is a <i>nullary product</i>? A <i>unary product</i>?	pg 2703<br>
What does it mean for a category to <i>have all finite products</i>? What does it mean for a category to <i>have all small products</i>?	pg 2704, def 2.19 near top<br>
Provide the seven axioms of category theory.<br>	pg 2709
Given a sentence Σ in the elementary language of category theory, how do we obtain its "dual statement" Σ*?<br>	pg 2709<br>
State and justify the category theoretic <i>duality principle</i>.<br>	pg 2710, prop 3.1<br>
State and justify the <i>conceptual</i> version of category theoretic duality. How does it differ from the formal version?<br>	pg 2710, proposition 3.2<br>
If A and B are objects in some category, what is a <i>coproduct</i> of A and B? How are coproducts related to products?<br>	pg 2711, def 3.3<br>
How can coproducts be characterized in the category of sets?	pg 2712, example 3.4<br>
In the category <b>Mon</b> what can be said about the coproduct M(A) + M(B) of the free monoids on the sets A and B?	A monoid homomorphism is determined entirely on how it maps between generating sets. If we have a homomorphism from M(A) to Z and another from M(B) to Z, it isn't hard to see how to build one from M(A+B) that commutes.<br><br>pg 2712<br><br>
Considering some poset P as a category, characterize the coproduct of two objects of this category.<br><br>	pg 2714, example 3.7<br>
Considering a deductive system as a category, where objects are formulas and arrows are proofs (using the domain as the hypothesis and the codomain as the conclusion), how would would characterize coproducts in this category? Are there any subtleties that arise which require us to formalize this category in a certain way to gain the presence of coproducts?<br>	pg 2714, example 3.8<br>
What is an <i>equalizer</i>?<br>	pg 2718<br>
Suppose we have the functions f,g : <b>R</b><sup>2</sup> → <b>R</b>.<br>What is the equalizer of these two arrows in the category <b>Top</b>?<br>	pg 2718<br>
In the category <b>Sets</b>, consider two functions f,g : A → B. What is their equalizer?<br>	pg 2719, example 3.15<br>
Consider the following statement:<br><br>In any category, if e : C → A is an equalizer of some pair of arrows, then e is monic.<br><br>Prove or disprove.<br> 	true. pg 2720<br>
Consider the following statement:<br><br>In any category, if e : C → A is an equalizer of some pair of arrows, then e is epic.<br><br>Prove or disprove.<br> 	IMPOSTOR<br><br>pg 2720
If X is a set and ~ is an equivalence relation on X, then what does X / ~ denote?<br>	pg 2722
What is an equivalence relation?	pg 2721, near bottom
What does it mean for one arrow to <i>extend along</i> another?	pg 2722 (explained implicitly by the triangle diagram and the text below it)
Let X be a set and ~ an equivalence relation on X. Let q : X → X/~ be the quotient mapping which takes x to [x]. When does a map f : X → Y extend along q?<br>	pg 2722
Give the definition of <i>coequalizer</i>.<br>	pg 2722, def 3.18<br>
Consider the following statement:<br><br>Coequalizers are epic.<br><br>Prove or disprove.<br>	pg 2722, near bottom<br>
Give intuition for what a coequalizer is.<br>	pg 2723, near top.<br>
Let R ⊆ X × X be an equivalence relation on a set X, and let r<sub>1</sub>, r<sub>2</sub> : R → X be the projections of the inclusion R ⊆ X × X. Characterize the coequalizer of r<sub>1</sub> and r<sub>2</sub>.<br>	pg 2723<br>
How do we construct the coequalizer in <b>Sets</b> of an arbitrary parallel pair of functions f·g : A ⇉ B?<br><br>	pg 2723, near bottom<br>
Describe the coproduct of rooted posets in terms of coequalizers.	pg 2724, example 3.21 (near top)<br>
Explain the intuition behind the idea that monos can be regarded as generalized subsets.	pg 2745
What is a <i>subobject</i> of an object X in a category <b>C</b>?<br>	pg 2745
Give the definition of a <i>morphism</i> between subobjects of an object.	pg 2746 (top)
If <b>C</b> is a category, and X is an object of <b>C</b>, define the category Sub<sub><b>C</b></sub>(X).<br>	pg 2746
For category <b>C</b> and object X of <b>C</b>, explain why Sub<sub><b>C</b></sub>(X) is considered a preorder category.<br>	pg 2746
Explain why "equivalent subobjects have isomorphic domains"	pg 2746
What is the difference between a subobject and the domain of a subobject?	a subobject is a mono. its domain is the domain of the mono<br><br>pg 2746
Two fundamentally different notions of subobject often get used. Explain the difference between these notions.	pg 2746, remark 5.2
Consider the following statement:<br><br>If M and M' are subobjects of X such that M ⊆ M' then M is a subobject of M'.<br><br>Prove or disprove.	true. pg 2747
If M is a subobject of X, then a functor Sub(M) → Sub(X) arises very naturally. Explain this functor.<br>	pg 2747
If z : Z → X is a generalized element of an object X, how do we define a <i>local membership relation</i> "z ∈<sub>X</sub> M" between such elements and subobjects m : M → X.<br><br>(todo: use epi arrow for m?)<br><br>	pg 2747<br>
Explain how an equalizer is a specific kind of subobject.	pg 2747
Give the definition of <i>pullback</i>.	pg 2748, def 5.4
If A, B, and C are objects of a category, what does the notation A ×<sub>C</sub> B mean?	you're probably wondering about the arrows of the corner: they are implicit from context<br>pg 2748, diagram on bottom
Prove proposition 5.5, from page 2749<br>	pg 2750<br>
Consider the following statement:<br><br>If a category <b>C</b> has binary products and equalizers, then it has pullbacks.<br><br>Prove or disprove.<br>	pg 2750<br>
Carefully read and consider example 5.7 on page 2750<br>	<br>
Explain how the notion of pullbacks can be used to define inverse images in categories other than <b>Sets</b>.<br>	pg 2751, top half.<br>
Prove lemma 5.8 1.) on page 2751<br>	why did I write all this text.... it is not that hard if you just draw a diagram and write down a few (~6) equations.<br><br>Let X be an object and let q : X → D and r : X → A be arrows such that<br>h ∘ q = (g ∘ f) ∘ r<br><br>Then X has a unique arrow y to E, since <br>g ∘ (f ∘ r) = (g ∘ f) ∘ r = h ∘ q<br><br>The UMP further gives:<br>g' ∘ y = q, and<br>h' ∘ y = f ∘ r<br><br>Now y and r make X a pullback of B wrt. arrows h' and f.<br>The UMP then gives z : X → F such that f' ∘ z = y and h'' ∘ z = r.<br><br>Then (g' ∘ f') ∘ z = g' ∘ ( f' ∘ z) = g' ∘ y = q.<br>We already have h'' ∘ z = r, and so the outer rectangle satisfies existence for pullbacks.<br><br>What about uniqueness? Noting that (f' ∘ z) = y and h'' ∘ z = r came from the UMP, z is the unique arrow with these properties.<br><br>Now suppose (g' ∘ f') ∘ z' = q and h'' ∘ z' = r for some z' : X → F.<br><br>We have:<br>1.) g' ∘ y = q = (g' ∘ f') ∘ z' = g' ∘ (f' ∘ z')<br>2.) h' ∘ (f' ∘ z') = h' ∘ y = f ∘ r.<br><br>Replacing f' ∘ z' with y, the UMP told us that there is only one arrow y with<br>those properties, and so (f' ∘ z') = y.<br><br>Not done proving existence yet, but I'm going to give up for now... maybe I should format this stuff on latex eventually.<br><br><br><br>
Prove lemma 5.8.2 on page 2751<br>	<br>
What does "the pullback of a commutative triangle is a commutative triangle" mean? Why is it true?	pg 2752, corollary 5.9 (NOTE: it seems to me that there is a simple proof of this fact that has nothing to do with the two pullbacks lemma. furthermore, I don't even know how two pullbacks is applicable here)<br>
Explain how "pulling back along a fixed arrow" is a functor.<br>	pg 2752, proposition 5.10<br>
Let <b>C</b> be a category with pullbacks. For any arrow f : A → B in <b>C</b>, draw a diagram in the category of categories and functors involving the categories Sub(A), Sub(B), <b>C</b>/A, and <b>C</b>/B.<br>	pg 2753, corollary 5.11<br>
Describe the isomorphism 2<sup>A</sup> ≅ P(A) in terms of pullbacks.<br>	pg 2754/2755, read both pages carefully<br><br><br>
Carefully read example 5.13 on page 2755/2756	<br>
Consider the following statement:<br><br>A category has finite products and equalizers iff it has pullbacks and a terminal object. <br><br>Prove or give a counterexample.<br>	pg 2756, prop 5.14<br>
Let <b>J</b> and <b>C</b> be categories. What is a <i>diagram of type</i> <b>J</b> in <b>C</b>?<br>	pg 2757, def 5.15<br>
What is a <i>cone</i> to a diagram D?<br>	pg 2757, def 5.15<br><br>
What is a <i>morphism of cones</i>?<br>	pg 2758<br>
Let D be a diagram in a category. Define the category <b>Cone</b>(D).<br>	pg 2758<br>
Give the definition of a <i>limit</i> for a diagram D : <b>J</b> → <b>C</b>.	pg 2758
Give the definition of a <i>finite limit</i> for a diagram D : <b>J</b> → <b>C</b>.<br>	pg 2758
What is the fancy mathematical notation for the limit of a diagram D?	pg 2758, def 5.16 (lim with a backward arrow)<br>
What UMP does a limit satisfy?	pg 2758, def 5.16
We can obtain an interesting thing if we have an arrow from some object to a limit. Explain what this thing is.	It's a cone. See the diagram at the bottom of pg 2758
Consider the following statement:<br><br>Products are a specific form of limit.<br><br>Prove or disprove.<br>	pg 2759, example 5.17<br>
Consider the following statement:<br><br>An equalizer is a specific kind of limit.<br><br>Prove or disprove.<br><br>	pg 2759, example 5.18<br>
Consider the following statement:<br><br>A terminal object is a specific kind of limit.<br><br>Prove or disprove.	True. pg 2759, example 5.19
Consider the following statement.<br><br>An initial object is a specific kind of limit.<br><br>Prove or disprove.	IMPOSTOR. Terminal object would be correct, pg 2759
Consider the following statement:<br><br>A pullback is a specific kind of limit.<br><br>Prove or disprove.<br>	true. Example 5.20, pg 2759/2760
What does it mean for a category to <i>have all finite limits</i>?	pg 2760, right below prop 5.21
Consider the following statement:<br><br>A category has all finite limits iff it has finite products and equalizers.<br><br>Prove or disprove.<br>	true. pg 2760<br>TODO: add impostor
What does it mean for a functor to <i>preserve limits of type <b>J</b></i>?<br>What does it mean for a functor to be continuous?<br><br>	pg 2762, def 5.24<br>
Let <b>C</b> be a locally small category. Let C be an object in <b>C</b>. Give the definition of the representable functor Hom(C, --).	pg 2762
Consider the following statement:<br><br>The representable functors Hom(C, --) preserve all limits.<br><br>Prove or disprove.<br>	true. pg 2762, prop 5.25
Consider the following statement:<br><br>The representable functors Hom(--, C) preserve all limits.<br><br>Prove or disprove.<br>	IMPOSTOR. this is a contravariant representable functor, which maps limits to colimits.<br>pg 2762
What does it mean for a category to have all limits of some cardinality?<br>Under what conditions does a category have all limits of a cardinality?<br><br>	pg 2761, corollary 5.22<br>
If <b>C</b> is a category, then what is a <i>contravariant functor</i> on C? Give a typical example of a contravariant functor.<br>	pg 2763<br>
Consider the following statement:<br><br>Contravariant representable functors map all colimits to limits.<br><br>Prove or disprove.<br>	pg 2763, cor 5.27
Give an example of a contravariant representable functor mapping a colimit to a limit.<br>	pg 2763, near bottom<br>
Explain the connection between ω-CPOs and category theory.<br>	pg 2768, example 5.33 (near bottom)<br>
Give the definition of a category theoretic <i>exponential</i>.<br>	pg 2777
Give the category-theoretic definitions of <i>evaluation</i> and <i>transpose</i>.<br>	pg 2777
What does it mean for a category to be cartesian closed?	pg 2778
Consider the following statement:<br><br>The category <b>Pos</b> of posets and monotone functions is cartesian closed.<br><br>Prove or disprove. 	true. pg 2778/2779<br>TODO: add impostor<br>
Consider the category whose objects are ωCPOs and whose arrows are monotone, ω-continuous functions.<br><br>Is this category cartesian closed?<br><br><br>	pg 2779<br>
Consider the following statement:<br><br>The category <b>Graphs</b> of graphs and graph homomorphisms is cartesian closed.<br><br>Prove or disprove.<br>	pg 2780<br>
Regarding categorical exponentials, characterize the transpose of an evaluation function.<br>	pg 2781<br>
Consider the following statement:<br><br>In any cartesian closed category <b>C</b>, exponentiation by a fixed object A is a functor:<br>(--)<sup>A</sup> : <b>C</b> → <b>C</b><br><br>Prove or disprove.<br>	true. pg 2782.<br>TODO: add impostor<br>
Provide the definition of <i>natural transformation</i>.<br>	pg 2812, def 7.6<br><br>
Let <b>C</b> and <b>D</b> be functors, F and G be functors from <b>C</b> to <b>D</b>, and <br>Given a natural transformation v : F → G, what is the component of v at C ∈ <b>C</b>?	pg 2812, def 7.6<br>
Provide some visual intuition for what natural transformations are.	pg 2812, bottom of page<br><br>
Provide the definition for the functor category Fun(<b>C</b>,<b>D</b>).<br>	pg 2814<br>
Provide the definition of <i>natural isomorphism</i>.<br>	pg 2814<br>
Consider the following statement:<br><br>A natural transformation v : F → G is a natural isomorphism iff each component v<sub>C</sub> : FC → GC is an isomorphism.<br><br>Prove or disprove.<br>	pg 2815<br>TODO: add impostor<br>
How is the composition of two natural transformations defined?<br>	pg 2814, def 7.9<br>
Show that <b>Cat</b> has small products and coproducts.	pg 2803 (the page doesn't actually explain why)<br>
Consider the following statement:<br><br><b>Cat</b> has all limits.<br><br>Prove or disprove.	true. pg 2803.<br>
What is a <i>subcategory</i>?<br>	pg 2803, near bottom<br>
What does it mean for a functor to be injective/surjective on objects? What does it mean for a functor to be injective/surjective on arrows?<br>	pg 2804, def 7.1<br>
What does it mean for a functor to be <i>faithful</i>?<br>	pg 2804, def 7.1<br>
What does it mean for a functor to be <i>full</i>?<br>	pg 2804, def 7.1<br>
Explain the difference between a functor being <i>faithful</i> and a functor being <i>injective on arrows</i>.	pg 2804<br>
What is a <i>full subcategory</i>?<br>	pg 2804<br><br>
Is the inclusion functor <b>Sets<sub>fin</sub></b> ↣ <b>Sets</b> full? Is it faithful?<br>	pg 2804, near bottom<br>
Is the forgetful functor <b>Groups</b>  ↣ <b>Sets</b> full? Is it faithful?<br>	pg 2804, near bottom<br>
Explain how <b>Cat</b> provides a setting for comparing structures of different kinds.<br>	pg 2805<br>
What kind of insight can be gained by considering a functor that maps from a poset to a group? (We are allowed to choose a specific poset and a specific group here.)<br>	pg 2805<br>
Give the definition of a <i>Heyting algebra</i>.<br>	pg 2785<br>
Consider the following statement:<br><br>Heyting algebras are distributive.<br><br>Prove or disprove.<br>	true. pg 2785<br>todo: add impostor<br>
State (but don't prove) the general rule which tells us that Heyting algebras are distributive.<br>	pg 2786, remark 6.9<br><br>
What does it mean for a poset to be <i>complete</i>?<br>	pg 2786, def 6.10<br>
Under what condition is a complete lattice a Heyting algebra?<br>	pg 2786, prop 6.11<br><br><br>
Consider the following statement:<br><br>Every boolean algebra is a Heyting algebra.<br><br>Prove or disprove.<br>	pg 2787<br>
Consider the following statement:<br><br>Every Heyting algebra is a boolean algebra.<br><br>Prove or disprove.<br>	False. pg 2787<br>
Give the six rules of intuitionistic propositional calculus.<br>	pg 2787<br>
Is "evaluation" entailment <br><br>(p ⇒ q) ∧ p ⊢ q<br><br>true in the intuitionistic propositional calculus? Prove your answer.<br>	pg 2787<br>
Is "modus ponens" <br><br>⊤ ⊢ p ⇒ q<br>and<br>⊤ ⊢ p<br><br>implies<br><br>⊤ ⊢ q<br><br>true in the intuitionistic propositional calculus? Prove your answer.<br><br><br>	pg 2787<br> 
Does the intuitionistic propositional calculus have "projections"?<br>Why or why not?<br>	pg 2788<br>
Is <br><br>p ⊣⊢ ⊤ ∧ p<br><br>Provable in the intuitionistic propositional calculus? Prove your answer.	pg 2788
State the typical axioms for implication.<br><br>Derive these axioms in the intuitionistic propositional caclulus.<br><br>	pg 2788<br>
State the equational definition of cartesian closed categories.<br>	pg 2790/2791<br>
If <b>C</b> is a category, what is a <i>generator</i> for <b>C</b>?<br><br>	pg 2806
Identify a generator in the category of sets. Identify a generator in the category of groups.<br>	pg 2806, near top<br>
Express the forgetful functor U : <b>Grp</b> → <b>Sets</b> via a natural isomorphism to a representable functor.<br><br>(hint: it should have something to do with <i>generators</i>)<br>	pg 2806
A category being "concrete" is somewhat of a vague notion when that category's objects are not sets and its arrows are not functions (the category <b>Grp</b> for example). Describe a more precise way to capture this notion.	there is a natural isomorphism between the the generator points of groups and the elements of the groups' underlying sets.<br><br>pg 2806<br>
Given a group G in a locally small, concrete category <b>C</b>, show that objects in the range of the contravariant representable functor Hom<sub><b>C</b></sub>(--, G) have group structure.<br> <br>	pg 2806<br>
Explain how Hom<sub><b>Sets</b></sub>(--,<b>2</b>) is a functor from sets to boolean algebras.<br>	pg 2807/2808
Show how the contravariant functor Hom<sub><b>Sets</b></sub>(--,<b>2</b>) : <b>Sets<sup>Op</sup></b> → <b>BA</b> is naturally isomorphic to the powerset functor P<sup><b>BA</b></sup> : <b>Sets<sup>Op</sup></b> → <b>BA</b>.	pg 2808<br>
Explain the fundamental difference between viewing coeffects syntactically and semantically.	pg 4066, bottom left corner section 3.1, *also* top-right corner adds some important points<br><br><br>
What is a <i>coeffect scalar structure</i>? (hint: there are six components)<br><br>	pg 4066
What is a <i>coeffect shape structure</i>?<br>	pg 4067<br>
What is a <i>coeffect algebra</i>?<br>	pg 4067, botton left<br><br>
<latex>~\\<br>Describe the two additional operators $\langle - \rangle$ and $r \oast S$ that a coeffect structure induces.<br></latex>	pg 4067 (bottom left)<br><br>
Explain the difference between the <br><$$>\overline{\times}\text{ and }\underline{\times}</$$> <br>operators.<br>	pg 4067<br>
Give the typing rules for the general coeffect calculus. (hint: there are 6)<br><br>	pg 4067<br>
Give the structural rules for the general coeffect calculus. (hint: there are 4)<br>	pg 4067<br>
What is a <i>structural coeffect system</i>?<br>	pg 4068, def 4.<br>
State the substitution lemma for structural coeffects.<br>	pg 4069, lemma 7<br>
State the subject reduction theorem for structural coeffect calculi.<br>	pg 4069<br>
Justify β and η equality using the typing rules of the general coeffect calculus (with structural coeffects).<br>	pg 4069<br>
What is an <i>ordered field</i>?	pg 4309/4308<br>
What is a <i>linear continuum</i>?<br>	pg 4309<br>
What does it mean for a set of real numbers to be inductive?<br>	pg 4310
What is the <i>Archimedian ordering property</i>?<br>	pg 4311<br>
State (and motivate) the <i>Principle of Recursive Definition</i>.	pg 4325<br>
Consider the following statement:<br><br>Let A be a set. There is no injective map f : P(A) -> A, and there is no surjective map g : A -> P(A).<br><br>Prove or disprove.<br>	pg 4328<br>
Consider the following statement:<br><br>Let A be a set. There is no surjective map f : P(A) -> A, and there is no injective map g : A -> P(A).<br><br>Prove or disprove.<br>	IMPOSTOR. pg 4328<br>
Exercise 4, pg 4329<br>	<br>
Exercise 9, pg 4330<br>	<br>
What is a <i>simple order</i>? 	pg 4302<br>
State the <i>maximum principle</i>. Give an intuitive "proof" of the maximum principle.	pg 4347<br>
State and prove Zorn's Lemma.<br>	pg 4348/4349<br>
Exercise 5, pg 4350	<br>
Exercise 6, pg 4350<br>	<br>
Exercise 8, pg 4350<br>	<br>
What is a <i>topology</i>?<br>	pg 4354<br>
What is a <i>topological space</i>?<br>	pg 4354<br>
What is the topological definition of <i>open set</i>?<br>	pg 4354<br>
Are the collections of sets in figure 12.2, pg 4355 topologies? Why or why not?<br>	Nope.<br>Left is not closed under union.<br>Right is not closed under intersection.<br>
What is the <i>discrete topology</i> of a set X? What is the <i>trivial topology</i> of X?<br>	pg 4355<br>
What is the <i>finite complement topology</i> of a set X? Show that it is actually a topology.	pg 4355<br>
Let X be a set. Let T<sub>c</sub> be the collection of all subsets U of X such that X - U either is countable or is all of X. <br><br>Consider the following statement:<br><br>T<sub>c</sub> is a topology on X<br><br>Prove or disprove.<br>	pg 4355<br>
Let T and T' be two topologies on a set X. What does it mean for T and T' to be <i>comparable</i>?<br>	pg 4355<br>
Let T and T' be two topologies on a set X. What does it mean for T' to be <i>finer</i> than T? <i>Strictly finer</i>? <i>Coarser</i>? <i>Strictly coarser</i>?	pg 4355<br>
If X is a set, what is a <i>basis</i> for a topology on X?<br>	pg 4356<br>
If B is a basis for a set X, what is <i>the topology T generated by B</i>?<br>Prove that it satisfies the requirements of a topology.<br>	pg 4356/4357<br><br>
Let T be the discrete toplogy of a set X. Give a basis for the topology T.<br>	pg 4357, example 3<br><br>
Let X be a set. Let B be a basis for a topology T on X.<br><br>Consider the following statement:<br><br>T equals the collection of all unions of elements of B<br><br>Prove or disprove.<br>	true. pg 4358, lemma 13.1<br>
Let T be a toplogy with basis B.<br><br>Consider the following statement:<br><br>Every open set in T is uniquely expressible as a union of basis elements.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 4358<br>
Given a topology T, explain a method for showing that a specific basis B generates T.<br>	this card is weird, because the text above lemma 13.2 implies that given some topology T, we are generating a basis for T out of nowhere. Lemma 13.2 actually assumes some collection of sets, and provides a technique for showing that it is a basis for T.<br><br>pg 4358, lemma 13.2<br>
Given two topologies T and T' with respective bases B and B', how can we determine whether one of the topologies is finer than the other?<br>	pg 4359, lemma 13.3<br>
What is the <i>standard topology</i> on the real line?	pg 4359<br>
What is the <i>lower limit topology</i> on the real numbers?<br>	pg 4360<br>
What is the <i>K-topology</i> on the real numbers?	pg 4360
How do the three topologies <b>R</b>, <b>R</b><sub>l</sub> and <b>R</b><sub>K</sub> relate via fineness?<br>	pg 4360, lemma 13.4<br>
What is a <i>subbasis</i> for a topology?<br> 	pg 4360
Let S be a subbasis on a set X. What is the <i>toppology generated by the subbasis X</i>? Prove that it is indeed a topology.	pg 4360, definition near bottom
Exercise 1, pg 4361<br>	<br>
Exercise 2, pg 4361<br>	<br>
Exercise 3, pg 4361 (example is on pg 4355)<br>	<br>
Exercise 8, pg 4361<br>	<br>
What is the <i>order topology</i> on a simply ordered set X? <br>	pg 4362<br>
Why do affine spaces provide a better framework than vector spaces for doing geometry?<br>	they allow one to deal with points, curves, and surfaces in an intrinsic manner,<br>i.e. independently of a specific coordinate system.<br><br>pg 4838<br>
What is a <i>frame</i> aka <i>affine frame</i>?<br>	It is an origin (a point) paired with a basis (of vectors).<br><br>pg 4839<br>
What is the <i>standard frame</i>? What unique properties does this frame that distinguishes it from other frames?	unique: points and vectors are identified.<br><br>pg 4839<br>
What if we pick a point with a different origin as the standard frame,<br>say <$>\Omega = (\omega_1, \omega_2, \omega_3)</$> but the same basis vectors <$>(\vec{e_1}, \vec{e_2}, \vec{e_3})</$>?<br><br>What is the position vector of the point <$>x = (x_1, x_2, x_3)</$> in this frame and why?	pg 4840<br>
What is a linear combination of vectors?<br>	pg 4840<br>
Consider the following statement:<br><br>The notion of a linear combination of points is frame independent.<br><br>Prove or disprove.<br>	FALSE. pg 4842, first wordy paragraph near top.<br><br>
Characterize the order topology on <b>R</b>.<br>	pg 4363, example 1
Characterize the order topology on <b>R</b>×<b>R</b>.<br>	pg 4363, example 2<br>
Characterize the order topology on the positive integers.<br>	pg 4363, example 3<br>
Characterize the order topology on {1,2} × <b>Z</b><sub>+</sub>.	pg 4363, example 4
If X is an ordered set and a is an element of X, what are the four <b>rays</b> determined by a?<br>	pg 4364
Let X and Y be topological spaces. What is the <b>product topology</b> on X × Y?<br>	pg 4364, definition<br>
Consider the following statement:<br><br>The basis that generates a product topology is itself a topology.<br><br>Prove or disprove.<br><br><br>	FALSE. pg 4364<br>
Let X and Y be topological spaces. Consider the following statement:<br><br>"<br>If <b>B</b> is a basis for the topology of X and <b>C</b> is a basis for the topology of Y then the collection<br><br>D = { B × C | B ∈ <b>B</b>, C ∈ <b>C</b> } <br><br>is a basis for the topology of X × Y.<br>"<br><br>Prove or disprove.	pg 4364/4365<br><br><br>
Let <b>R</b> be the standard topology on the real numbers. Discuss and weigh the benefits of various bases for the topology <b>R</b> × <b>R</b>.<br>	pg 4365<br>
Consider the following statement:<br><br>The collection<br>S = { π<sub>1</sub><sup>-1</sup>(U) | U open in X } ∪ { π<sub>2</sub><sup>-1</sup>(V) | V open in Y }<br><br>is a subbasis for the product topology on X × Y.<br><br>Prove or disprove.<br><br>	pg 4366<br>
Let X be a topological space with topology T. If Y is a subset of X, what is the <i>subspace topology</i> of X with respect to Y?<br>	pg 4366
Given a basis for a topology X, how can we obtain a basis for the subspace topology of X on Y? Prove your answer.<br>	pg 4367<br>
When dealing with a topological space X and a subspace Y, how does one differentiate between an open set of the topology of Y and an open set of the topology of X?<br>	pg 4367<br>
Let Y be a subspace of X. <br><br>Consider the following statement:<br>If U is open in Y and Y is open in X, then U is open in X.<br><br>Prove or disprove.<br>	true. pg 4367.<br>todo: add impostor<br>
Consider the following statement: <br><br><b>Sets</b><sub>*</sub> ≅ <b>Sets</b>/1<br><br>Prove or disprove.<br>	IMPOSTOR. pg 2673
What is an <i>equation in context</i>?<br>	pg 4174 (right side)<br>
What is an <i>algebraic theory</i>?<br>	pg 4174, right, disc 3.3.1<br>
If Th is a theory, what does "Th ▹ Γ ⊢ M = M' : α" mean?<br><br>	pg 4174, right, disc 3.3.1<br>
Give the algebraic signature for the theory of groups.<br>	pg 4174, bottom right<br>
Give an an algebraic theory for meet semilattices.<br>	pg 4175, top right<br><br>
Discuss the advantages of categorical semantics of algebras over traditional algebra semantics.	pg 4176, left<br><br>
How can we model, as a category, an algebraic type theory in which exactly one free variable appears in a term.<br>	pg 4176, bottom-left/full right side<br>
Explain the "Interpreting Substitution by Composition" basic principle of categorical type theory.<br>	pg 4177, fig 3.3 on left<br>
Let <b>C</b> be a category with finite products and let Sg be an algebraic signature. What is a <i>structure</i> M in <b>C</b> for Sg?<br>	pg 4177, left, disc 3.5.1<br>
Give definitions for the categorical denotational semantics for the typing judgments for variables, constants, and applications.	pg 4177, right, fig 3.4<br>
State a lemma characterizing simultaneous substitution using categorical semantics.<br>	pg 4177, lemma 3.5.2<br><br>
Let M be a structure for a algebraic signature Sg in a category <b>C</b> with finite products. Given an equation-in-context Γ ⊢ M = M' : α, what does it mean for model <b>M</b> to <i>satisfy</i> the equation-in-context?<br>	pg 4178, left, disc 3.8.1<br>
Give the algebraic theory for commutative monoids. Characterize categorical models of the theory.<br><br>Give a categorical model for addition on the natural numbers.<br><br>	pg 4178 (left)<br><br>
State and prove the soundness theorem for categorical denotational semantics of algebraic theories.<br>	pg 4178, thm 3.6.4<br>
Exercise 3.6.5, pg 4178	<br>
What does it mean for a subset of a topological space to be <i>closed</i>?<br>	pg 4371<br>
In the plane <b>R</b><sup>2</sup>, is the set { x × y | x ≥ 0 and y ≥ 0 } open? Is it closed? Why or why not? Prove your answer.<br>	pg 4371, example 2.<br>
What are the closed sets of the finite complement topology?	pg 4371, example 3.<br>
Consider the following subset of the real line:<br><br>Y = [0,1] U [2,3]<br><br>In the subspace topology with respect to the standard topology on real numbers. Is the set [0,1] open or closed in this toplogy? What about the set [2,3]?<br>	TRICK QUESTION IMPOSTOR. They are both open.<br><br>pg 4371, example 5<br>
What can be said about closed sets' closure under intersections and unions?<br>	theorem 17.1, pg 4372<br>
Let Y be a subspace of X. Consider the following statement:<br><br>A set A is closed in Y if and only if it equals the intersection of a closed set of X with Y.<br><br>Prove or disprove.<br>	pg 4372
Let Y be a subspace of X. When is a set A that is closed in Y also happen to be closed in X?<br> 	pg 4373, theorem 17.3<br>
Given a subset A of a topological space X, what is the <i>interior</i> of A?	pg 4373<br>
Given a subset A of a topological space X, what is the <i>closure</i> of A?	pg 4373
What can be said about the interior of an open set?<br>	It <i>is</i> the open set.<br>pg 4373<br>
Let A be a subset of a topological space X. Consider the following statement.<br><br>x ∈ cl(A) if and only if every open set U containing x intersects A<br><br>Prove or disprove.<br>	true. pg 4374<br>TODO: add impostor
Let A be a subset of a topological space X given by a basis B. Consider the following statement.<br><br>x ∈ cl(A) if and only if every basis element B containing x intersects A.<br><br>Prove or disprove.<br>	pg 4374<br>
In topology, what does the statement "U is a neighborhood of x" mean?<br>	pg 4374<br>
example 6, pg 4374 (turn this into a real card)	<br>
example 7, pg 4374 (turn this into a real card)	<br>
If A is a subset of the topological space X and if x is a point of X, what does it mean for x to be a <i>limit point</i> of A?<br>	pg 4375<br>
In the standard topology of the real line <b>R</b>, what are the limit points of (0,1]?<br>	pg 4375
In the standard topology on the real line <b>R</b>, what are the limit points of<br><br>{1/n | n ∈ Z<sub>+</sub>}?	pg 4375<br>
Let A be a subset of the topological space X; let A' be the set of all limit points of A.<br><br>Consider the following statement:<br><br>cl A = A ∪ A'<br><br>Prove or disprove.<br>	true. pg 4375<br>
Consider the following statement:<br><br>A subset of a topological space is closed if and only if it contains all its limit points.<br><br>Prove or disprove.<br>	pg 4376<br>
Consider the following statement:<br><br>In all topological spaces, singleton sets are closed.<br><br>Prove or disprove.<br>	FALSE. pg 4376. also see the definition of the T1 axiom on pg 4377.<br><br>
In an arbitrary topological space X, what does it mean for a sequence <br><br>x<sub>1</sub>, x<sub>2</sub>, ... <br><br>of points in X to <i>converge</i> to a point x ∈ X? 	pg 4376<br>
Consider the following statement:<br><br>If a sequence of points in a topological space converges, it converges to a <i>unique</i> point.<br><br>Prove or give a counterexample.<br>	There is a counterexample on pg 4376<br>
What is a <i>Hausdorff space</i>?<br>	pg 4376, definition at bottom<br>
Consider the following statement:<br><br>Every finite point set in a Hausdorff space X is closed.<br><br>Prove or disprove.<br>	true. pg 4377<br>TODO: add impostor
What is the <i>T<sub>1</sub> axiom</i>?	pg 4377<br>
Let X be a T1 space. Let A be a subset of X. Characterize the conditions under which a point x is a limit point of A, proving any claims.<br>	pg 4377, theorem 17.9<br><br>
Consider the following statement:<br><br>If X is a Hausdorff space, then a sequence of points of X converges to at most one point of X.<br><br>Prove or disprove.<br>	true. pg 4377, thm 17.10<br>TODO: add impostor?<br>
Exercise 1, pg 4378<br>	<br>
Exercise 2, pg 4378<br>	<br>
Exercise 5, pg 4378<br>	<br>
Exercise 7, pg 4379<br>	<br>
Exercise 6, pg 4379<br>	<br>
Exercise 10, pg 4379<br>	<br>
Exercise 13, pg 4379<br>	<br>
Exercise 14, pg 4379<br>	my answer: every point<br>
Exercise 19, pg 4380<br>	<br>
Exercise 20, pg 4380<br><br>The definition of <i>boundary</i> is right above in exercise 19.	<br>
Let X and Y be topological spaces. What does it mean for a function f : X → Y to be <i>continuous</i>?<br>	pg 4380<br>
Showing that the inverse image of an open set is open may be a bit tricky given the large variety of open sets that may exist. How do we circumvent this trickiness? Prove your answer.	pg 4381, top half of page -- both basis elements and subbasis elements could be used<br>
Let <b>R</b> be the set of real numbers with its standard topology. Let <b>R</b><sub>l</sub> be the set of real numbers with the lower limit topology.<br><br>Is the identity function id1 : <b>R</b> → <b>R</b><sub>l</sub> where id1(x) = x continuous? What about id2 : <b>R</b><sub>l</sub> → <b>R</b>?<br><br>Prove your answers.<br>	pg 4382<br>
<latex>~\\<br>Let $X$ and $Y$ be topological spaces. Let $f : X \to Y$ be a continuous function.<br>Consider the following statement:\\~\\<br>For every subset $A$ of $X$, one has $f(\overline{A}) \subseteq \overline{f(A)}$.\\~\\<br>Prove or disprove.<br></latex><br>	pg 4382, thm 18.1 (1 => 2)<br><br>
<latex><br>Let $X$ and $Y$ be topological spaces, and let $f : X \to Y$ be a function such that for every subset $A$ of $X$, one has $f(\overline{A}) \subseteq \overline{f(A)}$.<br>Consider the following statement:\\~\\<br>For every closed set $B$ of $Y$, the set $f^{-1}(B)$ is closed in X.\\~\\<br>Prove or disprove.<br></latex>	pg 4382, thm 18.1 (2 => 3)<br>
Let X and Y be topological spaces. Let f : X → Y be a continuous function.<br><br>Consider the following statement:<br><br>For each x ∈ X and each neighborhood V of f(x), there is a neighborhood U of x such that f(U) ⊆ V.<br><br>Prove or disprove.<br>	pg 4382, thm 18.1 (1 => 4)<br><br>
Let X and Y be topological spaces. Let f : X → Y be a function such that for each x ∈ X and each neighborhood V of f(x), there is a neighborhood U of x such that f(U) ⊆ V.<br><br>Consider the following statement:<br><br>f is continuous<br><br>Prove or disprove.<br>	true. pg 4382, thm 18.1 (4 => 1)<br>
Let f : X → Y. What does it mean for f to be <i>continuous at a point x ∈ X</i>?<br>	pg 4382, below thm 18.1<br>
What is a homeomorphism?<br>	pg 4383<br>
What is a <i>topological property</i>?<br>	pg 4383<br>
What is a <i>topological imbedding</i>?<br>	pg 4383, near bottom<br>
Consider the following statement:<br><br>The function f : <b>R</b> → <b>R</b> given by f(x) = 3x + 1 is a homeomorphism.<br><br>Prove or disprove.<br>	pg 4384, example 4<br><br>
Consider the following statement:<br><br>The function F : (-1, 1) → <b>R</b> defined by F(x) = x / (1 - x<sup>2</sup>) is a homeomorphism.<br><br>Prove or disprove.<br><br>	true. pg 4384, example 5.<br><br>TODO: add a counterexample.<br><br>
Given some examples of maps which are continuous, but not homeomorphisms.<br>	pg 4354/4358<br>
Let X and Y be topological spaces. Consider the following statement:<br><br>If f : X → Y maps all of X into the single point y<sub>0</sub> of Y, then f is continuous.<br><br>Prove or give a counterexample.<br>	true. pg 4385, thm 18.2, part a.)<br><br>
Let X be a topological space. Consider the following statement:<br><br>If A is a subspace of X, the inclusion function j : A → X is continuous.<br><br>Prove or give a counterexample.<br>	pg 4385. thm 18.2, b.)<br> <br>
Let X, Y, and Z be topological spaces. Consider the following statement:<br><br>If f : X → Y and g : Y → Z are continuous, then the map (g ∘ f) : X → Z is continuous. <br><br>Prove or give a counterexample.<br>	pg 4385, thm c.)<br>
Let X and Y be topological spaces. <br><br>Consider the following statement:<br><br>If f : X → Y is continuous and if A is a subspace of X, then the restricted function <br>f|A : A → Y is continuous.<br><br>Prove or disprove.<br>	pg 4386, part d.)<br><br>
Let X and Y be topological spaces. <br><br>Consider the following statement:<br><br>Let f : X → Y be continuous. If Z is a subspace of Y containing the image set f(X), then the function g : X → Z obtained by restricting the range of f is continuous. If Z is a space having Y as a subspace, then the function h : X → Z obtained by expanding the codomain of f is continuous.<br><br>Prove or disprove.	pg 4386, part e.) <br>TODO: add impostor<br>
Let X and Y be topological spaces. Consider the following statement:<br><br>The map f : X → Y is continuous if X can be written as the union of open sets U<sub>α</sub> such that f|U<sub>α</sub> is continuous for each α.<br><br>Prove or disprove.	true. pg 4386 f) near top.<br>TODO: add impostor<br>
State and prove "the pasting lemma".<br>	pg 4386, thm 18.3, near bottom<br><br><br><br>
Let f : A → X × Y be given by the equation f(a) = (f<sub>1</sub>(a), f<sub>2</sub>(a)).<br><br>Consider the following statement:<br><br>f is continuous if and only if the functions<br><br>f<sub>1</sub> : A → X <br>and<br>f<sub>2</sub> : A → Y<br><br>are continuous.<br><br>Prove or disprove. <br>	pg 4388, thm 18.4<br><br>todo: add impostor?<br><br>
Exercise 2, pg 4389<br>	<latex>~\\<br>My answer is no. Let $X = \{ 0, 1 \}$ with topology $\{ X, \emptyset \}$ and let $Y = \{ 2, 3 \}$ with topology $\{ Y, \emptyset, \{ 2 \}, \{ 3 \} \}$. Let $f(x) = 2$. Then $f$ is continuous. Let $A = \{ 1 \} \subseteq X$. $0$ is a limit point of $A$, but $f(0)$ is not a limit point of $f(A)$, since it only intersects $f(A)$ at itself.<br></latex>
Exercise 3, pg 4389	<br>
Exercise 4, pg 4389	<br>
Exercise 6, pg 4389	<br>
Exercise 8, pg 4389/4390<br>	<br>
Exercise 11, pg 4390	<br>
Let <b>C</b> be a category. What is a <i>group</i> in <b>C</b>?<br>	pg 2731<br>
Let <b>C</b> be a category with finite products. What is Group(<b>C</b>), the category of groups in <b>C</b>?	pg 2733
Let <b>C</b> be a category with finite products. What is a <i>homomorphism of groups in <b>C</b></i>?	pg 2733<br>
State the category-theoretic definition of <i>partially-ordered group</i>.<br>	pg 2734, near top<br><br>
Let G be a set equipped with two binary operations ∘, ★ : G × G → G, with uniits 1<sup>∘</sup> and 1<sup>★</sup>, respectively, such that<br><br>for all g,h ∈ G × G, <br>(g<sub>1</sub> ∘ h<sub>1</sub>) ★ (g<sub>2</sub> ∘ h<sub>2</sub>) = (g<sub>1</sub> ★ g<sub>2</sub>) ∘ (h<sub>1</sub> ★ h<sub>2</sub>)<br><br>Consider the following statements:<br><br>1<sup>∘</sup> = 1<sup>★</sup><br>∘ = ★<br>The operation ∘ = ★ is commutative.<br><br>Prove or disprove.<br>	pg 2734<br>TODO: add impostor?<br>
Consider the following statement:<br><br>The groups in the category of groups are exactly the abelian groups.<br><br>Prove or disprove.<br>	true. pg 2735<br>todo: add impostor?<br>
What is a <i>strict monoidal category</i>?	pg 2735, def 4.9<br><br>
Are lattices strict monoidal cateogries?	only bounded ones. pg 2735, below def 4.9<br>
Are posets strict monoidal categories?<br>	IMPOSTOR. not in general, but certain lattices are.<br>pg 2735<br>
Is the poset End(P) (of montone maps f : P → P, ordered pointwise) a strict monoidal category? Why or why not?	it is. pg 2735<br>
Explain how the category Ord<sub>Fin</sub> of finite ordinals is a strict monoidal category.	pg 2736, top<br>
Define the <i>kernel</i> of a group homomorphism in category-theoretic terms.<br>	pg 2736, section 4.2<br>
Consider the following statement:<br><br>Every group homomorphism h : G → H has a kernel ker(h) = h<sup>-1</sup>(u), which is a normal subgroup of G with the property that, for any normal subgroup N ⊆ G, <br><br>N ⊆ ker(h)<br><br>iff there is a (necessarily unique homomorphism h' : G/N → H with h' ∘ π = h.<br><br>Prove or disprove.<br>	pg 2738, thm 4.10<br>todo: add impostor<br><br>
Prove corollary 4.14 on page 2741<br>	<br>
What is a <i>congruence</i> on a category?	pg 2739<br>
Prove corollary 4.11 on page 2738<br>	<br>
If <b>C</b> is a category, then what is the congruence category <b>C</b><sup>~</sup>? What is the quotient category <b>C</b>/~? How are these categories related?<br>	pg 2739/2740<br>
What is the <i>kernel category</i> of a functor <b>F</b>?<br>	pg 2740, near bottom<br><br>
Consider the following statement:<br><br>Every functor F : <b>C</b> → <b>D</b> has a kernel category ker(F), determined by a congruence ~<sub>F</sub> on <b>C</b> such that given any congruence ~ on <b>C</b> one has <br><br>f ~ g ⇒ f ~<sub>F</sub> g<br><br>if and only if for all  π : <b>C</b> → <b>C</b>/~,<br>there is a factorization F' : <b>C</b>/~ → <b>D</b> such that F' ∘ π = F.<br><br><br><br><br><br>	pg 2741<br>todo: add impostor?<br>
Consider the following statement:<br><br><b>Cat</b> is cartesian closed, with the exponentials <br><b>D</b><sup><b>C</b></sup> = Fun(<b>C</b>,<b>D</b>)<br><br>Prove or disprove.<br>	pg 2817/2818, prop 7.13<br><br>
State and prove the bifunctor lemma.	pg 2817/2818, lemma 7.14<br>
Characterize the object <b>C<sup>1</sup></b> in the category <b>Cat</b>.<br>	pg 2820, example 7.15<br>
Characterize the object <b>C<sup>2</sup></b> in the category <b>Cat</b>.<br>	pg 2820, example 7.15<br>
Let 2 be the discrete 2-element category. Characterize the object <b>C</b><sup>2</sup> in the category <b>Cat</b>.<br><br>	pg 2820, example 7.15<br>
Let <b>I</b> be any small discrete category and let <b>C</b> be any small category. Characterize the object <b>C<sup>I</sup></b> of the category <b>Cat</b>.<br>	pg 2820, example 7.15<br><br>
Explain how graph homomorphisms can be viewed as natural transformations. 	pg 2821, example 7.17<br>
Explain how arrows of <b>Cone</b>(F) categories can be framed as natural transformations.	pg 2822, example 7.18<br>
Consider the following statement:<br><br>The inclusion functor <b>Pos</b> → <b>Cat</b> preserves CCC structure.<br><br>Prove or disprove.<br>	pg 2823, example 7.19
If G and H are two group categories, characterize the object H<sup>G</sup> in <b>Cat</b>. In particular, consider the arrows of the category H<sup>G</sup>.<br>	pg 2823, example 7.21<br>
What are <i>groupoids</i>, and what is the motivation for defining them?<br>	Groupoids are categories, possibly with multiple objects, in which every arrow is an iso. <br><br>The motivation behind them is explained near the bottom of pg 2823.<br>
Consider the following statement:<br><br>The category <b>Grpd</b> of groupoids is cartesian closed and the inclusion functor<br><br><b>Grpd</b> → <b>Cat</b><br><br>preserves the CCC structure.<br><br>Prove or disprove.<br>	pg 2824, prop 7.22<br><br>
Consider the following statement:<br><br>The category <b>Grp</b> of groups is cartesian closed and the inclusion functor<br><br><b>Grp</b> → <b>Cat</b><br><br>preserves the CCC structure.<br><br>Prove or disprove.<br>	IMPOSTOR. This is why groupoids were invented.<br><br>pg 2824<br><br>
Can we consider the endofunctors on an arbitrary category <b>C</b> as a strict monoidal category?<br>	Yes, see pg 2824, section 7.8<br>
Why can't a category with finite products be considered a strict monoidal category with respect to its product operator?<br>	pg 2825<br><br>
What is a <i>monoidal category</i>? (hint: the definition is rather intricate, but you should know it.)<br><br>	pg 2826, def 7.23<br>
Show that there is an equivalence of categories between categories <b>Sets<sub>Fin</sub></b> (finite sets) and <b>Ord<sub>Fin</sub></b> (finite ordinals).<br>	pg 2827<br>
What is an <i>equivalence of categories</i>? 	pg 2828, definition 7.25<br><br>
What does it mean for one functor to be a <i>psuedo-inverse</i> of another?<br>	pg 2828, def 7.25<br>
If <b>C</b> and <b>D</b> are categories, what does <b>C</b> ≃ <b>D</b> mean?	(note: the racket shorthand for this symbol is \simeq)<br>it means that there is an equivalence of categories between them.<br>pg 2828, def 7.25
Consider the following statement:<br><br>The following conditions on a functor F : <b>C</b> → <b>D</b> are equivalent:<br>1. F is (part of) an equivalence of categories.<br>2. F is full and faithful and "essentially surjective" on objects: for every D ∈ <b>D</b>, there is some C ∈ <b>C</b> such that FC ≌ D.<br><br>Prove or disprove.<br><br>	true. pg 2829, prop 7.26<br>todo: add impostor<br>
Consider the following statament:<br><br>Let <b>Par</b> be the category of sets and partial functions, and <b>Sets<sub>*</sub></b> be the category of pointed sets.<br><br><b>Par</b> ≃ <b>Sets<sub>*</sub></b> <br><br>Prove or disprove.<br><br>	pg 2831, example 7.27<br>todo: add impostor
Let <b>Sets</b><sup>I</sup> be the category of I-indexed families of sets, where the objects are I-indexed families of sets (A<sub>i</sub>)<sub>i ∈ I</sub> and the arrows are I-indexed families of functions <br><br>(f<sub>i</sub> : A<sub>i</sub> → B<sub>i</sub>)<sub>i ∈ I</sub> : (A<sub>i</sub>)<sub>i ∈ I</sub> → (B<sub>i</sub>)<sub>i ∈ I</sub>.<br><br>Consider the following statement:<br><br><b>Sets</b><sup>I</sup> ≃ <b>Sets</b>/I.<br><br>Prove or disprove.	true. pg 2833, example 7.29.<br>todo: add impostor?<br>
What is a <i>metric</i>?<br>	pg 4397
If x is a point in a metric space, what is the <i>ε-ball centered at x</i>?<br>	pg 4397<br>
If d is a metric on a set X, what is the <i>metric topology</i> induced by d?<br>	pg 4397<br>
Let d be a metric on a set X. Consider the following statement:<br><br>The collection of all ε-balls B<sub>d</sub>(x,ε), for x ∈ X and ε > 0, is a basis for a topology on X.<br><br>Prove or disprove.<br>	true. pg 4397, below definition of metric topology<br>todo: add impostor
Characterize the conditions under which a set U is open in a metric topology using ε-balls.<br>	pg 4398, below figure 20.1<br>
Is there some metric that induces the discrete topology? If not, why?	there is one.<br>pg 4398, example 1<br>
Is there some metric that induces the standard topology on the real numbers? If not, why?	there is one.<br>pg 4398, example 2<br>todo: add impostor<br>
What does it mean for a topological space to be <i>metrizable</i>?<br>	pg 4398<br>
What is a <i>metric space</i>?	pg 4398<br>
What does it mean for a subset of a metric space to be <i>bounded</i>?	pg 4399<br>
What is the <i>diameter</i> of a bounded, non-empty subset of a metric space?<br>	pg 4399<br>
Is boundedness a topological property? Why or why not?<br>	it is not. see pg 4399, theorem 20.1, along with the text directly above it.<br><br>
If d is a metric, what is the <i>standard bounded metric</i> corresponding to d?<br>	pg 4399<br>
Let d be a metric. Show that its standard bounded metric d' is indeed a metric.<br>	pg 4399<br>
Give two distinct metrics for <b>R</b><sup>n</sup>. (proving that they are metrics is not necessary)<br><br>	pg 4400<br>
Let X and Y be topological spaces. Let f : X → Y. Suppose that for each x ∈ X and each neighborhood V of f(x), there is a neighborhood U of x such that f(U) ⊆ V.<br><br>Consider the following statement:<br><br>f is continuous.<br><br>Prove or disprove.<br>	Top of page 4383 (4 => 1)<br>
What is a <i>box topology</i>?<br>	pg 4391, top two paragraphs<br>
How does a <i>box topology</i> differ from a <i>product topology</i>?<br>	pg 4391<br>
What is a <i>box topology</i>?	pg 4392
What is a <i>projection mapping</i> of a product space?	pg 4392<br>
Compare a basis for the box topology to the basis for the corresponding product topology.<br>	pg 4393, theorem 19.1, and discussion above.<br>
What is more important: the box topology or the product topology? Why?	pg 4393, second to bottom paragraph<br><br>
Given a J-indexed family of topological spaces, along with a basis B<sub>j</sub> generating each space, how can we construct a basis for the box topology on the product of the topological spaces? How can we construct a basis for the product topology on the product of the topological spaces?<br><br>Prove your answer.<br> 	pg 4394, thm 19.2<br><br>
Consider the following statement:<br><br>If X<sub>j</sub> is a J-indexed family of topological spaces, and for each X<sub>j</sub> we have a subspace A<sub>j</sub>, then ΠA<sub>j</sub> is a subspace of ΠX<sub>j</sub> if both products are given the product topology.<br><br>Prove or disprove.<br>	true. pg 4394, thm 19.3<br>todo: add impostor?<br><br>
Let X<sub>j</sub> be a J-indexed family of Hausdorff spaces. Consider the following statement:<br><br>ΠX<sub>j</sub> is Hausdorff in the product topology.<br><br>Prove or disprove.<br>	true. thm 19.4. pg 4394.<br>There's no proof provided, but I think it's simple.<br><br>todo: add impostor?<br>
Let X<sub>j</sub> be a J-index family of topological spaces. Let A<sub>j</sub> ⊆ X<sub>j</sub> for each j.<br><br>Consider the following statement:<br><br>If ΠX<sub>j</sub> is given the product topology, then<br>Π(cl A<sub>j</sub>) = cl (ΠA<sub>j</sub>)<br><br>Prove or disprove.<br>	true. pg 4394, thm 19.5<br>todo: add impostor?
Let f : A → Π<sub>j∈J</sub> X<sub>j</sub> be given by the equation <br>f(a) = (f<sub>j</sub>(a))<sub>j∈J</sub><br>where f<sub>j</sub> : A → X<sub>j</sub> for each j. Let ΠX<sub>j</sub> have the product topology. <br><br>Consider the following statement:<br><br>The function f is continuous iff each function f<sub>j</sub> is continuous.<br><br>Prove or disprove.<br>	true. pg 4395, thm 19.6.<br><br>
Let f : A → Π<sub>j∈J</sub> X<sub>j</sub> be given by the equation <br>f(a) = (f<sub>j</sub>(a))<sub>j∈J</sub><br>where f<sub>j</sub> : A → X<sub>j</sub> for each j. Let ΠX<sub>j</sub> have the box topology. <br><br>Consider the following statement:<br><br>The function f is continuous iff each function f<sub>j</sub> is continuous.<br><br>Prove or disprove.	IMPOSTOR. example 2, pg 4395<br>
pg 4396, exercise 4<br>	<br>
pg 4396, exercise 6<br>	<br>
pg 4396, exercise 10<br>	<br>
Let <b>C</b> be a category and C ∈ <b>C</b>. Explain the evaluation functor ev<sub>C</sub> : Sets<sup><b>C</b></sup> → Sets.<br>	pg 2841/2842<br><br>
Explain the "cylinder" mentioned on the top paragraph of pg 2842.<br>	pg 2842<br>
Explain why an arbitrary category of the form Sets<sup><b>C</b></sup> can be regarded as a generalized "category of structured sets" and their "homomorphisms". Provide a motivating example.<br>	pg 2842<br>
When is a functor considered an <i>embedding</i>?<br>	When it is full, faithful, and injective on objects.<br>pg 2843, below def 8.1<br><br>
What is the <i>Yoneda embedding</i>?<br>	pg 2843, definition 8.1<br><br>
Explain how the "principle downset" operator ↓ serves as a monotone injection from a poset P into the poset 2<sup>|P|</sup> of subsets and inclusions. How is the Yoneda embedding a "better" version of this phenomenon?<br>	maybe this card was a mistake... it's better than the group version (which is poorly explained),<br>but the poset example seems to already "good" as they describe.<br><br>pg 2844, near middle<br>
What is the Cayley representation of a group? If <b>C</b> is a category, what is the "Cayley representation" of <b>C</b>? How is the Yoneda embedding better than the Cayley representation?<br>	pg 2843(bottom)/2844<br><br>pg 2669<br>
State (but don't prove) the Yoneda lemma.<br>	pg 2844/2845<br>todo: add multiple cards for different aspects of the proof.<br>
If <b>C</b> is not locally small, what does the Yoneda lemma tell us about Hom(yC, F)?<br>	IMPOSTOR<br>yC's codomain would be a proper class, so y is not even well defined.<br>pg 2848<br>
If <b>C</b> is locally small, what does the Yoneda lemma tell us about Hom(yC,F)?<br>	That it is always a set.<br>pg 2848, remark 8.4<br>
Prove that the Yoneda embedding is full and faithful.<br>	pg 2848, theorem 8.3<br><br>
Prove that the Yoneda embedding is injective on objects.<br>	pg 2848, bottom paragraph<br>
State and prove the Yoneda principle.<br>	pg 2849, top paragraph<br>
Use the Yoneda principle to prove that in a cartesian closed category, there is always an isomorphism (A<sup>B</sup>)<sup>C</sup> ≌ A<sup>B×C</sup>.<br>	pg 2849<br>
Let <b>C</b> be a cartesian closed category with coproducts.<br><br>Consider the following statement:<br><br>For all A,B,C ∈ <b>C</b>, there is a canonical isomorphism<br>(A × B) + (A × C) ≌ A × (B + C)<br><br>Prove or disprove.<br>	pg 2849, prop 8.6 (proof on next page)<br><br>
Let d and d' be two metrics on the set X; let T and T' be the topologies they induce, respectively.<br><br>Consider the following statement:<br><br>T' is finer than T if and only if for each x in X and each ε > 0, there exists a δ > 0 such that<br><br>B<sub>d'</sub>(x, δ) ⊆ B<sub>d</sub>(x, ε)<br><br>Prove or disprove.<br>	true. pg 4400, lemma 20.2<br>todo: add impostor<br>
Consider the following statement:<br><br>The topologies <b>R</b><sup>n</sup> induced by the euclidean metric d and the square metric ρ are the same as the product topology on <b>R</b><sup>n</sup>.<br><br>Prove or disprove.<br>	pg 4401<br>
Let J be an index set. What is the <i>uniform metric</i> on <b>R</b><sup>J</sup>, and what is the motivation for defining such a metric?<br>	pg 4402<br>
Let J be an index set. How are the uniform, product, and box topologies on <b>R</b><sup>J</sup> related? Prove your answer.<br><br><br>	pg 4402<br>
Let d(a, b) = min{|a - b|, 1} be the standard bounded metric on <b>R</b>.<br>If x and y are two points of <b>R</b><sup>ω</sup>, define <br><br><$$>D(x,y) = sup \left \{ \frac{d(x_i,y_i)}{i} \right \}</$$><br><br>Prove that D is a metric that induces the product topology on <b>R</b><sup>ω</sup>.<br><br>	pg 4403, theorem 20.5<br>
Exercise 1, pg 4404<br>	<br>
Exercise 2, pg 4404<br>	<br>
Exercise 3, pg 4404<br>	<br>
Exercise 5, pg 4405<br>	<br>
Exercise 6, pg 4405<br>	<br>
Exercise 8, pg 4405<br>NOTE: the definition of uniform topology is on pg 4402	<br>
Explain the difference between intrinsic and extrinsic program semantics.<br>	pg 5318<br>
Is the standard category theoretic treatment of type systems intrinsic or extrinsic?<br>	pg 5318, right column<br>
What does <i>coherence</i> mean when used to describe type systems?<br>	pg 5318, bottom right
Let U : <b>D</b> → <b>T</b> be a functor. What does it mean for an object S ∈ <b>D</b> to refine an object A ∈ <b>T</b>? 	pg 5319, def 3
What is a <i>typing judgment</i>? A <i>subtyping judgment</i>? <br>	pg 5319, def 4.
What is a <i>derivation</i> of a typing judgment?<br>	pg 5319, def 5.<br>
How does "Functors are refinement type systems" define <i>types</i>? <i>Refinement types</i>? <i>Terms</i>?<br>	pg 5319<br>
What does <$>S \underset{f}{\Longrightarrow} T</$> denote? What does U ≤ V denote? Express U ≤ V in <$>\Longrightarrow</$> notation.<br>	pg 5319, right column, item 2<br>
What does <$>S \overset{\alpha}{\underset{f}{\implies}} T</$> denote? <$>\vdash S \underset{f}{\implies} T</$>? <$>\not\vdash S \underset{f}{\implies} T</$>?	pg 5319, right column, item 3<br>
Draw diagrams to demonstrate type refinement, typing and subtyping judgments, and derivations of typing and subtyping judgments. (Using dots to represent objects, circles to represent categories, etc..)<br>	pg 5320, left column, figure 1<br>
What is a <i>typing rule</i>? When are typing rules considered <i>valid</i>?<br><br>	pg 5320, item 4, left column<br>
Consider the following statement:<br><br>The following typing rule is always valid.<br><br><$$>\inferrule{S \underset{f}{\implies} T \\ T \underset{g}{\implies} U}{S \underset{f;g}{\implies} U}</$$><br><br>Prove or disprove.<br>	true. pg 5320, proposition 6<br>todo: add impostor<br>
Consider the following statement:<br><br>The following typing rule (axiom) is always valid.<br><br><$$>\frac{ }{S \underset{id}{\implies} S}</$$><br><br>Prove or disprove.<br>	pg 5320, proposition 6<br>todo: add impostor<br>
Consider the following statement:<br><br>Subtyping is reflexive and transitive, and admits rules of covariant and contravariant subsumption.<br><br>Prove or disprove.<br>	pg 5320, proposition 7 (top right)<br>
What is a <i>refinement system</i>?	pg 5321, definition 8 (top left)<br>
Explain the "folk model" for refinement type systems, in terms of "Functors are refinement type systems".<br>	pg 5321
What is a <i>monoidal refinment system</i>?	pg 5321, definition 9 (bottom right)<br><br>
What is a <i>refinement rule</i>? What does it mean for a refinement rule to be <i>valid</i>?<br>	pg 5321 bottom right<br>pg 5322 top left<br>
Consider the following statement:<br><br>In any monoidal refinement system, the following refinement rules and typing rules are valid:<br><br><$>\inferrule{S_1 \sqsubset A_1 \\ S_2 \sqsubset A_2}{S_1 \bullet S_2 \sqsubset A_1 \bullet A_2}</$><br><br><$>\inferrule{}{I \sqsubset I}</$><br><br><$>\inferrule{S_1 \underset{f_1}{\implies} T_1 \\ S_2 \underset{f_2}{\implies} T_2}{S_1 \bullet S_2 \underset{f_1;f_2}{\implies} T_1 \bullet T_2 }}</$><br><br><$>\inferrule{}{I \underset{I}{\implies} I}</$><br><br>Prove or disprove.<br>	true. pg 5322. proposition 11.<br><br>topo: add impostor
Consider the following statement:<br><br>If A us a subspace of the topological space X and d is a metric for X, then the restriction of d to A is ametric for the topology of A.<br><br>Prove or disprove.	true. pg 4407<br>
Consider the following statement:<br><br>All order topologies are metrizable.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 4407<br>
Consider the following statement:<br><br>There is a metric topology for which the Hausdorff axiom is not satisfied.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 4407<br>
Let f : X → Y; let X and Y be metrizable with metrics d<sub>X</sub><br>and d<sub>Y</sub> respectively. <br><br>Consider the following statement:<br><br>The continuity of f is equivalent to the requirement that given x ∈ X and given ε > 0, there exists δ > 0 such that δ<sub>X</sub>(x, y) < δ ⇒ d<sub>Y</sub>(f(x), f(y)) < ε.<br><br>Prove or disprove.<br><br><br>	true. pg 4407, thm 21.1<br>todo: add impostor?<br><br>
Let X be a topological space, and let A ⊆ X. Consider the following statement:<br><br>If there is a sequence of points of A converging to x, then x ∈ cl(A). The converse holds if X is metrizable.<br><br>Prove or disprove.<br>	true. pg 4408, thm 21.2<br>todo: add impostor?<br>
Let f : X → Y. Consider the following statement:<br><br>If the function f is continuous, then for every convergent sequence x<sub>n</sub> → x in X, the sequence f(x<sub>n</sub>) converges to f(x). The converse holds if X is metrizable.<br><br>Prove or disprove.<br><br>	true. pg 4408, thm 21.3<br>todo: add impostor?<br>
What does it mean for a space X to have a <i>countable basis at the point x</i>?<br>What does it mean for a space X to satisfy the <i>first countability axiom</i>?<br>	pg 4408/4409<br>
Let X be a topological space, and let f,g : X → <b>R</b> be continuous functions.<br>Consider the following statement:<br><br>f+g, f-g, f·g are continuous. If g(x) ≠ 0 for all x, then f/g is continuous.<br><br>Prove or disprove.<br>	true. pg 4409<br>todo: add impostor?<br>
Let f<sub>n</sub> : X → Y be a sequence of continuous functions from the<br>topological space X to the metric space Y.<br><br>Consider the following statement:<br><br>If (f<sub>n</sub>) converges uniformly to f, then f is continuous.<br><br>Prove or disprove.<br>	pg 4410<br>todo: add impostor?<br>
Let f<sub>n</sub> : X → Y be a sequence of functions from the set X to the<br>metric space Y.<br><br>What does it mean for the sequence (f<sub>n</sub>) to <i>converge uniformly</i> to the function f : X → Y?<br><br><br>	pg 4409, definition near bottom<br>
How does the notion of uniform convergence relate to the definition of the uniform metric?<br>	pg 4410, below thm 21.6<br><br>
Consider the following statement:<br><br><b>R</b><sup>ω</sup> in the box topology is metrizable.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 4410, example 1.<br>
Consider the following statement:<br><br>An uncountable product of <b>R</b> with itself is not metrizable.<br><br>Prove or disprove.<br>	true. pg 4411, example 2.<br>
pg 4411, exercise 1<br>	<br>
pg 4411, exercise 2	<br>
pg 4411, exercise 3	<br>
pg 4411, exercise 4<br>	<br>
Consider the following statement:<br><br>For any locally small category <b>C</b>, the functor category <b>Sets<sup>C<sup>op</sup></sup></b> is complete. Moreover, for every object C ∈ <b>C</b>, the evaluation functor<br><br>ev<sub>C</sub> : <b>Sets<sup>C<sup>op</sup></sup> → Sets</b><br><br>preserves all limits.<br><br><br>Prove or disprove.<br>	pg 2850/2851, prop 8.7<br><br>
Consider the following statement.<br><br>If <b>C</b> is a category and <b>D</b> a cocomplete category, then so is the functor category <b>D<sup>C</sup></b>, and the colimits in <b>D<sup>C</sup></b> are "computed pointwise," in the sense that for every C   ∈ <b>C</b>, the evaluation functor<br><br>ev<sub>C</sub> : <b>D<sup>C</sup></b> → <b>D</b><br><br>preserves colimits. Thus, for any small index category J and functor A : J → <b>D<sup>C</sup></b>, for each C ∈ <b>C</b>, there is a canonical isomorphism,<br><br><$$>\lim_{\overset{\longrightarrow}{j \in J}} A_j(C) = <br>\lim_\overset{\longrightarrow}{j \in J}} (A_j C)</$$><br><br>Prove or disprove.<br>	true. pg 2851.<br>
Consider the following statement:<br><br>For any locally small <b>C</b>, the functor category <b>Sets<sup>C<sup>op</sup></sup></b> is cocomplete, and colimits there are computed pointwise.<br><br>Prove or disprove.<br>	true. pg 2852, corollary 8.9.<br><br>todo: add impostor?<br>
Consider the following statement:<br><br>For any small category <b>C</b>, every object P in the functor category <b>Sets<sup>C<sup>op</sup></b> is a colimit of representable functors,<br><br><$$>\lim_{\overset{\longrightarrow}{j \in J}} yC_j \cong P</$$><br><br>More precisely, there is a cononical choice of an index category J and a functor π : J → <b>C</b> such that there is a natural isomorphism <$$>\lim_{\longrightarrow J} y \circ \pi \cong P</$$>.<br><br>Prove or disprove.<br>	true. pg 2852, prop 8.10.<br><br>todo: add impostor?<br>
State the universal mapping property of free monoids, and explain how it is an example of adjoints.<br>	pg 2863<br>
Write a <i>two-way rule</i> describing the UMP of the free monoid.<br>	pg 2864<br>
Give the <b>preliminary</b> definition of <i>adjunction</i>. (the preliminary one is centered around a natural transformation)<br><br>	pg 2864, def 9.1<br>
What is a <i>left adjoint</i>? A <i>right adjoint</i>? A <i>unit of adjunction</i>?<br>	pg 2865, top<br><br>
What is the relation between adjunctions and equivalences of categories?<br>	this is not at all clear. maybe I need to consult a different source to get to the bottom of this...<br><br>pg 2865, near top<br>
Consider the "diagonal functor" Δ : <b>C</b> → <b>C</b> × <b>C</b> defined on objects by Δ(C) = (C,C) <br>and on arrows by<br>Δ(f : C → C') = (f, f) : (C,C) → (C',C')<br><br>What would it mean for this functor to have a right adjoint?<br><br><br>	pg 2865, example 9.2<br><br>
Consider the category <b>Pos</b> of posets and monotone maps and C<b>Pos</b> of cocomplete posets and cocontinuous maps. A poset C is cocomplete just if it has a join <$>\bigvee_i c_i</$> for every family of elements (c<sub>i</sub>)<sub>i ∈ I</sub> indexed by a set I, and a monotone map f : C → D is cocontinuous if it preserves all such joins.  There is an obvious forgetful functor U : C<b>Pos</b> → <b>Pos</b>.<br><br>What would a left adjoint F ⊣ U be?<br>	pg 2866, example 9.3<br>
Let <b>C</b> and <b>D</b> be categories and <br>F : <b>C</b> → <b>D</b><br>and<br>U : <b>D</b> → <b>C</b><br><br>be functors.<br><br>Consider the following statement:<br><br>The following are equivalent:<br>1. F is a left adjoint to U; that is, there is a natural transformation<br>η : 1<sub><b>C</b></sub> → U ∘ F<br><br>that has the UMP of the unit:<br>For any C ∈ <b>C</b>, D ∈ <b>D</b> and f : C → U(D), there exists a unique g : FC → D such that <br>f = U(g) ∘ η<sub>C</sub><br><br>2. For any C ∈ <b>C</b>, D ∈ <b>D</b>, there is an isomorphism,<br>φ : Hom<sub><b>D</b></sub>(FC,D) ≌ Hom<sub><b>C</b></sub>(C, UD)<br>that is natural in both C and D.<br><br>moreover, the two conditions are related by the formulas<br>φ(g) = U(G) ∘ η<sub>C</sub><br>η<sub>C</sub> = φ(1<sub>FC</sub>)<br><br><br>Prove or disprove.<br>	true. pg 2867, prop 9.4<br>todo: add impostor?<br>
What is the <i>counit</i> of an adjunction?<br>	pg 2871, def 9.6
What is the <b>official</b> definition of <i>adjunction</i>?<br>	pg 2871, def 9.6<br>
Suppose <b>C</b> has binary products. Take a fixed object A ∈ <b>C</b>, and consider the product functor <br><br>- × A : <b>C</b> → <b>C</b><br><br>defined on objects by <br><br>X ↦ X × A.<br><br>and arrows by<br><br>(h : X → Y) ↦ (h × 1<sub>A</sub> : X × A → Y × A).<br><br>When does - × A have a right adjoint?	<latex>~\\<br>Look at all the work I went through, because I focused on the unit and totally ignored the counit.<br>When approached from the perspective of the counit, the adjunction is obvious.<br><br>In a cartesian closed category, the functor $(-)^A : \mbf C \to \mbf C$ is a right adjoint to <br>$- \x A : \mbf C \to \mbf C$.<br>This functor's action on objects $X \in \mbf C_0$ is<br>$$ X \mapsto X^A $$<br>and its action on arrows $f : C \to D$ is<br>$$ (f : C \to D) \mapsto \Lambda(f \circ ev_{A,C})$$<br>Noting that $C^A \times A \rTo^{ev_{A,C}} C \rTo^{f} D$, it becomes clear that<br>$\Lambda(f \circ ev_{A,C}) : C^A \to D^A$\\<br><br>Here is a dumb way to prove it which requires way too much work. See Awodey's better way on pg 2872.<br><br>To show that we have an adjunction, let's start by looking at the following diagrams:<br><br>\begin{diagram}<br>(C \times A)^A  & \rTo^{g^A} & D^A \\<br>\uTo<{\eta_C} & \ruTo_{f}   &         \\<br>C                    &                  & \\<br>\end{diagram}<br><br>\begin{diagram}<br>C \times A & \rDotsto_g & D \\<br>\end{diagram}<br><br>We need a bijection between arrows of type $C \times A \to D$ and $C \to D^A$. This falls <br>straight out of the definition of exponentials. Given some $f : C \to D^A$, we obtain<br>$g : C \times A \to D$ as $g = ev_{D,A} \circ \langle f, id_A \rangle $.<br><br>We also need a natural transformation $\eta$ such that for all $f : C \to D^A$ <br>we have $g^A \circ \eta_C = f$... TODO: finish the work<br><br><br>pg 2872, example 9.7<br></latex>
For any category <b>C</b>, consider the unique functor to the terminal category <b>1</b>,<br><br>! : <b>C</b> → <b>1</b>.<br><br>When does ! have a right adjoint? When does ! have a left adjoint?<br>	pg 2872, def 9.8<br><br>
Consider the following statement:<br><br>Adjoints are unique up to isomorphism. Specifically, given a functor F : <b>C</b> → <b>D</b> and right adjoints U,V : <b>D</b> → <b>C</b>,<br>F ⊣ U and F ⊣ V<br>we then have U ≌ V.<br><br>Prove or disprove.<br>	pg 2873<br>todo: add impostor?<br>
Consider the "diagonal functor" Δ : <b>C</b> → <b>C</b> × <b>C</b> defined on objects by Δ(C) = (C,C) <br>and on arrows by<br>Δ(f : C → C') = (f, f) : (C,C) → (C',C')<br><br>What is the left adjoint to this function?<br>	pg 2873<br>
Let Δ<sub>J</sub> : <b>C</b> → <b>C</b><sup>J</sup> be defined as the functor such that for all C ∈ <b>C</b>, j ∈ J, Δ<sub>J</sub>(C)(j) = C, and for all f : j<sub>1</sub> → j<sub>2</sub>, Δ<sub>J</sub>(C)(f) = 1<sub>C</sub>.<br><br>What is the left adjoint of Δ<sub>J</sub>? The right adjoint?	pg 2873
Characterize adjunctions in preordered sets.<br>	pg 2875
What is the left adjoint of the interior operator on subsets of a topological space?<br>	pg 2875, example 9.11<br>
Describe the adjunction on powersets induced by any function f : A → B, between the inverse image operation f<sup>-1</sup> and the direct image im(f).<br><br>	pg 2876, example 9.12<br><br>
Explain how the universal and existential quantifiers of logic can be characterized as adjunctions.<br>	pg 2877, 2878<br>
<br>Explain how the following logical "forall elimination" rule can be explained in<br>terms of category theory.<br><br>∀x. ψ(x,y) ⊢ ψ(x,y)<br><br><br>	pg 2879<br>
<br>Explain how the following logical "exists introduction" rule can be explained in<br>terms of category theory.<br><br>ψ(x,y) ⊢ ∃y. ψ(x,y)<br><br><br>	pg 2878/2879<br>
Explain how the following logical fact can be explained in terms of category theory.<br><br>∀x. ψ(x,y) ⊢ ∃y. ψ(x,y)<br>	pg 2879<br>
Explain how the following logical fact can be explained in terms of category theory.<br><br>∃y∀x. ψ(x,y) ⊢ ∃y. ψ(x,y)<br>	pg 2879<br>
What is a <i>complete partial order</i>?<br>	pg 5339 (top-left)<br><br>
Let (D, ⊑) be a cpo. What is the <i>Scott topology</i> defined on D?<br>	pg 5339, def 1.2.3<br>
Let D be a cpo with Scott topology.<br><br>Consider the following statement:<br><br>The set <br><$$>U_x = \{ z \in D \mid z \not \sqsubseteq x \}</$$><br>is open.<br><br>Prove or disprove.	true. pg 5339, lemma 1.2.4<br>
Let D be a cpo with Scott topology.<br><br>Consider the following statement:<br><br>The set <br><$$>U_x = \{ z \in D \mid z \sqsubseteq x \}</$$><br>is open.<br><br>Prove or disprove.	IMPOSTOR. pg 5339, def 1.2.4<br><br><br>
Let D and D' be cpos with Scott topologies. And f : D → D'.<br><br>Consider the following statement:<br>f is continuous iff f(⊔X) = ⊔f(X) for all directed X ⊆ D.<br><br>Prove or disprove.<br>	true. pg 5339, prop 1.2.6 (right)<br>
Consider the following statement:<br><br>Continuous maps on cpo's are always monotonic.<br><br>Prove or disprove.<br>	true. If x ⊑ y then {x,y} is a directed set... you can figure out the rest.<br><br>pg 5339, corollary 1.2.7<br><br>
If D and D' are cpos, how does the cartesian product D × D' form a CPO? Prove that it is actually a CPO.<br><br><br>	pg 5339, prop.1.2.8 (bottom right)<br>
Let D and D' be CPO's with scott topologies. <br><br>Consider the following statement:<br><br>The Scott topology on D × D' is the product topology on D and D'.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 5340.<br><br>
Let D and D' be CPOs. What does [D → D'] denote?<br>	pg 5340, def 1.2.0, lemma 1.2.10, prop 1.2.11<br><br>
Let D, D', and D'' be CPOs with Scott topologies. Consider the following statement:<br><br>A map f : D × D' → D'' is continuous iff it is continuous in each of its arguments separately.<br><br>Prove or disprove.<br>	true. pg 5340, lemma 1.2.12<br><br>The definition of "Scott topology" is on pg 5339, left side, def 1.2.3,
Let D and D' be cpo's with Scott topologies.<br><br>Consider the following statement:<br><br>The function Ap : [D → D'] × D → D' defined by Ap(f, x) = f(x)<br>is continuous with respect to the Scott topology on the product [D → D'] × D.<br><br>Prove or disprove.<br><br>	pg 5340, prop 1.2.13<br>
Let D and D' be CPOs with Scott topologies.<br>Let f ∈ [D × D' → D'']. Define <$>\hat{f}(x) = \lambda y \in D' f(x,y).</$><br><br>Consider the following statements:<br>(i) <$>\hat{f}</$> is continuous, i.e. <$>\hat{f} \in [D \to [D' \to D'']]</$><br>(ii) <$>\lambda f. \hat{f} : [D \times D' \to D''] \to [D \to [D' \to D'']]</$> is continuous.<br><br>Prove or disprove.	TRUE. pg 5341, prop 1.2.14<br>TODO: add impostor
Consider the following statement:<br><br><b>CPO</b>, the category of CPOs and scott-continuous maps, is cartesian closed.<br><br>Prove or disprove.	true. pg 5341<br>
Let D be a cpo. Consider the following statement:<br><br>Every f ∈ [D → D] has a fixed point.<br><br>Prove or disprove.<br>	true. Theorem 1.2.17, pg 5341<br>
Let D be a cpo. Consider the following statement:<br><br>There exists a Fix ∈ [[D → D] → D] such that for all f ∈ [D → D], Fix(f) is the least fixed point of f.<br><br>Prove or disprove.<br>	pg 5341, thm 1.2.17 (ii)<br>
What is a <i>projective system</i> of CPOs? What does is a <i>projective limit</i> of a projective system of CPOs, and how is it an instance of the category theoretic notion of limits?<br>	pg 5341, bottom right<br>It is a limit in the category of CPOs and continuous functions. <br>(J is an infinite, well-founded downward chain * <- * <- ...)<br><br>
Consider the following statement:<br><br>The projective limit of a projective system is a CPO.<br><br>Prove or disprove.<br>	true. pg 5342, prop 1.2.19.<br>
Let D be a CPO, X ⊆ D, and f ∈ [D → D]. <br><br>What does it mean for f to be a <i>retraction</i> of D onto X?<br><br>	pg 5342, def 1.2.20 (i)<br><br>category theoretic definition on pg 2688<br>
Let D be a CPO and X ⊆ D. <br><br>What does it mean for X to be a <i>retract</i> of D?<br><br>	pg 5342<br><br>category theoretic definition on pg 2688<br>
Let D be a CPO with retract X. <br><br>Consider the following statement:<br><br>X is a cpo whose directed subsets have the same supremum as in D and whose topology is the subspace topology.<br><br>Prove or disprove.<br>	true.<br>pg 5342<br><br>todo: add impostor?<br>
Let D be a cpo. What does it mean for x ∈ D to be <i>compact</i>?	pg 5342, definition 1.2.22<br>
What does it mean for a CPO to be <i>algebraic</i>?<br>	pg 5342<br>
Consider the following statement:<br><br>THe set cpo (Pω, ⊆) of all subsets of the natural numbers, ordered by inclusion, is algebraic.<br><br>Prove or disprove.<br>	true. pg 5342, example 1.2.23<br>
Let D be algebraic and f : D → D. <br><br>Consider the following statement:<br><br>f is continuous iff f(x)=⊔{f(e) | e ⊑ x, e compact} <br><br>Prove or disprove.<br>	true. pg 5342, prop 1.2.24.<br>
Let D be an algebraic CPO. Define O<sub>e</sub> = {x ∈ D | e ⊆ x}. Consider the following statement:<br><br>{O<sub>e</sub> | e compact} is a basis for the Scott topology on D.<br><br>Prove or disprove.<br>	true. pg 5343, prop 1.2.25<br>todo: add impostor<br>
Let D, D' be CPOs. Consider the following statement:<br><br>(x,y) ∈ D × D' is compact ⇔ x and y are compact<br><br>Prove or disprove.<br>	true. pg 5343. prop 1.2.26 (i)<br>todo: add impostor
Let D, D' be CPOs. Consider the following statement:<br><br>D and D' are algebraic ⇒ D × D' is algebraic<br><br>Prove or disprove.<br>	true. pg 5343, lemma 1.2.26<br>
Let D and D' be algebraic CPOs. Consider the following statement:<br><br>The Scott topology on D × D' is the product of the Scott topologies on D and D'.<br><br>Prove or disprove.<br>	true. pg 5343, prop 1.2.27<br>
Let D be a CPO. What does it mean for X ⊆ D to be <i>consistent</i>?<br>	pg 5343, def 1.2.28<br>
Let D be a CPO. What does it mean for D to be <i>coherent</i>?<br>	pg 5343, def 1.2.28 (ii)<br>
Let D be a CPO and x,y ∈ D. What does x << y mean?<br>	pg 5343, def 1.2.29.<br>
What is a <i>continuous lattice</i>?<br>	pg 5343, top (ii)<br>
What is an <i>algebraic lattice</i>? pg 	pg 5343, top (ii)<br><br>
If X and Y are sets, characterize the CPO X ⇀ Y of partial functions from X to Y. Which elements of X ⇀ Y are compact?<br>	pg 5343, prop 1.2.31 (ii)<br><br>definition of "compact" on pg 5342, top-right, def 1.2.22<br><br>
If X is a set, characterize it powerset CPO P(X). Which elements of P(X) are compact?<br>	pg 5343, prop 1.2.31 (i)<br>
List the seven axioms of the theory λ.<br>	pg 5345 (right page)
What does it mean for two lambda terms M and N to be <i>convertible</i>?<br>	pg 5345, def 2.1.4
If M and N are lambda terms, what does λ ⊢ M = N mean?<br>	pg 5345, def 2.1.4<br><br>
Consider the following statement:<br><br>In the theory λ, ∀F ∃X FX = X<br><br>Prove or disprove.<br>	true. pg 5346, Fixed Point Theorem.<br>
In lambda calculus, what is a <i>combinator</i>?<br>	pg 5346, def 2.1.7 ii<br>
What does Λ<sup>0</sup> denote?<br>	pg 5346, def 2.1.7 (iii)<br><br><br>
What does <$>\Lambda^0(\vec{x})</$> denote?<br><br>	pg 5346, def 2.1.7<br><br>
If M ∈ Λ, what is a <i>closure</i> of M?<br>	pg 5346, def 2.1.7 (v)<br>
If M and N are lambda terms, what does M ⊂ N mean?<br><br>	pg 5346. def 2.1.8 (i)<br>
Let N<sub>1</sub> and N<sub>2</sub> be subterms of M. What does it mean for N<sub>1</sub> and N<sub>2</sub> to be <i>disjoint</i>?<br>	it means that their syntax does not overlap<br>(λx. x) and x are both subterms of (λx. x), but they are not disjoint.<br>pg 5346 (iii) near top<br>
What is an <i>active</i> subterm of a lambda term?<br>What is a <i>passive</i> subterm of a lambda term?<br>	pg 5346, (iv) near top.<br>
Let M ≡ λx.xy(λz.y). Are the following claims true or false?<br>- xy ⊂ M<br>- z ⊂ M<br>- y(λz.y) ⊂ M<br><br>	t,f,f<br>pg 5346 (r) example (i)<br><br>
Let M ≡ λx.xy(λz.y). Are the following subterms active or passive?<br>- x<br>- y<br>- xy<br>- (λz.y)	active <br>passive<br>active<br>passive<br><br>pg 5346 (r) example iii<br><br>
What is <i>combinatory completeness</i>?<br>	pg 5349, top-right<br>
How are the <b>I</b>, <b>S</b>, and <b>K</b> combinators defined. What are their fundamental equational rules, and how do these rules follow from their definitions.<br>	pg 5349 (right), def 2.1.25, corollary 2.1.26<br>
What is the <i>extensionality</i> equational rule?	def 2.1.27 (right) pg 5349<br>
What is the theory <b>λ + ext</b>?<br>	pg 5349, right, def 2.1.27<br><br>
What is the theory <b>λη</b>?<br>	pg 5350, top-left, def 2.1.28<br>
Let T be a formal theory with equations as formulas. What does it mean for T to be <i>consistent</i>?<br>	pg 5350, top right (ii)<br>
If T is a set of equations, then what is <b>λ + T</b>? What does it mean for T to be consistent?<br><br>	pg 5350, top right, iii<br><br><br>
Consider the following statement:<br><br>The theories <b>λ + ext</b> and <b>λη</b> are equivalent.<br><br>Prove or disprove.<br><br>	true. pg 5350. top left.<br>todo: add impostor?<br>
Consider the following statement:<br><br>The theories λ and λη are consistent.<br><br>Prove or disprove.<br>	note that this requires some future knowledge from chpt 3, <br>see pg 5365 right side (3.2.10 ii)<br>see pg 5367, right side (3.3.11) (ii)<br><br>S and K, for example, are distinct normal forms, and so cannot be proven equal<br><br>pg 5350. def 2.1.31<br><br>
Let M, N ∈ Λ. What does M # N mean?<br>	pg 5350, def 2.1.32<br>
Consider the following statement:<br><br><b>K</b> # <b>S</b><br><br>Prove or disprove.<br>	pg 5350, example 2.1.33<br><br>
What does it mean for a lambda term M to be a β-normal form?<br>	pg 5351, top-left, def 2.1.34 
What does it mean for a lambda term M to <i>have</i> a β-nf?<br>	pg 5351, top-left. def 2.1.34 (ii)
True or false (first desugaring SKI combinators into lambda terms):<br><br>- <b>KI</b> has an nf<br>- <b>SK</b> is an nf<br>- (λx. xx) (λx .xx) has an nf.<br><br>	true<br>false<br>false<br><br>pg 5351, left side, examples 2.1.34<br>
What does it mean for a lambda term M to be a βη-nf?<br>	pg 5351, def 2.1.35<br>
Is (λx. x (λz. xz)) a βη-nf? Does it <i>have a βη-nf?	pg 5351, bottom left, examples 2.1.35<br>
State the two axioms of Curry's combinatory logic CL.<br>	pg 5352, (left, *)<br><br>
Consider the following statment:<br><br>I = S K K<br><br>Prove or disprove.<br>	pg 5352, prop 2.2.1<br>
Suppose x ∉ FV(M)<br><br>Consider the following statement:<br><br>(λx. M) = K M<br><br>Prove or disprove.<br>	pg 5352, prop 2.2.1<br><br>
Consider the following statement:<br><br>(λx . M N) = S (λx. M) (λx. N)<br><br>Prove or disprove.<br>	true. pg 5352, prop 2.2.1<br><br>
Consider the following statement:<br><br>(λx . M N) = K (λx. M) (λx. N)<br><br>Prove or disprove.<br>	IMPOSTOR.<br><br>pg 5352, prop 2.1.1
Translate the lambda term (λx y. y x) into Curry's <b>CL</b>.<br><br><br>	pg 5352 (right, near top)<br>
Provide the definition of the set of λI terms.<br>	pg 5352, bottom right, def 2.2.2 (i)<br><br><br>
Provide the definition of the theory <b>λI</b>.<br>	pg 5352, bottom right, def 2.2.2 (ii)<br><br>
Why did Church think that the λK calculus, unlike the λI calculus, might lead to inconsistencies?<br>	pg 5353, right page, second paragraph.<br>
Consider the following statement:<br><br>Let T = { M = N | M, N ∈ Λ<sub>K</sub> without nf}.<br>Then Con(T)<br><br>Prove or disprove.<br>	IMPOSTOR. pg 5353, prop 2.2.4<br>
What is a sequence of <i>numerals</i> within the lambda calculus?<br>What does it mean for a function f : <b>N</b><sup>k</sup> → <b>N</b> to be <i>λ-definable</i>?<br>	<br>note that the only constraint on numerals is that they must be in nf<br><br>pg 5353, bottom right, def 2.2.5
When one wishes to reason about the λ-definability of partial functions, it is necessary to have a lambda term that represents "undefined". The classic proposal by Church is to use terms without normal form as "undefined". But there are problems with this proposal. What are they?<br>	pg 5354, left page.<br>
Let M ∈ Λ<sup>0</sup>. What does it mean for M to be <i>solvable</i>?<br><br>Let N ∈ Λ. What does it mean for N to be solvable?<br><br>	pg 5354, right page, def 2.2.10 (i), (ii)<br><br><br>
Consider the following statement:<br><br>The term "x <b>I</b> <b>Ω</b>" is K-solvable.<br><br>Prove or disprove.<br><br><br>	true. pg 5354, right page, examples below def 2.2.10<br>
What does it mean for a lambda term to be a <i>head normal form</i>? What does it mean for a lambda term to <i>have</i> a head normal form?<br>	pg 5354, bottom right, definition 2.2.11<br>
Does (λx. <b>I</b> x <b>Ω</b>) have a nf? Does it have an hnf?<br>	pg 5354, bottom right example.<br>
Explain the difference between Church's thesis and Church's superthesis.<br>	pg 5355, top right<br><br>
Let X and Y be topological spaces. Let p : X → Y be a surjective map. What does it mean for the map p to be a <i>quotient</i> map?<br><br>How is the notion of quotient maps different from the notion of continuous maps?<br>	pg 4415, definition near top<br>
Let p : X → Y be a surjective map on topological spaces X and Y. Suppose that we formulate the definition of quotient map in the following way:<br><br>p is a quotient map means:<br>A subset A of Y is closed in Y if and only if p<sup>-1</sup>(A) is closed in X.<br><br>Is this equivalent to the standard definition of quotient map? Why or why not?<br><br>	pg 4415<br>
Let p : X → Y be a surjective map on topological spaces X and Y. What does it mean for a subset C of X to be <i>saturated</i> with respect to p?<br><br>Why is the notion of a saturated set important?<br>	pg 4415 (it can be used for an equivalent formulation of the definition of quotient map)<br>
List and name two special kinds of quotient maps, and provide their definitions.<br>	Open maps and closed maps, <br>pg 4415, paragraph above example 1.<br>
Let X be the subspace [0,1] ∪ [2,3] of <b>R</b>, and let Y be the subspace [0,2] of <b>R</b>. Consider the map p : X → Y defined by<br>p(x) = x      for x ∈ [0,1]<br>p(x) = x-1   for x ∈ [2,3]<br><br>Is p a quotient map? Is it an open map? A closed map?<br>	pg 4415. example 1, near bottom.<br><br><br><br>
Let X be the subspace [0,1) ∪ [2,3] of <b>R</b>, and let Y be the subspace [0,2] of <b>R</b>. Consider the map p : X → Y defined by<br>p(x) = x      for x ∈ [0,1)<br>p(x) = x-1   for x ∈ [2,3]<br><br>Is p a quotient map? Is it an open map? A closed map?<br>	IMPOSTOR. pg 4415, example 1 near bottom<br>
Let π<sub>1</sub> : <b>R</b> × <b>R</b> be a projection onto the first coordinate. Is π<sub>1</sub> a quotient map? Why or why not?<br>	pg 4416, example 2, near top<br>
If X is a space, A is a set, and p : X → A is a surjective map, then what is the <i>quotient topology</i> on A induced by p?<br>	pg 4416, definition<br>
Let p be the map of the real line <b>R</b> onto the three-point set A = {a,b,c} defined by<br><br>p(x) = a   if x > 0<br>p(x) = b   if x < 0<br>p(x) = c   if x = 0<br><br>What is the quotient topology on {a,b,c} induced by p?<br>	pg 4416, example 3 near bottom<br>
Let X be a topological space and let X* be a partition of X into disjoint subsets whose union is X. What is the <i>quotient space</i> induced by X*?<br>	pg 4417, definition, top of page.<br>
If X* is a partition of a topological space X, one way think of the topology X* is that a subset U of X* is a collection of equivalence classes, and the set p<sup>-1</sup>(U) is the union of the equivalence classes belonging to U.<br><br>What does this tell us about an open set of X*?<br><br>	pg 4417, second paragraph below definition.<br>
Let X be the closed unit ball {x × y | x<sup>2</sup> + y<sup>2</sup> ≤ 1} in <b>R</b><sup>2</sup>, and let X* be the partition of X consisting of all the one-point sets {x × y} for which x<sup>2</sup> + y<sup>2</sup> < 1, along with the set S<sup>1</sup> = {x × y | x<sup>2</sup> + y<sup>2</sup> = 1}.<br><br>Describe a typical saturated open set in X. Describe the quotient topology X*.<br><br>	pg 4417, example 4<br>
Let X be the rectangle [0, 1] × [0, 1]. Define a partition X* of X as follows:<br><br>It consists of all the one-point sets {x × y}, where 0 < x < 1 and 0 < y < 1, the following two-point sets:<br>{x × 0, x × 1}  where 0 < x < 1<br>{0 × y, 1 × y}  where 0 < y < 1<br><br>and the four-point set<br><br>{0 × 0, 0 × 1, 1 × 0, 1 × 1}<br><br>Describe a typical saturated open set in X.	pg 4417, example 5, near bottom, see next page as well<br>
What does it mean for a binary relation R on Λ to be <i>compatible</i>?<br>	pg 5359, def 3.1.1 (i)<br>
What is an <i>equality relation</i> on Λ?<br>	pg 5359, def 3.1.1 (ii)<br>
What is a <i>reduction relation</i> on Λ?<br>	pg 5359, def 3.1.1 (iii)
What is a <i>notion of reduction</i> on Λ?<br>	pg 5359, def 3.1.2<br>
If R<sub>1</sub> and R<sub>2</sub> are notions of reduction on Λ, what is R<sub>1</sub>R<sub>1</sub>?	pg 5359, def 3.1.2 (ii)<br>
Define the notion of reduction β.<br>	pg 5359, right page, def 3.1.3
Let R be a notion of reduction on Λ.<br>Then provide the definitions of:<br>→<sub>R</sub><br>↠<sub>R</sub><br>and =<sub>R</sub><br><br><br>	pg 5359, right side, def 3.1.5<br>
Consider the following statement:<br><br>The relations →<sub>R</sub>, ↠<sub>R</sub>, and =<sub>R</sub> are all compatible. Therefore ↠<sub>R</sub> is a reduction relation and =<sub>R</sub> is an equality relation.<br><br>Prove or disprove. You need to prove (or disprove) that they are compatible, which is the hard part: you don't just get to assume this.<br>	true. pg 5360, lemma 3.1.6, top left side
Let R be a notion of reduction. What is an <i>R-redex</i>? If M is a term, what is an <i>R-contractum</i> of M?	pg 5360, right, def 3.1.8.<br><br><br>
If R is a notion of reduction and M is a term, what does it mean for M to be an <i>R-normal form</i>?<br>	pg 5360, right page, def 3.1.8 (ii)<br>
If R is a notion of reduction and N and M are terms, what does it mean for N to be an <i>R-nf of M</i>?	pg 5360<br>
Let M be an R-nf. Consider the following statement:<br><br>For no N one has M →<sub>R</sub> N<br><br>Prove or disprove.<br>	pg 5360
Let M be an R-nf. Consider the following statement:<br><br>M ↠<sub>R</sub> N ⇒ M ≡ N<br><br>Prove or disprove.	pg 5360, right side, corollary 3.1.10 (ii)
Let ⤚ be a binary relation on Λ. What does it mean for ⤚ to have the diamond property?<br>	pg 5360, bottom right page, def 3.1.11<br>
What does it mean for a notion of reduction R to be <i>Church-Rosser (CR)</i>?	pg 5361, top left page<br>
Let R be CR. Consider the following statement:<br><br>M =<sub>R</sub> N ⇒ ∃Z. [M ↠<sub>R</sub> Z ∧ N ↠<sub>R</sub> Z]<br><br>Prove or disprove.<br>	true. pg 5361 thm 3.1.12, top left.<br>todo: add impostor?<br><br>
Let R be CR. Then consider the following statement:<br><br>If N is an R-nf of M, then M ↠<sub>R</sub> N.<br><br>Prove or disprove.	true. pg 5361, left page, corollary 3.1.13<br>R-nf is defined on pg 5360, right page, def 3.1.8 (iii)<br><br>Todo: add impostor?<br>
Let R be CR. Then consider the following statement:<br><br>A term M can have at most one R-nf.<br><br>Prove or disprove.<br><br>	true. pg 5361, corollary 3.1.13 (ii)<br><br>todo: add impostor?<br>
What does it mean for a binary relation to be <i>substitutive</i>?<br>	pg 5361, right page, def 3.1.14<br>
Consider the following statement:<br><br>β is substitutive<br><br>Prove or disprove.<br>	true. pg 5361, right page, prop 3.1.16<br>
Let Δ be a subterm occurrence of M, that is M ≡ C[Δ].<br><br>What does <$>M \overset{\Delta}{\rightarrow}_R N</$> mean?<br>	pg 5361, right side, def 3.1.17 (i)<br><br>
What is an <i>R-reduction</i>?<br>	pg  5361, right side, def 3.1.17 (ii)<br>ALSO: read the conventions below and on the next page<br><br>
If σ and τ are reduction paths, then what does σ+τ denote?<br>	pg 5362, top-left (v)<br>
If Δ is an R-redex occurence in M with contractum Δ', then what does (Δ) denote?<br>	pg 5362, top left (vi)<br>
If R is a notion of reduction and M is a term, what does G<sub>R</sub>(M) denote?<br>	pg 5362, bottom left, def 3.1.20<br>
Draw G<sub>β</sub>(<b>I</b>x).<br>Draw G<sub>β</sub>(<b>I</b>(<b>I</b>x))<br>	pg 5362, top-right, examples 3.1.21 (i), (ii)<br>
Draw G<sub>β</sub>(Ω).<br>Draw G<sub>β</sub>(<b>WWW</b>) where <b>W</b> ≡ (λxy. xyy).<br><br><br>	pg 5362, top-right, examples 3.1.21, (iii), (iv)<br>
Draw G<sub>β</sub>(MM) where M ≡ λx.(λy. yy)x<br>Draw G<sub>β</sub>(ω<sub>3</sub>ω<sub>3</sub>) where ω<sub>3</sub> ≡ λx. xxx<br><br><br>	pg 5362, top-right, examples 3.1.21 (v), (vi)<br>
Let M ∈ Λ. What does R-SN(M) mean?<br>	pg 5362, right side, def 3.1.22 (i)<br>
Let M ∈ Λ. What does R-∞(M) mean?<br>	pg 5362, right side, def 3.1.22 (ii)<br>
Let R be a notion of reduction. What does it mean for R to be <i>strongly normalizing</i>?<br>	pg 5362, right side, def 3.1.22 (iii)<br>
Consider the following statement:<br><br>M having a β-nf neither implies nor is implied by G<sub>β</sub>(M) being finite.<br><br>Prove or disprove.<br>	true. pg 5362, bottom right, fact 3.1.23 (i)<br>TODO: add impostor!<br>
Consider the following statement:<br><br>β-SN(M) implies G<sub>β</sub>(M) is finite and M has a β-nf, but not conversely.<br><br>Prove or disprove.	true. pg 5362, bottom right, fact 3.1.22 (ii)<br>todo: ADD IMPOSTOR!<br>
What does it mean for a binary relation ⤚ to satisfy the <i>weak diamond property</i>?<br>	pg 5363, left side, def 3.1.24 (i)<br>
What does it mean for a notion of reduction R to be <i>weakly Church-Rosser</i>?	pg 5363, left side, def 3.1.24 (ii)<br>
Consider the following statement:<br><br>For notions of reduction, one has SN ∧ WCR ⇒ CR.<br><br>Prove or disprove.<br>	true. pg 5363, bottom left, prop 3.1.25<br>
Let M ∈ ∧<sup>0</sup>. What does it mean for M to be <i>R-solvable</i>?<br>	pg 5363, top right, def 3.1.27 (i)<br>
Let M ∈ ∧. What does it mean for M to be <i>R-solvable</i>?	pg 5363, top right, def 3.1.27 (ii)<br>
Consider the following statement:<br><br>Right adjoints preserve limits.<br><br>Prove or disprove.<br>	true. this can be remembered with the mnemonic RAPL.<br><br>pg 2881, prop 9.14<br><br>
Show that <$>(\colimit{i}{X_i}) \times A \cong \colimit{i}{(X_i \times A)}</$><br>	pg 2882<br>
Show that in the propositional caclulus (or any Heyting algebra)<br><$>p \Rightarrow (a \wedge b) \dashv \vdash (p \Rightarrow a) \wedge (p \Rightarrow b)</$><br>	pg 2882
Show that in any Heyting algebra, <$>(a \vee b) \wedge p \dashv \vdash (a \wedge p) \vee (b \wedge p)</$>	pg 2882<br>
Explain why "∃x" cannot be a right adjoint in the category of first-order propositions.<br>	pg 2882, near bottom<br><br>
Consider the following statement:<br><br>For any locally small category <b>C</b>, the functor category <b>Sets<sup>C<sup>op</sup></sup></b> is complete. Moreover, for every object C ∈ <b>C</b>, the evaluation functor ev<sub>C</sub> : <b>Sets<sup>C<sup>op</sup></sup> → Sets</b> preserves all limits.<br><br>Prove or disprove.<br>	pg 2851, prop 8.7<br>
Consider the following statement:<br><br>Given any categories <b>C</b> and <b>D</b>, if <b>D</b> is cocomplete, then so is the functor category <b>D<sup>C</sup></b>, and the colimits in <b>D</sup>C</sup></b> are "computed pointwise"," in the sense that for every C ∈ <b>C</b>, the evaluation functor ev<sub>C</sub> : <b>D<sup>C</sup></b> → <b>D</b> preserves colimits. Thus, for any small index category J and functor A : J → <b>D<sup>C</sup></b>, for each C ∈ <b>C</b> there is a canonical isomorphism,<br><br><$$>(\colimit{j \in J}{A_j})(C) \cong \colimit{j \in J}{A_j C}</$$><br><br>Prove or disprove.<br>	true. pg 2851, prop 8.8.<br>TODO: add impostor<br>
Consider the following statement:<br><br>For any locall small <b>C</b>, the functor category <b>Sets<sup>C<sup>op</sup></sup> is cocomplete, and colimits there are computed pointwise.<br><br>Prove or disprove.<br>	true. pg 2852, corollary 8.9.<br>todo: add impostor.<br>
Consider the following statement:<br><br>For any small category <b>C</b>, every object P in the functor category <b>Sets<sup>C<sup>op</sup></sup></b> is a colimit of representable functors,<br><br><$$>\colimit{j \in J}{yC_j} \cong P</$$><br><br>More precisely, there is a canonical choice of an index category J and a functor π : J → <b>C</b> such that there is a natural isomorphism <$>\colimit{J}{(y \circ \pi)} \cong P</$>.<br><br>Prove or disprove.	pg 2852, prop 8.10.<br>
Let <b>C</b> be a small category and P an object in the functor category <b>Sets<sup>C<sup>op</sup></sup></b>, provide the definition for the category<br><br><$$>\int_C P</$$>	pg 2852, in proof of proposition 8.10<br>
Consider the following statement:<br><br>(M =<sub>β</sub> N) ⇔ (λ ⊢ M = N)<br><br>Prove or disprove.	true. pg 5363, right, prop 3.2.1<br>todo: add impostor?<br>
Let ⤚ be a binary relation on a set and let ⤚<sup>*</sup> be its transitive closure. <br><br>Consider the following statement:<br><br>(⤚ ⊨ ⋄) ⇒ (⤚<sup>*</sup> ⊨ ⋄) <br><br>Prove or disprove.<br>	true. pg 5363, bottom right, lemma 3.2.2<br>
How do we go about proving that β is CR?<br>	Several lemmas spread across pg 5363-5365 lay out the strategy.<br>pg 5363-5365<br>
Consider the following statement:<br><br>A term M may have multiple β-nf's.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 5365, corollary 3.2.9 (corollary 3.1.13 is on pg 5361)<br>
Define a binary relation <$>\underset{I}{\twoheadrightarrow}</$> as follows:<br><br><$><br>\newcommand{\redi}{\underset{I}{\twoheadrightarrow}}<br>M \redi M; \\\\<br>M \redi M' \Rightarrow (\lambda x. M) \redi (\lambda x. M'); \\\\<br>M \redi M', N \redi N' \Rightarrow M N \redi M' N';\\\\<br>M \redi M', N \redi N' \Rightarrow (\lambda x. M) N \redi M'[x := N']<br></$><br><br>Consider the following statement:<br><br><$><br>\newcommand{\redi}{\underset{I}{\twoheadrightarrow}}<br>\text{If } M \redi M' \text{ and } N \redi N' \text{, then } M[x := N] \redi M'[x := N']</$><br><br>Prove or disprove.	true. pg 5364, left side, lemma 3.2.4<br>
Define a binary relation <$>\underset{I}{\twoheadrightarrow}</$> as follows:<br><br><$><br>\newcommand{\redi}{\underset{I}{\twoheadrightarrow}}<br>M \redi M; \\\\<br>M \redi M' \Rightarrow (\lambda x. M) \redi (\lambda x. M'); \\\\<br>M \redi M', N \redi N' \Rightarrow M N \redi M' N';\\\\<br>M \redi M', N \redi N' \Rightarrow (\lambda x. M) N \redi M'[x := N']<br></$><br><br>Consider the following statement:<br><br><$><br>\newcommand{\redi}{\underset{I}{\twoheadrightarrow}}<br>\twoheadrightarrow_\beta \text{ is the transitive closure of } \redi.<br></$><br><br>Prove or disprove.	true. pg 5365, lemma 3.2.7<br>
Consider the following statement:<br><br>M =<sub>β</sub> N ⇒ ∃Z. [M ↠<sub>β</sub> Z ∧ N ↠<sub>β</sub> Z]<br><br>Prove or disprove.	true. pg 5365, thm 3.2.8.<br>todo: add impostor?<br><br>
Consider the following statement.<br><br>Let M,N ∈ β-NF be distinct. Then M ≠<sub>β</sub> N.<br><br>Prove or disprove.	true. pg 5365, top right side, thm 3.2.10.<br>
Consider the following statement:<br><br>The theory λ is consistent.<br><br>Prove or disprove.<br>	pg 5365, top-right, thm 3.2.10 (ii)<br>
Define the notion of reduction <b>η</b>, as well as <b>βη</b>.<br>What is the point of βη-reduction?<br>	pg 5365, bottom right, def 3.3.1<br>"The point of βη-reduction is that it axiomatizes provable equality in the extensional λ-calculus and it is CR."<br>
Consider the following statement:<br><br>(M =<sub>βη</sub> N) ⇔ (λη ⊢ M = N) ⇔ (λ + ext ⊢ M = N)<br><br>Prove or disprove.<br>	pg 5365, bottom right, prop 3.3.2<br><br>TODO: add impostor?<br><br><br>
Let ⤚<sub>1</sub> and ⤚<sub>2</sub> be two binary relations on a set X. What does it mean for ⤚<sub>1</sub> and ⤚<sub>2</sub> to <i>commute</i>?<br>	pg 5366, left page, def 3.3.4<br><br>
Let ⤚<sub>1</sub> and ⤚<sub>2</sub> be two binary relations on a set X. Suppose<br><br>(1) ⤚<sub>1</sub> ⊨ ⋄, ⤚<sub>2</sub> ⊨ ⋄.<br>(2) ⤚<sub>1</sub> commutes with ⤚<sub>2</sub><br><br>Consider the following statement:<br><br>(⤚<sub>1</sub> ∪ ⤚<sub>2</sub>)* ⊨ ⋄.<br><br>Prove or disprove.<br>	true. pg 5366, bottom left page, prop 3.3.5 (i)<br>todo: add impostor?<br>
Let <b>R<sub>1</sub></b>, <b>R<sub>2</sub></b> be two notions of reduction. Suppose<br><br>(1) <b>R<sub>1</sub></b>, <b>R<sub>2<sub></b> are CR.<br>(2)  ↠<sub>R<sub>1</sub></sub> commutes with ↠<sub>R<sub>2</sub></sub><br><br>Consider the following statement.<br><br><b>R<sub>1</sub></b><b>R<sub>2<sub></b> is CR.<br><br>Prove or disprove.	true. pg 5366. bottom left page, prop 3.3.5 (ii)<br><br>
Prove lemma 3.3.6 on the top right of page 5366<br><br>note that the diagram is a bit shoddy, but the proof of lemma 3.3.8 shows<br>a concrete instantiation of this lemma, which verifies what you probably<br>expected: the bottom-right half of the the square should have dashed ("exists") lines, and the omission of * from the bottom relation is intentional and correct)<br><br>	pg 5366<br>
Consider the following statement: <br><br><b>η</b> is CR.<br><br>Prove or disprove.<br><br><br><br>	true. pg 5366, right page, lemma 3.3.7<br>
Consider the following statement:<br><br>↠<sub>β</sub> commutes with ↠<sub>η</sub><br><br>Prove or disprove.	true. pg 5367, top-left, lemma 3.3.8<br><br>todo: add impostor?<br>
Consider the following statement:<br><br>The notion of reduction <b>βη</b> is CR.<br><br>Prove or disprove.<br>	true. pg 5367, bottom left page<br>todo: add impostor?<br><br>
Consider the following statement:<br><br>M =<sub>βη</sub> N ⇒ ∃Z. [M ↠<sub>βη</sub> Z ∧ N ↠<sub>βη</sub> Z]<br><br>Prove or disprove.<br>	pg 5367, thm 3.3.9 (ii)<br>todo: add impostor?<br><br><br>
Consider the following statement:<br><br>Each M has at most one βη-nf.<br><br>Prove or disprove.<br>	true. pg 5367, right side, corollary 3.3.10 (ii)<br>todo: add impostor?<br>
Consider the following statement:<br><br>The theory λ + ext is consistent.<br><br>Prove or disprove.<br>	true. pg 5367.<br>todo: add impostor?<br>
Explain the information ordering intuition behind the Scott topology.<br>	NOTE: Carl Mummert's answer is okay, but I think the second to last paragraph is extremely confusing. I wouldn't bother reading that paragraph.<br><br>pg 5628<br>
If T is a set of closed equations, then what does T<sup>+</sup> denote?<br>	pg 5372, left, def 4.1.1
If T is a set of closed equations, what does it mean for T to be a λ-theory?<br>	pg 5372, left, def 4.1.1<br><br>
Let T be a set of closed equations. Consider the following statement:<br><br><$$>Con(T) \Leftrightarrow \lambda + T \not \vdash \mathbf{T} = \mathbf{F}</$$><br><br>Prove or disprove.<br>	true. pg 5372. left. remark 4.1.2 (iii)<br><br>hint: If T = F, and M and N are arbitrary lambda terms, then T M N = F M N.<br>
What can be said about the relation between the closed and open equations provable in a λ-theory T?<br>	Because of the ξ rule, equations between open terms are provable iff the corresponding equation between their closures is provable.<br><br>pg 5372, left, remarks 4.1.2<br>ξ rule is given on pg 5345, bottom right<br><br><br><br>
Let T be a λ-theory and C a context. Consider the following statement:<br><br><$$>T \vdash M = M' \Rightarrow T \vdash C[M] = C[M']</$$><br><br>Prove or disprove.<br>	true. pg 5372, left, prop 4.1.3 (i)<br>todo: add impostor?<br>
Let T be a λ-theory. Consider the following statement:<br><br><$$>T \vdash M = M', T \vdash N = N' \Rightarrow T \vdash M[x := N] = M'[x := N']</$$><br><br>Prove or disprove.<br>	<$>M[x := N]</$><br><$>= (\lambda x. M) N</$><br><$>= (\lambda x. M) N' \text{(by prop 4.1.3 (i))}</$><br><$>= (\lambda x. M') N' \text{(again by 4.1.3 (i))}</$><br><$>= M'[x := N']</$><br><br>pg 5372, bottom left/top right, prop 4.1.3 (ii)<br>
Let T be a λ-theory. <br><br>What does <$>T \vdash M = N</$> mean? What does <$>M =_T N</$> mean?<br><br>What does T + (M = N) stand for?<br><br>What does Tη stand for?<br>	pg 5372, top right, notation 4.1.4 (i) (ii) (iii)<br>
Let T be a λ-theory and X a set of terms.<br><br>What does it mean for T to be <i>axiomatized by T<sub>0</sub></i>?<br><br>What does x ∈<sub>T</sub> M mean?<br><br>What does M ∈<sub>T</sub> X mean?<br><br>What lambda term does the combinator <b>1</b> denote?<br><br><br><br>	pg 5372, top right, notation 4.1.4<br>
Consider the following statement:<br><br>For a λ-theory T one has Tη = T + (<b>I</b> = <b>1</b>).<br><br>Prove or disprove.<br>	true. pg 5372 right, lemma 4.1.5<br>todo: add impostor?<br>
Let T be a λ-theory. What does it mean for T to be <i>sensible</i>? What does it mean for T to be <i>semi-sensible</i>?	pg 5372, bottom right, def 4.1.7<br>
Consider the following statement:<br><br>Let <b>K<sup>∞</sup></b> be a fixed point of <b>K</b>. Then <b>I</b> # <b>K<sup>∞</sup></b>.<br><br>Prove or disprove.<br>	true. pg 5373, left, lemma 4.1.8<br>
Consider the following statement:<br><br>T is sensible ⇒ T is semi sensible<br><br>Prove or disprove.<br>	true. pg 5373, corollary 4.1.9.<br><br>my own approach has the same underlying idea, but IMHO is more straightforward to understand.<br><br>If a solvable term M is equated to an unsolvable term, it is equated to all unsolvable terms by sensibility and transitivity. K<sup>∞</sup> is unsolvable, and so M = K<sup>∞</sup>. But by compatibility, <br><br><$>I = M~\vec{P} = K^\infty~\vec{P} = K^\infty</$><br><br>We know that I # K<sup>∞</sup>, so we have derived a contradiction. <br><br>--<br>for their approach, in case you care, here is a hint:<br>hint: in case you didn't notice, the basic structure of the proof is to first assume that T is sensible, and show that T must be semi sensible by contradiction. Note that if T is sensible then any two unsolvable terms are provable in T, and so <$>T \vdash N\vec{P} = \mathbf{K^\infty}</$><br><br>todo: add impostor?
State the ω-rule.<br>	pg 5373, bottom left, 4.1.10<br>
Give the <i>term rule</i> tr.<br>	pg 5373, right page, very top
Let T be a λ-theory and <b>R</b> a rule.  What does the notation T ⊢ <b>R</b> mean?	pg 5373, right page, def 1.11 (i) (ii)
What does it mean for a λ-theory to be <i>extensional</i>?<br>	pg 5373, right page, def 4.1.11 (iii)<br>
Let T be a λ-theory. Consider the following statement:<br><br>T ⊢ ω ⇔ (T ⊢ <b>tr</b> and T ⊢ <b>ext</b>)<br><br>Prove or disprove.<br>	true. pg 5373, right page, lemma 4.1.12 (i)<br>todo: add impostor?<br><br>
Let T be a λ-theory. Consider the following statement:<br><br>T ⊢ <b>ext</b> ⇔ T ⊢ <b>I</b>=<b>1</b> ⇔ T ⊢ T<b>η</b><br><br>Prove or disprove.<br>	true. pg 5373, right page, lemma 4.1.12 (ii)<br>todo: add impostor?<br>
If T is a λ-theory and <b>R</b> is a rule, what does the notation T + <b>R</b> mean?<br>	pg 5373, bottom right, notation 4.1.13<br>
Let <b>R</b> be a rule. What does <b>R<sup>0</sup></b> denote?	pg 5347, top left, def 4.1.14
Let T be a λ-theory. Consider the following statement:<br><br>T ⊢ <b>ω<sup>0</sup></b> ⇔ T ⊢ <b>ω</b><br><br>Prove or disprove.<br>	true. pg 5374, left page, prop 4.1.15 (i)<br>todo: add impostor?<br><br><br>
Let T be a λ-theory. Consider the following statement:<br><br>T ⊢ <b>tr<sup>0</sup></b> ⇔ T ⊢ <b>tr</b><br><br>Prove or disprove.<br>	true. pg 5374, left page, prop 4.1.15 (ii)<br>todo: add impostor?<br>
What is a <i>combinatory algebra</i>?<br>	pg 5374, bottom left, def 4.1.16 (i)<br><br>note that this is an <i>algebraic</i> structure.<br>· : X × X → X<br>k : X × X → X<br>s : X × X × X → X<br>
What does it mean for for a combinatory algebra to be <i>extensional</i>?	pg 5374, left page, def 4.1.16<br><br>Showing the cdots explicitly might make this more clear:<br>(∀x. a·x = b·x) → a = b<br><br>
Let <$>\frak T</$> be a λ-theory. What does <$>\frak M(\frak T)</$> denote?<br><br>	pg 5374, bottom left, def 4.1.17 (i)<br>the definition of · and other things on the top of the right-hand page.<br>
Let T be a λ-theory. What is the <i>closed term model <$>\frak M^0(T)</$>?<br>	pg 5374, top-right, (ii)<br>
Let T be a λ-theory. Consider the following statement:<br><br>M(T) and M<sup>0</sup>(T) are combinatory algebras.<br><br>Prove or disprove.<br>	true. pg 5374, right page, prop 4.1.18 (i)<br>todo: add impostor?<br>
Let T be a λ-theory. Consider the following statement:<br><br>T ⊢ <b>ext</b> ⇔ M(T) is extensional<br><br>Prove or disprove.<br>	true. pg 5374, prop 4.1.18 (ii)<br>TODO: add impostor?<br>
Let T be a λ-theory. Consider the following statement:<br><br>T ⊢ <b>ω</b> ⇔ M<sup>0</sup>(T) is extensional<br><br>Prove or disprove.<br>	true. pg 5374, right page, prop 4.1.18 (iii)<br>todo: add impostor?<br>
Let T be a λ-theory. How is the <i>canonical map<i> φ<sub>T</sub> defined?<br>	pg 5375, left page, def 4.1.19 (i)<br><br>
Let T<sub>1</sub> and T<sub>2</sub> be λ-theories with T<sub>1</sub> ⊆ T<sub>2</sub>. How is the canonical map φ<sub>T<sub>1</sub>T<sub>2</sub></sub> defined?<br><br>	pg 5375, left page, def 4.1.19 (ii)<br>
Let T be a λ-theory. <br><br>How is φ<sup>0</sup><sub>T</sub> defined?<br><br>	pg 5375, left page, def 4.1.19 (iii)<br>
Let T<sub>1</sub> and T<sub>2</sub> be λ-theories with T<sub>1</sub> ⊆ T<sub>2</sub>. Draw a commutative diagram involving the canonical maps <br><$$>\varphi^{0}_{T_1}, \varphi^{0}_{T_2},\text{ and }\varphi^{0}_{T_1 T_2}</$$><br><br>argue that this commutativity actually holds	<br>pg 5375, left page, lemma 4.1.20<br>
What does it mean for an equational theory T to be <i>HP-complete</i>?<br>	pg 5375, right page, def 4.1.22<br>
What is an <i>applicative structure</i>? What does it mean for an applicative structure to be <i>extensional</i>?<br><br>	pg 5378, top-left, def 5.1.1<br><br>
Let 𝔐 be an applicative structure. How do we define the set of <i>terms over</i> 𝔐?  	pg 5378, left, def 5.1.2<br>
If 𝔐 is an applicative structure, what is a <i>valuation in</i> 𝔐?  	pg 5378, left page, def 5.1.2 (ii)<br> 
If ρ is a valuation in 𝔐 and A is a term over M, then what does <$>(A)^{\frak M}_\rho</$> denote?<br> 	pg 5378, left page, def 5.1.2 (ii)<br>
What does 𝔐,ρ ⊨ A = B mean? What about 𝔐 ⊨ A = B?<br>  	pg 5378, left page, def 5.1.2 (iii) (iv)<br>
If A is a term in an applicative structure and ρ is a valuation on that structure, when can the notation (A) be used in place of (A)<sub>ρ</sub>?	pg 5378, bottom left paragraph, above def 5.1.3<br> 
What does it mean for an applicative structure to be <i>combinatory complete</i>?<br>	pg 5378, bottom left, def 5.1.3<br>
What does <$>\rho(x ::= a)</$> denote? <$>\rho(\vec{x} ::= \vec{a})</$>?<br><br>	pg 5378, right, notation 5.1.4
Let 𝔐 be an applicative structure and A,B ∈ T(𝔐). Consider the following statement:<br><br>(A[x := B])<sub>ρ</sub> = (A)<sub>ρ(x := (B)<sub>ρ</sub>)</sub><br><br>Prove or disprove.<br>  	true. pg 5378, right page, lemma 5.1.5 (i)<br>todo: add impostor?
Let 𝔐 be an applicative structure and A,A',B,B' ∈ T(𝔐). Consider the following statement:<br><br><$$>\frak M \vDash A = A' \wedge B = B'~~\Rightarrow~~\frak M \vDash A[x := B] = A'[x := B']</$$><br><br>Prove or disprove.<br>  	true. pg 5378, right page, lemma 4.1.5 (ii)<br>todo: add impostor?<br>
Let  𝔐 = (X,·) be an applicative structure and let φ : X<sup>n</sup> → X be a map.<br>What does it mean for φ to be <i>representable</i> over 𝔐?<br>  	pg 5378, bottom right page, def 5.1.6 (i)<br>
Let  𝔐 = (X,·) be an applicative structure and let φ : X<sup>n</sup> → X be a map.<br>What does it mean for φ to be <i>algebraic</i> over 𝔐?<br>  	pg 5378, bottom right page, def 5.1.6 (ii)<br>
What is a <i>combinatory algebra</i>?<br>	pg 5379, left page, def 5.1.7<br>
What does combinatory completeness of an applicative structure tell us about the relation between its representable functions and its algebraic functions?<br>	pg 5379, top left paragraph, above def 5.1.7
Let 𝔐 be a combinatory algebra, let T(𝔐) be the terms of 𝔐, extended with the constants <b>K</b> and <b>S</b>, corresponding the elements k and s of 𝔐. Moreover, define <b>I</b>=<b>SKK</b>.<br><br>For A ∈ T(𝔐), define (λ*x.A) ∈ T(𝔐) as follows: <br>(λ*x. x) = <b>I</b><br>(λ*x. P) = <b>K</b>P,   if P does not contain x<br>(λ*x. P Q) = <b>S</b> (λ*x. P) (λ*x. Q)<br><br>Consider the following statement:<br><br>FV(λ*x.A) = FV(A) - {x}<br><br>Prove or disprove.<br><br><br> <br>            	true. pg 5379, left prop 5.1.9 (i)<br>
Let 𝔐 be a combinatory algebra, let T(𝔐) be the terms of 𝔐, extended with the constants <b>K</b> and <b>S</b>, corresponding the elements k and s of 𝔐. Moreover, define <b>I</b>=<b>SKK</b>.<br><br>For A ∈ T(𝔐), define (λ*x.A) ∈ T(𝔐) as follows: <br>(λ*x. x) = <b>I</b><br>(λ*x. P) = <b>K</b>P,   if P does not contain x<br>(λ*x. P Q) = <b>S</b> (λ*x. P) (λ*x. Q)<br><br>Consider the following statement:<br><br>(λ*x.A) x = A, in every combinatory algebra<br><br>Prove or disprove.<br><br>            	true. pg 5379, left page, prop 5.1.9 (ii)<br>todo: add impostor?<br>
Let 𝔐 be a combinatory algebra, let T(𝔐) be the terms of 𝔐, extended with the constants <b>K</b> and <b>S</b>, corresponding the elements k and s of 𝔐. Moreover, define <b>I</b>=<b>SKK</b>.<br><br>For A ∈ T(𝔐), define (λ*x.A) ∈ T(𝔐) as follows: <br>(λ*x. x) = <b>I</b><br>(λ*x. P) = <b>K</b>P,   if P does not contain x<br>(λ*x. P Q) = <b>S</b> (λ*x. P) (λ*x. Q)<br><br> If <$>\vec{x} = x_1, ..., x_n</$> then define <$>\lambda^* \vec{x}. A \doteq (\lambda^* x_1 \cdots (\lambda^* x_n. A) \cdots )</$>.<br><br>Consider the following statement:<br><br><$>(\lambda^*\vec{x}.A) \vec{x} = A</$>, in every combinatory algebra<br><br>Prove or disprove.<br><br>      	true. pg 5379, left page, prop 5.1.9 (iii)<br>
Let 𝔐<sub>i</sub> = (X<sub>i</sub>, ·<sub>i</sub>, k<sub>i</sub>, s<sub>i</sub>), i=1,2, be two combinatory algebras. Then what does it mean for φ : X<sub>1</sub> → X<sub>2</sub> to be a <i>homomorphism</i>? 	pg 5379, bottom left & top right, def 5.1.12 (i)<br>
Let 𝔐<sub>i</sub> = (X<sub>i</sub>, ·<sub>i</sub>, k<sub>i</sub>, s<sub>i</sub>), i=1,2, be two combinatory algebras. What does the notation 𝔐<sub>1</sub> → 𝔐<sub>2</sub> mean?   	<br>pg 5379, top right, (ii)<br><br>φ : 𝔐<sub>1</sub> → 𝔐<sub>2</sub> means that φ is a homomorphism between these structures.<br>  
Let 𝔐<sub>i</sub> = (X<sub>i</sub>, ·<sub>i</sub>, k<sub>i</sub>, s<sub>i</sub>), i=1,2, be two combinatory algebras. What does it mean for 𝔐<sub>1</sub> to be <i>embeddable</i> in 𝔐<sub>2</sub>? What does it mean for 𝔐<sub>1</sub> to be a <i>substructure</i> of 𝔐<sub>2</sub>? What does it mean for 𝔐<sub>1</sub> to be <i>isomorphic</i> to 𝔐<sub>2</sub>?       	pg 5379, top-right, (iii) (iv) (v)<br>
What do 𝓒 and 𝓒<sup>0</sup> denote?<br>  	pg 5379, right page, def 5.1.13<br>
Let 𝔐 be a combinatory algebra. What does Th(𝔐) denote?<br>  	pg 5379, def 5.1.13 (ii)
Let φ : 𝔐<sub>1</sub> → 𝔐<sub>2</sub>. Consider the following statement:<br><br>For P, Q ∈ T(𝔐<sub>1</sub>)<br><$$>\varphi(\sem{P}^{\frak M_1}_\rho) = \sem{\varphi(P)}^{\frak M_2}_{\varphi \circ \rho}</$$><br><br>where φ(P) results from P by replacing the constants c<sub>a</sub> by c<sub>φ(a)</sub>.<br><br>Prove or disprove.      	true. pg 5379, prop 5.1.14 (i)<br>todo: add impostor?<br>
Let φ : 𝔐<sub>1</sub> → 𝔐<sub>2</sub>. Consider the following statement:<br><br>𝔐<sub>1</sub> ⊨ P = Q   ⇒   𝔐<sub>2</sub> ⊨ φ(P) = φ(Q), <br><br>provided P,Q ∈ 𝓒<sup>0</sup> or φ is surjective.<br><br>Prove or disprove.<br>     	pg 5379, right page, def 5.1.14 (ii)<br>todo: add impostor?<br>
Let φ : 𝔐<sub>1</sub> → 𝔐<sub>2</sub>. Consider the following statement:<br><br>Th(𝔐<sub>1</sub>) ⊆ Th(𝔐<sub>2</sub>)<br><br>Prove or disprove.<br>        	true. pg 5379, right page, prop 5.1.14 (iii)<br>todo: add impostor?<br>
Let φ : 𝔐<sub>1</sub> → 𝔐<sub>2</sub>. Consider the following statement:<br><br>Th(𝔐<sub>1</sub>) = Th(𝔐<sub>2</sub>), provided that φ is injective.<br><br>Prove or disprove.<br>    	true. pg 5379, right page, prop 5.1.14 (iv)<br>todo: add impostor?
<$>\\<br>\text{Let C be a set of constants and } \frak M \text{ an applicative structure.}\\<br>\text{What do the notations } \Lambda(C) \text{ and } \Lambda(\frak M) \text{ mean}?<br></$>	pg 5380, left page, Notation section below the start of 5.2<br>
<$>\\<br>\text{Let } \frak M \text{ be a combinatory algebra.}\\<br>\text{Give the definitions of the maps }\\<br>CL : \Lambda(\frak M) \to \frak T(\frak M)\\<br>\text{and}\\<br>\lambda : \frak T(\frak M) \to \Lambda(\frak M)<br></$>	pg 5380, def 5.2.1 (i)<br>
<$>\\<br>\text{For } M,N \in \Lambda(\frak M)\text{, give the definitions of}\\<br>\sem{M}^{\frak M}_\rho, \\<br>\frak M, \rho \vDash M = N, \\<br>\text{and}\\<br>\frak M \vDash M = N<br></$><br>	pg 5380, def 5.2.1 (ii)<br>
Consider the following statement:<br><br>All equations provable in the λ-calculus are true in every combinatory algebra.<br><br>Prove or disprove.	IMPOSTOR. pg 5380, top right<br><br>
What does it mean for a combinatory algebra to be a <i>λ-algebra</i>?	pg 5380, right page, def 5.2.2 (i)<br>
What is a <i>λ-algebra homomorphism</i>?<br>	pg 5380, right page, def 5.2.2 (ii)<br>
<$>\\<br>\text{Let } \frak M \text{ be a combinatory algebra.}\\<br>\text{Consider the following statement:}\\\\<br>\frak M\text{ is a } \lambda \text{-algebra iff for all } M, N \in \Lambda(\frak M):\\<br>1.~\lambda \vdash M = N \Rightarrow \frak M \vDash M = N \\<br>2.~\frak M \vDash K_{\lambda,CL} = K \\<br>3.~\frak M \vDash S_{\lambda,CL} = S \\\\<br>\text{Prove or disprove.}<br></$>	true. pg 5380, right page lemma 5.2.3<br>todo: add impostor?<br> 
WARNING: I don't even know what this question means. What does it mean to <br>map an algebra homomorphism over a lambda term? I suspect that it means homomorphically traversing the lambda term and mapping constants.<br><br>Consider the following statement:<br><br><$>\\<br>\text{If }\varphi : \frak M_1 \to \frak M_2 \text{, then } \varphi \sem{M}^{\frak M_1}_\rho = \sem{\varphi(M)}^{\frak M_2}_{\varphi \circ \rho}\\<br>\text{for }M \in \Lambda(\frak M_1)<br></$><br><br>Prove or disprove.	true. pg 5379, right page, prop 5.1.14 (i)<br><br>
Consider the following statement:<br><br><$>\\<br>\text{Let }\frak M_1 \to \frak M_2\text{. Then }Th(\frak M_1) \subseteq Th(\frak M_2).\\<br>\text{Thus, if } \frak M_1 \text{ is a } \lambda \text{-algebra, so is } \frak M_2.<br></$><br><br>Prove or disprove.	true. pg 5381, top left, (ii)<br>todo: add impostor?<br>
Consider the following statement:<br><br><$>\frak M_1 \Subset \frak M_2 \Rightarrow Th(\frak M_1) = Th(\frak M_2)</$><br><br>Prove or disprove.<br>	true. pg 5381, top left, (iii)<br>todo: add impostor?<br>note that I use \Subset for Barendregt's big curly symbol<br>
Let <$>\frak M</$> be a combinatory algebra. What does it mean for <$>\frak M</$> to be <i>weakly extensional</i>?<br>	pg 5381, bottom left, def 5.2.6<br>
How is the <b>1</b> combinator of combinatory algebras defined?	pg 5381, right page, def 5.2.7 (i)
What is a <i>λ-model</i>?<br>	pg 5381, right page, def 5.2.7 (ii)<br>
Let <$>\frak M</$> be a combinatory algebra. Consider the following statement:<br><br>In <$>\frak M</$>, <b>1</b>ab = ab<br><br>Prove or disprove.<br>	true. pg 5381, right page, lemma 5.2.8 (i)<br>
Let <$>\frak M</$> be a lambda algebra. Consider the following statement:<br><br>In <$>\frak M</$>, <b>1</b> = λxy. xy, and hence <b>1</b>a = λy. ay<br><br>Prove or disprove.<br>	true, pg 5381, right page, def 5.2.8 (ii)<br>todo: add impostor?
Let <$>\frak M</$> be a lambda algebra. Consider the following statement:<br><br>In <$>\frak M</$>, <b>1</b>(λx. A) = λx. A <br>for all <$>A \in \frak T(\frak M)</$> <br><br>Prove or disprove.<br>	pg 5381, right page, def 5.2.8 (ii)<br>todo: add impostor?
Let <$>\frak M</$> be a lambda algebra. Consider the following statement:<br><br>In <$>\frak M</$>, <b>1</b><b>1</b> = <b>1</b><br><br>Prove or disprove.<br>	true. pg 5381, def 5.2.8 (iv)<br>todo: add impostor?
Consider the following statement:<br><br><$>\frak M\text{ is a }\lambda\text{-model }\Leftrightarrow \frak M\text{  is a weakly extensional }\lambda\text{-algebra}</$><br><br>Prove or disprove.<br>	true. pg 5381, right page, prop 5.2.9<br>todo: add impostor?<br><br>
<$>\\<br>\text{Let }\frak M\text{ be a }\lambda\text{-algebra. Consider the following statement:}\\<br>\\<br>\frak M\text{ is extensional} \Leftrightarrow \frak M\text{ is weakly extensional and satisfies }\mathbf{I} = \mathbf{1}.\\<br>\\<br>\text{Prove or disprove.}<br></$><br>	true. pg 5381, right page, prop 5.2.10<br>todo: add impostor?<br>
Let T be a λ-theory.<br><br>What does M =<sub>T</sub> N denote? <br>What does [M]<sub>T</sub> denote?<br><br>	pg 5382, def 5.2.11 (i)<br>
Let T be a λ-theory.<br><br>What does Λ/T denote? <br>What does [M]<sub>T</sub>[N]<sub>T</sub> denote?<br><br><br>	pg 5382, left page, def 5.2.11 (i)<br>
Let T be a λ-theory. What is the <i>open term model</i> of T?<br>	pg 5382, left page, def 5.2.11 (i)<br><br>
Let T be a λ-theory. What is the <i>closed term model</i> of T?<br>	pg 5382, left page, def 5.2.11 (ii)<br>
Let T be an extension of the λ-calculus and let <$>\frak M</$> be <$>\frak M(T)</$> or <$>\frak M^0(T)</$>. Consider the following statement:<br><br><$>\\<br>\text{For M with FV(M) }= \{x_1, ..., x_n\}\text{ and }\rho\text{ with }\rho(x_i) = [P_i]^{(0)}_T\text{ one has:\\~\\ <br><br>\sem{M}^{\frak M}_\rho = [M[\vec{x} := \vec{P}]]^{(0)}_T<br></$><br><br>where <$>\vec{x} := \vec{P}</$> denotes simultaneous substitution.<br> 	pg 5382, bottom left, prop 5.2.12 (i)<br>
Let T be an extension of the λ-calculus and let <$>\frak M</$> be <$>\frak M(T)</$> or <$>\frak M^0(T)</$>. Consider the following statement:<br><br><$>\\<br>T \vdash M = N~~\Rightarrow~~\frak M \vDash M = N<br></$><br><br>Prove or disprove.<br>	pg 5382, bottom left, prop 5.2.12 (ii)<br>
Let T be an extension of the λ-calculus and let <$>\frak M</$> be <$>\frak M(T)</$> or <$>\frak M^0(T)</$>. Consider the following statement:<br><br><$>\\<br>T \vdash M = N~~\Leftrightarrow~~\frak M \vDash M = N\\<br>\text{Provided that }\frak M = \frak M(T)\text{ or that M,N are closed.}<br></$><br><br>Prove or disprove.<br>	true. pg 5382, bottom left, def 5.2.12 (iii)<br><br>todo: add impostor?<br>
Let T be a λ-theory. Consider the following statement:<br><br><$>\frak M^0(T)\text{ is a }\lambda\text{-algebra.}</$><br><br>Prove or disprove.<br>	true. pg 5382, right page, corollary 5.2.13 (i)<br><br><br>
Let T be a λ-theory. Consider the following statement:<br><br><$>\frak M(T)\text{ is a }\lambda\text{-model.}</$><br><br>Prove or disprove.<br>	true, pg 5382, right page, corollary 5.2.13 (ii)<br>todo: add impostor?<br><br>
Let T be a λ-theory. Consider the following statement:<br><br><$>\frak M^0(T)\text{ is a }\lambda\text{-model.}</$><br><br>Prove or disprove.<br>	IMPOSTOR. pg 5382, bottom-right remark (i)<br>
<$>\\<br>\text{Let }\frak A\text{ be a combinatory algebra.}\\<br>\text{What is the \emph{interior} of }\frak A\text{?}\\<br></$><br>	pg 5383, top-left, def 5.2.14 (i)
<$>\\<br>\text{Let }\frak A\text{ be a combinatory algebra.}\\<br>\text{What does it mean for }\frak A\text{ to be \emph{hard}?}\\<br></$><br>	pg 5383, left page, def 5.2.14 (ii)<br>
<$>\\<br>\text{Let }\frak A\text{ be a }\lambda\text{-algebra. Consider the following:}\\<br>\text{Let }Th(\underline{\frak A}) = \{ M = N \mid M,N \in T(\frak A),~M, N\text{ closed and }\frak A \vDash M = N \}.\\<br>\text{Then }\frak M^0(Th(\underline{\frak A})) \cong \frak A.\\\\<br>\text{Prove or disprove}<br></$><br>	true. pg 5383, left, prop 5.2.15 (ii)<br>todo: add impostor?<br>
Consider the following statement:<br><br>Every λ-algebra can be embedded into a λ-model.<br><br>Prove or disprove.	true. pg 5383, left, prop 5.2.16 (i)<br>
Consider the following statement:<br><br>Every λ-algebra is the homomorphic image of a λ-model.<br><br>Prove or disprove.	true. pg 5383, left, prop 5.2.16 (ii)<br>todo: add impostor<br>
Read theorem 5.2.17 on the bottom left of page 5383 and marvel.<br>	<br>
Let M, N ∈ Λ. Consider the following:<br><br>(λ ⊢ M = N  ⇔  M = N) is true in all λ-models.<br><br>Prove or disprove.<br>	true. pg 5383, top right, thm 5.2.18 (i)<br>todo: add impostor?<br>
Let M, N ∈ Λ. Let T be an extension of the λ-calculus. Consider the following:<br><br>T ⊢ M = N  ⇔  (M = N is true in all λ-models satisfying T.)<br><br>Prove or disprove.<br>	true. pg 5383, top-right, thm 5.2.18 (ii)<br>todo: impostor?<br>
Give the general form for the <b>R</b>-rules (like <b>ω</b> and <b>ext</b>).<br><br>There are two ways that a λ-algebra <$>\frak M</$> can satisfy a rule of this form.<br>Describe these two ways and give their notations.<br><br> 	pg 5383, bottom right<br>pg 5384, top left<br><br>
One of the <b>R</B>-rules from chapter 4 has the property that:<br><br><$>\frak M \vDash \mathbf{R}\text{-ax}</$><br>is equivalent to weak extensionality (w.e.)<br><br>Which <b>R</b>-rule is this, and why?<br>	pg 5384, left page, middle "note that ξ-ax = w.e."<br><br>
Consider the following statement:<br><br><$>\frak M \vDash \mathbf{R}\text{-ax} \Rightarrow \frak M \vDash \mathbf{R}\text{-rule}</$><br><br>Prove or disprove.<br>	true. pg 5384, left page, fact 5.2.20 (i)<br>
Consider the following statement:<br><br><$>\frak M \vDash \mathbf{R}\text{-rule} \Rightarrow \frak M \vDash \mathbf{R}\text{-ax} </$><br><br>Prove or disprove.<br>	IMPOSTOR. pg 5384, left page, fact 5.2.20 (i)<br>
Consider the following statement:<br><br><$>\mathfrak M^0 \vDash \mathbf{R}\text{-ax} \Leftrightarrow \mathfrak M^0 \vDash \mathbf{R}\text{-rule}</$><br><br>Prove or disprove.<br><br>	true. pg 5384, left page, fact 5.2.20 (ii)<br><br>
Consider the following statement:<br><br><$>\mathfrak M^0 \vDash \mathbf{R} \Leftrightarrow \mathfrak M^0 \vDash \mathbf{R}^0</$><br><br>Prove or disprove.	true. pg 5384. left side, fact 5.2.20 (iii)
Consider the following statement:<br><br><$>\frak M \vDash \mathbf{R}\text{-ax} \Rightarrow \frak M^0 \vDash \mathbf{R}</$><br><br>Prove or disprove.<br>	IMPOSTOR. pg 5384, left page, fact 5.2.20 (iv)<br>
Let <$>\frak M</$> be a λ-algebra. Consider the following statement:<br><br><$>\frak M \vDash \mathbf{ext}-ax \Leftrightarrow \frak M\text{ is extensional.}</$><br><br>Prove or disprove.<br>	true. pg 5384, left, prop 5.2.21 (i)<br>
Let <$>\frak M</$> be a λ-algebra. Consider the following statement:<br><br><$>\frak M \vDash \mathbf{\xi}\text{-ax} \Leftrightarrow \frak M \vDash \mathbf{\xi}\text{-rule}</$><br><br>Prove or disprove.<br>	pg 5384. left page, prop 5.2.21 (ii)<br>
Let <$>\frak M</$> be a λ-algebra. Consider the following statement:<br><br><$>\frak M \vDash \mathbf{\omega}\text{-rule} \Leftrightarrow \frak M^0 \vDash \mathbf{\omega} \Leftrightarrow \frak M^0\text{ is extensional}</$><br><br>Prove or disprove.<br>	<br>true. pg 5384, left side, prop 5.2.21 (iii)<br>TODO: impostor?
Let <$>\frak T</$> be a λ-theory and <b>R</b> one of the rules. Then consider the following statement:<br><br><$>~\\<br>\frak T \vdash \mathbf{R} \Leftrightarrow \frak M(\frak T) \vDash \mathbf{R}\text{-rule}\\<br>\Leftrightarrow \frak M(\frak T) \vDash \mathbf{R}\text{-ax}</$><br><br>	true. pg 5384, right, prop 5.2.22<br>todo: add impostor?<br>
Consider the following statement:<br><br>If <$>\frak T</$> is an extensional λ-theory, then <$>\frak M(\frak T)</$> is an extensional λ-model.<br><br>Prove or disprove.<br>	true. pg 5384, right side, cor 5.2.23 (i)<br>todo: add impostor?<br>
Consider the following statement:<br><br>If <$>\frak T \vdash \omega</$> then <$>\frak M^0(\frak T)</$> is an extensional λ-model.<br><br>Prove or disprove.<br>	true. pg 5384, right, corollary 5.2.23.<br>
What does <$>Val(\frak M)</$> denote?<br>What is a <i>syntactical interpretation</i> in <$>\frak M</$>?<br>	pg 5384, bottom left, def 5.3.1, pg 5385, top right
What is a <i>syntactical applicative structure</i>?<br>	pg 5385, top left (iii)<br>
If <$>\frak M</$> is an applicative structure and M and N are in Λ(<$>\frak M</$>), then what does <$>\frak M \vDash M = N</$> mean?	pg 5385, left, def 5.3.2 (i)<br>
When is a syntactical applicative structure considered a <i>syntactical λ-algebra</i>?<br>	pg 5385, def 5.3.2 (ii)<br>
When is a syntactical applicative structure considered a <i>syntactical λ-model</i>?<br>	pg 5383, left page, def 5.3.2 (iii)
Let <$>\frak M</$> be a syntactical λ-model. Define<br><$>\varphi(M,N) \equiv \forall \rho \sem{M[x := N]}_{\rho} = \sem{M}_{\rho(x := \sem{N}_\rho)}</$><br><br>Consider the following statement:<br><br>For M,N ∈ Λ(M). z ∉ FV(M) ⇒ φ(M,z)<br><br>Prove or disprove.<br>	true. left, pg 5385, lemma 5.3.3 (i)<br>
Let <$>\frak M</$> be a syntactical λ-model. Define<br><$>\varphi(M,N) \equiv \forall \rho \sem{M[x := N]}_{\rho} = \sem{M}_{\rho(x := \sem{N}_\rho)}</$><br><br>Consider the following statement:<br><br>For M,N ∈ Λ(M). φ(M,N) ⇒ φ(λy. M, N)<br><br>Prove or disprove.<br>	true. pg 5385, left, lemma 5.3.3. (ii)<br>
Let <$>\frak M</$> be a syntactical λ-model. Define<br><$>\varphi(M,N) \equiv \forall \rho \sem{M[x := N]}_{\rho} = \sem{M}_{\rho(x := \sem{N}_\rho)}</$><br><br>Consider the following statement:<br><br>For M,N ∈ Λ(M). φ(M,N)<br><br>Prove or disprove.<br>	pg 5385, left page, lemma 5.3.3 (iii)<br>
Let <$>\frak M</$> be a syntactical λ-model. Consider the following statement:<br><br><$>\lambda \vdash M = N \Rightarrow \frak M \vDash M = N</$><br><br>Prove or disprove.<br>	true. pg 5385, right side, thm 5.3.4<br>todo: add impostor?<br>
What is a <i>homomorphism</i> between syntactical λ-algebras?	pg 5386, left, def 5.3.5<br>
Consider the following statement:<br><br>The category of syntactical λ-algebras and homomorphisms and that of λ-algebras and homomorphisms are isomorphic.<br><br>Prove or disprove.	True. pg 5386, left page, thm 5.3.6<br>
What does it mean for a set to be <i>countable</i>? What does it mean for a set to be <i>at most countable</i>?<br>	pg 5648, near top<br><br>
Consider the following statement:<br><br>If A is an at most countable alphabet, then the set A* of strings over A is countable.<br><br>Prove or disprove.<br>	true. pg 5649, lemma 1.2<br>
Exercise 1.3, pg 5649	<br>
Exercise 1.4, pg 5649	<br>
Exercise 1.5, pg 5649	<br>
What is an <i>alphabet of a first-order language</i>?<br>	pg 5650, def 2.1<br>
What is the <i>symbol set</i> of a first-order language?<br>	pg 5650, second paragraph after def 2.1<br><br>
What does A<sub>S</sub> denote?<br>	pg 5650, second paragraph below definition.<br>
Given a symbol set S, there is a specific subset of A<sub>S</sub>* called <i>S-terms</i>.<br>Provide the definition of <i>S-term</i>.<br>	pg 5651<br>
If S is a symbol set then what does T<sup>S</sup> denote?<br>	pg 5651, right below def 3.1<br>
What does it mean to <i>derive</i> a string in a calculus of S-terms?<br>	pg 5652, at very top<br>
If S is a symbol set, then what is an <i>S-formula</i>?<br>	pg 5652, def 3.2<br><br>
What is an <i>atomic formula</i>?<br>	pg 5652, near bottom<br>
If S is a symbol set, then what does L<sup>S</sup> denote?<br>	pg 5653, top paragraph.<br>
The symbol set for the theory of equivalence relations is S<sub>eq</sub>={R}.<br>Give the equivalence axioms as S<sub>eq</sub>-formulas.<br>	pg 5653, middle of page.<br><br>
Let S be a symbol set. Consider the following statement:<br><br>If S is at most countable, then T<sup>S</sup> and L<sup>S</sup> are countable.<br><br>Prove or disprove.<br>	true. pg 5654, lemma 3.3
Consider the following statement:<br><br>For all symbol sets S, every S-formula contains the same number of left parentheses as right parentheses. <br><br>How would this be proven? (no need to actually do it)	pg 5656, 4.1<br>
Consider the following statement:<br><br>For all terms t and t', t is not a proper initial segment of t'.<br>(i.e. there is no ς distinct from the empty string · such that tς = t')<br><br>Prove or disprove.<br>	true. pg 5657, lemma 4.2 (a)<br>
Consider the following statement:<br><br>If t<sub>1</sub>,...,t<sub>n</sub> and t<sub>1</sub>',...,t<sub>m</sub>' are terms, and if t<sub>1</sub>...t<sub>n</sub>=t<sub>1</sub>'...t<sub>m</sub>', then n=m and t<sub>i</sub>=t'<sub>i</sub> for 1 ≤ i ≤ n.<br><br>Prove or disprove.<br>	true. pg 5658, lemma 4.3<br>
Consider the following statement:<br><br>If φ<sub>1</sub>,...,φ<sub>n</sub> and φ<sub>1</sub>', ..., φ<sub>m</sub>' are formulas, and if φ<sub>1</sub>...φ<sub>n</sub> = φ<sub>1</sub>'...φ<sub>m</sub>' then n = m and<br>φ<sub>i</sub>=φ<sub>i</sub>' for 1 ≤ i ≤ n.<br><br>Prove or disprove.<br>	true. pg 5658, lemma 4.3 (b)<br>
Consider the following statement:<br><br>Every term is either a variable or a constant or a term of the form f t<sub>1</sub> ... t<sub>n</sub>. In the last case the function symbol f and the terms t<sub>1</sub>,...,t<sub>n</sub> are uniquely determined.<br><br>Prove or disprove.<br>	true. pg 5658, thm 4.4<br>todo: add impostor?<br>
Exercise 4.6, pg 5659<br>	<br>
Exercise 4.9, pg 5660<br>	<br>
What is a <i>sentence</i>?<br>	a formula without free variables<br>pg 5661
Exercise 5.2, pg 5661<br>	<br>
What is an <i>S-structure</i>?<br>	pg 5664, def 1.1 near top<br><br>
What is an <i>assignment</i> in an S-structure <$>\frak A</$>?<br>	pg 5664, def 1.2<br>
What is an <i>S-interpretation</i> <$>\frak T</$>?<br>	pg 5664, def 1.3, near bottom<br>
If <$>\beta</$> is an assignment in <$>\frak A</$>, <$>a \in A</$> and x is a variable, then what does <$>\beta \frac{a}{x}</$> denote?<br>	the assignment extended with an extra variable mapping from x to a. (weird notation for a common thing)<br>pg 5665, near top<br><br>
If <$>\frak T</$> is an interpretation, then what does <$>\frak T \frac{a}{x}</$> denote?	pg 5665, near top<br>
Exercise 1.4, pg 5665<br>	<br>
Exercise 1.5, pg 5665<br>	<br>
Exercise 1.6, pg 5665<br>	part c.) might be the most tricky. In the product, I think the field property which <br>fails to hold is that every non-zero element has a multiplicative inverse.<br><br>elements of the form (a,0) are non-zero when a is non-zero, however, we cannot<br>multiply this by anything to get (1,1).<br><br>see friedberg insel spence page 553 for a list of the field properties.<br>
If t is an S-term and <$>\frak T</$> is an S-interpretation, then what does <$>\frak T(t)</$> mean?	pg 5667, def 3.1<br>
Let <$>\frak T</$> be an S-interpretation and <$>t_1</$> and <$>t_2</$> be S-terms.<br>What does <$>\frak T \vDash t_1 \equiv t_2</$> mean?<br>	pg 5667, near bottom<br><br>
Let <$>\frak T</$> be an S-interpretation and <$>\varphi</$> an S-formula. What does <$>\frak T \vDash \varphi</$> mean?<br><br>	pg 5668, near top<br>
Exercise 3.3, pg 5668<br>	<br>
Exercise 3.4, pg 5668<br>	<br>
Consider the following statement:<br><br>There exist two irrational real-numbers a, b such that a<sup>b</sup> is rational.<br><br>Here is a proof:<br><br><$>(\sqrt 2)^{\sqrt 2}</$> is either rational, and then we can take a = b = <$>\sqrt 2</$>, or <$>(\sqrt 2)^{\sqrt 2}</$> is irrational, and then we can take a = <$>(\sqrt 2)^{\sqrt 2}</$>, b = <$>\sqrt 2</$>.<br><br>Is this proof constructive? Why or why not? 	it is not. pg 29, below proposition<br>
Consider Konig's lemma:<br><br>Let T be an infinite, finitely branching tree. Then T has an infinite branch.<br><br>Give a non-constructive proof of this fact and explain why it is not constructive.	pg 30, prop 2.4<br>
Give the 6 rules of the BHK interpretation of constructive first-order logic proofs.<br>	pg 31, 3.1<br>
Let A and B be propositional atoms. Give a constructive proof of A → (B → A).<br><br>	pg 32, section 3.2<br>
Let A be a propositional atom. Is ⊥ → A constructively provable?	yes. pg 32, 3rd paragraph of section 3.2<br>
What is the principle of excluded middle (PEM)? Is it valid in constructive logic? Why or why not?	it is not. see pg 32, near bottom and pg 33, near top.<br>
What does the term "weak counterexample" refer to in constructive mathematics.<br>Give an example of a weak counterexample.	pg 33, second paragraph<br>
Let A be a propositional atom. In intuitionistic logic, can we ever prove ¬(A ∨ ¬A)?<br>Why or why not?<br>	pg 33, section 3.3<br>
Are the following laws valid in BHK? Why or why not?<br><br>A → ¬¬A<br>¬A ↔ ¬¬¬A<br>¬¬A → A<br> <br>	true/true/false<br><br>pg 34<br>
Are the following laws valid in BHK? Why or why not?<br><br>(A → B) ∨ (B → A)<br><br>¬A ∨ ¬¬A<br><br>¬(A ∨ B) ↔ (¬A ∧ ¬B)<br>	false/false/true<br>pg 34<br>
Which of the following are valid in BHK?<br><br>( ¬∃x A(x) ) ↔ ( ∀x ¬A(x) )<br><br>if A → B then ¬B → ¬A<br><br>( ∀x ¬¬A(x) ) → ( ¬¬∀x A(x) )	true/true/false<br><br>pg 34<br>
In intuitionistic mathematics, terms are not necessarily well-defined. How do we deal with this formally?<br>	pg 35 near top<br>
Why isn't the principle ( ∀x A(x) ) → A(t) used in intuitionistic mathematics <i>with existence predicates</i>? Which principle is used instead?<br>	pg 35, right above section 3.5<br>
Provide a weak counterexample to the decidability of equality between reals.<br>	pg 35/36, section 3.5<br>
Consider the following definition of a function f:<br><br>f(x) = 1   if x ≠ 0<br>f(x) = 0   if x = 0<br><br>In constructive mathematics, is this function everywhere defined?<br>	no. pg 36, section 3.6<br><br>
In constructive mathematics, the failure of decidability of equality between the reals does not have disastrous consequences for the development of analysis. Why is this the case?<br>	pg 36 near bottom / pg 37<br>
What does it mean for a CPO to be <i>reflexive</i>? Why is this concept important?<br>	pg 5386, def 5.4.1<br>
How can we interpret the lambda calculus with respect to a reflexive CPO?<br>	pg 5386, right page, def 5.4.2<br>
<$>\\<br>\text{Let D be a reflexive cpo via the maps F,G.}\\<br>\text{Let }x \cdot y \doteq F(x)(y)\\<br>\text{Let }\rho\text{ be a valuation in D.}\\<br>\text{Define the interpretation }\sem{~}_\rho : \Lambda \to D\text{ by induction}\\ <br>\text{as follows:}\\\\<br>\sem{x}_\rho = \rho(x)\\<br>\sem{c_a}_\rho = a\\<br>\sem{M~N}_\rho = \sem{M}_\rho \cdot \sem{N}_\rho\\<br>\sem{\lambda x. M}_\rho = G(\underline{\lambda} d. \sem{M}_{\rho(x := d)})<br></$><br><br>Consider the following statement:<br><$>\\<br>\underline{\lambda} d. \sem{M}_{\rho(x := d)}\text{ is continuous.}<br></$><br><br>Prove or disprove.	true. pg 5386, right page, lemma 5.4.3<br>todo: add impostor?<br>
Let D be a reflexive cpo via F,G and let <$>\frak M = (D,\cdot,\sem{~})</$> be a syntactical applicative structure. Consider the following statement:<br><br><$>\frak M\text{ is a }\lambda\text{-model}</$><br><br>Prove or disprove.	true. pg 5386, right page, thm 5.4.4 (i)<br>todo: add impostor?<br><br>
Let D be a reflexive cpo via F,G and let <$>\frak M = (D,\cdot,\sem{~})</$> be a syntactical applicative structure. Consider the following statement:<br><br>The functions representable in the applicative structure <$>\frak M</$> are exactly the continuous functions on D.<br><br>Prove or disprove.	true. this is a striking fact! All continuous functions on D can be represented by lambda terms!<br>pg 5386, right page, thm 5.4.4 (ii)<br>todo: add impostor?<br>
Let D be a reflexive cpo via F,G and let <$>\frak M = (D,\cdot,\sem{~})</$> be a syntactical applicative structure. Consider the following statement:<br><br><$>\frak M</$> is extensional iff G∘F = id<sub>D</sub>, i.e. G=F<sup>-1</sup> and <br>D≌[D → D] via F,G.<br><br>Prove or disprove.	true. pg 5386, right page, thm 5.4.4<br>todo: add impostor?<br><br>So the cases in which the retraction is an iso are exactly the cases in which the structure is extensional. That's pretty striking.<br><br>
Given an arbitrary set A, how do we form the reflexive cpo D<sub>A</sub>?<br>	pg 5387, right side, def 5.4.5, thm 5.4.6<br>
What does it mean for a category to be <i>cartesian closed</i>?	pg 5378, bottom right, def 5.5.1 
Let A be an object in a category <b>C</b>. What does |A| denote?<br>	pg 5388, left page, (ii)<br>
What does it mean for an object in a category to have <i>enough points</i>?<br>	pg 5388, left page (ii)<br>
Let f : C × A → B be an arrow in a cartesian closed category.<br>What does Λf denote?<br>	the adjoint of f.<br>pg 5388, above def 5.5.2<br>
Consider the following statement:<br><br>In any ccc one has Λ(h ∘ g × id<sub>A</sub>) = Λ(h) ∘ g<br><br>Prove or disprove.<br><br>	true. pg 5388, right page, in middle of page<br>todo: add impostor?<br>
Consider the following statement:<br><br>In any ccc one has ⟨f,g⟩ ∘ h = ⟨f ∘ h, g ∘ h⟩<br><br>Prove or disprove.<br><br>	true. pg 5388, left page, middle of page<br>todo: add impostor?<br>
What does it mean for an object in a ccc to be <i>reflexive</i>?<br>	pg 5388, def 5.5.2<br>
How does a ccc <b>C</b> with a reflexive object U determine a syntactical applicative structure <$>\frak M(\mathbf C)</$>?	pg 5388, def 5.5.3
Let C be a cartesian closed category with reflexive object.<br><$>\\<br>\text{Let M, N } \in \Lambda(\frak M(\mathbf{C}))\text{ and }\{ \Delta \} \supseteq FV(M N).\text{ Then}\\<br>\lambda \vdash M = N~~\Rightarrow~~\sem{M}_{\Delta} = \sem{N}_{\Delta}<br></$><br><br>Prove or disprove.  	true. pg 5389, left, prop 5.5.5<br>todo: add impostor?<br>
Consider the following statement:<br><br>Every ccc <b>C</b> with reflexive object U determines a λ-algebra <$>\frak M(\mathbf{C}) = \langle |U|, \cdot, \sem{~} \rangle</$>.<br><br>	true. pg 5389, right page, thm 5.5.6<br>todo: add impostor?<br><br>
Let <$>\frak M = \frak M(\mathbf{C},U,F,G)</$>. Let { Δ } ⊇ FV(M). Consider the following statement:<br><br><$>\sem{1M}_{\Delta} = G \circ F \circ \sem{M}_{\Delta}\text{ in }\mathbf{C}</$><br><br>Prove or disprove.<br>	true. pg 5389, right page, prop 5.5.7 (i)<br>todo: add impostor?<br>
Let <$>\frak M = \frak M(\mathbf{C},U,F,G)</$>. Consider the following statement:<br><br><$>\text{U has enough points}~~\Leftrightarrow~~\frak M\text{ is a }\lambda\text{-model}</$><br><br>Prove or disprove.<br>	true. prop 5.5.7 (ii). right side, pg 5389<br>
Let <$>\frak M = \frak M(\mathbf{C},U,F,G)</$>. Consider the following statement:<br><br><$>U \cong U^U\text{ via F,G}~~\Leftrightarrow~~\frak M \vDash \mathbf{1} = \mathbf{I}</$><br><br>Prove or disprove.<br>	pg 5389, right page, prop 5.5.7 (iii)<br>todo: add impostor?<br>
Let <$>\frak M = \frak M(\mathbf{C},U,F,G)</$>. Consider the following statement:<br><br><$>\\<br>U \cong U^U\text{ via F,G and U has enough points}~~\Leftrightarrow\\ \frak M\text{ is extensional.}</$><br><br>Prove or disprove.<br>	true. pg 5389, right page, prop 5.5.7 (iv)<br>todo: add impostor?<br>
What does it mean for a ccc <b>C</b> to be <i>strictly concrete</i>?<br>	pg 5390, right page, def 5.5.8 
Let <b>C</b> be a strictly concrete ccc with reflexive object U.<br><br>How is the map <$>\varphi : |U| \to \Phi(U)</$> defined?	pg 5390, right page, def 5.5.9 (i)
Let <b>C</b> be a strictly concrete ccc with reflexive object U.<br><br>How is the map <$>\square : \Phi(U^U) \to \Phi(U)</$> defined?	pgg 5390, right page, def 5.5.9 (ii)<br>
Let <b>C</b> be a strictly concrete ccc with reflexive object U.<br><br>For <$>a,b \in \Phi(U)</$>, how is <$>a \cdot b</$> defined?<br>	pg 5390, right page, def 5.5.9 (iii)<br>
Let <b>C</b> be a strictly concrete ccc with reflexive object U.<br><br>How is <$>\sem{M}^\Phi_\rho</$> defined, for M ∈ Λ(Φ(U))?<br><br>	pg 5390, right page, def 5.5.9 (iv)<br>
Let <b>C</b> be a strictly concrete ccc with reflexive object U.<br><br>How is <$>\frak M^\Phi</$> defined?<br>	pg 5390, right page, def 5.5.9 (v)<br>
Let {Δ} ⊇ {Γ} ⊇ FV(M). Consider the following statement:<br><br><$>\sem{M}_\Delta = \sem{M}_{\Gamma} \circ \Pi_{\Gamma}^{\Delta}</$><br><br>Prove or disprove.<br><br>	true. pg 5389, left page, lemma 5.5.4<br>todo: add impostor?
<$>\\<br>\text{Let }\{ \Delta \} = \{ \vec{x} \} \supseteq FV(M)\text{,}\\<br>\vec{N}\text{ fit in } \vec{x}\text{ and }\{ \Gamma \} \supseteq FV(\vec{N}).</$><br><br>Consider the following statement:<br><br><$><br>\sem{M[\vec{x} := \vec{N}]}_{\Gamma} = \sem{M}_{\Delta} \circ <br>\langle \sem{N_1}_{\Gamma}, \ldots, \sem{N_n}_\Gamma \rangle</$><br><br>Prove or disprove.	true. pg 5389, left page, def 5.5.4 (ii)<br>todo: add impostor?<br><br>
Let <$>\{ \Delta \} \supseteq FV(\lambda x.M), \{ \Gamma \} \supseteq<br>FV((\lambda x.M) N)\text{ and } \{ \Gamma \} \supseteq \{ \Delta \}</$><br><br>Consider the following statement:<br><br><$>\sem{M[x := N]}_\Gamma = \sem{M}_{\Delta, x} \circ \langle \Pi_\Delta^\Gamma, <br>\sem{N}_\Gamma \rangle</$><br><br>Prove or disprove.	true. pg 5389, left page, lemma 5.5.4 (iii)<br>todo: add impostor?<br>
What does the following notation mean?<br><$>\\<br>\text{[} A \text{]}\\<br>\mathcal D\\<br>B\\<br></$><br>	pg 61
What is the <i>intuitionistic absurdity rule</i>?<br>	pg 62, near top<br>
Give the intuitionistic introduction and elimination rules for all standard logical operators.<br><br>What are the laws determining which assumptions get cancelled in these rules?<br><br>Explain why these rules are justified by the BHK interpretation.<br><br><br>	pg 62<br>BHK interpretation on pg 31<br>
What is the <i>crude discharge convention</i> (CDC)?<br>	pg 63<br>
Prove that ¬¬(A ∨ ¬A) holds intuitionistically	pg 64, example (a)<br>
Consider the following statement:<br><br><$>(\neg \neg \forall x~Ax) \rightarrow (\forall x~\neg \neg Ax)</$> holds intuitionistically<br><br>Prove or disprove.<br>	Hello <br><$$><br>\begin{prooftree}<br>\AxiomC{$\forall x. A x~(1)$}<br>\UnaryInfC{$A y$}<br>\AxiomC{$\neg (Ay)~(2)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg (\forall x. A x)~(1)$}<br>\AxiomC{$(\neg \neg \forall x. (A x))$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg \neg (A y)~(2)$}<br>\UnaryInfC{$\forall x. \neg \neg (A x)$}<br>\UnaryInfC{$(\neg \neg \forall x. (A x)) \rightarrow (\forall x. \neg \neg (A x))$}<br>\end{prooftree}<br></$$><br><br><br>pg 65, example (b)<br><br>
Consider the following statement:<br><br><$>(\neg \neg \neg A) \rightarrow \neg A</$> holds intuitionistically<br><br>Prove or disprove<br>	true. pg 66, example (c)<br>todo: add impostor<br>
Consider the following statement:<br><br><$>B \rightarrow \neg \neg B</$> holds intuitionistically.<br><br>Prove or disprove.<br>	true. pg 66, example (c)<br>todo: add impostor?<br>
Conisder the following statement:<br><br><$>\neg A \leftrightarrow \neg \neg \neg A</$> holds intuitionistically<br><br>Prove or disprove.	true. pg 66, example (c)<br>todo: add impostor?<br>
Consider the following statement:<br><br><$>(A \rightarrow B) \rightarrow (\neg B \rightarrow \neg A)</$> is valid intuitionistically<br><br>Prove or disprove.<br>	This is simple and should be clear without having to write out a proof tree (though that might be worthwhile).<br><br>Assume <$>A \to B</$> and <$>\neg B</$>. To prove <$>\neg A</$>, we must assume <br>A is true and derive a contradiction from that, which is quite easy. If A is true, we conclude B,<br>from which we use <$>\neg B</$> to conclude <$>\bot</$>.<br><br>true. pg 67, exercise (f) <br>todo: add impostor?<br>
Consider the following statement:<br><br><$>(\neg \neg (A \rightarrow B)) \rightarrow (A \rightarrow \neg \neg B)</$> is valid intuitionistically<br><br>Prove or disprove.<br>	It should be possible to see this without writing a proof. But nonetheless, here is a proof:<br><br><$$><br>\begin{prooftree}<br>\AxiomC{$A \rightarrow B~(1)$}<br>\AxiomC{$A~(2)$}<br>\BinaryInfC{$B$}<br>\AxiomC{$\neg B~(3)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg (A \to B)~(1)$}<br>\AxiomC{$\neg \neg (A \to B)~(4)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg \neg B~(3)$}<br>\UnaryInfC{$A \to \neg \neg B~(2)$}<br>\UnaryInfC{$(\neg \neg (A \to B)) \to (A \to \neg \neg B)~(4)$}<br>\end{prooftree}<br></$$><br><br>true. pg 67, exercise g<br>todo: add impostor?<br>
Consider the following statement:<br><br><$>\neg \neg (A \wedge B) \leftrightarrow \neg \neg A \wedge \neg \neg B</$> is valid intuitionistically<br><br>Prove or disprove.<br>	Here is the key portion of the proof. The rest is either symmetric or trivial.<br><$$><br>\begin{prooftree}<br>\AxiomC{$A \wedge B$}<br>\UnaryInfC{$A$}<br>\AxiomC{$\neg A$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg(A \wedge B)$}<br>\AxiomC{$\neg \neg (A \wedge B)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg \neg A$}<br>\UnaryInfC{$\neg \neg (A \wedge B) \rightarrow \neg \neg A$}<br>\end{prooftree}<br></$$><br>true. pg 67, exercise h.)<br>
Give a rule schema for substitution of logically equivalent statements.<br>Show that the instances of this schema are derived rules.<br>	pg 68, near top (see rule R')<br><br>This would involve induction on the syntax of the context F.<br><br>Case <$>F = C \wedge F'[A]</$>:<br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~F(A)$}<br>\UnaryInfC{$C \wedge F'(A)$}<br>\UnaryInfC{$C$}<br><br>\AxiomC{$(1)~F(A)$}<br>\UnaryInfC{$C \wedge F'(A)$}<br>\UnaryInfC{$F'(A)$}<br>\AxiomC{$(IH)~F'(A) \leftrightarrow F'(B)$}<br>\BinaryInfC{$F'(B)$}<br><br>\BinaryInfC{$C \wedge F'(B)$}<br>\UnaryInfC{$F(B)$}<br>\UnaryInfC{$(1)~F(A) \to F(B)$}<br>\end{prooftree}<br></$><br><br>The other direction is symmetric, by swapping As and Bs.<br><br>Case F = <$>F[A] \to C</$>:<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~F(A)$}<br>\UnaryInfC{$F'(A) \to C$}<br><br>\AxiomC{$F'(B)$}<br>\AxiomC{$(IH)~F'(A) \leftrightarrow F'(B)$}<br>\BinaryInfC{$F'(A)$}<br><br>\BinaryInfC{$C$}<br><br>\UnaryInfC{$(2)~F'(B) \to C$}<br><br>\UnaryInfC{$F(B)$}<br><br>\UnaryInfC{$(1)~F(A) \to F(B)$}<br><br>\end{prooftree}<br></$><br><br>The other direction is symmetric, swapping A for B.<br><br><br>
What is classical logic? How is it different than <i>intuitionistic logic</i>? Show that ∨ and ∃ are redundant in classical logic.<br>	We first show <$>A \vee B \leftrightarrow \neg(\neg A \wedge \neg B)</$><br><br>The left-to-right direction is true intuitionistically as well as classically:<br><$$><br>\begin{prooftree}<br>\AxiomC{$A \vee B~(1)$}<br>\AxiomC{$[A]$}<br>\AxiomC{$\neg A \wedge \neg B~(2)$}<br>\UnaryInfC{$\neg A$}<br>\BinaryInfC{$\bot$}<br>\AxiomC{$\overset{[B]}{\vdots}$}<br>\UnaryInfC{$\bot$}<br>\TrinaryInfC{$\bot$}<br>\UnaryInfC{$\neg (\neg A \wedge \neg B)~(2)$}<br>\UnaryInfC{$(A \vee B) \rightarrow \neg (\neg A \wedge \neg B)~(1)$}<br>\end{prooftree}<br></$$><br><br>The left-to-right direction does not seem to be provable intuitionistically<br><$$><br>\begin{prooftree}<br>\AxiomC{$\neg (A \vee B)~(1)$}<br>\AxiomC{$A~(2)$}<br>\UnaryInfC{$A \vee B$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg A~(2)$}<br>\AxiomC{$\vdots$}<br>\UnaryInfC{$\neg B$}<br>\BinaryInfC{$\neg A \wedge \neg B$}<br>\AxiomC{$\neg (\neg A \wedge \neg B)~(3)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$A \vee B~(1)$}<br>\UnaryInfC{$\neg(\neg A \wedge \neg B) \rightarrow A \vee B~(3)$}<br>\end{prooftree}<br></$$><br><br>TODO: explain how exists is redundant<br><br>pg 69, near top<br>
In deduction proofs, why is it important to distinguish between <i>axioms</i> and <i>open assumptions</i>?<br>	pg 69, section 1.7<br>
Explain the "empty premiss" technique for natural deduction that allows us to avoid having to deal with the distinction between open assumptions and axioms.<br>	pg 69, near bottom<br>
Explain the fundamental difference between the way classical and constructive logic deals with equality.<br>	pg 70, section 1.8<br>
What axioms (and axiom schema) do we use in constructive logic with equality? Give two alternative formulations.<br>	pg 70, section 1.8<br>
Consider the following statement:<br><br>The complete partial orders with continuous maps is a strictly concrete ccc.<br><br>Prove or disprove.<br> 	true. pg 5390, right page.<br>todo: add impostor?<br>
Consider the following statement:<br><br>The category of complete lattices with continuous maps is a ccc.<br><br>Prove or disprove.<br> 	true. pg 5390, right page, below def 5.5.8<br>todo: add impostor?<br>
Read the theorem on page 5390, right page, thm 5.5.10 and prove it.<br>	<br>
Let <$>\frak A</$> be a lambda-algebra. Define the <i>Karoubi envelope</i> of <$>\frak A</$>, and prove that it is a category.	pg 5391, left page, def 5.5.11<br><br>
Let<$>\frak A</$> be a lambda-algebra. Consider the following statement:<br><br>The Karoubi envelope <$>\mathbf C(\frak A)</$> is a cartesian closed category.<br><br>Prove or disprove.<br>	true. pg 5391, left page, prop 5.5.12<br>todo: add impostor?<br>
Let <$>\frak A</$> be a lambda-algebra and <$>\mathbf C(\frak A)</$> its Karoubi envelope. Consider the following statement:<br><br><$>\mathbf I \text{ is a reflexive object in }\mathbf C(\frak A)\text{ via the arrows F = G = }\mathbf{1}.</$><br><br>prove or disprove.<br>	true. pg 5391, left page, prop 5.5.12 (ii)<br>todo: add impostor?<br>
Let <$>\frak A</$> be a lambda-algebra. Consider the following statement:<br><br><$>\frak A \cong \frak M(\mathbf C(\frak A), \mathbf I, \mathbf 1, \mathbf 1)</$><br><br>Prove or disprove.<br><br>	true. pg 5391, right page, thm 5.5.13<br>
How do we define pairing (more generally tupling) and projection operators in the lambda<br>calculus?<br>	pg 5391, left page, right above prop 5.5.12<br>
What is the significance of the concept of a <i>Karoubi envelope</i>?<br>	Any lambda algebra has a corresponding Karoubi envelope (a ccc with reflexive object) from which that lambda algebra can be generated; this is a consequence of thm 5.5.13 on pg 5391.<br><br>For this reason, we can say that every lambda algebra can be obtained from a ccc with reflexive object.<br>
What does it mean for a functor Φ between two cartesian closed categories to be <i>cartesian</i>?<br>	pg 5392, left page, def 5.5.14<br>
For i = 1,2 let <b>C</b><sub>i</sub> be a ccc with reflexive objects U<sub>i</sub> via the maps F<sub>i</sub>,G<sub>i</sub>. Let Φ : <b>C</b><sub>1</sub> → <b>C</b><sub>2</sub> be a cartesian functor with Φ(U<sub>1</sub>) = U<sub>2</sub>,<br>Φ(F<sub>1</sub>) = F<sub>2</sub>, Φ(G<sub>1</sub>) = G<sub>2</sub>.<br><br>Consider the following statement:<br><br>Φ induces a homomorphism <$>\Phi^* : \frak M(\mathbf C_1) \to \frak M(\mathbf C_2)</$>.<br><br>Prove or disprove.<br><br> 	pg 5392, left page, prop 5.5.15<br>
Let <$>\varphi : \frak A_1 \to \frak A_2</$> be a homomorphism. Consider the following statement:<br><br>φ induces a cartesian functor <$>\varphi^+ : \mathbf{C}(\frak A_1) \to \mathbf{C}(\frak A_2)</$> preserving the reflexive elements <b>I</b> and retraction map <b>1</b>.<br>Moreover φ<sup>+*</sup> = φ up to isomorphism.<br><br>Prove or disprove.<br>	pg 5392, left page, prop 5.5.15 (ii)<br>
What do <b>IPC</b>, <b>IQC</b>, <b>CPC</b>, and <b>CQC</b> stand for?<br>	pg 70, def 1.9<br>
What issue do we run into when we try to allow partially defined terms in our forall elimination rule?<br>	pg 72, section 2.1 (bottom paragraph)<br><br>
What is an <i>existence predicate<i>?<br>	pg 72, section 2.2 (near bottom)<br>
Explain the fundamental difference between free variables and quantified variables when using an existence predicate.<br><br>Give the four rules for forall and exists introduction and elimination in E-logic.<br>	Free variables can refer to any object, whereas quantified variables refer to existing objects only.<br><br>pg 72, bottom/pg 73, top<br>
Give the "substitution rule" of E-logic. Why is this rule necessary?<br>	pg 73, see rule (SUB) in middle<br>necessary for instantiating axiom schemas, as described in the paragraph below the definition of SUB<br><br>
There is a theory for E-logic called "the theory of global existence". Describe this theory.<br>	pg 73, above section 2.3<br><br>
What is E<sup>+</sup> logic?<br>	pg 73, section 2.3 near bottom<br><br>
Explain E-logic and E<sup>+</sup>-logic's version of "reflexive equality" when equality is added to these logics.<br>	pg 74, section 2.4<br>
Adding equality to E-logic and E<sup>+</sup>-logic, an operator written "≃" is defined.<br>How is this operator defined?<br> 	pg 74, section 2.4<br>
Adding equality to E-logic and E<sup>+</sup>-logic, the replacement axiom schema must be revised. Give the new replacement axiom schema.<br>	pg 74, section 2.4<br>
Give the <i>strictness</i> axiom schema STR for E-logic with equality.<br>	pg 74, section 2.4
Consider the following statement:<br><br>In E-logic with STR, the following is derivable:<br>Et ↔ t = t ↔ ∃x(t = x)<br><br>Prove or disprove<br>	true.<br><br>Et ↔ t = t <br>is an axiom schema of E-logic<br><br>See page 73 for a description of the rules used for this next part:<br>(∃x (t=x)) → (t = t)<br>To apply ∃-elimination, we suppose that t=x is true<br>and that (Ex). We then derive (t=t) by using the replacement<br>schema described on page 74, section 2.4<br><br>(t = t) → (∃x (t=x))<br>= is a binary relation, and so by strictness, we have<br>Et. Hence we apply ∃-introduction (pg 73) on t=x to get<br>(∃x. t=x)<br><br>pg 74, near bottom<br>
Consider the following statement:<br><br>In E-logic with STR, the following is derivable:<br>t = s ↔ ∃x(t = x ∧ s = x)<br><br>Prove or disprove<br>	We can prove t = s → ∃x(t = x ∧ s = x) as follows:<br><br><$$><br>\begin{prooftree}<br>\AxiomC{$t=s~(1)$}<br>\LeftLabel{STR}<br>\UnaryInfC{E t}<br>\AxiomC{$t=s~(1)$}<br>\LeftLabel{STR}<br>\UnaryInfC{$E t$}<br>\UnaryInfC{$t = t$}<br>\AxiomC{$t=s~(1)$}<br>\RightLabel{SYMM}<br>\UnaryInfC{$s=t$}<br>\BinaryInfC{$t=t \wedge s=t$}<br>\BinaryInfC{$\exists x. (t=x \wedge s=x)$}<br>\UnaryInfC{$t=s \rightarrow \exists x. (t=x \wedge s=x)~(1)$}<br>\end{prooftree}<br></$$><br><br>Here SYMM is a derived form... can you prove it?<br><br>TODO: handle the other direction<br><br>true. pg 74, near bottom<br>
Consider the following statement:<br><br>In E-logic with STR, the following is derivable:<br><$>f \vec{t} = x \leftrightarrow \exists \vec{y}(\vec{y} = \vec{t} \wedge f \vec{y} = x)</$><br><br>Prove or disprove 	true. pg 74, near bottom<br>
Consider the following statement:<br><br>In the presence of STR, the replacement schema<br><$>A(t) \wedge t \simeq s \rightarrow A(s)</$><br>is derivable on the basis of the other axioms and rules of <b>IQCE</b> or <b>IQCE</b><sup>+</sup> from the special cases:<br><$>R \vec{t} \wedge \vec{t} = \vec{s} \rightarrow R \vec{s}</$><br><$>E(f \vec{s}) \wedge \vec{t} = \vec{s} \rightarrow f \vec{t} = f \vec{s}</$><br><br>Prove or disprove.<br>	true. pg 75, proposition near top<br>todo: add impostor?<br>
What is <b>IQCE</b>* and how is it defined?	pg 75, section 2.7 near bottom<br>
In a sense, <b>IQCE</b> and <b>IQCE</b>* are equivalent. Explain why this is so, and provide a proof.<br><br><br>	top of pg 76<br>
Let <b>IQC</b>* be <b>IQC</b> with the equality axioms for = and a predicate E relative to which STR holds. We define a mapping --<sup>E</sup> from the formulae of <b>IQCE</b> to <b>IQC</b>* by:<br><br><$$>\\<br>\begin{array}{ll}<br>(R t_0 \ldots t_{n-1})^E & := R t_0 \ldots t_{n-1};\\<br>(t_0 = t_1)^E & := E t_0 \wedge E t_1 \wedge t_0 = t_1;\\<br>(A \circ B)^E & := A^E \circ B^E \text{ for } \circ \in \{ \wedge, \vee, \to \};\\<br>(\forall x A)^E & := \forall x [Ex \to A^E];\\<br>(\exists x A)^E & := \exists x [E x \wedge A^E]<br>\end{array}<br></$$><br><br>Prove that:<br><br><$>\mathbf{IQCE} \vdash A \Leftrightarrow \mathbf{IQC^*} \vdash A^E</$><br>	pg 76, near bottom<br>pg 77, near top (no proof is given, but doing a proof by induction should work)<br>
Explain and define the <i>description operator</i> Ix.A(x)	pg 77, top of section 2.9
Describe the <i>description axiom</i> DESCR capturing the interpretation of the description operator.<br>	pg 77, section 2.9, DESCR
Let y ∉ FV(A). Consider the following statement:<br><br>E(<b>I</b>x.A(x)) ↔ ∃y∀x[A(x) ↔ x = y], working in E-logic with descriptions:<br><br>Prove or disprove.<br>	true. pg 77, prop 2.10 (i)<br>
Consider the following statement, working in E-logic with descriptions:<br><br>E(<b>I</b>x.A(x)) → A(<b>I</b>x.A(x))<br><br>Prove or disprove.<br>	true. pg 77. prop 2.10 (ii)<br>
What is a <i>conservation result</i> of <b>CQC</b> over <b>IQC</b>?<br>i.e., what does the term <i>conservation result</i> mean?<br>	pg 78, near bottom<br>
If φ is a formula and Φ is a set of formulas, what does Φ ⊨ φ mean?<br>	pg 5669, top<br>
Does not (Φ ⊨ φ) imply (Φ ⊨ ¬φ)?<br>	pg 5669<br>
What does it mean for a formula φ to be </i>valid</i>?<br>What does it mean for a formula φ to be <i>satisfiable</i>?<br>What does ite mean for a set of formulas Φ to be satisfiable?<br>	pg 5670, top of page.<br>
Consider the following statement:<br><br>For all Φ and all φ,<br>Φ ⊨ φ iff not Sat Φ ∪ { ¬φ }<br><br>Prove or disprove.<br>	true. pg 5670<br>todo: add impostor?<br>
What does it mean for two formulas to be <i>logically equivalent</i>?<br>	pg 5670, definition 4.5<br>
Consider the following statement:<br><br>Only the operators ¬, ∨, and ∃ are necessary for first order logic.<br><br>Prove or disprove.<br>	true. bottom of page 5670/ top of page 5671<br>
What is the <i>Coincidince lemma</i>?<br>	pg 5671, lemma 4.6<br><br>
What does the notation <$>\frak A \vDash \phi[a_0,\ldots,a_n]</$> mean?<br>	pg 5672, near bottom<br><br>
If <$>\frak A</$> is an S-structure, what does the notation<br><$>t^{\frak A}[a_0,\ldots,a_{n-1}]</$> mean?<br>	pg 5672, near bottom<br>
Let S and S' be symbol sets such that S ⊂ S'. Let <$>\frak A = (A,a)</$> be an S-structure,<br>and <$>\frak A' = (A',a')</$> an S'-structure.<br><br>What does it mean for <$>\frak A</$> to be a <i>reduct<i> of <$>\frak A'</$>?<br>	pg 5673, def 4.7<br>
Let S' ⊃ S and Φ a set of S formulas. Consider the following statement:<br><br>Φ is satisfiable with respect to S iff Φ is satisfiable with respect to S'.<br><br>Prove or disprove.<br>	true. pg 5673, thm 4.8<br>
Do exercise 4.9 on pg 5673<br>	<br>
Do exercise 4.10 on pg 5673<br>	<br>
Do exercise 4.11 on pg 5673<br>	<br>
Do exercise 4.12 on pg 5674<br>	<br>
Do exercise 4.13 on pg 5674<br>	<br>
Do exercise 4.14 on pg 5674	<br>
Do exercise 4.15 on pg 5674	<br>
Do exercise 4.16 on pg 5674	<br>
Let <$>\frak A</$> and <$>\frak B</$> be S-structures. What does the notation <$>\pi : \frak A \cong \frak B</$> mean?	pg 5675, def 5.1<br>
Let <$>\frak A</$> and <$>\frak B</$> be S-structures. What does it mean for <$>\frak A</$> and <$>\frak B</$> to be <i>isomorphic</i>?<br>	pg 5675, def 5.1<br>
The S<sub>gr</sub>-structure (<b>N</b>,+,0) is isomorphic to the S<sub>gr</sub>-structure (G,+<sup>G</sup>,0) consisting of the even natural numbers with ordinary addition.<br><br>Give an isomorphism demonstrating this, and prove that it is in fact an isomorphism.<br>	<latex>~\\<br>it's important to remember here that $S_{Gr}$ merely refers to a symbol set, the symbols of groups, but not necessarily their \emph{semantics}. The existence of inverses can be expressed using existential quantifiers, and so an "inverse" operator is not part of the syntax. See page 5650, second-to-last pargraph, for the definition of $S_{Gr}$\\~\\<br>pg 5675, below def 5.1<br></latex>
State and prove the <i>isomorphism lemma</i>.<br>	pg 5675, theorem 5.2<br>
In the rational numbers every number is divisible by 2. Therefore we have<br><br>(<b>Q</b>,+,0) ⊨ ∀v<sub>0</sub>∃v<sub>1</sub>. v<sub>1</sub>+v<sub>1</sub> ≡ v<sub>0</sub><br><br>Does this remain true if we replace the rationals <b>Q</b> with the integers <b>Z</b>?<br>What lesson can be learned from this?<br>	pg 5676, bottom<br>
Let <$>\frak A</$> and <$>\frak B</$> be S-structures. What does it mean for <$>\frak A</$> to be a <i>substructure</i> of <$>\frak B</$>?<br><br>What notation is used to indicate this?<br><br>	pg 5677, def 5.4<br><br>
Let <$>\frak B</$> be an S-structure. What does it mean for a set X to be S-closed in <$>\frak B</$>?<br>	pg 5677, below def 5.4<br><br>
Let <$>\frak B = (B,b)</$> be an S-structure and X ⊆ B. What does <$>[X]^{\frak B}</$> denote?<br><br>	pg 5677, below def 5.4<br>
Let <$>\frak A</$> and <$>\frak B</$> be S-structures with <$>\frak A \subset \frak B</$> and let β : {v<sub>n</sub> | n ∈ <b>N</b>} → A be an assignment in <$>\frak A</$>. Consider the following statement:<br><br>For every S-term t:<br><$$>(\frak A,\beta)(t) = (\frak B, \beta)(t)</$$><br>and for every quantifier-free S-formula φ:<br><$$>(\frak A, \beta) \vDash \phi~~~iff~~~(\frak B,\beta) \vdash \phi</$$><br><br>Prove or disprove.<br> 	pg 5677, lemma 5.5<br>todo: add impostor<br>
If <$>\frak B</$> is a group and <$>\frak A</$> a substructure of <$>\frak B</$>, does the associative law necessarily hold for <$>\frak A</$>? Why or why not? 	It does. pg 5677, near bottom.<br>
What does it mean for a predicate-logic formula to be <i>universal</i>?<br>	pg 5678, def 5.6
State and prove the substructure lemma. 	pg 5678, thm 5.7<br><br>
Do exercise 5.9, pg 5679<br>	<br>
Do exercise 5.10, pg 5679<br>	<br>
Do exercise 5.11, pg 5679<br>	<br>
Translate the following statement into formal logic terminology:<br><br>The cancellation low holds in a group <$>\frak G</$>.<br>	pg 5679, near bottom<br>
Translate the following statement into formal logic terminology:<br><br>The cancellation law holds in all groups.<br>	pg 5679, near bottom<br>
Translate the following statement into formal logic terminology:<br><br>There is no element of order two in the group (<b>Z</b>,+,0)<br><br>	pg 5679, near bottom<br>
Formalize the notion of an equivalence relation in first-order logic.<br><br>Then formalize the following fact about equivalence relations in first-order logic:<br><br><i>If x and y are both equivalent to a third element then they are<br>equivalent to the same elements.</i>	pg 5680, section 6.1<br>
How can we formalize the freshman calculus notion of continuity using first-order logic?<br>	pg 5680, section 6.2<br>
State a first-order formula that holds in any S-structure with at least two elements.<br>State a first-order formula that holds in any S-structure with exactly three elements.<br>	pg 5681, section 6.3<br><br>
Give a set of first-order formulas modeled by precisely the set of structures with infinitely many elements.	pg 5681, section 6.3<br>
What does it mean for a structure <$>\frak A = (A, <^{\frak A})</$> to be an <i>ordering</i>?<br>	pg 5681, section 6.4<br>
Read section 6.4, pg 5681 to see this book's weird definition of <i>partial ordering</i> (totally not the standard definition)<br>	<br>
Formalize the notion of a <i>field</i> (yes, the one from linear algebra) using first-order logic.<br>Also formalize the notion of an <i>ordered field</i> in first-order logic.<br>	pg 5682, section 6.5<br><br>
How do we formalize the notions of <i>graphs</i> and <i>directed graphs</i> in first-order logic?<br>	pg 5682, section 6.6<br>
Do exercise 6.7, pg 5682<br>	<br>
Do exercise 6.8, pg 5682<br>	<br>
Do exercise 6.9, pg 5682<br>refers to Exercise 4.16 on pg 5674<br><br>	<br>
Do exercise 6.10, pg 5682<br>	Let M be a finite subset of positive integers. We show that M is a spectrum.<br><br>a.)<br>Let the alphabet S = { 1, 2, 3 , ... }<br>For each n in M, we conjoin the following clause:<br><br>(c1 ≠ c2) ∧ ... ∧ (c(n-1) ≠ cn)  ensures that there are at least n elements in the carrier set<br>                                 if the current conjunct is chosen.... in fact, any carrier set with at least n works<br>                                 but we want to rule out larger carrier sets<br><br>we can rule out more by conjoining a clause of the form<br><br>(c(n+1) = c1 ∨ c(n+1) = c2 ∨ ...)<br><br>b.)<br><br>In addition to an equality predicate, we need an "is-bisimilar-to" predicate,<br>with the restriction that bisimilar atoms cannot be equal.<br><br>c.)<br><br>Here we need "left column" predicates and "top column" predicates,<br>as well as "same-column-as", "same-row-as", and "top-left-corner" predicates <br><br>We form the conjunction of <br>(c1)
State and prove the fixed point theorem.<br>	pg 5399, thm 6.1.1<br>
What is a <i>fixed point combinator</i>?<br>	pg 5399, def 6.1.2<br>
Give the definition of the Y combinator as a lambda term.	pg 5399, cor 6.1.3<br>
Give Turing's "improved" Y-combinator <b>Θ</b>. What was wrong with the original Y-combinator, and how does Turing's version fix (no pun intended) it?<br><br>	pg 5400, def 6.1.4, cor 6.1.5<br>
Construct a lambda term F such that F x y = F y x F.<br>	pg 5400, below corollary 6.1.5<br>
Let C ≡ C(f, x) be a term. Then consider the following statement:<br><br><$>\exists F. \forall \vec{N}. F~\vec{N} = C(F, \vec{N})</$><br><br>Prove or disprove.<br>	true. pg 5400, prop 6.1.6<br>
Let C ≡ C(f, x) be a term. Then consider the following statement:<br><br><$>\exists F. \forall \vec{N}. F~\vec{N} \twoheadrightarrow C(F, \vec{N})</$><br><br>Prove or disprove.<br>	pg 5400, prop 6.1.6 (ii).<br>
Give the definition of <b>Ω</b>.<br>Then define <b>Ω</b> in terms of <b>Y</b> and <b>I</b>.<br><br>	pg 5400, right page, def 6.2.1<br>
"If B then M else N" is syntactic sugar for which lambda term?<br>	B M N,<br>pg 5400, right page, def 6.2.3<br>
Given two lambda terms M and N, how do we define their Church pairing [M, N]?<br>How do we define the projections (M)<sub>0</sub> and (M<sub>1</sub>) for Church pairings?<br>	pg 5400, right page, def 6.2.4<br>
Given lambda terms M<sub>0</sub>, ..., M<sub>n</sub>, give two ways to define the ordered n-tuple [M<sub>0</sub>, ..., M<sub>n</sub>].<br><br>Also show how the projection functions for both approaches are defined.	pg 5401, left page, def 6.2.5, def 6.2.6<br>
How do we define the <i>composition</i> (M ∘ N) of two lambda terms M and N?<br>	pg 5401, left page, def 6.2.8<br><br>
<br><$>\\<br>\text{For each }n \in \mathbb N\text{ a term }\lceil n \rceil\text{ is defined as follows}\\<br>\lceil 0 \rceil \equiv \mathbf{I}, ~~~ \lceil n + 1 \rceil \equiv [\mathbf{F},\lceil n \rceil].<br></$> <br><br>Consider the following statement:<br><br>There are terms <$>\mathbf{S}^+, \mathbf{P}^-, \text{\textbf{Zero}}</$> such that<br><br><$>\\<br>\mathbf{S}^+ \lceil n \rceil = \lceil n +1 \rceil \\<br>\mathbf{P}^- \lceil n + 1 \rceil = \lceil n \rceil \\<br>\text{\textbf{Zero}} \lceil 0 \rceil = \mathbf{T} \\<br>\text{\textbf{Zero}} \lceil n+1 \rceil = \mathbf{F}\\<br></$><br><br>Prove or disprove. <br>	true. pg 5401, left page, def 6.2.9, lemma 6.2.10<br>
What is a <i>numeric function</i> what does it mean for a numeric function to be <i>λ-definable</i>?<br><br>We require that λ-calculus numeral representations be in normal form. Why is this convenient for reasoning about λ-definable numeric functions?	pg 5401, right page, def 6.3.1<br><br>the convenience is explained in the reference to Church-Rosser.<br>
A group of numeric functions called <i>initial functions</i> are useful for reasoning about recursion. They are denoted by<br><br><$>U_i^p(n_0,\ldots,n_p)~~~~~S^+(n)~~~~~Z(n)</$><br><br>Define each of these notations.<br><br>	pg 5402, top left<br>
Let P(n) be a numeric relation.<br><br>What does μm[ P(m) ] denote?<br>	make sure to mention the undefined case<br>pg 5402, left page, below def 6.3.2<br><br>
Let <$>\mathcal A</$> be a class of numeric functions. What does it mean for <$>\mathcal A</$> to be <i>closed under composition</i>?<br>	pg 5402, left page, def 5.3.3 (i)<br><br>
Let <$>\mathcal A</$> be a class of numeric functions. What does it mean for <$>\mathcal A</$> to be <i>closed under primitive recursion</i>?<br>	pg 5402, left page, def 5.3.3 (ii)<br>
Let <$>\mathcal A</$> be a class of numeric functions. What does it mean for <$>\mathcal A</$> to be <i>closed under minimialization</i>?<br>	pg 5402, left page, def 5.3.3 (iii)<br>
Define the class <$>\mathcal R</$> of <i>recursive numeric functions</i>.<br>	pg 5402, left page, def 6.3.4<br>
Consider the following statement:<br><br>The initial functions are λ-definable.<br><br>Prove or disprove.<br>	pg 5402, left page (bottom), lemma 6.3.5<br>TODO: add impostor<br>
Consider the following statement:<br><br>The initial functions are not λ-definable.<br><br>Prove or disprove.<br>	IMPOSTOR. pg 5402, left page (bottom), lemma 6.3.5<br>TODO: add impostor<br>
Consider the following statement:<br><br>The λ-definable functions are closed under composition.<br><br>Prove or disprove.<br>	true. pg 5402, top right. lemma 6.3.6<br>
Consider the following statement:<br><br>The λ-definable functions are closed under primitive recursion.<br><br>Prove or disprove.<br>	pg 5402, top left, lemma 6.3.7
How can we define, as a lambda term, the minimalization μP of a lambda-defined boolean predicate P?	pg 5402, right page, def 6.3.8, prop 6.3.9<br><br>
A group is called a <i>torsion group</i> when every element of the group has finite order. Why is the formalization of torsion groups beyond the reach of first-order logic?<br>	pg 5685, near top (1)<br><br>
It's often desirable to use first-order logic to model partial functions, for example the division operator on the real numbers. The first-order logic framework doesn't have any obvious built-in mechanisms to handle partial functions, however. List three ways to deal with this.<br><br><br>	pg 5683, section 7.1<br>
The basic framework of first order logic models a formula using a single carrier set. What happens when we wish to have terms which are modeled by various carrier sets (such as vector spaces with both field and vector terms)? In other words, how to do we accomodate many-sorted languages?<br><br>There are two approaches. Explain both. One involves expanding the first order logic framework. The other involves a "hack" that lets us work within it.<br><br> 	pg 5684<br>
The Peano axiom system is an axiomatization of the natural numbers. Give the three of its axioms, and explain why their formalization is beyond the reach of first-order logic.<br>	pg 5685 (section 2)<br><br>
State and prove Dedekind's theorem.<br>	pg 5685 (veeery bottom) / pg 5686<br>
pg 5686, exercise 7.5 (bottom of page)<br>	<br>
Consider the following statement:<br><br>The λ-definable functions are closed under minimalization.<br><br>Prove or disprove.<br>	pg 5403, lemma 6.3.10<br><br>
Consider the following statement:<br><br>All recursive functions are λ-definable.<br><br>Prove or disprove.<br>	true. pg 5403, left page, prop 6.3.11.<br><br>
Let φ be λ-defined by F. Then for all <$>\vec{n}, m \in \mathbb N</$><br><br><$>\varphi(\vec{n}) = m \Leftrightarrow F \lceil \vec n \rceil = \lceil m \rceil</$><br><br>Prove or disprove	true. pg 5403.<br>
Consider the following statement:<br><br>The λ-definable numeric functions are exactly the recursive functions.<br><br>Prove or disprove.<br>	true. pg 5403, left page, thm 6.3.13<br>
Let R ⊆ <b>N</b><sup>k</sup> be a relation. Then R is recursive iff there is a term F such that<br><br><$>F \lceil \vec n \rceil = T \Leftrightarrow R(\vec{n})</$><br><$>F \lceil \vec n \rceil = F \Leftrightarrow \neg R(\vec n)</$><br><br>Prove or disprove.<br>	true. pg 5403, right page. cor 6.3.14<br>
What does it mean for a term F to λ-define a numeric relation R ⊆ <b>N</b><sup>k</sup>?<br>	pg 5403, right page, directly above section 6.4<br><br>
What is a <i>numeral system</i>?<br>What is a <i>normal numeral system</i>?<br>What is the <i>standard numeral system</i>?<br>	pg 5403, bottom right, def 6.4.1<br><br>
Let d be a numeral system.<br><br>What does it mean for a numeric function φ : <b>N</b><sup>p</sup> → <b>N</b> to be <i>λ-definable with respect to d</i>?<br>	pg 5405, top left, def 5.4.2 (i)<br>
Let d be a numeral system.<br><br>What does it mean for d to be <i>adequate</i>?<br><br>	pg 5404, top left, def 6.4.2 (ii)<br>
Let d be a numeral system. Consider the following statement:<br><br>d is adequate iff<br><br><$>\exists P_d^-~\forall n \in \mathbb N~~~P_d^- d_{n+1} = d_n</$><br><br>Prove or disprove.<br>	true. 5404, top left, prop 6.4.3<br><br>todo: add impostor?
Give the definition of the <i>Church numerals</i>, as well as the successor function on Church numerals.<br>	pg 5404, left page, def 6.4.4
Let c<sub>0</sub>,c<sub>1</sub>,... be the Church numerals and <br><$>\lceil 0 \rceil, \lceil 1 \rceil, \ldots</$> be the standard numerals.<br><br>Consider the following statement:<br><br>There are H, H<sup>-1</sup> ∈ Λ such that for all n ∈ <b>N</b><br><br><$>H \lceil n \rceil = c_n</$><br><$>H^{-1}c_n = \lceil n \rceil</$><br><br>Prove or disprove.<br><br><br>	pg 5404, bottom left, lemma 6.4.5<br>
Consider the following statement:<br><br>The Church numerals are an adequate numeral system.<br><br>Prove or disprove.<br>	true. pg 5404, bottom left/top right, corollary 6.4.6<br>
What does it mean for a formula A in a first-order language to be in the <i>negative fragment</i>?<br>	pg 79, def 3.1 near top
What does <b>MQC</b> denote?<br>	pg 79, def 3.2<br><br>
What do <$>\vdash_c, \vdash_m</$>, and <$>\vdash_i</$> denote?<br>	pg 79, def 3.2<br>
How can we characterize the role of ⊥ in <b>MQC</b>?<br>	pg 79, N.B. below section 3.2<br>
Let A be a negative formula. Consider the following statement:<br><br><$>\mathbf{MQC} \vdash A \leftrightarrow \neg \neg A</$><br><br>Prove or disprove	true. pg 79, lemma 3.3<br>
Give the Godel-Gentzen <i>negative translation</i> from first-order formulas to negative first-order formulas.<br>	pg 79, def 3.4<br>
What are the two properties of the Godel-Gentzen negative translation which make it so useful? Prove that these properties hold.<br>	pg 80, top thm 3.5<br>
Consider the following statement:<br><br>For negative A, <$>\mathbf{CQC \vdash A}~\text{iff}~\mathbf{IQC} \vdash A</$><br><br>Prove or disprove.<br>	true. pg 81, corollary 3.6<br>
Read section 3.7 on pg 81, and prove proposition 3.8<br>	<br>
What is a "subformula occurrence"? Is there a shorthand abbreviation for the term "subformula occurrence"?<br>	pg 82, section 3.9<br>spills over to pg 83<br>
What is a <i>formula context</i>? <br><br>	pg 82, below example near top
What does <$>\mathcal {CON}</$> denote?<br>	pg 82, definition in middle of page. <$>\mathcal{CON}</$> is just the set of all first-order formula contexts.<br>
Explain how an sfo can be specified as a pair (F,B).<br>	pg 82, bottom paragraph, spills over onto pg 83<br><br>
Provide the definitions of the set of positive contexts <$>\mathcal{POS}</$> and the set of negative contexts <$>\mathcal{NEG}</$> using mutually referential inductive definitions.<br>	pg 83, definition 3.11
Are the following contexts positive, negative, or neither?<br><br><$>C[\ast] \equiv \forall x ( P(x) \to Q ) \to \ast</$><br><br><$>B[\ast] \equiv \forall x ( P(x) \to \ast ) \to Q</$><br> 	1.) pos<br>2.) neg<br><br>example on pg 83<br>
What does it mean for a set L of lattice elements to be <i>filtered</i>?<br>	pg 7428<br>
What is a <i>net</i>?<br>	pg 7428, def 1.2<br>
Let <$>j \mapsto x_j : J \to L</$> be a net. What does it mean for some property P(x) for x ∈ L to <i>hold eventually</i>?<br>	pg 7428, bottom of def 1.2<br>
Let L carry a preorder. What does it mean for a net <$>j \mapsto x_j : J \to L</$> to be a <i>directed net</i>?<br>	pg 7428, definition 1.2, bottom paragraph<br>
What is an <i>upper set</i>? A <i>lower set</i>? An <i>ideal</i>? A <i>filter</i>?<br>	pg 7429, def 1.3<br>
What is a <i>principal ideal</i>? A <i>principal filter</i>?	pg 7429, def 1.3
Let L be a set with a preorder.<br><br>What do the following notations mean?<br><br>-Id L<br>-Id<sub>0</sub>L<br>-Filt<sub>0</sub>L<br>	pg 7429, def 1.3 (xi) - (xiii)
Let L be a preorderd set and X ⊆ L. Consider the following statement:<br><br>The following are equivalent:<br>(1) X is directed<br>(2) ↓X is directed<br>(3) ↓X is an ideal<br><br>Prove or disprove.<br>	pg 7429, remark 1.4<br><br>
Let L be a preordered set and X ⊆ L. Consider the following statement:<br><br>The following are equivalent:<br>(1) sup X exists<br>(2) sup ↓X exists.<br><br>And if these conditions are satisified then sup X = sup ↓X. Moreover, if every finite subset of X has a sup and if F denotes the set of all those finite sups, then F is directed, and (1) and (2) are equivalent to:<br><br>(3) sup F exists.<br><br>Prove or disprove.	true. pg 7429, remark 1.5<br>todo: add impostor<br>
Statements about arbitrary sups can often be reduced to statements about finite sups and sups of directed sets. Why is this?	pg 7430
What is a <i>semilattice</i>? (i.e. is the default a <i>sup</i> semi-lattice or a <i>inf</i> semi-lattice?<br>	pg 7431, def 1.8<br>
What is a <i>unital</i> semi-lattice? 	pg 7431, def 1.8<br>
What does it mean for a function f between to posets to preserve:<br><br>1.) finite infs<br>2.) arbitrary infs<br>3.) filtered infs<br><br>?<br>	pg 7431, def 1.9<br>
What is a <i>semilattice homomorphism</i>? Prove that semilattice homomorphisms are monotone.	pg 7432, top paragraph
Let f : S → T be a function between posets. Consider the following statement:<br><br>The following are equivalent:<br>1) f preserves directed sups.<br>2) f preserves sups of ideals<br><br>Moreover, if S is a sup-semilattie and f preserves finite sups, then (1) and (2) are also equivalent to:<br><br>3) f preserves arbitrary sups<br><br>Prove or disprove.<br>	true. pg 7432, remark 1.10<br>todo: add impostor?<br>
Exercise 1.11, pg 7433<br>	<br>
Exercise 1.12, pg 7433<br>	<br>
Exercise 1.13, pg 7433<br>	<br>
Exercise 1.14, pg 7433<br>	<br>
Exercise 1.15, pg 7433<br>	<br>
Exercise 1.16, pg 7434<br>	<br>
Let M and N be models of an algebraic theory Th in a category <b>C</b> with finite products. What is a <i>homomorphism</i> from M to N?<br>	pg 4179 (right) 
Let <b>C</b> be a category with finite products and Th an algebraic theory. Then what does Mod(Th,C) denote?<br>	pg 4179 (right)
Let <b>C</b> and <b>D</b> be categories with finite products. What is the category FP(C,D)?<br>	pg 4179, right, near bottom<br>
Given categories C and D, verify that the functor category [C, D] is indeed a category.<br>	pg 4173, left page, top, exercise 2.2.4 (1)
Exercise 2.4.4 (2), pg 4137, top left<br>	<br>
Let C and D be categories and F : C → D and G : D → C be functors. <br>What does F : C ≃ D : G mean?	pg 4173 (bottom right), above example 2.5.6<br>
Consider the following statement:<br><br><b>Part</b> ≃ 1/<b>Sets</b><br><br>(Recall that <b>Part</b> is the category of sets and partial functions)<br><br>Prove or disprove.	pg 4137, bottom right<br>
Exercise 2.5.7 (1), pg 4138, bottom left<br>	<br>
Exercise 2.5.7 (3), pg 4138, bottom left<br>	<br>
Given a finite product-preserving functor F, how is the functor F<sub>•</sub> : Mod(Th,C) → Mod(Th, D) defined and what is its purpose?<br>	The definition is on page 4180, left side<br><br>Its purpose is for the definition of Ap<sub>M</sub>, on the top right of page 4180.<br>
<latex><br>If $\phi$ is a natural transformation between finite product-preserving functors F, G : C → D and M is an object of $\mathcal{M}od$(\emph{Th},$\mathcal C$), how is the homomorphism $\phi_{\ast}M : F_{\ast} M \to G_{\ast}M$ defined? What is its purpose? Show that $\phi_{\ast} M$ is indeed a homomorphism of models.<br></latex><br>	The definition is on page 4180, left side<br><br>Its purpose is for the definition of Ap<sub>M</sub>, on the top right of page 4180.
In quelea terminology, what is an <i>effect</i>?<br>	pg 6309, top right col
In quelea terminology, what is a <i>session</i>?<br>	pg 6309, right column, near top<br>
In Quelea, clients are oblivious to which replica an operation is routed. Why is this?<br>	pg 6309, right column near top<br>
What does the notation vis(w<sub>1</sub><sup>x</sup>, w<sub>2</sub><sup>x</sup>)<br>mean?<br>	pg 6309, right column<br>
True or false:<br><br>The vis relation is reflexive.<br>	false, pg 6309, right column
True or false:<br><br>The vis relation is asymmetric<br>	true. pg 6309, right column
True or false:<br><br>The vis relation relates only effects produced by operations on the same object.<br>	true. pg 6309, right column.<br>
How does Quelea resolve concurrent conflicting updates?<br>	It just hands resolution off to the reader.<br><br>pg 6309, right column.<br>
What does the notation so(w<sub>4</sub><sup>x</sup>, w<sub>5</sub><sup>x</sup>) mean?<br>	pg 6309, right column.<br>
What does the notation oper(w<sub>4</sub><sup>x</sup>, foo) mean?<br> 	pg 6309, right column
Quelea separates a datatype's <i>convergence semantics<i> from its <i>consistency properties</i>. Elaborate on this.<br>	pg 6309, bottom right<br>pg 6310, top left<br>
Give Quelea's <i>Operation</i> type using Haskell syntax.<br>	pg 6310, left column<br>
Give Quelea source code for a bank account datatype and its operations.<br>	pg 6310, left column<br>
What does it mean for two RDT values to be <i>observably equivalent</i>?<br>What is a <i>summarization function</i> for an RDT?<br><br>	pg 6310, left column, section 3.1.1<br>
Explain the three anomolies shown in figure 3, in the right column on page 6310.<br>	pg 6310 (duh)<br>
What does it mean for an operation to be <i>strongly consistent</i>?<br>	pg 6311, left column<br>
Write a Quelea contract requiring that an operation (called, say, withdraw) is strongly consistent.<br>	pg 6311, left column
What is a smart constructor? How can a smart constructor be used to help implement a purely functional queue?<br>	pg 6348<br>
Why do the traditional banker's and physicist's approaches break down when performing amortized analysis of <i>persistent</i> data structures?<br>	pg 6350<br>
What is an <i>execution trace</i>?<br>	pg 6350, near bottom<br>pg 6351, near top<br><br>
Provide the definitions for <i>shared costs</i>, <i>unshared costs</i>, <i>realized costs</i> , <i>unrealized costs</i>, and <i>complete cost</i> of persistent data structure operations.<br><br>	pg 6352, 6353<br>
What is the <i>amortized cost</i> of an operation in a persistent data structure?<br>	pg 6353<br>
What are the three important moments in the lifecycle in a suspended computation (for persistent data structures)?<br>	pg 6535<br>
Explain why debt is sometimes paid off more than once in Okasaki's strategy for analyzing persistent data structures.<br>	pg 6353, bottom paragraph<br>
Explain how number systems (unary, binary, etc.) influence the design of data structures.<br>	pg 6392<br>**especially important info on pg 6393<br>
What is a <i>positional number system</i>? What does it mean for a positional number system to be <i>redundant</i>?<br>	pg 6393
What is the difference between <i>dense</i> and <i>sparse</i> number systems?<br>	pg 6394<br>
What is a <i>complete binary leaf tree</i>?<br>	pg 6395<br>
Relating to binomial trees, what is a <i>pennant</i>?<br>	pg 6395<br>
Explain <i>linking</i> and <i>unlinking</i> operators for complete binary leaf trees, binomial trees, and pennants.<br> 	pg 6395 bottom<br>pg 6396 bottom<br><br>
What does it mean for a tree to be <i>heap-ordered</i>?<br>	pg 6402<br>
How can we determine the number of trees in a binomial heap from looking at number of elements contained by the heap?	pg 6402, bottom paragraph<br>
Give ML type declarations for binomial trees.<br>How are the children of a binomial tree ordered?<br>Explain the <i>link</i> operation on binomial trees.<br>	pg 6402, top half of page<br>
Exercise 2.1.1, pg 125<br>(skip the first two, already done those... answers on back of card)	First formula<br><$$><br>\begin{prooftree}<br>\AxiomC{$A~(2)$}<br>\AxiomC{$A \to B~(3)$}<br>\BinaryInfC{$B$}<br>\AxiomC{$\neg B~(1)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg A~(2)$}<br>\UnaryInfC{$\neg B \to \neg A~(1)$}<br>\UnaryInfC{$(A \to B) \to (\neg B \to \neg A)~(3)$}<br>\end{prooftree}<br></$$><br><br>Second formula<br><$$><br>\begin{prooftree}<br>\AxiomC{$A \to B~(4)$}<br>\AxiomC{$A~(3)$}<br>\BinaryInfC{$B$}<br>\AxiomC{$\neg B~(2)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg (A \to B)~(4)$}<br>\AxiomC{$\neg \neg (A \to B)~(1)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$\neg \neg B~(2)$}<br>\UnaryInfC{$A \to \neg \neg B~(3)$}<br>\UnaryInfC{$\neg \neg (A \to B) \to (A \to \neg \neg B)~(1)$}<br>\end{prooftree}<br></$$>
Exercise 2.1.2, pg 125<br>	<br>
Exercise 2.1.3, pg 126<br>	<br>
Exercise 2.1.4, pg 126<br>	<br>We first prove left to right.<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(0)~(A \vee \neg A) \wedge (A \vee \forall x. B(x))$}<br>\UnaryInfC{$A \vee \neg A$}<br><br>\AxiomC{$(0)~(A \vee \neg A) \wedge (A \vee \forall x. B(x))$}<br>\UnaryInfC{$A \vee \forall x. B(x)$}<br><br>\AxiomC{$(1)~A$}<br>\UnaryInfC{$A \vee B(x)$}<br><br>\AxiomC{$(1)~\forall x. B(x)$}<br>\UnaryInfC{$B(x)$}<br>\UnaryInfC{$A \vee B(x)$}<br><br>\TrinaryInfC{$(1)~A \vee B(x)$}<br><br>\BinaryInfC{$(A \vee \neg A) \wedge (A \vee B(x))$}<br><br>\UnaryInfC{$\forall x. (A \vee \neg A) \wedge (A \vee B(x))$}<br><br>\UnaryInfC{$(0)~(A \vee \neg A) \wedge (A \vee \forall x. B(x)) \to <br>                           \forall x.~(A \vee \neg A) \wedge (A \vee B(x))$}<br><br>\end{prooftree}<br></$>
Exercise 2.1.5, pg 126<br>	<br><br><br>% move above to "here is one such theorem. the other follows from duality"<br><br>First the lemma:<br><br>Suppose neither A nor B is negated and all quantifiers are universal.<br><br>Intuitionistically:<br>Applying exercise 2.1.4 from right to left strips off one universal quantifier, taking us a step closer from C to A \/ B. We end up with (S \/ \neg S) /\ (A \/ B); using /\-elimination gives us what we want.<br><br>We can get from (S \/ \neg S) /\ (A \/ B) to C, but not from (A \/ B) to C.<br><br>Classically:<br>Here going from C to (A \/ B) is the same. But because (S \/ \neg S) is a theorem in classical predicate logic, we can go from (A \/ B) to C as well, and so we have the bimplication needed to show that C majorizes A \/ B.<br><br>--<br><br>How does negating A and/or B change things?<br><br>I think we need to prove new theorems showing that peeling a quantifier off a negated<br>prenex term can be done, but flips the quantitifer (between universal and existential)<br><br>Here is one such theorem, the other follows from duality:<br><br>First we prove <$>(s \vee \neg s) \wedge (s \vee \neg \exists x. t(x)) <br>                     \to (\forall x. (s \vee \neg s) \wedge (s \vee \neg t(y)))</$><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~(s \vee \neg s) \wedge (s \vee \neg \exists x. t(x))$}<br>\UnaryInfC{$s \vee \neg s$}<br><br>\AxiomC{$(1)~(s \vee \neg s) \wedge (s \vee \neg \exists x. t(x))$}<br>\UnaryInfC{$s \vee \neg \exists x. t(x)$}<br>\AxiomC{$(2)~s$}<br>\UnaryInfC{$s \vee \neg t(y)$}<br>\AxiomC{$(2)~\neg \exists x. t(x)$}<br>\AxiomC{$(3)~t(y)$}<br>\UnaryInfC{$\exists x. t(x)$}<br>\BinaryInfC{$\bot$}<br>\UnaryInfC{$(3)~\neg t(y)$}<br>\UnaryInfC{$s \vee \neg t(y)$}<br><br>\TrinaryInfC{$(2)~s \vee \neg t(y)$}<br>\BinaryInfC{$(s \vee \neg s) \wedge (s \vee \neg t(y))$}<br>\UnaryInfC{$\forall x. (s \vee \neg s) \wedge (s \vee \neg t(y))$}<br>\UnaryInfC{$(1)~(s \vee \neg s) \wedge (s \vee \neg \exists x. t(x)) <br>                     \to (\forall x. (s \vee \neg s) \wedge (s \vee \neg t(y)))$}<br><br>\end{prooftree}<br></$><br><br>Then we prove from right to left.<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~\forall x. (s \vee \neg s) \wedge (s \vee \neg t(x))$}<br>\UnaryInfC{$(s \vee \neg s) \wedge (s \vee \neg t[x/\bot])$}<br>\UnaryInfC{$s \vee \neg s$}<br><br>\AxiomC{$(2)~\exists x. t(x)$}<br>\AxiomC{$(3)~t(y)$}<br>\AxiomC{$(1)~\forall x. (s \vee \neg s) \wedge (s \vee \neg t(x))$}<br>\UnaryInfC{$(s \vee \neg s) \wedge (s \vee \neg t(y))$}<br>\UnaryInfC{$s \vee \neg t(y)$}<br>\UnaryInfC{$\neg t(y)$}<br>\BinaryInfC{$\bot$}<br>\BinaryInfC{$(3)~\bot$}<br>\UnaryInfC{$(2)~\neg \exists x. t(x)$}<br>\UnaryInfC{$s \vee \neg \exists x. t(x)$}<br><br>\BinaryInfC{$(s \vee \neg s) \wedge (s \vee \neg \exists x. t(x))$}<br><br>\UnaryInfC{$(1)~(\forall x. (s \vee \neg s) \wedge (s \vee \neg t(x))) \to<br>                           ((s \vee \neg s) \wedge (s \vee \neg \exists x. t(x)))$}<br><br>\end{prooftree}<br></$><br><br>--<br><br>The problem mentions all quantifiers, both existential and universal - can we derive a<br>similar theorem to E2.1.4, but for existential quantifiers?<br><br>First we go from left to right intuitionistically:<br>We want <$>(A \vee \neg A) \wedge (A \vee \exists x. B(x)) \rightarrow \exists x. ( (A \vee \neg A) \wedge (A \vee B(x) ) )</$><br><br>Here is our proof.<br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~(A \vee \neg A) \wedge (A \vee \exists x B(x))$}<br>\UnaryInfC{$A \vee \exists x. B(x)$}<br><br>\AxiomC{$(2)~A$}<br>\UnaryInfC{$A \vee \neg A$}<br>\AxiomC{$(2)~A$}<br>\UnaryInfC{$A \vee B[x/\bot]$}<br>\BinaryInfC{$(A \vee \neg A) \wedge (A \vee B[x/\bot])$}<br>\UnaryInfC{$\exists x. (A \vee \neg A) \wedge (A \vee B(x))$}<br><br>\AxiomC{$(2)~\exists x.~B(x)$}<br>\AxiomC{$(1)~(A \vee \neg A) \wedge (A \vee \exists x. B(x))$}<br>\UnaryInfC{$A \vee \neg A$}<br>\AxiomC{$B(y)~(3)$}<br>\UnaryInfC{$A \vee B(y)$}<br>\BinaryInfC{$(A \vee \neg A) \wedge (A \vee B(y))$}<br>\UnaryInfC{$\exists x.(A \vee \neg A) \wedge (A \vee B(x))$}<br>\BinaryInfC{$\exists x. (A \vee \neg A) \wedge (A \vee B(x))~(3)$}<br><br>\TrinaryInfC{$(2)~\exists x. (A \vee \neg A) \wedge (A \vee B(x))$}<br>\UnaryInfC{$(1)~(A \vee \neg A) \wedge (A \vee \exists x. B(x)) <br>                            \to \exists x. (A \vee \neg A) \wedge (A \vee B(x))$}<br>\end{prooftree}<br></$><br><br>Now we go from right to left intuitionistically:<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~\exists x.~(A \vee \neg A) \wedge (A \vee B(x))$}<br>\AxiomC{$(2)~(A \vee \neg A) \wedge (A \vee B(y))$}<br>\UnaryInfC{$A \vee \neg A$}<br>\BinaryInfC{$(2)~A \vee \neg A$}<br><br>\AxiomC{$(1)~\exists x. (A \vee \neg A) \wedge (A \vee B(x))$}<br>\AxiomC{$(3)~(A \vee \neg A) \wedge (A \vee B(y))$}<br>\UnaryInfC{$A \vee B(y)$}<br>\AxiomC{$(4)~A$}<br>\UnaryInfC{$A \vee \exists x. B(x)$}<br>\AxiomC{$(4)~B(y)$}<br>\UnaryInfC{$\exists x. B(x)$}<br>\UnaryInfC{$A \vee \exists x. B(x)$}<br>\TrinaryInfC{$(4)~A \vee \exists x. B(x)$}<br>\BinaryInfC{$A \vee \exists x. B(x)$}<br><br>\BinaryInfC{$(A \vee \neg A) \wedge (A \vee \exists x. B(x)))$}<br><br>\UnaryInfC{$(1)~(\exists x. (A \vee \neg A) \wedge (A \vee B(x))) <br>                            \to ((A \vee \neg A) \wedge (A \vee \exists x. B(x)))$}<br>\end{prooftree}<br></$><br><br><br><br>END PROOF OUTLINE FOR LEMMA -----
Exercise 2.1.6, pg 126<br>	<br>
Exercise 2.1.7, pg 126<br>	<br>
Exercise 2.1.8, pg 126<br>	<br>
Exercise 2.1.9, pg 127<br>	<br>
Exercise 2.2.1, pg 127<br>	<br>
Exercise 2.2.2, pg 127<br>	First we prove <$>t \simeq s \wedge t' \simeq s \to t \simeq t'</$>, which is a simple application of the replacement rule on pg 74<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(0)~t \simeq s \wedge t' \simeq s$}<br>\RightLabel{\tiny{repl}}<br>\UnaryInfC{$t' \simeq t'$}<br>\UnaryInfC{$(0)~(t \simeq s \wedge t' \simeq s) \to (t \simeq t')$}<br>\end{prooftree}<br></$><br><br>We next prove <$>t \simeq s \to s \simeq t</$>:<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(0)~t \simeq s$}<br>\AxiomC{$(0)~t \simeq s$}<br>\BinaryInfC{$t \simeq s \wedge t \simeq s$}<br>\AxiomC{$(t \simeq s \wedge t \simeq s) \to (s \simeq s)$}<br>\RightLabel{\tiny{repl}}<br>\BinaryInfC{$s \simeq s$}<br>\AxiomC{$(0)~t \simeq s$}<br>\BinaryInfC{$s \simeq s \wedge t \simeq s$}<br>\AxiomC{$(s \simeq s \wedge t \simeq s) \to (s \simeq t)$}<br>\RightLabel{\tiny{repl}}<br>\BinaryInfC{$s \simeq t$}<br>\UnaryInfC{$(0)~(t \simeq s) \to (s \simeq t)$}<br>\end{prooftree}<br></$><br><br>Now we will prove that <$>t=s \wedge t'=s \to t=t'</$> using the helpful proposition<br>near the top of page 76 that <$>IQCE \vdash t = s \leftrightarrow (Et \wedge Es \wedge t \simeq s)</$><br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~t=s \wedge t'=s$}<br>\UnaryInfC{$t=s$}<br>\RightLabel{\tiny{pg 76}}<br>\UnaryInfC{$Et \wedge Es \wedge t \simeq s$}<br>\UnaryInfC{$E t \wedge E s$}<br>\UnaryInfC{$E t$}<br><br>\AxiomC{$\vdots$}<br>\noLine<br>\UnaryInfC{$E t'$}<br><br>\AxiomC{$(0)~t = s \wedge t' = s$}<br>\UnaryInfC{$t=s$}<br>\RightLabel{\tiny{pg 76}}<br>\UnaryInfC{$t \simeq s$}<br>\AxiomC{$(0)~t = s \wedge t' = s$}<br>\UnaryInfC{$t'=s$}<br>\RightLabel{\tiny{pg 76}}<br>\UnaryInfC{$t' \simeq s$}<br>\UnaryInfC{$s \simeq t'$}<br>\RightLabel{\tiny{repl}}<br>\BinaryInfC{$t \simeq t'$}<br>\AxiomC{$(0)~t = s \wedge t' = s$}<br>\UnaryInfC{$t = s$}<br>\RightLabel{\tiny{pg 76}}<br>\UnaryInfC{$E t$}<br>\AxiomC{$(0)~t = s \wedge t' = s$}<br>\UnaryInfC{$t' = s$}<br>\RightLabel{\tiny{pg 76}}<br>\UnaryInfC{$E t'$}<br>\RightLabel{\tiny{pg 76}}<br>\TrinaryInfC{$t = t'$}<br>\UnaryInfC{$(0)~(t = s \wedge t' = s) \to (t=t')$}<br>\end{prooftree}<br></$><br><br>TODO: finish the rest of the problem
Exercise 2.2.3, pg 127<br>	First we prove <$>\forall x. x \simeq x</$>.<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~x \simeq y$}<br>\AxiomC{$\forall z.~(x \simeq z \leftrightarrow x \simeq z) \to x \simeq x$}<br>\AxiomC{$(2)~E z$}<br>\noLine<br>\UnaryInfC{$\vdots$}<br>\noLine<br>\UnaryInfC{$x \simeq z \leftrightarrow x \simeq z$}<br>\UnaryInfC{$(2)~\forall z. x \simeq z \leftrightarrow x \simeq z$}<br>\BinaryInfC{$x \simeq x$}<br>\BinaryInfC{$x \simeq y \wedge x \simeq x$}<br>\AxiomC{$x \simeq y \wedge x \simeq x \to y \simeq x$}<br>\BinaryInfC{$y \simeq x$}<br>\UnaryInfC{$(1)~(x \simeq y) \to (y \simeq x)$}<br>\end{prooftree}<br></$><br><br>Now for transitivity, which is a bit confusing because the roles of x and y are <br>swapped from those of the replacement rule.<br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(1)~x \simeq y \wedge y \simeq z$}<br>\UnaryInfC{$x \simeq y$}<br>\AxiomC{$x \simeq y \to y \simeq x$}<br>\BinaryInfC{$y \simeq x$}<br>\AxiomC{$(1)~x \simeq y \wedge y \simeq z$}<br>\UnaryInfC{$y \simeq z$}<br>\BinaryInfC{$y \simeq x \wedge y \simeq z$}<br>\AxiomC{$(y \simeq x \wedge y \simeq z) \to x \simeq z$}<br>\RightLabel{(replacement)}<br>\BinaryInfC{$x \simeq z$}<br>\UnaryInfC{$(1)~(x \simeq y \wedge y \simeq z) \to x \simeq z$}<br>\end{prooftree}<br></$><br><br>We're now ready to prove the bottom sequent <$>\mathbf{IQCE}^* \vdash t \simeq s \leftrightarrow (E t \vee E s \to (E t \wedge E s \wedge t \simeq s))</$><br><br>As a first step, let's show that <$>\mathbf{IQCE}^* \vdash t \simeq s \rightarrow (E t \vee E s \to (E t \wedge E s \wedge t \simeq s))</$><br><br><$>~\\<br>\begin{prooftree}<br>\AxiomC{$(2)~E t \vee E s$}<br>\AxiomC{$(3)~E t$}<br>\AxiomC{$t \simeq s \wedge E t \to E s$}<br>\AxiomC{$(1)~t \simeq s$}<br>\AxiomC{$(3)~E t$}<br>\BinaryInfC{$t \simeq s \wedge E t$}<br>\RightLabel{\tiny{repl}}<br>\BinaryInfC{$E s$}<br>\BinaryInfC{$E t \wedge E s$}<br>\AxiomC{$(1)~t \simeq s$}<br>\BinaryInfC{$E t \wedge E s \wedge t \simeq s$}<br><br>\AxiomC{$t \simeq s \wedge E s \to E t$}<br>\AxiomC{$(1)~t \simeq s$}<br>\AxiomC{$(3)~E s$}<br>\BinaryInfC{$t \simeq s \wedge E s$}<br>\RightLabel{\tiny{repl}}<br>\BinaryInfC{$E t$}<br>\AxiomC{$(3)~E s$}<br>\BinaryInfC{$E t \wedge E s$}<br>\AxiomC{$(1)~t \simeq s$}<br>\BinaryInfC{$E t \wedge E s \wedge t \simeq s$}<br><br>\TrinaryInfC{$(3)~E t \wedge E s \wedge t \simeq s$}<br>\UnaryInfC{$(2)~(E t \vee E s) \to (E t \wedge E s \wedge t \simeq s)$}<br>\UnaryInfC{$(1)~(t \simeq s) \to ((E t \vee E s) \to (E t \wedge E s \wedge t \simeq s))$}<br>\end{prooftree}<br></$><br><br>Now we prove the opposite direction: <$>\mathbf{IQCE}^* \vdash t \simeq s \leftarrow (E t \vee E s \to (E t \wedge E s \wedge t \simeq s))</$><br><br><$>~\\<br>todo<br></$><br>%%%<br><br><br>
Exercise 2.2.4, pg 127<br>	<br>
Exercise 2.2.5, pg 127<br>	<br>
Consider the following Kripke structure, where A is a propositional atom.<br><br><$$><br>\begin{tikzpicture}<br>\draw (0,0) -- (0,1);<br>\draw [fill=black] (0,0) circle [radius=0.05];<br>\draw (0,0) circle [radius=0.1];<br>\node [left] at (0,0) {0};<br>\draw [fill=black] (0,1) circle [radius=0.05];<br>\node [left] at (0,1) {1};<br>\node [right] at (0,1) {A};<br>\end{tikzpicture}<br></$$><br><br>When interpreted in terms of intuitionistic logic, what does this structure represent?<br>Why does node 0 highlight the difference between intuitionistic and classical logic?<br>	pg 98 near top<br>
How can the following Kripke structure be simplified and why?<br><br><$$><br>\begin{tikzpicture}<br>\draw (0,0) -- (1,1);<br>\draw (0,0) -- (-1,1);<br>\draw [fill=black] (0,0) circle [radius=0.05];<br>\draw (0,0) circle [radius=0.1];<br>\node [left] at (0,0) {0};<br>\draw [fill=black] (-1,1) circle [radius=0.05];<br>\node [left] at (-1,1) {1};<br>\node [right] at (-1,1) {A};<br>\draw [fill=black] (1,1) circle [radius=0.05];<br>\node [left] at (1,1) {2};<br>\node [right] at (1,1) {$\neg A$};<br>\end{tikzpicture}<br></$$><br><br><br>	pg 98, diagram in middle of page<br>
Consider the following Kripke structure:<br><br><$$><br>\begin{tikzpicture}<br>\draw  (0,0) circle [radius = 0.1];<br>\draw  [fill] (0,0) circle [radius = 0.06];<br>\draw  [fill] (-1,1) circle [radius = 0.06];<br>\draw  [fill] (1,1) circle [radius = 0.06];<br>\node [right] at (0,0) {0};<br>\draw (0,0) -- (-1,1);<br>\node [left] at (-1,1) {A};<br>\node [above] at (-1,1) {1}; <br>\draw (0,0) -- (1,1);<br>\node [right] at (1,1) {B};<br>\node [above] at (1,1) {2};<br>\end{tikzpicture}<br></$$><br><br>Is the formula <$>(A \to B) \vee (B \to A)</$> acceptable at node 0 of this structure?	no. pg 99, above def 5.2<br>
Provide the definition of a <i>propositional Kripke model</i>.<br>	pg 99, def 5.2<br>
Consider the following statement:<br><br>In propositional Kripke semantics, we have<br><br><$>k \Vdash \neg A \Leftrightarrow \forall k' \geq k.~k'  \not \Vdash A</$><br><br>Prove or disprove.<br>	true. pg 99, very bottom
Consider the following statement:<br><br>In propositional Kripke semantics, we have:<br><br><$>k \Vdash \neg \neg A \Leftrightarrow \forall k' \geq k.~\neg \forall k'' \geq k'.~k'' \not \Vdash A</$><br><br>Prove or disprove:<br><br>	true. pg 100, very top<br>
Consider the following statement:<br><br>For all formulas A of <b>IPC</b> we have:<br><br><$>\forall k, k' \in \mathcal{K}.~(k \Vdash A \text{ and } k' \geq k) \Rightarrow k' \Vdash A</$><br><br>Prove or disprove.<br>	true. pg 100, lemma 5.3<br>todo: add impostor<br>
When is a formula <i>valid at world k</i> of a propositonal Kripke model <$>\mathcal K</$>?<br>What does <$>\mathcal K \Vdash A</$> mean? If <$>\Gamma</$> is a set of formulas, what does <$>\Gamma \Vdash A</$> mean? What does <$>\Vdash A</$> mean?<br>	pg 100, def 5.4<br>
Suppose that <$>\mathcal K \equiv (K,\leq,\Vdash)</$> is a propositional Kripke model and <$>k \in \mathcal K</$>. Then what does <$>\mathcal K_k</$> denote?<br>	pg 100, remark below def 5.4<br>
Let <$>\mathcal K \equiv (K, \leq ,\Vdash),~k \in K,~\mathcal K_k \equiv (K', \leq', \Vdash')</$>.<br><br>Consider the following statement:<br><$>k \Vdash A \text{ iff } \mathcal K_k \Vdash' A \text{ iff } k \Vdash' A</$><br><br>Prove or disprove.<br><br>	pg 100, remark.<br>todo: add impostor?<br>
Is <$>k \Vdash P</$> assumed to be decidable in the Kripke semantics of <b>IPC</b>?<br>	no<br>pg 100, remark 5.5<br>
Discuss the meaning of the terms "external reasoning" and "internal reasoning" in the context of Kripke models for intuitionistic logic.<br>	pg 100, remark 5.5, second paragraph
Give a Kripke model which, under classical external reasoning, is equivalent to a classical propsitional valuation with truth values in {0,1}. <br>	the model must contain a single node<br>pg 101 above example 5.6<br>
Consider the following statement:<br><br><$>\neg \neg P \vee \neg P</$> is not K-valid.<br><br>Prove or disprove.<br>	todo: add counterexample.<br>pg 101, example 5.6<br>
Show that <$>(P \to Q) \vee (Q \to P)</$> is not K-valid.<br>	todo: add impostor?<br>pg 101, second example in 5.6
Show that <$>(\neg \neg P \to P) \vee (\neg P \vee \neg \neg P)</$> is not K-valid.<br>	todo: add impostor?<br>pg 101, third example in 5.6<br>
Provide the definition of a <i>Kripke model for <b>IQC</b></i>.<br>	pg 102, def 5.7<br>
Consider the following statement:<br><br>For a Kripke model <$>\mathcal K</$> for IQC, we have:<br><$>(k \Vdash A \text{ and } k' \geq k) \Rightarrow k'<br> \Vdash A</$><br><br>Prove or disprove.<br><br>	pg 103, remark above 5.8<br>todo: add impostor?<br>
Read remark 5.8 on pg 103<br>	<br>
Consider the following <b>IQC</b> Kripke model:<br><br><$$><br>\begin{tikzpicture}<br>\draw (0,0) -- (0,1);<br>\draw (0,0) circle [radius=0.1];<br>\draw [fill] (0,0) circle [radius=0.06];<br>\draw [fill] (0,1) circle [radius=0.06];<br>\node [left] at (0,0) {0};<br>\node [right] at (0,0) {$\{ a \}~~~R'(a)$};<br>\node [left] at (0,1) {1}; <br>\node [right] at (0,1) {$\{ a, b \}~R, R'(a)$};<br>\end{tikzpicture}<br></$$><br><br>Do we have the following?<br><$>0 \Vdash \forall x (R \vee R'(x)) \to R \vee \forall x R'(x)</$><br><br>Prove or disprove.	The formula does not hold.<br>pg 104, first example from 5.9<br><br>todo: add impostor (or non-impostor)?<br>
Consider the following <b>IQC</b> Kripke model<br><br><$$><br>\begin{tikzpicture}<br>\node at (-2,0) {$k_0$};<br>\node at (-2,1) {$k_1$};<br>\node at (-2,2) {$k_2$};<br>\node at (-2,3) {$k_3$};<br>\node at (-2,4) {$k_3$};<br><br>\node at (0,0) {$\{ 0 \}$};<br>\node at (0,1) {$\{ 0,1 \}$};<br>\node at (0,2) {$\{ 0,1,2 \}$};<br>\node at (0,3) {$\{ 0,1,2,3 \}$};<br>\node at (0,4) {$\{ 0,1,2,3,4 \}$};<br><br>\draw (0,0.3) -- (0,0.7);<br>\draw (0,1.3) -- (0,1.7);<br>\draw (0,2.3) -- (0,2.7);<br>\draw (0,3.3) -- (0,3.7);<br>\draw [dotted] (0,4.3) -- (0,4.7);<br><br><br>\node [right] at (1,0) {$~$};<br>\node [right] at (1,1) {$R0$};<br>\node [right] at (1,2) {$R0,~R1$};<br>\node [right] at (1,3) {$R0,~R1,~R2$};<br>\node [right] at (1,4) {$R0,~R1,~R2,~R3$};<br><br>\end{tikzpicture}<br></$$><br><br>Does this model satisfy <$>\neg \neg \forall x.~(R(x) \vee \neg R(x))</$>?<br><br>	No it does not.<br>pg 104, second example in 5.9<br><br>todo: add non-impostor?<br>
Consider the following statement:<br><br>For pure <b>IQC</b>, we have the following formula holds<br><$>\Gamma \vdash A \Rightarrow \Gamma \Vdash A</$><br><br>Prove or disprove.<br>	<br>the proof is too long. A proof outline with one or two induction cases should be given.<br>true. pg 104, thm 5.10<br><br>induction cases that I have tried recently:<br>exists elimination<br><br>induction cases that might be interesting to try in the near future:<br>forall introduction,<br>implication introduction<br><br>
Is the priciple of excluded middle valid in classical logic? Why or why not?<br><br>	It is valid, which can be seen from the equivalence<br><$>A \vee B \leftrightarrow \neg(\neg A \wedge \neg B)</$><br><br>Instantiating A with <$>C</$> and B with <$>\neg C</$><br><br>pg 69<br>
After taking an initial step of proving semantics for <b>IQC</b> with predicates and constants, how do we take the next step to get a semantics for <b>IQC</b> with<br>equality, predicate symbols, function symbols, and constants?<br>	pg 105, bottom<br>pg 106<br><br>
Explain the method for defining Kripke models using <i>transition functions</i> aka <i>restrictions</i>.<br>	It is an alternative to requiring that k ≤ k'  ⇒ D(k) ⊆ D(k').<br>pdf pg 107<br><br><br>
Draw a Kripke model demostrating <$>\not \vdash \forall x y(x = y \vee x \neq y)</$>	pg 107, section 5.13 near bottom<br>
Exercise 2.5.1, pg 129<br>	<br>
Exercise 2.5.2, pg 129<br>	<br>
Exercise 2.5.3, pg 129<br>	<br>
Exercise 2.5.4, pg 130<br>	<br>
Exercise 2.5.5, pg 130<br>	<br>
Exercise 2.5.6, pg 130<br>	<br>
Exercise 2.5.7, pg 130	<br>
Exercise 2.5.8, pg 130	<br>
Exercise 2.5.9, pg 130	<br>
Exercise 2.5.10, pg 130<br><br>	<br>
Give the definition of the class of <i>primitive recursive functions</i>.<br>	pg 137, def 1.2
Show that constant-valued functions are primitive recursive.<br>	pg 137, section 1.3 near bottom<br>
Show that addition on natural numbers is primitive recursive.<br>	pg 137, section 1.3 near bottom<br><br>
Consider the following statment:<br><br>Multiplication on natural numbers is primitive recursive.<br><br>Prove or disprove.<br>	true. pg 138, top of page.<br><br>todo: add impostor?<br>
Consider the following statment:<br><br>Exponentiation on natural numbers is primitive recursive.<br><br>Prove or disprove.<br>	pg 138, near top<br><br>todo: impostor?<br>
Consider the following statment:<br><br>The predecessor function on natural numbers is primitive recursive.<br><br>Prove or disprove.<br>	pg 138 near top<br>
What is "cut-off subtraction" and how can it be defined as a primitive function?<br>	pg 138, kinda near top<br>
Explain the "absolute difference" function on natural numbers. How is it defined as a primitive recursive function?	pg 138<br>
Define the signum function <i>sg</i> and the inverse signum function <i>sg'</i>.<br>	pg 138<br>
Consider the following statement:<br><br>The max(x,y) and min(x,y) functions on natural numbers are primitive recursive.<br><br>Prove or disprove.<br>	true. pg 138, bottomish<br><br>todo: impostor?<br>
Let σ be a permutation of {1,...,n} and let g ∈ PRIM. Consider the following statement:<br><br>If we define f as<br><$>f(\vec{x}) = g(x_{\sigma (1)},\ldots,x_{\sigma (n)})</$><br><br>Then f ∈ PRIM (i.e. f is primitive recursive).	pg 138, prop 1.4 (i)<br>
Consider the following statement:<br><br>Let g ∈ PRIM (i.e. g is primitive recursive). Then if we define f by contracting g's first two arguments:<br><$>f(\vec{x}) = g(x_1,\vec{x})</$><br><br>f ∈ PRIM<br><br>Prove or disprove.<br>	pg 138, prop 1.4, section (ii)<br>
Consider the following statement:<br><br>Let g ∈ PRIM (i.e. g is primitive recursive). Then if we define f with a superfluous argument as:<br><$>f(y,\vec{x}) = g(\vec{x})</$><br><br>f is primitive recursive.<br><br>Prove or disprove.<br><br><br>	true. pg 138, prop 1.4 (iii)<br>
Consider the following statement:<br><br>Let g ∈ PRIM (i.e. g is primitive recursive). Then if we define f as:<br><br><$$>f(z, \vec{x}) = \prod_{y < z} g(y,\vec{x})</$$><br><br>where<br><br><$$>\prod_{y < 0} g(y, \vec{x}) = 1</$$><br><$$>\prod_{y < Sz} g(y, \vec{x}) = g(z, \vec{x}) \cdot <br> (\prod_{y < z} g(y, \vec{x}))</$$><br><br>Where · is a primitive recursive multiplication function on natural numbers.<br><br>f is primitive recursive.<br><br>Prove or disprove.<br><br><br>	true. pg 138, prop 1.4 (iv)<br>
Consider the following statement:<br><br>Let g ∈ PRIM (i.e. g is primitive recursive). Then if we define f as:<br><br><$$>f(z, \vec{x}) = \sum_{y < z} g(y,\vec{x})</$$><br><br>where<br><br><$$>\sum_{y < 0} g(y, \vec{x}) = 0</$$><br><$$>\sum_{y < Sz} g(y, \vec{x}) = g(z, \vec{x}) +<br> (\sum_{y < z} g(y, \vec{x}))</$$><br><br>Where + is a primitive recursive addition function on natural numbers.<br><br>Then f is primitive recursive.<br><br>Prove or disprove.	pg 139, (v) at very top of page<br><br>todo: impostor?<br>
Exercise 3.1.1, pg 200<br>	<br>
Consider the following statement:<br><br>Let g ∈ PRIM (i.e. g is primitive recursive). Then<br><$>f(z, y,\vec{x}) = g^z(y, \vec{x})</$><br>where<br><$>g^0(y,\vec{x}) = \mathbf{p_{0}^{n+1}}(y, \vec{x})</$><br><$>g^{S z}(y,\vec{x}) = g(g^z(y,\vec{x}), \vec{x})</$><br><br>Then f is primitive recursive.<br><br>Prove or disprove.	remember that <$>\mathbf{p_{0}^{n+1}}</$> is an (n+1)-argument function that simply returns its first argument.<br><br>true. pg 139 (vi), near top<br>
Consider the following statement:<br><br>Let g ∈ PRIM (i.e. g is primitive recursive). Then defining f as:<br><br><$>f(z, \vec{x}) = min_{y \leq z}(g(y, \vec{x}) = 0)</$><br>where<br><$$>min_{y \leq z}(g(y,\vec{x}) = 0) := \sum_{u < S z} sg( \prod_{y < S u} g(y, \vec{x}))</$$><br><br>Thus <$>min_{y \leq z} (g(y, \vec{x}) = 0)</$> is the leat <$>y \leq z</$> such that <br><$>g(y, \vec{x}) = 0</$>, if existing, z + 1 otherwise.<br><br>Then f is primitive recursive. <br><br>Prove or disprove.	true. pg 139 (viii) topish<br><br>todo: impostor?<br>
What does it mean for a relation R to be <i>primitive recursive</i>?<br>	pg 139, def 1.5<br>
Consider the following statement:<br><br>The relation =  on natural numbers is primitive recursive.<br><br>Prove or disprove.<br>	true. pg 139, examples below def 1.5<br>
Consider the following statement:<br><br>The primitive recursive relations are closed under intersection, union, complementation and bounded quantification, and under substitution:<br>If <$>R(x, \vec{y})</$> is primitive recursive, then so is <$>R(f(x,\vec{y},\vec{z}), \vec{y})</$> for any <$>f \in PRIM</$>.<br><br>Prove or disprove.<br>	true. pg 139, prop 1.6<br>todo: add counterexample?<br>
If <$>R(y,\vec x)</$> is a primitive recursive relation, then how is <br><$>min_{y \leq z} R(y, \vec{x})</$> defined?<br>	pg 139, def 1.7<br>
Show that the divisibility relation x|y is primitive recursive.<br>	pg 139, examples near bottom<br>
Show that the isPrime predicate is primitive recursive.	pg 139, examples near bottom<br>
Show that the factorial function is primitive recursive.	pg 139<br>
Is the function p(n) for computing the nth prime primitive recursive? Prove or disprove.<br>	it is. pg 139, examples at the very bottom<br>
<latex>~\\<br>Consider the following statement:<br>~\\~\\<br>Let $h : On \times V \to V$ be a 'class function'. Let $\lambda$ be an ordinal.<br>Then there exists a unique function $f : \lambda \to \lambda$ such that, for every \alpha \in \lambda,\\~\\<br>$f(\alpha) = h(\alpha, f \upharpoonright \alpha)$<br>~\\~\\<br>Prove or disprove.<br></latex>	true. pg 3680, thm 2.6.1<br>todo: impostor?<br>
<latex>~\\<br>How do we know that for every ordinal $\lambda$, the hierarchy~\\~\\ <br>$\langle V_\alpha \mid \alpha < \lambda \rangle$<br>~\\~\\<br>Exists?<br></latex><br>	pg 3681, as described in the second-to-top paragraph<br>
<latex>~\\~\\<br>Consider the following statement~\\~\\<br>Let $\mu \leq \lambda$. Suppose $f_i : \mu \to V$, i = 1,2, are such that, for all $\alpha < \mu$,~\\~\\<br>$f_i(\alpha) = h(\alpha, f_i \upharpoonright \alpha)$<br>~\\~\\<br>Then $f_1 = f_2$<br>~\\~\\<br>Prove or disprove<br></latex>	true. pg 3681, lemma 2.6.2 near bottom<br>todo: impostor?<br>
<latex>~\\<br>Define $M \doteq \{ f \mid (\exists \mu \leq \lambda) [(f : \mu \to V) \wedge (\forall \alpha \in \mu)(f(\alpha) = h(\alpha, f \upharpoonright \alpha))] \}$<br>~\\~\\<br>Let $f,g \in M$. Let $\mu = dom(f)$, $\nu = dom(g)$, and suppose $\mu < \nu$.<br>~\\~\\<br>Consider the following statement: $f = g \upharpoonright \mu$. Prove or disprove.<br></latex>	true. pg 3682, lemma 2.6.3, near bottom.<br>
State and prove the "Ordinal Recursion" theorem.<br>	pg 3683, thm 2.6.4<br>
Express and prove the recursion theorem in the language of LAST, without using the concept of a 'class'.<br>	pg 3683, after last paragraph<br>pg 3684, from top down to section 2.7<br>
<latex><br>Let's say we're trying to define the notion of a set. We could assume that a set is defined by prescribing how its elements are formed. For example, we could define the set \mathbb N of natural numbers by giving the rules:<br>~\\~\\<br>\begin{mathpar}<br>\inferrule{}{0 \in \mathbb N}<br>\and<br>\inferrule{a \in \mathbb N}{a' \in \mathbb N}<br>\end{mathpar}<br>~\\~\\<br>What is the weakness of this approach?<br></latex><br><br><br>	pg 6492, near top<br>
In inuitionistic type theory, what is the difference between a <i>canonical</i> and a <i>non-canonical</i> element of a set?<br>	pg 6492<br>
How is a set A defined in intuitionistic type theory?<br>	(1) a set A is defined by prescribing how a canonical element of A is formed<br>as well as how two equal canonical elements of A are formed.<br><br>pg 6492<br>
<latex>~\\<br>Suppose that two sets $A$ and $B$ have been defined in intuitionistic type theory. How do we define the cartesian product $A \times B$ of these two sets?<br></latex><br>	pg 6492<br>
Suppose that two sets A and B have been defined in intuitionistic type theory. How can we show that the two sets are equal?<br>	pg 6492 bottom<br>pg 6493 top<br>
In inuitionistic type theory, what is an <i>element</i> of a set?<br>	pg 6493 <br>(3) an element a of a set A is a method (or program) which, when executed,<br>yields a canonical element of A as result.
In intuitionistic type theory, when does the computation of an element a of a set A terminate?<br>	pg 6493<br><br>The rules of computation (execution) of the<br>present language will be such that the computation of an element a of a set A<br>terminates with a value b as soon as the outermost form of b tells that it is<br>a canonical element of A (normal order or lazy evaluation). For instance, the<br>computation of 2 + 2 ∈ N gives the value (2 + 1) , which is a canonical element<br>of N since 2 + 1 ∈ N.
<latex>~\\<br>In intuitionistic type theory, when are two arbitrary elements $a$ and $b$ of a set $A$ considered equal?<br></latex>	pg 6493<br><br>(4) two arbitrary elements a, b of a set A are equal if, when executed, a and b<br>yield equal canonical elements of A as results.<br><br><br>
<latex>~\\<br>In intuitionistic type theory, let $e,f \in A \times B$. What does $e = f$ mean?<br></latex>	pg 6493 example<br>
How does one define a proposition in intuitionistic logic?<br>What does it mean for a proposition to be true in intuitionistic logic?<br>	pg 6493 bottom, 6494 top<br><br>"<br>a proposition is defined by laying down what counts as a proof of the proposition, and that a proposition is true if it has a proof, that is, if a proof of it can be given 8 .<br>"<br><br>what about being valid w.r.t. kripke semantics? isn't that an equivalent notion of truth?<br>
Look at the two tables demonstrating inuitionistic logic on page 6494. <br>The bottom one can be considered more detailed than the top, since it is more concrete. But there is something inaccurate about the bottom table. Explain.<br>	these show proofs in canonical form only. In general, a proof is a method for producing a proof in canonical form.<br><br>pg 6494 - the explanation is given in the paragraph directly below the bottom table.<br>
The Curry-Howard functor is cool and all, but why bother in practice (in intuitionistic type theory) with identifying propositions as sets? How is it useful?	doing otherwise would just be redundant and wasteful, please read:<br>bottom paragraph of pg 6494
Give intuitionistic type theory's rules for <b>reflexivity</b>, <b>symmetry</b>, and <b>transitivity</b>. Justify these rules.<br><br><br>	pg 6495. read the whole page.<br><br>The rules for elements are justified in the paragraphs directly above and below the rules.<br><br>The justifications for the set equality rules span the rest of the page.<br>
If A and B are sets, what does the judgment A = B mean in intuitionistic type theory?<br>	pg 6495, "The meaning of  A = B is that"<br><br>
Give intuitionistic type theory's two <b>Equality of sets</b> rules, which allow us to make inferences from the premise (possibly among others) that A = B for two sets A and B.<br> 	pg 6495, bottom<br>
In intuitionistic type theory, what is a <i>hypothetical judgment</i>? Define two of ITT's  <b>Substitution</b> rules (with conclusions "B(a) is a set" and "B(a) = B(c)") using hypothetical judgments (and possibly non-hypothetical judgments as well) as premises.<br><br>	pg 6496<br>
<latex>~\\<br>Derive the following rule from intuitionistic type theory's substitution rules.<br>~\\~\\<br>\begin{prooftree}<br>\AxiomC{$a = c \in A$}<br><br>\AxiomC{$(x \in A)$}<br>\noLine<br>\UnaryInfC{$B(x) = D(x)$}<br><br>\BinaryInfC{$B(a) = D(c)$}<br>\end{prooftree}<br></latex><br>	pg 6496<br>
Intuitionistic type theory includes four forms of <i>hypothetical judgments</i>. List and describe these four forms.<br>	(1) and (2) ------- pg 6496 <br>(3) and (4) ------- pg 6497<br>
<latex>~\\<br>Define ITT's two substitution rules with conclusions $b(a) \in B(a)$ and $b(a) = b(c) \in B(a)$.<br></latex><br><br>	pg 6497<br>
<latex>~\\<br>Define ITT's substitution rule with conclusion $b(a) = d(a) \in B(a)$ .<br></latex><br><br>	pg 6498, top<br><br>
<latex><br>In intuitionistic type theory, what does a judgment of the form:\\<br>$A(x_1, \ldots, x_n)~set~(x_1 \in A_1, x_2 \in A_2(x_1), \ldots, x_n \in A_n(x_1, \ldots, x_{n-1}))$\\<br>mean?<br></latex>	pg 6497 near bottom (judgments with more than one assumption and contexts)<br>pg 6498 near top<br>
In the context of intuitionistic type theory, what is a <i>category</i>?<br>List some of the categories that we encounter when dealing with intuitionistic type theory.<br><br>	It is a preorder category where the preorder in question is equality.<br><br>"A category is defined by explaining what an object of the category is and when<br>two such objects are equal."<br><br>pg 6498 -- section "Sets and categories"<br><br>
There are many types of judgments in intuitionistic type theory, but when viewed through the lens of category theory, they can be separated into just two groups. Explain these two groups.<br><br>	pg 6499<br><br>"<br>We will say object of a category but element of a set, which reflects the<br>difference between categories and sets. To define a category it is not necessary<br>to prescribe how its objects are formed, but just to grasp what an (arbitrary)<br>object of the category is. Each set determines a category, namely the category<br>of elements of the set, but not conversely: for instance, the category of sets and<br>the category of propositions are not sets, since we cannot describe how all their<br>elements are formed. We can now say that a judgement is a statement to the<br>effect that something is an object of a category (a ∈ A, A set, . . . ) or that two<br>objects of a category are equal (a = b ∈ A, A = B, . . . ).<br>"<br>
Read the last two paragraphs of pg 6499<br>	<br>
<latex>~\\<br>Consider the function $\gamma$ from sets to sets defined as follows.\\~\\<br>$\gamma(x) = \{ \emptyset \} \cup \{ \bigcup x \} \cup \{ y \cup \{ y \} \mid y \in x \}$\\~\\<br>And consider the class operator $\Gamma$ defined as follows:\\~\\<br>$\Gamma(X) = \bigcup \{ \gamma(x) \mid x \subseteq X \wedge\text{ x is a set} \}$\\~\\<br>Consider the following statement:\\~\\<br>$\Gamma$ is inflative, i.e. for any class $X$ we have $X \subseteq \Gamma(X)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 3788<br><br><latex><br>Let $x \in X$. Then $\{ x \} \subseteq X$. Then $x = \bigcup \{ x \} \in \gamma(\{ x \})$.<br>Then $x \in \Gamma(X)$.<br></latex><br>
<latex>~\\<br>Consider the function $\gamma$ from sets to sets defined as follows.\\~\\<br>$\gamma(x) = \{ \emptyset \} \cup \{ \bigcup x \} \cup \{ y \cup \{ y \} \mid y \in x \}$\\~\\<br>And consider the class operator $\Gamma$ defined as follows:\\~\\<br>$\Gamma(X) = \bigcup \{ \gamma(x) \mid x \subseteq X \wedge\text{ x is a set} \}$\\~\\<br>Consider the following statement:\\~\\<br>$\Gamma$ is deflative, i.e. for any class $X$ we have $\Gamma(X) \subseteq X$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 3788<br><br><latex><br>$X = \emptyset$ works as a counterexample. $\{ \emptyset \} \in \Gamma(\emptyset)$ but<br>$\{ \emptyset \} \not \in \emptyset$<br></latex>
What is a <i>coinductive definition</i> of a class X?<br>	pg 3789 second paragraph<br><latex><br>It is a montone, set-based class operator $\Gamma$ whose greatest fixpoint is $X$<br></latex>
<latex><br>Assume for simplicity that the collection $\mathcal A$ of atoms is finite. Consider<br>the operator $\Gamma$ that assigns to any class $X$ the class of all finite subsets of $X \cup A$.\\~\\<br>The smallest fixpoint-point of $\Gamma$, $HF_0$, can be characterized as the smallest set satisfying the condition:\\<br>if $a \subseteq HF_0 \cup A$ and $a$ is finite, then $a \in HF_0$\\<br>(i.e. $\Gamma(HF_0) \subseteq HF_0$)\\~\\<br>The greatest fixpoint, $HF_1$, can be characterized as the largest set satisfying\\<br>if $a \in HF_1$, then $a \subseteq HF_1 \cup A$ and $a$ is finite.\\<br>(i.e. $HF_1 \subseteq \Gamma(HF_1)$)~\\~\\<br>What is the relation between $HF_0$ and $HF_1$ under $ZFCA$?\\<br>What is their relation under $ZFCA^- + AFA$?<br></latex><br><br><br>	it would be great to do a detailed analysis of this and prove it.<br>pg 3789<br>
What does it mean for a set to be <i>hereditarily finite</i>? What do the sets HF<sub>0</sub> and HF<sub>1</sub> denote?<br>	pg 3789
Explain why, when AFA is assumed, co-inductive definitions are often more useful than inductive definitions.<br>	pg 3790<br><br>read the paragraph beginning with "suppose we have some finite system of equations of the form..."<br><br>Note that for non-well-founded systems, the solution will not be in HF<sub>0</sub> even when the sets a<sub><b>x</b></sub> are, but they are guaranteed to be in HF<sub>1</sub>. (The definitions of HF<sub>0</sub> and HF<sub>1</sub> are on page 3789)<br><br><br>
Informally paraphrase the Co-inductive Closure Theorem.<br>	pg 3790
<latex>~\\<br>Let $\Gamma$ be a monotone, set-based class operator. Define the collection of \emph{$\Gamma$-objects} and the collection of \emph{parametric $\Gamma$-objects}. What does the Co-inductive Closure Theorem tell use about the relation between these two classes?<br></latex>	pg 3791, top section.<br>
What is the difference between a <i>graph</i> and a <i>system</i>?<br>	A system is like a graph, but its node collection and edge collection may be proper sets. Each node may on have a <i>set</i> of outgoing edges, though, and so a system may be viewed as the graph equivalent of a <i>locally small category</i>.<br><br>pg 3791<br>
A tagging for a system is defined as a <i>partial function</i> on the system's leaf nodes. Why partial rather than total? <br><br>	pg 3791, very bottom paragraph<br><br>
In order to establish the solution lemma, we need to define the three following notions:<br>* A <i>labelling</i> of a tagged system<br>* A <i>labeled system</i><br>* A <i>decoration</i> of a labeled system<br><br>Provide the definitions of these three notions, and explain how they relate to the solution lemma's proof.<br>	pg 3792<br>
What is the relation between the Anti-Foundation Axiom and "The Anti-Foundation Axiom for Labeled Systems"?<br>	The AFA for labeled systems says that any labeled, tagged system has a unique decoration.<br><br>The latter, apparently stronger, result is implied by AFA. Since a tagged graph can be viewed as a special case of a labelled tagged system (where all labels are the empty set), it's useful to simply call "The Anti-Foundation Axiom for Labeled Systems" the "Anti-Foundation Axiom".<br><br>pg 3792, bottom paragraph<br><br>
Consider the following statment:<br><br>Assuming the AFA, every tagged system has a unique decoration.<br><br>Prove or disprove.<br>	true. pg 3793, thm 7.5.1<br><br>TODO: add impostor?<br>
Consider the following statement:<br><br>Assuming the AFA, every labeled, tagged system has a unique decoration.<br><br>Prove or disprove.<br>	true. pg 3794, thm 7.5.2<br><br>TODO: add impostor?
<latex>~\\<br>Assume the AFA. Let $(M, t, l)$ be a labeled system (in $V_{\mathcal A}[\mathcal X]$) such that $t(n) \in \mathcal A$ for all tagged nodes $n \in M$, and $l(n) \subseteq \mathcal X$ for all untagged nodes $n \in M$. Consider the following statements:<br>\begin{description}<br>\item{(i)} Let $\pi : \mathcal X \to V_{\mathcal A}$. Then there is a unique map $\hat \pi : M \to V_{\mathcal A}$ such that for each $n \in M$:<br>\begin{itemize}<br>\item if $n$ is a tagged node of M, then $\hat \pi(n) = t(n)$;<br>\item if $n$ is an untagged node of M, then<br>$$ \hat \pi (n) = \{ \hat \pi(n') \mid n \longrightarrow n' \text{ in }M \} \cup \{ \pi(x) \mid x \in l(n) <br>\}$$<br>\end{itemize}<br>\item{(ii)} Suppose that to each $x \in \mathcal X$ there is assigned a node $a_x$ of $M$. Then there is a unique map $\pi : \mathcal X \to V_{\mathcal A}$, such that for all $x \in \mathcal X$,<br>$$ \pi(x) = \hat \pi (a_x) $$<br>\end{description}<br>Prove or disprove.<br></latex>	true. pg 3795, thm 7.5.3 <br><br>todo: impostor?<br>
<latex>~\\<br>What is a \emph{concrete semantic domain} $\mathcal P^\natural$?<br></latex><br>	pg 6541, section 3<br>
What is a <i>concrete iteration</i>? What are <i>concrete iterates</i>?<br>	pg 6542<br>
<latex><br>What is the "default method" for specfying a concrete iteration (i.e. the sequence $F^{\natural \lambda}$)<br></latex>	pg 6542, second bullet point<br>
<latex>~\\<br>What does it mean for a concrete iteration $F^{\natural \lambda}$ to be \emph{ultimately stationary}?<br></latex>	<latex>~\\<br>\exists \epsilon \in Ord : \forall \lambda \geq \epsilon : F^{\natural \lambda} = F^{\natural \epsilon}}<br></latex><br><br>pg 6542, second bullet point<br>
<latex>~\\<br>Associated with a concrete domain $\mathcal P^{\natural}$ we often have a partial order $\sqsubset^{\natural}$. Explain the role of this partial order and how it typically relates<br>to the rest of the abstract interpretation machinery.<br></latex>	pg 6542, third bullet point.<br>
Explain how basic denotational semantics for recursive procedures fits into the abstract interpretation framework.<br>	pg 6542, example 3.1<br>
Explain how forward collecting semantics for invariance properties of a transition system fits into the framework of abstract interpretation.<br>	pg 6542, example 3.2<br><br>
<latex>~\\<br>What is an \emph{abstract semantic domain} $\mathcal P^{\sharp}$?<br></latex>	pg 6543<br>
<latex>~\\<br>What is an \emph{abstract iteration} $F^{\sharp \lambda}$? What is standard method for ensuring that an abstract iteration is convergent?<br></latex>	1.) pg 6543, first bullet point<br>2.) pg 6543, third bullet point<br>
<latex>~\\<br>Describe the soundness relation $\sigma$. Give its type signature and its intuitive meaning.<br></latex>	pg 6544<br>
<latex>~\\<br>Suppose that we use maximal execution traces as a concrete semantics. What might be an appropriate abstract semantics? How would the soundness relation $\sigma$ be defined?<br></latex><br><br>	pg 6544, example 4.1<br>
What is the <i>existence of abstract approximations</i> assumption?<br>	pg 6544, formula (4.5)<br><br>
<latex>~\\<br>Given limits of concrete and abstract iterates $F^{\natural \epsilon}$ and $F^{\sharp \epsilon}$, described the "Inductive soundness proof" technique for proving that <br>$(F^{\natural \epsilon}, F^{\sharp \epsilon}) \in \sigma$<br></latex>	pg 6545, proposition 4.3<br>
State and motivate the axiom of plentitude. (The set form)<br><br>	read pg 3249, 3250, 3251 to the section for "The class form of the axiom of plentitude"<br>
State and motivate the "Strong Axiom of Plentitude"<br>	pg 3251<br>
<latex>~\\<br>State the "Proof by \in-induction on well-founded sets" principle.<br></latex>	pg 3253
Exercise 2.10<br>	pg 3253<br>
Prove proposition 2.6 (1, 2, and 3) on page 3253	<br>
Prove proposition 2.6 (4, 5, and 6) on page 3253	<br>
Prove proposition 2.6 (7, 8, and 9) on page 3254	<br>
Prove proposition 2.7 (1,2, and 3) on pg 3254<br>	<br>
Prove proposition 2.7 (4,5, and 6) on pg 3254	<br>
Exercise 2.11, pg 3255<br>	<br>
How many solutions should an equation like d = {q,d} have?<br>	pg 3297<br>
Read example 6.1 on page 3298<br>	<br>
How do we model a solution to the system described in Example 6.1 on page 3298?<br>	pg 3299, 3rd paragraph<br><br>
Provide the definition of a <i>flat system of set equations</i>.<br>	pg 3299, def 1 near bottom<br>
Provide the definition of <i>indeterminates</i> with regard to set equations.<br>Provide the definition of <i>atoms</i>.<br><br>	pg 3299, item 2<br>
<latex>~\\<br>If $\mathcal E$ is a flat system of set equations, what is a \emph{solution} to $\mathcal E$?<br></latex><br>	pg 3300, item 3 at very top of page<br>
What is the solution to a set equation with an empty set of indeterminates?<br>	the empty function<br>pg 3300<br>
State the <i>Flat Solution Lemma</i>.<br>	Note that this is a name for a specific form of the anti-foundation axiom.<br>pg 3300 (see the text under ANTI-FOUNDATION AXIOM)<br><br>
What does ZFA stand for?	pg 3300
<latex>~\\<br>What is a \emph{solution set} to a flat system of equations $\mathcal E$?<br></latex><br>	pg 3300
Exercise 6.2, very bottom of pg 3300<br>	<br>
<latex>~\\<br>Let $A \subseteq \mathcal U$ and let $\mathcal E = \langle X, A, e \rangle$ be a flat system. Consider the following statement:\\~\\<br>$\textit{solution-set}(\mathcal E)$ is transitive on sets: that is, if $b$ and $c$ are sets and $c \in b \in \textit{solution-set}(\mathcal E)$, then also $c \in \textit{solution-set}(\mathcal E)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3301, proposition 6.1<br>todo: add impostor! a good impostor would remove the "on sets" part.<br>
<latex>~\\<br>Let $\mathcal E = \langle X, A, e \rangle$ be a flat system of equations whose atoms are urelements, and let s be the solution of $\mathcal E$. Consider the following statement:\\~\\<br>For all $x \in X$, $support(s_x) \subseteq A$.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 3301, prop 6.2<br>todo: add impostor<br><br>
<latex>~\\<br>How is $V_{afa}[A]$ defined?<br></latex>	pg 3300 near bottom<br>
Suppose that we want to model the following single-indeterminate system of set equations:<br>x = {{x,q},p}<br>This system is not flat, could we somehow model it as a flat system of equations regardless of this?<br>	pg 3301, example 6.2<br><br>
Use the solution lemma to show that there is a unique set<br>{0, {1, {2, {3, ...}}}.<br>	pg 3302, exercise 6.3 at very top of page.<br><br>pretty easy problem, but here is the solution (taken from back of book):<br>x<sub>0</sub> = {0, x<sub>1</sub>}<br>x<sub>1</sub> = {1, x<sub>2</sub>}<br>x<sub>2</sub> = {2, x<sub>3</sub>}<br>...<br><br>letting s be the unique solution to this system, the set is s(x<sub>0</sub>)
What is a <i>generalized flat system</i> of set equations?<br>	pg 3302, thm 6.3<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every generalized flat system $\mathcal E = \langle X, A, e \rangle$ has a unique solution s.<br>Moreover, there is a flat system $\mathcal E' = \langle Y, A, e' \rangle$ using the same set A of atoms such that $\textit{solution-set(\mathcal E) = \textit{solution-set}(\mathcal E')$\\~\\<br>Prove or disprove.<br></latex>	true. pg 3302, thm 6.3<br>todo: add impostor?<br>
Let A be a set. What is the <i>canonical flat system</i> for A?<br>	pg 3303, definition near top<br><br>
<latex>~\\<br>Let $\langle X, A, e \rangle$ be any system of equations such that $A = \emptyset$ but each $e_x \neq \emptyset$. Show that $\Omega$ is the solution set for this system.<br></latex><br>	pg 3306<br>
<latex>~\\<br>Let $A \subset \mathcal U$, and let $\mathcal E = \langle X, A, e \rangle$ and $\mathcal E' = \langle X', A, e' \rangle$ be two generalized flat systems.\\~\\<br>What is a \emph{A-bisimulation relation} between $\mathcal E$ and $\mathcal E'$?<br></latex><br><br>	pg 3306
<latex>~\\<br>Let $A \subseteq \mathcal U$, and let $\mathcal E = \langle X, A, e \rangle$ and $\mathcal E' = \langle X', A, e' \rangle$ be two generalized flat systems.\\~\\<br>What does it mean for $\mathcal E$ and $\mathcal E'$ to be \emph{A-bisimilar}?<br></latex>	pg 3306
Show that the two systems of example 7.2 on page 3306 are bisimilar.<br>	pg 3307, example 7.3<br><br>todo: impostor?<br>
Show that the two systems of example 7.1 on page 3305 are bisimilar.<br>	pg 3307, example 7.3<br><br>todo: add impostor?<br>
<latex>~\\<br>Let $\mathcal E$ and $\mathcal E'$ be flat systems over the same set $A \subseteq \mathcal U$.<br>Consider the following statement:\\~\\ <br>$\mathcal E$ and $\mathcal E'$ have the same solution sets if and only if they are bisimilar.\\~\\<br>Prove or disprove.<br></latex><br> 	pg 3307, thm 7.1<br><br><br><br>TODO: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>The relation of bisimulation on generalized flat systems over A is an equivalence relation.\\~\\<br>Prove or disprove<br></latex>	true. pg 3309, corollary 7.2<br><br>todo: add impostor?<br>
Do exercise 7.2 on pg 3309<br>	<br>
What is a <i>bisimulation relation on sets</i>?<br>	pg 3309, section 7.2<br>
What does it mean for two sets <i>a</i> and <i>b</i> to be <i>bisimilar</i>?	pg 3309<br>
<latex>\\~\\<br>Suppose that $p$ is an urelement and let $a = \{ p, a \}$ and $b = \{ p , \{ p , b \} \}$. Give a bisimulation $R$ such that $aRb$.<br></latex> 	pg 3310
<latex>\\~\\<br>State and prove the strong extensionality theorem.<br></latex>	pg 3310, thm 7.3<br><br>
Does strong extensionality hold in the universe of wellfounded sets?<br>	pretty sure it does. The wellfounded sets are a subclass of the non-wellfounded sets, so their identity relation is subsumed by the identity relation on non-wellfounded sets.<br><br>pg 3311, exercise 7.3<br>
In general, a bisimulation relation can be a set or a proper class. Consider the following statement:<br><br>If there is a bisimulation relation R between sets a and b such that aRb then R is a set.<br><br>Prove or disprove.<br>	pg 3311, exercise 7.4<br><br>todo: add impostor?<br>
<latex>~\\<br>Let $A$ be a set. What does $A^\infty$ denote?<br></latex><br><br>	pg 3311, section 7.3<br>
What is a <i>stream bisimulation</i>?<br>	pg 3312<br>
Let s and t be streams from a set A, and suppose that there is a stream bisimulation R on A<sup>∞</sup> such that sRt. Then consider the following statement:<br><br>s = t<br><br>Prove or disprove.<br>	pg 3312<br>
<latex>~\\<br>The successor function $s$ is defined as: $s(a) = a \cup \{ a \}$. Consider the following statement:\\~\\<br>The successor function is injective.\\~\\<br>Prove or disprove.<br></latex><br><br> 	true. pg 3312, prop 7.5<br><br>todo: add counterexample?<br>
<latex>~\\<br>Consider the following statement. For all sets $a$ the following are equivalent: \\<br>1. $s(a) \in a$ \\<br>2. $s(a) = a$ \\<br>3. $a$ is reflexive\\~\\<br>Prove or disprove.<br></latex><br>	pg 3313
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mathcal C$ is a small category and $\mathcal D$ is a locally small category, then<br>$[\mathcal C, \mathcal D]$ is locally small.\\~\\<br>Prove or disprove.<br></latex>	true. pg 4141 (right page)<br>
<latex>~\\<br>Let $\mathcal C$ and $\mathcal D$ be locally small categories. Consider the following statement:\\~\\<br>$[\mathcal C$, $\mathcal D]$ is locally small\\~\\<br>Prove or disprove.<br></latex><br>	pg 4141 (right page)<br>
<latex>~\\<br>Let $\mathcal C$ be a locally small category. Defining $\mathcal C(-,+)$ in the standard manner related to the Yoneda lemma, and letting A be an object of $\mathcal C$, what does $\mathcal C(A, +)$ denote? $\mathcal C(-, A)$?<br></latex><br>	pg 4142, top left<br>
<latex>~\\<br>Letting $\mathcal C$ be a category and $A \in \mathcal C_0$, what do $H^A$ and $H_A$ denote?<br></latex>	pg 4142<br>
<latex>~\\<br>Let $\mathcal C$ be a locally small category, $A \in \mathcal C_0$, and $f \in \mathcal C_1$.<br>What does $H^A_f$ denote?<br></latex>	pg 4142, top left<br>
<latex>~\\<br>Let $C$ be a locally small cartesian category. Explain the functor:<br>$$ H : \mathcal C^{op} \to [\mathcal C, \textit{Set}]$$<br>How does it act on objects? How does it act on arrows?<br></latex>	pg 4142<br><br>
<latex>~\\<br>Let $F : \mathcal C \to \mathcal D$ and $G : \mathcal D \to \mathcal C$ be functors between locally small categories $\mathcal C$ and $\mathcal D$. What do $\mathcal D(-, F+)$ and $\mathcal C(G-,+)$ denote?<br></latex>	pg 4142, left page, near middle<br>
When does a monotone function between preorders have a <i>left adjoint</i>? When does it have a <i>right adjoint</i>? What is an <i>adjunction</i> between preorders?<br>	pg 4149, right bottom<br>
<latex>~\\<br>Let $f : X \Rightarrow Y$ and $g : Y \Rightarrow X$ be montone functions between the preorders $X$ and $Y$. Under what conditions do we have $f \vdash g$? Prove your answer. These conditions should not be the definition of $f \vdash g$, but instead constraints involving the compositions $fg$ and $gf$.<br></latex>	pg 4149<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A monotone function $f : X \to Y$ has a right adjoint iff there is a function $r : Y \to X$ such that<br>\begin{itemize}<br>\item for all $y \in Y$ we have $f(r(y)) \leq y$, and<br>\item for all $x \in X$ and $y \in Y$ we have $f(x) \leq y$ implies $x \leq r(y)$<br>\end{itemize} <br>Prove or disprove.<br></latex>	pg 4150, top left, prop 2.10.3. note that the left-to-right proof becomes clear when looking at the previous proposition, 2.10.2<br><br>TODO: add impostor<br>
<latex>~\\<br>Let $X$ and $Y$ be preorders. Suppose that $f, f' \in X \Rightarrow Y$ (remember that $\Rightarrow$ is a type constructor for monotone functions ordered pointwise) and $g, g' \in Y \Rightarrow X$ with ($f \dashv g$) and ($f' \dashv g'$). Consider the following statement:\\~\\<br>$f \leq f'$ iff $g' \leq g$ and similarly $f' \leq f$ iff $g \leq g'$.\\~\\<br>Prove or disprove<br></latex>	true. pg 4150, left page, prop 2.10.4<br>TODO: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The adjoint to a montone function on preorders is unique up to isomorphism.\\~\\<br>Prove or disprove.<br></latex>	see proposition 2.10.4, left pg 4150<br><br>
<latex>~\\<br>Let $X$ and $Y$ be preorders. Suppose that $f, f' \in X \Rightarrow Y$ (remember that $\Rightarrow$ is a type constructor for monotone functions ordered pointwise) and $g, g' \in Y \Rightarrow X$ with ($f \dashv g$) and ($f' \dashv g'$). Consider the following statement:\\~\\<br>$f \leq f'$ iff $g \leq g'$ and similarly $f' \leq f$ iff $g' \leq g$.\\~\\<br>Prove or disprove<br></latex>	IMPOSTOR<br>of prop 2.10.4 on pg 4150 left<br>
<latex>~\\<br>Suppose we are given preorders $X$ and $Y$ and monotone functions $f : X \Rightarrow Y$, $h : Y \Rightarrow Z$, $k : Z \Rightarrow Y$, and $g : Y \Rightarrow X$ for which ($f \vdash g$) and ($h \vdash k$). Consider the following statement:\\~\\<br>($hf \vdash gk$)\\~\\<br>Prove or disprove.<br></latex>	true. pg 4150, left page bottom, prop 2.10.5<br>todo: add impostor?<br>
<latex>~\\<br>Let $f : X \to Y$ be a monotone function between preorders $X$ and $Y$. Consider the following statement:\\~\\<br>If $f$ has a right adjoint then $f$ preserves all joins which exist in $X$\\~\\<br>Prove or disprove<br></latex>	true. pg 4150, left bottom, thm 2.10.6<br><br>
<latex>~\\<br>Let $f : X \to Y$ be a monotone function between preorders $X$ and $Y$. Consider the following statement:\\~\\<br>If $f$ has a right adjoint then $f$ preserves all meets which exist in $X$\\~\\<br>Prove or disprove<br></latex>	IMPOSTOR. pg 4150, left page, thm 2.10.6<br>
<latex>~\\<br>Let $f : X \to Y$ be a monotone function between preorders and suppose that X has all joins. Consider the following statement:\\~\\<br>$f$ has a right adjoint if it preserves joins.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 4150, right page, thm 2.10.8<br>
<latex>~\\<br>Let $f : X \to Y$ be a monotone function between preorders and suppose that X has all joins. Consider the following statement:\\~\\<br>$f$ has a left adjoint if it preserves joins.\\~\\<br>Prove or disprove.<br></latex><br>	IMPOSTOR. pg 4150, right page, thm 2.10.8<br>
<latex>~\\<br>Let $1 \overset{def}{=} \{ \ast \}$ be the preorder with $\ast \leq \ast$, a terminal object in \textit {PreSet}. Given a preorder $X$, consider the unique monotone function $!_X : X \to 1$.\\~\\<br>Does $!_X$ have a left adjoint? Does $!_X$ have a right adjoint?<br></latex><br>	pg 4150, right page, examples 2.10.9 (1)<br>
<latex>~\\<br>Let $X$ be a preorder with binary meets and joins. There is a monotone function $\Delta : X \to X \times X$ given by $\Delta(x) = (x, x)$. Does $\Delta$ have a left adjoint? Does $\Delta$ have a right adjoint?<br></latex><br>	pg 4150, right page, example 2.10.9 (2)<br>
<latex>~\\<br>Let $f : X \to Y$ be a function. Then $f^{-1} : \mathcal P(Y) \to \mathcal P(X)$ is a monotone function from the powerset preorder $\langle \mathcal P(Y), \subseteq \rangle$ to the powerset preorder $\langle \mathcal P(X), \subseteq \rangle$. Does $f^{-1}$ have a right adjoint? Does it have a left adjoint? <br></latex><br>	pg 4150, right page, example 2.10.9 (3)<br>*see page 4134, right side, item 8 for the definitions of <br>
<latex>~\\<br>Let $V$ be a transitive set and let $b = V - \{ V \}$. Consider the following statement:\\~\\<br>$b \not \in V$.\\~\\<br>Prove or disprove.<br></latex>	pg 3313, prop 7.7 near bottom<br><br>
Do exercise 7.5 on pg 3314<br>	<br>
Do exercise 7.6 on pg 3314<br>	<br>
Do exercise 7.7 on pg 3314, near bottom<br><br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The relation of bisimulation on generalized flat systems over A is an partial order.\\~\\<br>Prove or disprove<br></latex>	IMPOSTOR, it is not anti-symmetric. Distinct systems may have the same solution sets.<br><br>pg 3309<br><br><br>
<latex>\\~\\<br>Consider the following sentences (1) and (2):\\<br>\begin{enumerate}<br>\item Sentence 1 is not true<br>\item Sentence 1 is not true<br>\end{enumerate}<br>What can be said about the truth of these sentences? How can we model these sentences as hypersets, and what might go wrong when attempting to construct such a model?<br></latex>	pg 3315<br>
What does it mean for a term t to be <i>structurally smaller</i> (in the standard sense, not the Agda sense) than another term t'?<br>	<latex>~\\<br>$t$ and $t'$ normalize to $v$ and $v'$, such that $v < v'$ is in the reflexive transitive closure of the relation determined by:<br>$$ w \leq C(\cdots w \cdots)$$<br>Where $w$ is a value and $C$ is a data constructor.<br></latex><br><br>pg 6625, axiom (1) in section 1.1
<latex>~\\<br>The following standard axiom for reasoning about termination is based on \emph{term structure}.<br>$$w \leq C(\cdots w \cdots)$$<br>Agda completements this axiom with another axiom based on \emph{type structure}. State and describe this second axiom.<br></latex>	pg 6625<br>
Give an example of how impredicative polymorphism would cause issues for termination checking in Agda.<br>	pg 6626, near top<br><br>
<latex><br>What does it mean for a function to be \emph{structurally recursive}? Is the following ML function structurally recursive? Why or why not?<br><br>\begin{verbatim}<br>datatype Ord = O’<br>       | S’ of Ord<br>       | Lim of Nat -> Ord<br><br>fun addord x O’        = x<br>  | addord x (S’ y’)    = S’ (addord x y’)<br>  | addord x (Lim f)  = Lim (fn z:Nat => addord x (f z))<br>\end{verbatim}<br></latex><br>	pg 6626, section 1.2<br><br>TODO: add impostor?<br>
<latex>~\\<br>Can Agda's termination checker prove the following function terminating? If so, why? If not, why not?<br>\begin{verbatim}<br>fun ack O y = S y<br>  | ack (S x’) O = ack x’ (S O)<br>  | ack (S x’) (S y’) = ack x’ (ack (S x’) y’)<br>\end{verbatim}<br></latex>	pg 6627, top<br>TODO: impostor? perhaps my finposet example works as a counterexample<br>
<latex>~\\<br>Consider the following mutually recursive function definitions, for flattening a list.<br>\begin{verbatim}<br>fun flat []        = []<br>  | flat (l :: ls) = aux l ls<br>fun aux []        ls = []<br>  | aux (x :: xs) ls = x :: aux xs ls<br>\end{verbatim}<br></latex><br><br>Can Agda's termination checker prove the termination of the above functions? If so, how? If not, why not?	pg 6627. Make sure to understand the entire page; the part about <i>call matrices</i> and <i>completion</i> is important.<br><br>TODO: impostor?
<latex>~\\<br>Explain the data structure $\Delta$ of dependencies in the Foetus termination checker.<br></latex>	pg 6637<br>
<latex>~\\<br>Explain the data structure $\mathcal C$ of \emph{calls} in the Foetus termination checker.<br></latex>	pg 6637<br>
<latex>~\\<br>Explain the \emph{function stack} data structure $\Phi$ ofthe Foetus termination checker.<br></latex>	pg 6637<br>
<latex>~\\<br>A \emph{Function Call Extraction} judgment in the Foetus termination checker has the form:<br>$$ \Delta ; \Phi \vdash t \sqsupset \mathcal C $$<br>Explain the meaning of such a judgment.<br></latex>	pg 6638/6639<br>
What is the difference between a <i>predicative</i> and an <i>impredicative</i> theory, as Abel and Altenkirch use the terms?<br>	pg 6628
Give the definition of <i>set based operator</i> used by the development of the Foetus termination checker.<br> 	pg 6628
<latex>~\\<br>What does it mean  for a type variable to appear \emph{strictly positively} within a type $\tau$?<br></latex><br>	pg 6630, section "Type variables"<br>
<latex>~\\<br>Give Foetus' inductive definition of the family of types $Ty(\vec{X})$ indexed over a finite list of distinct type variables $\vec{X} \in TyVar$.<br></latex>	pg 6630, def 2.1<br>
Read the notation and substitution sections on pg 6630 (because memorizing notation is stupid)<br>	<br>
<latex>~\\<br>Give some of Foetus's inductive rules for defining the set of well-typed terms $Tm^\sigma[\Gamma]$ of a closed type $\sigma$ in context $\Gamma$.\\~\\<br>Specifically, give the rules for variables, injections, case expressions, and tuples.<br></latex>	pg 6631<br>
<latex>~\\<br>Give some of Foetus's inductive rules for defining the set of well-typed terms $Tm^\sigma[\Gamma]$ of a closed type $\sigma$ in context $\Gamma$.\\~\\<br>Specifically, give the rules for projections, lambdas, and fixpoint abstractions.<br></latex>	pg 6631<br>
Read the sections "Renaming Convention for Terms", "Notation", and "Currying" on page 6632<br>	<br>
What is a <i>pointed flat system</i>? Give an algorithm to tell whether two pointed flat systems are bisimilar or not. What is its complexity? Argue its correctness.<br> 	pg 3316/3317<br><br>note that on pg 3317, they only give an outline of the correctness proof; you should fill in the details.<br>
What is a <i>general system of equations</i>? Explain the motivation behind this notion.	pg 3320, definition near top<br>
Explain the motivation for introducing the notion of a <i>substitution operation</i> for reasoning about the solutions to general systems of equations.	pg 3320, bottom paragraph<br>pg 3321, top paragraph<br>
What is a </i>substitution</i>? What is a <i>substitution operation</i>?<br>	pg 3321, definitions near top.<br>
What does <i>sub</i> denote, related to the solutions of general systems of equations?<br>	pg 3321, paragraph after points (1),(2),(3)<br>
What are the <i>corecursion conditions</i> for substitution operators?<br>	pg 3321, points (1), (2), and (3) under the definition.<br>
<latex>~\\<br>Let $A = \{ x , y , z \}$ be a set of three distinct urelements and let <br>$$ b = \{ x , y , \Omega , \{ b , x , z \} \}$$ <br>Substitute 3 for x and x for y in the above set in a systematic manner.<br></latex>	pg 3321, 3322, example 8.4<br>
Why is the domain X of a general system of equations required to consist entirely of urelements? Hint: it has something to do with substitution.	pg 3323, example 8.5<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There is a unique operation sub(s, b) which obeys the corecursion conditions for substitution and which is defined for all pairs $\langle s, b \rangle$ such that $dom~s \subseteq \mathcal U$ and $b \in \mathcal U \cup V_{afa}[\mathcal U]$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3323<br><br>todo: impostor?<br>
Exercise 8.1, pg 3324<br>	<br>
Exercise 8.2, pg 3325<br>	<br>
Exercise 8.3, pg 3325<br>	<br>
What is a <i>solution</i> to a general system of equations.<br><br>Not a general flat system, but a <b>general system of equations</b>.<br>	pg 3325, definition<br>
Exercise 8.4, pg 3325<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every general system of equations $\mathcal E$ has a unique solution $s$. Moreover, the solution set of $\mathcal E$ is a subset of $V_{afa}[A]$, where $A$ is the set of atoms of $\mathcal E$.\\~\\<br>Prove or disprove<br></latex><br>	pg 3325<br><br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Let $\mathcal E = \langle X, A, e \rangle$ be a general system of equations. There is a flat system $\mathcal E^{\flat} = \langle Y, A, e' \rangle$ with $X \subseteq Y$ such that the following hold:<br>\begin{enumerate}<br>\item If $s$ is a solution of $\mathcal E$, then $s$ extends to a solution $s'$ of $\mathcal E^{\flat}$. (Note that $s'$ is necessarily unique, being a solution of $\mathcal E^{\flat}$.)<br>\item If $s'$ is a solution of $\mathcal E^{\flat}$ and $s = s' \upharpoonright X$ (the restriction of $s'$ to $X$), then $s$ is a solution to $\mathcal E$.<br>\end{enumerate}<br>In particular, there is a one-to-one correspondence between solutions of $\mathcal E$ and $\mathcal E^{\flat}$.\\~\\<br>Prove or disprove. (hint: theorem 6.3 on pg 3302 may be useful here)<br></latex><br>	true. pg 3326, lemma 8.3<br><br>Flat system of equations defined on <br>General system of equations defined on pg 3320<br><br><br>todo: add impostor?<br>
Do exercise 8.5 on pg 3327<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>AFA is equivalent (in $ZFC^-$) to the assertion that every general system of equations has a unique solution.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 3327, thm 8.4<br><br>todo: add impostor?<br><br><br>
Do exercise 8.6 on page 3328<br>	<br>
<latex>~\\<br>Let $\mathcal C$ be a locally small category and $F : \mathcal C \to Set$ be a functor. What does it mean for $F$ to be \emph{representable} functor?<br></latex>	pg 4142, bottom left / top right <br>
<latex>~\\<br>What is a \emph{representation} of a representable functor?<br></latex>	pg 4142, top right<br>
<latex>~\\<br>Use a representable functor to formalize the idea that, given a set $X$, $P(X)$ is in bijection with the set of functions from $X$ to a two-point set $\{ 0 , 1 \}$.<br></latex><br>	pg 4142, example 2.7.2<br>
What is a <i>discrete dynamical system</i>? What is the <i>universal discrete dynamical system</i>?	pg 6732, example 2.1.1<br>
Express the concepts of <i>initial</i> and <i>terminal</i> objects in terms of representable functors.<br>	pg 6733, def 2.1.3<br>
<latex>~\\<br>Let $\mathcal C$ be a locally small category and $F : \mathcal C \to Set$ be a functor. What does it mean for $F$ to be \emph{representable}?<br></latex>	pg 6733, def 2.1.4<br>
<latex>~\\<br>Let $\mathcal C$ be a locally small category and $F : \mathcal C \to Set$ a representable functor. What is a \emph{representation} of $F$?<br></latex>	pg 6733, def 2.1.4 (ii)<br>
<latex>~\\<br>Show that the identity functor $1_{Set} : Set \to Set$ is representable.<br></latex>	pg 6733, example at bottom<br>
<latex>~\\<br>Show that the forgetful functor $U : Group \to Set$ is representable.<br></latex><br>	pg 6734, item (ii)<br><br>
<latex>~\\<br>Show that the forgetful functor $U : Top \to Set$ is representable.<br></latex><br>	pg 6735, item (viii) at top<br><br>
<latex>~\\<br>Show that the functor $ob : Cat \to Set$ which takes a small category to its set of objects is representable.<br></latex>	pg 6735<br>
<latex>~\\<br>Show that the functor $mor : Cat \to Set$ that takes a small category to its set of morphisms is representable.<br></latex>	pg 6735, item (x)<br><br>
<latex>~\\<br>Let the functor $iso : Cat \to Set$ be the functor that takes a small category to its set of isomorphisms, where the two morphisms involved in an iso pair are considered \emph{distinct} isomorphisms. Show that $iso$ is representable.<br></latex>	pg 6735, item (xi)<br><br>
<latex>~\\<br>Consider the functor $comp : Cat \to Set$, which takes a small category to the set of its composable pairs of morphisms. Show that $comp$ is representable.<br></latex><br>	pg 6735, item (xii)<br><br>
<latex>~\\<br>Consider the forgetful functor $U : Set_{\ast} \to Set$ from the category of pointed sets and point-preserving functions to $Set$. Show that this functor is representable.<br></latex>	note that here they use the terminology "based" for pointed<br>pg 6735, item (xiii)<br><br>
<latex>~\\<br>Let $\mathcal O : Top^{op} \to Set$ be the functor that sends a topological space to its set of\\<br>open subsets. Show that this functor is contravariantly representable.<br></latex>	pg 6736 (ii)<br><br>
<latex>~\\<br>Let $\mathcal O : Top^{op} \to Set$ be the functor which maps a topological space to its set of open subsets. Let $\mathcal C : Top^{op} \to Set$ be the functor which maps a topological space to its set of closed subsets. Prove $\mathcal O \cong \mathcal C$, i.e. the two functors are naturally isomorphic.<br></latex> 	pg 6736, item (iii) -- and also (ii) is used as a lemma
<latex>~\\<br>Show that the functor $Hom(- \times A, B) : Set^{op} \to Set$ that sends a set X to the set of functions $X \times A \to B$ is contravariantly representable.<br></latex>	pg 6736, item (iv)<br>
<latex>~\\<br>Show that the functor $U(-)* : Vect^{op}_{\Bbbk} \to Set$ that sends a vector space to the set of vectors in its dual space is contravariantly representable.<br></latex><br>	pg 6736 (v)<br>
Exercise 2.1.i, pg 6737<br>	<br>
Exercise 2.1.ii, pg 6737<br>	<br>
Exercise 2.1.iii, pg 6737<br>	<br>
Exercise 2.1.iv, pg 6737<br>	<br>
Exercise 2.1.v, pg 6737<br>	<br>
Consider the following statement:<br><br>In propositional Kripke semantics, we have<br><br><$>k \Vdash \neg A \Leftrightarrow \exists k' \geq k.~k'  \not \Vdash A</$><br><br>Prove or disprove.<br>	IMPOSTOR. change the exists to a forall and you are good.<br>pg 99 very bottom
<latex>~\\<br>The set of all streams on A should satisfy the equation $Z = A \times Z$. How many solutions does this equation have? Which solutions to this equation are most useful?<br></latex>	pg 3425/3426<br>
<latex>~\\<br>Consider the following statment:\\~\\<br>For every set $A$ there is a largest set $Z$ such that $Z \subseteq A \times Z$. This set $Z$ in fact satisfies the equation $Z = A \times Z$. Moreover, if $A \neq \emptyset$, then $Z \neq \emptyset$ as well.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 3426/3427<br>todo: add impostor?<br>
<latex>~\\<br>Provide an explicit definition of the largest set $Z$ such that $Z \subset A \times Z$.<br>Prove that it in fact is a subset of $A \times Z$. (Proof that it is the largest such set is unnecessary for now)<br></latex><br>	pg 3426/3427<br>
<latex><br>Let $F$ be the set of functions $f$ from $\mathbb N$ to $A$. For each such $f$, we define another such function $f^+$ by<br>$$ f^+(n) = f(n+1)$$<br>For each such $f$, let $x_f$ be a urelement that is distinct from $support(A)$. Then we can define the system of equations:<br>$$x_f = \langle f(0) , x_{f^+} \rangle $$<br>Denote the unique solution to this system of equations using the family of sets $s_f$ for $f \in F$.\\ <br>Prove $Z = \{ s_f \mid f \in F \}$ is the largest set $W$ such that $W \subseteq A \times W$.<br>Prove that $A \times Z \subseteq Z$.<br></latex>	pg 3427<br>
<latex>~\\<br>Is the operator $\Gamma(c) = A \times c$ monotone? What about the operator $\Gamma(c) = c \to c$?<br></latex><br>	pg 3428, near top<br>
Exercise 14.1, pg 3428<br>	<br>
Exercise 14.2, pg 3428<br>	answer on pg 3587<br>
Exercise 14.3, pg 3428<br>	<br>
Exercise 14.4, pg 3428<br>	<br>
<latex>~\\<br>Let $f : A \to A$ be arbitrary. Then $f$ naturally induces a function $map_f : A^\infty \to A^\infty$ by "corecursion":<br>$$map_f(s) = \langle f(1^{st}(s)) , map_{f}(2^{nd}(s)) \rangle$$<br>How can $map_f$ be desugared into a set-theoretic representation?<br>How do we know that for all $f$ and $s$, $map_f(s)$ is a stream under this set-theoretic representation?<br></latex>	pg 3428, 3429 (the section after [Coinduction Prinicple for Streams] explains why we know the values are streams)<br>
<latex><br>State the \emph{Coinduction Principle for Streams}. Why is this a valid principle?<br></latex>	pg 3429<br>
<latex>~\\<br>Let $C$ be an arbitrary set. Consider the following statement:\\~\\<br>Given any functions $G : C \to A$ and $H : C \to C$ there is a unique function $F : C \to A^\infty$ satisfying the following, for all $c \in C$:<br>$$F(c) = \langle G(c), F(H(c)) \rangle$$<br>Prove or disprove.<br></latex><br>  	true. pg 3429 bottom / pg 3430 top<br>todo: add impostor?
State and prove the corecursion principle for streams.<br>	pg 3429/3430<br>
<latex>~\\<br>Define the function $c : A \to A^\infty$ by<br>$$ c_a = \langle a , c_a \rangle $$<br>Let $map_f$ be defined as on page 3428, section 14.2. Consider the following statement: \\~\\<br>$$ map_f(c_a) = c_{f(a)}$$<br>Prove or disprove.<br></latex>	true. pg  3431.<br>todo: add impostor?<br>
Read example 14.1 on page 3431, then do exercise 14.5 on page 3432<br> 	<br>
Read example 14.1 on page 3431, then do exercise 14.6 on page 3432	<br>
<latex>~\\<br>Define $zip : A^\infty \times A^\infty \to A^\infty$ corecursively as follows:<br>$$zip(\langle a , s \rangle, \langle b , t \rangle) = \langle a , \langle b , zip(s, t) \rangle \rangle$$<br>Consider the following statement:<br>$$zip(\langle a, s \rangle, t) = \langle a, zip(t, s) \rangle $$<br>Prove or disprove.<br></latex>	true. pg 3432, example 14.2<br>todo: add impostor?
What is an <i>operator</i>?	pg 3440, section 15.1
<latex>~\\<br>Consider the following operators:\\<br>$\Gamma_1(a) = \mathcal P(A)$\\<br>$\Gamma_2(a) = \mathcal P_{fin}(a)$\\<br>$\Gamma_3(a) = A \times a$\\~\\<br>Verify that these operators are monotone.<br></latex>	pg 3440. todo: add impostor?<br>
<latex>~\\<br>Consider the following operators:\\<br>\Gamma_4(a) = \{ f \mid \text{f is a partial function from } a \text{ to } a \} \\<br>\Gamma_5(a) = \mathcal P(Act \times a) \text{ for some fixed set Act } \\~\\<br>\text{Verify that these operators are monotone}.<br></latex><br><br>	pg 3440, section 15.1<br><br>todo: add impostor?<br>
How can a monotone operator on sets be extended to a monotone operator on classes?<br>	pg 3440, near bottom<br>
<latex>~\\<br>Let $C$ be $V_{afa}[\mathcal U]$, the class of all sets. Which of the following is true:<br>$C \subseteq \mathcal P(C)$, or $\mathcal P(C) \subseteq C$?<br></latex>	pg 3441, exercise 15.2<br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator.<br>What does it mean for a set or class $G$ to be $\Gamma-correct$?<br></latex>	pg 3441<br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator.<br>What does it mean for a set or class $G$ to be $\Gamma$-closed?<br></latex>	pg 3441, definition<br>
<latex>~\\<br>If $X$ is a set of urelements and $\Gamma$ is a monotone operator, then what is a $\Gamma$-form over $X$?<br></latex>	pg 3441, right above example 15.1<br>
<latex>~\\<br>Consider the monotone operator $\Gamma_1$ defined by <br>$\Gamma_1(a) = \mathcal P(a)$.<br>What are the $\Gamma_1$ forms? Can a set be $\Gamma_1$-closed?<br>Does $\Gamma_1$ have any fixed points?<br></latex><br>	pg 3441/3442<br>
<latex>~\\<br>Let $X$ be a set of urelements. Define the monotone operator $\Gamma_3$ by $\Gamma_3(a) = A \times a$. What are the $\Gamma_3$-forms over $X$? Does $\Gamma_3$ have fixed points?<br></latex>	pg 3442, example 15.2<br>
<latex>~\\<br>Let $X$ be a set of urelements. Let $\Gamma_4$ be the monotone operator $\Gamma_4(a) = a \rightharpoonup a$, the set of partial functions from $a$ to itself. What are the $\Gamma_4$-forms on $X$? Does $\Gamma_4$ have fixpoints? <br></latex>	pg 3442, example 15.3<br>
Exercise 15.3, pg 3442<br>	<br>
<latex>~\\<br>Every monotone operator $\Gamma$ has a least fixed point which we denote by $\Gamma_{\ast}$. There are two ways that $\Gamma_{\ast}$ can be characterized. Give both of them and prove that they are correct.<br></latex>	pg 3443, theorem 15.2<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every monotone operator $\Gamma$ has a least fixed point which we denote by $\Gamma_{\ast}$. This least fixed point may be characterized in either of the following ways:<br>\begin{enumerate}<br>\item $\Gamma_{\ast} = \bigcup_{\alpha} \Gamma_{\alpha}$, where $\Gamma_{\alpha}$ is defined by recursion on the ordinals by <br>$$\Gamma_{\alpha} = \bigcup_{\beta < \alpha} \Gamma(\Gamma_\beta).$$<br>\item $\Gamma_{\ast}$ is the least $\Gamma$-closed class.<br>\end{enumerate}<br>Prove or disprove.<br></latex>	pg 3443, thm 15.2<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every monotone operator $\Gamma$ has a least fixed point which we denote by $\Gamma_{\ast}$. This least fixed point may be characterized in either of the following ways:<br>\begin{enumerate}<br>\item $\Gamma_{\ast} = \bigcup_{\alpha} \Gamma_{\alpha}$, where $\Gamma_{\alpha}$ is defined by recursion on the ordinals by <br>$$\Gamma_{\alpha} = \bigcup_{\beta < \alpha} \Gamma_\beta.$$<br>\item $\Gamma_{\ast}$ is the least $\Gamma$-correct class.<br>\end{enumerate}<br>Prove or disprove.<br></latex>	IMPOSTOR.<br>There are two problems here, one with point 1 and the other with point 2.<br>The real theorem is on the top of page 3443: theorem 15.2.<br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator and $\Gamma_{\ast}$ the least fixed point of $\Gamma$. State and justify the \emph{Preliminary Induction Principle for $\Gamma_{\ast}$}<br></latex>	pg 3443, 1st "Method of Proof"<br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator and $\Gamma_{\ast}$ the least fixed point of $\Gamma$. State and justify the \emph{Induction Principle for $\Gamma_{\ast}$}<br></latex>	pg 3443, 2nd "Method of Proof"<br>pg 3444, exercise 15.4 at top<br>
What is a <i>subfunctor</i>?<br>	pg 6737, exercise 2.1.iv
What is a narrowing operator? What is a widening operator? What are the basic properties that narrowing and widening operators must satisfy?<br>	pg 6545/6546<br>
Prove proposition 4.5 on pg 6545<br><br>(I would copy it here, but I don't know how to typeset the upside-down Pi symbol)<br>Note to self: learn how to typeset upside down pi next time you are on the computer with an internet connection.<br>	<br>
Explain one strategy that can be used to ensure termination when we have abstract computation trees that are not regular. <br><br>	pg 6929, section 2.3<br>pg 6930<br>
Consider the following statement:<br><br>memoization is an instance of <i>widening</i><br><br>Prove or disprove.	true. pg 6930, right above section 2.4<br> 
Consider the following statement:<br><br>Memoization is an instance of <i>narrowing</i><br><br>Prove or disprove.<br>	impostor. pg 6930<br>
Under what conditions can memoization ensure termination of the generation of an abstract computation tree? Why?<br>	pg 6930<br>
<latex>~\\<br>Give the UTT dependent type signature of the $\mathbb N$-elim elimation operator for natural numbers. Also give the type signature for primitive recursion. Compare the two.<br></latex><br>	pg 6580, near bottom.
Elimination operators involve methods. What is a <i>method</i>?<br>	pg 6581, near top<br>
How do the types of eliminators give an <i>abstract interface</i> to pattern analysis?<br>	pg 6581, above N-compare type<br>
<latex>~\\<br>How do let bindings work in UTT?\\<br>What is $\delta$-reduction? $\gamma$-reduction?<br></latex>	pg 6583, near bottom<br><br>
Give UTT's term syntax.<br>	pg 6584<br>
Give UTT's type syntax.	pg 6584<br>
Explain the four types of judgments in UTT.<br>	pg 6585<br>
Give UTT's validity rules.	pg 6584<br>
Give UTT's seven <i>typing</i> rules.<br>	pg 6584<br>
Give UTT's three <i>reduction</i> rules.	pg 6584<br>
Give UTT's four <i>cumulativity</i> rules.	pg 6584<br>
<latex>~\\<br>What does the notation $\forall \Delta. T$ mean?<br></latex>	pg 6585<br>
<latex>~\\<br>If $\Gamma \vdash t : T$ then we can "split" $\gamma$ into two contexts $\Gamma^t$ and $\Gamma_t$. Explain.<br></latex>	pg 6586
Explain the basic structure of a "concrete syntax" program.<br>	pg 6586 / 6587<br>See the "program" syntactic category in figure 2, specifically<br>
<latex>~\\<br>What does the judgment $\Gamma \vdash t_1 \cong t_2$ mean in UTT?<br></latex><br>	It's the conversion relation, i.e. equivalence closure of reduction under Gamma.<br>pg 6548<br>
In UTT programs, function calls can be executed in three different ways, giving a hierarchical structure to the program. Explain the three different ways of executing function calls.<br><br>	pg 6587<br>
<latex>~\\<br>State the coinductive proof principle (cpp) for streams ($A^{\mathbb N}$). Use this<br>principle to prove $merge(odd(\alpha), even(\alpha)) = \alpha$.<br>Assume that even is defined as $odd(tail(\alpha))$.<br></latex><br>	pg 3852<br>
<latex>~\\<br>State the coinductive proof principle (cpp) for streams ($A^{\mathbb N}$). Prove that this<br>principle is sound using coalgebra finality.<br></latex><br>	pg 3852<br>
<latex>~\\<br>Explain how the functor $B(X) = \mathcal P(A \times X)$, when used as a coalgebra signature,<br>corresponds to transition systems. What do coalgebra maps in the coalgebra category induced by $B(X)$ correspond to when framed in the language of transition systems?<br></latex>	pg 3853<br>
Define the common notion of <i>bisimulations</i> on labeled transition systems.<br>	pg 3853<br>
Give a bisimulation between the labeled transition systems X and Y shown on pg 3853	pg 3853 (duh)
<latex>~\\<br>Consider the coalgebra induced by the functor $B(X) = \mathcal P(A \times X)$.<br>Does this coalgebra category have a final object?<br></latex><br>	Nope... for cardinality reasons. Pg 3853<br>
<latex>~\\<br>Consider the coalgebra category induced by the functor $B_{fin}(X) = \mathcal P_{fin}(A \times X)$, <br>i.e. the coalgebra category of finitely non-deterministic labeled transition systems. This category has a final object $(P, \pi)$. It's difficult to prove that this final object exists, so don't worry about it.<br>In concurrency theory, the elements of $P$ are called processes. Prove that if $R(p,p')$ for some bismulation $R$ on $P$, then $p = p'$.<br></latex><br> 	pg 3854<br>
<latex>~\\<br>The functor $B_{fin}(X) = \mathcal P_{fin}(A \times X)$ induces a coalgebra of finitely nondeterministic labeled transition systems. It has a final coalgebra $(P, \pi)$; in <br>concurrency theory, the elements of P are called processes. We supply $P \times P$ with the <br>coalgebra structure $$\langle - , - \rangle : P \times P \to \mathcal P_{fin}(A \times (P \times P))$$<br>by<br>$$\langle p, q \rangle \mapsto \{ \langle a, \langle p', q \rangle \rangle \mid p \overset{a}{\to} p' \}<br>  \cup \{ \langle a, \langle p , q' \rangle \rangle \mid q \overset{a}{\to} q' \}$$<br><br>What can be said about the unique coalgebra homomorphism from $P \times P$ to $P$?<br></latex>	pg 3854<br>
<latex>~\\<br>The functor $B_{fin}(X) = \mathcal P_{fin}(A \times X)$ induces a coalgebra of finitely nondeterministic labeled transition systems. It has a final coalgebra $(P, \pi)$; in <br>concurrency theory, the elements of P are called processes. <br>\\\\<br>The \emph{terminated process} $p_0$: formally, $p_0 = \pi^{-1}(\emptyset)$, for which <br>no transitions exist.<br>\\\\<br>How would we define a \emph{merge} operator on processes that satisfies the following properties:<br><br>\begin{enumerate}<br>\item $merge\langle p_0, p \rangle = p$<br>\item $merge\langle p, q \rangle = merge \langle q, p \rangle$<br>\item $merge\langle merge\langle p, q \rangle r \rangle = merge \langle p, merge \langle q, r \rangle \rangle$<br>\end{enumerate}<br>\\\\<br>Prove your answer<br></latex> 	pg 3854
<latex>~\\<br>Let T be a functor and $c : U \to T(U)$ a $T$-coalgebra. What is a \emph{bisimulation} on $U$?<br></latex>	pg 3855<br>
<latex>~\\<br>Consider the following statement:<br>\\\\<br>Let $c : Z \overset{\cong}{\to} T(Z)$ be the final $T$-coalgebra. For all $z$ and $z'$ in $Z$,<br>if $R(z,z')$, for some bisimulation $R$ on $Z$, then $z = z'$. <br>\\\\<br>Prove or disprove<br></latex><br>	pg 3855<br><br>todo: add impostor<br>
What is the <i>binary induction principle</i> for algebras?<br>	pg 3856 - see lower text square<br>Start reading at "A <i>congruence</i>..."<br>
What is a <i>black hole definition</i>, and how does Agda prevent them?<br>	pg 7342<br>
How would one implement a CoList datatype (the type of finite and infinite lists) in Agda?<br>	pg 7341/7342
Describe the generic recipe for expressing coalgebras in Agda, the one for expressing the terminal coalgebra of a functor, and the one for generating the unique map from any coalgebra of a functor F to the terminal coalgebra.<br>	pg 7343<br>
Define and explain Object-Oriented Agda's IOInterface type.<br>	pg 7344
How would we set up an interface for console input-output in object-oriented Agda?<br>	pg 7345
Explain the do, return, and monadic bind operator for use with object-oriented Agda.<br>	pg 7345 / 7346
Write an object-oriented Agda program which echoes lines of text extracted from standard input onto standard output.<br>	pg 7346/7347
What do "constructor delay" declarations do when placed in Agda's coinductive record type definitions?<br>	pg 7348<br>
How do we actually run IO-monad computations in object-oriented Agda?	pg 7347 bottom / 7348 top<br><br>
How are the do, return, and monadic bind operators implemented in object-oriented Agda?	pg 7346 / 7347
Explain Setzer's view of objects in dependent type theory, as well as how this view manifests in object-oriented Agda. Also, what is the difference between an Object and an IOObject?	pg 7349
How do object constructors work in Object-Oriented Agda?<br>	pg 7349, near bottom<br>
Write a mutable cell object with a parameterized element type A in object-oriented Agda.	pg 7351
Explain the basics of sized types as they apply to inductive and coinductive data in Agda.	pg 7352, section 6<br>
Explain how to represent the terminal coalgebra of a "functor" F (in Agda, F is a datatype of course), using sized types and coinductive records. How is this reminiscent of deflationary iteration to produce greatest fixpoints?<br>	pg 7353, near top<br>Note: We cannot interact with values of type vF 0, and so vF 0 is really the top type: it is permissible to not interact with any value constructible in Agda.<br> 
Consider the following coinductive record for the terminal coalgebra of a functor:<br><br>record νF (i : Size) : Set where<br>  constructor delay<br>  force : ∀(j : Size< i) → F (νF j)<br><br>How would we define a coiterator function unfoldF for this? (Note: first give its type)<br>	pg 7353
Give Agda's IO and IO' types (make sure they include <i>sized</i> types to handle productivity checking)<br>	pg 7353
What does it mean for a relation R to be primitive recursive?<br>	pg 139, def 1.5<br>
<latex>~\\<br>Consider the following statement:<br><br>The relations $=$ and $\leq$ are primitive recursive.<br><br>Prove or disprove.<br></latex> 	pg 139<br>todo: add impostor
Consider the following statement:<br><br>The primitive recursive relations are closed under union.<br><br>Prove or disprove.	true. pg 139, prop 1.6 <br>todo: add impostor
Consider the following statement:<br><br>The primitive recursive relations are closed under bounded quantification.<br><br>Prove or disprove.	true. pg 139, prop 1.6<br>todo: add impostor.<br>
<latex>~\\<br>If $R(y, \vec{x})$ is primitive recursive, how is $min_{y \leq z}R(y, \vec{x})$ defined?<br></latex>	pg 139, def 1.7<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The following predicate is primitive recursive.\\~\\<br>$x \mid y := \exists z \leq y.~(x \cdot z = y)$~~~(divisibility)\\~\\<br>Prove or disprove.<br></latex>	pg 139, example near bottom<br>todo: add impostor<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The following function is primitive recursive:\\~\\<br>$0! = 1$, $(S x)! = (x!) \cdot S x$~~~(factorial function)\\~\\<br>Prove or disprove.<br></latex>	true. pg 139, example near bottom<br>
<latex>\\~\\<br>How do we define the $Prime(x)$ predicate (x is a prime) in such a way that demonstrates it is primitive recursive?<br></latex>	pg 139, example near bottom
<latex>~\\<br>Consider a mapping $j \in \mathbb N^2 \to \mathbb N$ which encodes a pair of natural numbers into a natural number.<br>What properties would we like this mapping to have?<br></latex>	pg 140, section 1.8<br>
<latex>~\\<br>Define functions $j$, $j_1$, and $j_2$ for encoding and projecting natural numbers with\\<br>$j(x, y) := 2^x \cdot (2 y + 1) \dotminus 1$,\\<br>$j_1(z) := min_{x \leq z}[\exists y \leq z.~2^x \cdot (2 y + 1) = S z)]$\\<br>$j_2(z) := min_{y \leq z}[\exists x \leq z.~2^x \cdot (2 y + 1) = S z)]$\\~\\<br>Consider the following statement:\\<br>$x \leq j(x, y)$ and $y \leq j(x,y)$\\<br>Prove or disprove.<br></latex>	true. pg 140, prop 1.10 (i)<br>todo: add impostor?
<latex>~\\<br>Define functions $j$, $j_1$, and $j_2$ for encoding and projecting natural numbers with\\<br>$j(x, y) := 2^x \cdot (2 y + 1) \dotminus 1$,\\<br>$j_1(z) := min_{x \leq z}[\exists y \leq z.~2^x \cdot (2 y + 1) = S z)]$\\<br>$j_2(z) := min_{y \leq z}[\exists x \leq z.~2^x \cdot (2 y + 1) = S z)]$\\~\\<br>Consider the following statement:\\<br>$x < x' \to j(x, y) < j(x', y) \wedge j(y,x) < j(y, x')$\\<br>Prove or disprove.<br></latex>	true. pg 140, prop 1.10<br>todo: add impostor?<br>
<latex>~\\<br>Define functions $j$, $j_1$, and $j_2$ for encoding and projecting natural numbers with\\<br>$j(x, y) := 2^x \cdot (2 y + 1) \dotminus 1$,\\<br>$j_1(z) := min_{x \leq z}[\exists y \leq z.~2^x \cdot (2 y + 1) = S z)]$\\<br>$j_2(z) := min_{y \leq z}[\exists x \leq z.~2^x \cdot (2 y + 1) = S z)]$\\~\\<br>Consider the following statement:\\<br>$j(0,0) = 0$\\<br>Prove or disprove.<br></latex>	true. pg 140, prop 1.10.<br><br>
<latex>~\\<br>Define functions the function $j$ for encoding pairs of natural numbers with\\<br>$j(x, y) := 2^x \cdot (2 y + 1)~ \dotminus ~1$,\\<br>List a few interesting properties that this function has.<br></latex>	pg 140, prop 1.10
How do we code sequences using constructive arithmetic?	pg 141, near top
<latex>~\\<br>For any primitive recursive arithmetic function $\phi$, what is the course-of-values function $\bar{\varphi}$ obtained from $\varphi$?<br></latex>	pg 141, def 1.13<br>
Define the notion of a <i>cartesian closed category</i> using three isomorphisms.<br>	pg 8067<br>
<latex>~\\<br>What does $B \Leftarrow A$ mean?<br></latex><br>	pg 8068<br>
Discuss the correspondence between cartesian closed categories and typed combinatory logic.<br>	pg 8069/8070<br><br>
What does Lambek mean when he writes "Curry algbera"?<br>	I believe this is what Barendregt refers to as "lambda algebra".<br><br>pg 8069<br>(see pg 5380 for barendregt)<br><br>
How does one add static types for SK combinators? Give types for S, K, and I.<br>	pg 8069<br>REMEMBER: the type of the first (leftmost) argument is on the right<br>
Explain the representation of natural numbers in untyped lambda calculus, why it isn't compatible with types, and how to get around this issue.<br>	pg 8070
What is a <i>weak natural numbers object</i>? Give a commutative diagram.	pg 8071<br>
What is a <i>deductive system</i>?<br>	pg 8072<br>
What is a <i>conjunction calculus</i>?	pg 8072/8073<br><br>
<latex>~\\<br>Use the laws of conjunction calculus to prove the "commutative law" for conjunction,<br>$A \wedge B \to B \wedge A$.<br></latex> 	pg 8073<br>
<latex>~\\<br>Use the laws of conjunction calculus to prove the "associative law" for conjunction,<br>$$(A \wedge B) \wedge C \to A \wedge (B \wedge C)$$.<br></latex> 	pg 8073<br>
<latex>~\\<br>Derive the following rule using the conjunction calculus laws.<br>\begin{mathpar}<br>\inferrule<br>  {A \overset{f}{\longrightarrow} B \\ C \overset{g}{\longrightarrow} D}<br>  {A \wedge C \overset{f \wedge g}{\longrightarrow} B \wedge D}<br>\end{mathpar}<br></latex>	pg 8073<br>
What is the <i>positive intuitionistic propositional calculus</i>?<br>	pg 8073/8074<br><br>
<latex>~\\<br>How do we derive $C \overset{\eta__{(C,B)}}{\longrightarrow}(C \wedge B) \Leftarrow B$<br>in the positive intuitionistic propositional calculus?<br></latex>	pg 8074, R'4b<br>
<latex>~\\<br>How do we derive<br>\begin{mathpar}<br>\inferrule<br>  {D \overset{g}{\longrightarrow} A}<br>  {(D \Leftarrow B) \overset{g \Leftarrow 1__B}{\longrightarrow}(A \Leftarrow B)}<br>\end{mathpar}<br>in the positive intuitionistic propositional calculus?<br></latex>	pg 8074, R'4c<br>
<latex>~\\<br>Derive the following two rules using positive intuitionistic propositional calculus:<br>\begin{mathpar}<br>\inferrule<br>  {A \overset{f}{\longrightarrow} B}<br>  {T \overset{\lceil f \rceil}{\longrightarrow} B \Leftarrow A}<br>\and<br>\inferrule<br>  {T \overset{g}{\rightarrow} B \Leftarrow A}<br>  {A \overset{g^\wr}{\longrightarrow} B}<br>\end{mathpar}<br></latex>	<latex>~\\<br>$\lceil f \rceil \equiv (f \pi^\prime_{1,A})^*$,\\<br>$g^\wr \equiv \epsilon_{B,A} \langle g \bigcirc_A, 1_A \rangle$<br></latex><br><br>pg 8074, kinda near bottom<br><br>
What is <i>intuitionistic propositional calculus</i>?<br>	pg 8074/8075<br><br>
Exercise 1, pg 8075<br>	<br>
Exercise 2, pg 8075<br>	<br>
Exercise 3, pg 8075<br>(note: I have worked out a solution on the answer section of this card)<br>	<latex>~\\<br>We have $((C \Leftarrow A) \wedge (C \Leftarrow B)) \wedge A \rTo^{\langle \pi_1 \circ \pi_1 , \pi_2 \rangle } (C \Leftarrow A) \wedge A \rTo^{ev_{A,C}} C$.\\~\\<br>We also have $((C \Leftarrow A) \wedge (C \Leftarrow B)) \wedge B \rTo^{\langle \pi_2 \circ \pi_1 , \pi_2 \rangle } (C \Leftarrow B) \wedge B \rTo^{ev_{B,C}} C$\\~\\<br>We then apply R'6c to get\\<br>$(((C \Leftarrow A) \wedge (C \Leftarrow B)) \wedge A) \vee (((C \Leftarrow A) \wedge (C \Leftarrow B)) \wedge B) \to C$\\~\\<br>Using the distributive property (see the bottom arrow in exercise 1) gives:\\~\\<br>\ldots<br></latex>
Exercise 4, pg 8075<br>(partial answer given on back of card... read that first and pick up from where you left off)<br>	<latex>~\\<br>Assume $T \to A \vee (\bot \Leftarrow A)$. We need an arrow $g : T \to A \Leftarrow (\bot \Leftarrow (\bot \Leftarrow A))$ so that we can obtain $g^\imath : \bot \Leftarrow (\bot \Leftarrow A) \to A$ (see pg 8074).\\~\\<br>Our strategy is to apply R'6c. First we need its premises. Can we obtain an arrow $A \to A \Leftarrow (\bot \Leftarrow (\bot \Leftarrow A))$? Yes. For all $Z$ we have $A \to A \Leftarrow Z$, since<br>$A \rTo{\eta} (A \wedge Z \Leftarrow Z) \rTo^{exerc. 1} (A \Leftarrow Z) \wedge (Z \Leftarrow Z) <br>  \rTo^{\pi_1} (A \Leftarrow Z)$.<br><br>... to be continued\\<br>Note that we will also need $(\bot \Leftarrow A) \to A \Leftarrow (\bot \Leftarrow (\bot \Leftarrow A))$<br></latex>
<latex>~\\<br>The usual \emph{deduction theorem} asserts:<br>$$\text{if } A \wedge B \vdash C \text{ then } A \vdash C \Leftarrow B$$<br>How is this represented using exponentials in categorical logic?<br></latex><br>	pg 8075/8076<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a conjunction, positive, intuitionistic or classical calculus, with every proof $\phi(x) \to C$ from the assumption $x : \mathbf{T} \to A$ there is associated a proof $f : A \wedge B \to C$ in $\mathcal L$ not <br>depending on $x$.\\~\\<br>Prove or disprove\\~\\<br>(Useful notation: Write $f = \kappa_{x \in A}\phi(x)$, where the subscript '$x \in A$' indicates that $x$ is of type $A$)<br></latex>	pg 8076<br>todo: add impostor<br>
Exercise, pg 8077	<br>
Define the notion of a <i>category</i> in terms of deduction systems.<br>	pg 8077<br>
Define the notion of a <i>cartesian category</i> in terms of deduction systems.<br>	pg 8077, near bottom<br>
<latex>~\\<br>Cartesian categories satisfy the equation:\\<br>$$f = \bigcirc_A \text{, for all } f : A \to T$$<br>among others. Use the laws of cartesian categories to prove this equivalent to:\\<br>$$1_1 = \bigcirc_1 \text{and} \bigcirc_B f = \bigcirc A \text{ for all } f : A \to B$$<br></latex><br>	pg 8077/8078
<latex>~\\<br>Consider the following statement\\<br><br>$$<f, g>h = <fh, gh>$$<br>Holds in cartesian categories.<br>\\~\\<br>Prove or disprove.<br></latex>	pg 8078<br>
Define the notion of a <i>cartesian closed category</i> in terms of deduction systems. In particular, what is the difference between a cartesian category and a cartesian closed category?<br>	pg 8078, near bottom<br><br>
State and prove the adjoint functor theorem.<br>	pg 2895, thm 9.29<br><br><br>
<latex>~\\<br>State the simplified version of the adjoint functor theorem, which applies for functors:<br>$$F : \mbf C \to \mbf X$$<br>when $\mbf C$ is a small category.\\~\\<br>Justify the simplified version of the AFT.<br></latex>	pg 2898, corollary 9.32<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mbf C$ is a small and complete category, then for any functor<br>$$U : \mbf C \to \mbf{Sets}$$ the following are equivalent:<br>\begin{enumerate}<br>\item $U$ preserves all limits<br>\item $U$ has a left adjoint<br>\item $U$ is representable<br>\end{enumerate}<br>Prove or disprove.<br></latex>	pg 2898, corollary 9.34 near bottom<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mbf{C}$ is small and complete, then $\mbf C$ is a preorder.\\~\\<br>Prove or disprove.<br></latex>	true. pg 2899.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mbf{C}$ is small and complete, then $\mbf C$ is a poset.\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>IMPOSTOR.<br>I think the $\mbf{Sets_{fin}}$ is a counterexample, but I'll have to doublecheck this.\\<br>pg 2899, prop 9.35<br></latex><br><br>
<latex>~\\<br>What does it mean for a category to be \emph{well-powered}, and how is well-poweredness relevant to the adjoint functor theorem?<br></latex>	pg 2899
<latex>~\\<br>What does it mean for a category to have a \emph{co-generating set}, and how are co-generating sets relevant to the adjoint functor theorem?<br></latex>	pg 2899
What is the </i>special adjoint functor theorem (SAFT)</i>?	pg 2899
<latex>~\\<br>Define the polynomial functor $T(M) = (1 + M) \to M$. Consider the following statement:\\~\\<br>The forgetful functor $U : T \text{-} \mbf {Alg} \to \mbf{Sets}$ has a left adjoint.<br>Prove or disprove.<br></latex><br><br><br>	for a more in-depth discussion of algebras, see pg 3835 (Jacobs and van Rutten's "(Co)algebras" tutorial)<br>pg 2900/2901, example 9.39<br>
<latex>~\\<br>Define the polynomial functor $T(M) = (1 + M) \to M$. Consider the following statement:\\~\\<br>The forgetful functor $U : T-\mbf{Alg} \to \mbf{Sets}$ has a right adjoint.<br>Prove or disprove.<br></latex><br><br>	IMPOSTOR. pg 2900/2901, example 9.39<br><br>
<latex>~\\<br>State and prove the ``triangle identities'' for adjunctions.<br></latex><br>	pg 2909, 2910 (10.1) and (10.2)<br>
<latex>~\\<br>Given categories, functors, and natural transformations<br>$$  F : \mbf C \pile{\lTo \\ \rTo} \mbf D : U $$<br>$$ \eta : 1_{\mbf C} \to U \circ F $$<br>$$ \epsilon : F \circ U \to 1_{\mbf D} $$<br>Consider the following statement:\\~\\<br>One has $F \dashv U$ with unit $\eta$ and counit $\epsilon$ iff the triangle identities hold.\\~\\<br>Prove or disprove.<br></latex>	pg 2910/2911, prop 10.1<br><br>todo: add impostor<br>
<latex>~\\<br>If we have $F \dashv U$, how can we describe the adjunction $F \dashv U$ in terms of the composite functor $T = U \circ F$? (warning: not sure this is satisfactorily answered in the text, but you can try it regardless)<br></latex>	pg 2911, 2912, intro to section 10.2<br><br>
<latex>~\\<br>Give the definition of a \emph{monad} on a category $\mbf C$. Show how any adjunction gives rise to a monad.<br></latex><br>	definition on page 2913,<br><br>deriving monad from adjunction starts at the very bottom of page 2911<br>and goes all the way to page 2913<br><br>
<latex>~\\<br>Given an adjunction $F \dashv U$, define $T = U \circ F$. Let<br>$\eta$ be the unit of this adjunction, and define $\mu = U(\epsilon_{F-})$.<br>Show that the following diagram commutes.<br><br>\begin{diagram}<br>T^3                 & \rTo^{T\mu} & T^2        \\<br>\dTo<{\mu_T} &                    & \dTo \mu \\<br>T^2                 & \rTo_\mu      & T            \\<br>\end{diagram}<br></latex>	"To prove the first one, ..." bottom of page 2912
<latex>~\\<br>Given an adjunction $F \dashv U$, define $T = U \circ F$. Let<br>$\eta$ be the unit of this adjunction, and define $\mu = U(\epsilon_{F-})$.<br>Show that the following diagram commutes.<br><br>\begin{diagram}<br>T & \rTo^{\eta_T} & T^2            & \lTo^{T \eta} & T \\<br>   & \rdTo_=         & \dTo_\mu    & \ldTo_=        &    \\<br>   &                      & T               &                     &     \\<br>\end{diagram}<br></latex>	pg 2013, "The equations (10.4) in the form"...<br>TODO: add impostor?<br>
Explain the connection between monads and monoids.<br>	bottom paragraph of page 2913
<latex>~\\<br>Let $P$ be a poset. Explain the significance of monads $(T : P \to P, \eta : 1 \to T^2, \mu : T^2 \to T)$ on $P$. Can we recover an adjunction from this monad?<br></latex><br><br>	pg 2914, example 10.4<br>
<latex>~\\<br>Consider the covariant powerset functor<br>$$\mathcal P : \mbf{Sets} \to \mbf{Sets}$$<br>which takes each function $f : X \to Y$ to the image mapping $im(f) : \mathcal P(X) \to \mathcal P(Y)$.<br>Let $\eta_X : X \to \mathcal P(X)$ be the singleton operation<br>$$\eta_X (x) = \{ x \}$$<br>and let $\mu_X : \mathcal P \mathcal P(X) \to \mathcal P(X)$ be the union operation<br>$$\mu_X(\alpha) = \bigcup \alpha$$<br>Verify that these operations are natural in $X$ and that this defines a monad $(\mathcal P, \{-\}, \bigcup)$<br></latex>	pg 2914<br>
<latex>~\\<br>Consider the following statement:\\<br>Every monad arises from an adjunction. More precisely, given a monad $(T, \eta, \mu)$ on the category $\mbf C$, there exists a category $\mbf D$ and an adjunction $F \dashv U$, $\eta : 1 \to UF$, $\epsilon : FU \to 1$ with $U : \mbf D \to \mbf C$ such that <br>$$T = U \circ F$$<br>$$\eta = \eta~(\text{the unit})$$<br>$$\mu = U \epsilon_F$$<br>Prove or disprove.<br></latex><br>	lol. the proof is so long. I'm sorry. see prop 10.6, pg 2915-2918
<latex>~\\<br>Let $(T : \mbf C \to \mbf C, \eta : 1 \to T, \mu : T^2 \to T)$ be a monad. What is the \emph{Eilenberg-Moore category} $\mbf C^T$?<br></latex> 	pg 2915, beginning of proof of prop 10.6<br>
<latex>~\\<br>Let $\mbf C$ be a locally small category, let $\mbf X$ be any category, and let $U : \mbf C \to \mbf X$ be a limit-preserving functor.<br>Letting $X$ be an object of $\mbf X$, what is the \emph{comma category} $(X \mid U)$? <br>What conditions are necessary for $(X \mid U)$ to have an initial object? Prove or disprove.<br></latex>	having an initial object requires completeness of <b>(X | U)</b>, which follows easily from completeness of C.<br><br>pg 2897<br><br>todo: impostor involving asking to prove that comma category has a terminal object?
What is a <i>sequent</i>?<br>	pg 8375
<latex>~\\<br>What is the \emph{natural deduction system for }$\wedge, \supset$?<br></latex>	pg 8375, table 1.3<br>
<latex>~\\<br>What is the \emph{cut rule}? Is it admissible in the natural deduction system for $\wedge, \supset$? Prove or disprove. You are allowed to utilize the weakening rule, which is admissible under the natural deduction system for $\wedge, \supset$.<br></latex>	<latex>~\\<br><br>\begin{prooftree}<br><br>\AxiomC{$\Gamma \vdash A$}<br>\UnaryInfC{$\Gamma,\Delta \vdash A$}<br><br>\AxiomC{$A,\Delta \vdash B$}<br>\UnaryInfC{$\Delta \vdash A \supset B$}<br>\UnaryInfC{$\Gamma,\Delta \vdash A \supset B$}<br><br>\BinaryInfC{$\Gamma,\Delta \vdash B$}<br><br>\end{prooftree}<br><br>pg 8376<br></latex>
<latex>~\\<br>State the weakening rule of natural deduction and prove it admissible in the natural deduction system for $\wedge, \supset$.<br></latex>	<latex>~\\<br>This must be proven by induction on the derivation of <br>$$\Gamma \vdash B$$<br>All cases are trivial. Except for the id case, they are just a matter of applying the IH and then reapplying the rule.<br>pg 8376<br></latex>
<latex>~\\<br>What does it mean for a proof rule<br>\begin{mathpar}<br>\inferrule<br>  {\Gamma_1 \vdash A_1 \\ \cdots \\ \Gamma_n \vdash A_n}<br>  {\Delta \vdash B}<br>\end{mathpar}<br>to be admissible?<br></latex><br>	<latex>~\\<br>*alert* This tripped me up at first.<br>It does *not* mean that $\Delta \vdash B$ can be proven using $\Gamma_i \vdash A_i$ as assumptions.<br>Under that definition, weakening would not be admissible. Instead, it is the definition on \emph{pg 8376}.<br></latex>
<latex>~\\<br>What is \textbf{structural proof theory}, and why should we study it?<br></latex><br>	pf 8376<br>
<latex>~\\<br>What is the difference between a \emph{term} and a \emph{raw term}?<br></latex><br>	pg 8378<br>
Read Definition 83 on page 8378, and do exercise 84<br>	1.<br>Let z be a variable distinct from x and y.<br>(z x) · x = z = (z y) · y<br><br>2.<br>Let z be distinct from x,y,x',y'.<br>Then we need (z x) · (λy.xy) = (λy.zy) =α (λx.zx) (z y) · (λx.yx) <br>Do we have (λy.zy) =α (λx.zx)?<br>Let w be a variable distinct from z, y, and x.<br>Then (w y) · (zy) = (zw) = (w x) · (zx)<br>
Read Definition 83 on page 8378, and do exercise 85<br>	<br>
Give a careful, but simple definition of substitution on lambda terms that takes capture avoidance into account.	pg 8379, def 86<br>
Exercise 90, pg 8381<br>	1. no. the (t u) rule requires that x has type U, and also type T → U. These are distinct types.<br><br>
Exercise 91, pg 8381/8382<br>	<br>
<latex>~\\<br>What are the relations $\longrightarrow_\beta$, $=_\eta$, and $=_\beta$?<br></latex><br>	pg 8382<br>
Explain the Curry-Howard correspondence for STLC.<br>	pg 8383<br>
Demonstrate the correspondence between natural deduction and cartesian-closed categories in the Curry-Howard triangle.<br>	pg 8384<br>
Give the semantic translation of STLC typing derivations into a cartesian closed category.<br>	pg 8385<br>
It's possible to interpret STLC typing derivations as arrows of a cartesian closed category. But what theorem do we need to prove to show that this interpretation is <i>sound</i>? Outline the method for proving this.<br><br>	method: Show that interpretation is preserved across beta and eta equality.<br>their definition of soundness seems kind of weird. maybe I should ask about it on cs stack exchange.<br>pg 8386, top<br><br>
Summarize the basic properties of products and exponentials in cartesian closed categories.<br>	pg 8386<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any $f : A \times B \to C$ and $g : A' \to A$,<br>$$\Lambda(f) \circ g = \Lambda (f \circ (g \times id_B))$$<br>Prove or disprove.<br></latex>	<latex>~\\<br>true. pg 8386.<br>Apparently this theorem is a statement of $\Lambda$'s naturality. How?<br></latex><br>
<latex>~\\<br>1. Give the definition of typed simultaneous substitution on STLC.\\~\\<br>2. Letting $\sem{-}$ denote the translation of STLC derivations into a cartesian closed category, consider the following statement:\\~\\<br>Let $\Gamma = x_1 : T_1, \ldots, x_k : T_k$, $t,t_1, \ldots t_k$ with $\Gamma \vdash t : T$, $\Delta \vdash t_1 : T_1$, $\ldots$, $\Delta \vdash t_k : T_k$.\\<br>Then we have $\sem{t[t_1/x_1,\ldots,t_k/x_k]} = \sem{t} \circ \langle \sem{t_1}, \ldots, \sem{t_k}\rangle$.\\~\\<br>Prove or disprove.<br></latex>	pg 8387
<latex>~\\<br>Explain the \emph{uniqueness equation} for exponentials<br>$$\forall h : D \longrightarrow (E \Rightarrow F).~\Lambda(ev \circ (h \times id_E)) = h$$<br>in terms of commutative diagrams. Why is this equation important for proving the soundness<br>of the translation of the STLC into a cartesian closed category.<br></latex>	statement on pg 8386<br>soundness explanation on 8388<br><br>
<latex>~\\ <br>Assume the following\\<br>$$\Gamma = x_1 : X_1, \ldots, x_n : X_n$$ <br>$$\Gamma, x:S \vdash t : T$$ <br>$$\Gamma \vdash u : S$$<br>Prove that $\sem{(\lambda x.~t)~u} = \sem{t[x_1 / x_1, \ldots, x_n / x_n, u/x]}$ <br>using the standard translation from STLC to a cartesian closed category.<br>Why is this fact useful?<br></latex>	pg 8388
<latex>~\\ <br>Prove that $\sem{\lambda x. t x} = \sem{t}$ <br>using the standard translation from STLC to a cartesian closed category.<br>Why is this fact useful?<br></latex>	pg 8388<br>
What is a <i>term model</i>?<br>	pg 8388<br>
<latex>~\\<br>How is the relation $(x,t) \sim_{T,U} (y, u)$ on variable/term pairs defined?<br>How is the relation $(\cdot, t) \sim_{\cdot,U} (\cdot, u)$ on terms defined?<br>What does $[(x,t)]_{T,U}$ denote?<br></latex><br>	pg 8388<br>
<latex>~\\<br>What is the relation $=_{\lambda}$?<br></latex><br><br>	<latex>~\\<br>the transitive closure of $=_\beta \cup =_\eta$\\~\\<br>pg 8382<br></latex><br>
<latex>~\\<br>Define the category $C_{\lambda}$.<br></latex><br>	pg 8389<br>
<latex>~\\<br>Show that $C_\lambda$ has finite products.<br></latex><br>	pg 8389<br>
<latex>~\\<br>Show that $C_\lambda$ has exponentials.<br></latex><br>	pg 8390<br>
Construct the first to proofs of Exercise 1.6.7 (1), pg 8391<br>	<br>
Construct the second two proofs of Exercise 1.6.7 (1), pg 8391<br>	<br>
Handle the first three lambda terms of Exercise 1.6.7 (2), pg 8391<br>	<br>
Handle the second three lambda terms of Exercise 1.6.7 (2), pg 8391<br>	<br>
What are the <i>structural rules</i> for logic?<br>	pg 8392<br>
How are the assumptions in a Gentzen Sequent Calculus sequent fundamentally different from those of a natural deduction sequent?<br>	In sequent calculus, the assumptions are a list rather than a set.<br>pg 8392<br>
Give the categorical interpretations for the structural rules of Gentzen's sequent calculus.<br>	pg 8392<br>
<latex>~\\<br>Give the \emph{Gentzen sequent calculus} for $\wedge, \supset$.<br></latex><br>	It is a combination of the <b>structural rules</b> on page 8392, table 1.8<br>and the other rules on page 8393, table 1.9.<br>
What is the intuitive purpose of the cut rule in Gentzen's sequent calculus?<br>	pg 8393, paragraph below exercise 109<br>
<latex>~\\<br>Show that $\supset L$ is admissible in Natural Deduction. <br>Exercise 109, pg 8393.<br>You can and should consult the natural deduction rules on page 8375.<br></latex>	Remember "admissible" means that whenever there exist proofs of the premises, there also exists a proof of the conclusion. It does not necessarily mean that the conclusion is provable from the premises.<br><br><latex>~\\<br>\begin{prooftree}<br>\AxiomC{$\Delta, B \vdash C$}<br>\UnaryInfC{$\Delta, A \supset B, B \vdash C$}<br>\UnaryInfC{$\Delta, A \supset B \vdash B \supset C$}<br>\UnaryInfC{$\Gamma, A \supset B, \Delta \vdash B \supset C$}<br><br>\AxiomC{$\Gamma \vdash A$}<br>\UnaryInfC{$\Gamma, A \supset B \vdash A$}<br>\AxiomC{}<br>\UnaryInfC{$\Gamma, A \supset B \vdash A \supset B$}<br>\BinaryInfC{$\Gamma, A \supset B \vdash B$}<br>\UnaryInfC{$\Gamma, A \supset B, \Delta \vdash B$}<br><br>\BinaryInfC{$\Gamma, A \supset B, \Delta \vdash C$}<br>\end{prooftree}<br></latex><br>
<latex>~\\<br>Show that $Cut$ is admissible in Natural Deduction. <br>Exercise 109, pg 8393.<br>You can and should consult the natural deduction rules on page 8375.<br></latex>	Remember "admissible" means that whenever there exist proofs of the premises, there also exists a proof of the conclusion. It does not necessarily mean that the conclusion is provable from the premises.<br><br><latex>~\\<br><br>\begin{prooftree}<br><br>\AxiomC{$\Gamma \vdash A$}<br>\UnaryInfC{$\Gamma, \Delta \vdash A$}<br><br>\AxiomC{$A,\Delta \vdash B$}<br>\UnaryInfC{$\Delta \vdash A \supset B$}<br>\UnaryInfC{$\Gamma, \Delta \vdash A \supset B$}<br><br>\BinaryInfC{$\Gamma, \Delta \vdash B$}<br><br>\end{prooftree}<br><br></latex>
<latex>~\\<br>Show that $\supset~\text{elim}$, on pg 8375, is admissible in Gentzen sequent calculus, on pg 8393 (which extends structural rules on pg 8392). <br></latex>	<latex>~\\<br>We can apply inversion to get $\Gamma, A \vdash B$ from $\Gamma \vdash A \supset B$.<br>Then we can apply Cut:<br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \vdash A \\ \Gamma, A \vdash B}<br>  {\Gamma, \Gamma \vdash B}<br>\end{mathpar}<br>From here, getting hand-wavy, we can apply contraction multiple times until we get $\Gamma \vdash B$.<br></latex><br>
<latex>~\\<br>Show that $\wedge$-intro, on pg 8375, is admissible in Gentzen sequent calculus, on pg 8393. <br></latex>	Remember "admissible" means that whenever there exist proofs of the premises, there also exists a proof of the conclusion. It does not necessarily mean that the conclusion is provable from the premises.<br>
What is <i>cut elimination</i>?	pg 8393, fact 110<br>
How do the assumptions of a sequent in Multiplicative Linear Logic differ from the assumptions of a sequent in natural deduction?<br>	They are contained in a multiset rather than a set.<br>pg 8394<br><br>
Give the rules for multiplicative linear logic.<br>	pg 8394, table 1.10<br><br>
What does the word <i>multiplicative</i> mean in <i>multiplicative linear logic</i>?	pg 8394<br>
<latex>~\\<br>Can we construct a proof in Linear Logic of the following sequent?<br>$$A \vdash A \otimes A$$<br></latex>	<latex>~\\<br>No, we cannot.<br><br>Due to cut elimination, our proofs must involve the other four rule on figure 1.10, pg 8394, along<br>with the identity rule $A \vdash A$.<br>\\~\\<br>We can't construct a proof of an arbitrary proposition $A$ from an empty assumption set, because<br>left rules and id all require at non-empty assumption sets in the conclusion, while right rules prove non-arbitrary propositions (i.e. propositions built from the outer-level connectives $\otimes$ and $\multimap$, respectively.<br>\\~\\<br>From the above observation, it's clear that we cannot prove $A \vdash A \otimes A$ from the $\otimes R$ rule, as one of the two premises would necessarily prove $A$ from an empty assumption set.<br>\\~\\<br>$\multimap R$ proves conclusions with the wrong outer-level connective.<br>\\~\\<br>$\otimes L$ and $\multimap L$ both include assumptions distinct from the formula $A$ in the assumption sets of their conclusions.<br><br>pg 8394<br></latex>
<latex>~\\<br>Can we construct a proof in Linear Logic of the following sequent.<br>$$(A \otimes A) \multimap B \vdash A \multimap B$$<br></latex>	pg 8394<br>
<latex>~\\<br>Can we construct a proof in Linear Logic of the following sequent.<br>$$\vdash A \multimap (B \multimap A)$$<br></latex>	pg 8395
Define the linear lambda calculus, its typing rules, and its reduction rules.<br>	pg 8395, def 113, table 1.11<br>
<latex>~\\<br>Explain the difference between the $\multimap L$ and $\multimap E$ rules. Which one is preferred in linear logic, and why?<br></latex>	pg 8394<br>
Why are cartesian closed categories not adequate for modelling the linear lambda calculus?<br> 	pg 8396<br>
What is a <i>monoidal category</i>?<br>	pg 8396<br>
Give some examples of monoidal categories.<br>	pg 8396/8397<br>
<latex>~\\<br>Show that \textbf{Rel}, the category of sets and relations, with cartesian product (which is \emph{not}<br>the categorical product) is a monoidal category.<br></latex><br>	pg 8397<br>
<latex>~\\<br>Verify that $(\mathbb N, \leq, +, 0)$ is a monoidal category.<br></latex><br>	pg 8397, exercise 115<br><br>
<latex>~\\<br>Let $\mathcal C$ be a monoidal category $(\mathcal C, \otimes, I, a, l, r)$.\\<br><br>Consider the following statement:\\<br><br>$\otimes$ induces a product structure iff there exist natural diagonals and projections, i.e. natural transformations given by arrows <br>$$d_A : A \longrightarrow A \otimes A,~~~~~p_{A,B} : A \otimes B \to A,~~~~~q_{A,B} : A \otimes B \to B$$<br>such that the following diagrams commute:<br>\begin{diagram}<br>   &                        & A               &                        &   \\<br>   & \ldTo^{id_A}     & \dTo>{d_A}  & \rdTo^{id_A}     &    \\<br>A & \lTo_{p_{A,A}} & A \otimes A & \rTo_{q_{A,A}} & A \\  <br>\end{diagram}<br><br>\begin{diagram}<br>A \otimes B & \rTo^{d_{A \otimes B}} & (A \otimes B) \otimes (A \otimes B) \\<br>   & \rdTo_{id_{A \otimes B} & \dTo>{p_{A, B} \otimes q_{A, B}}     \\<br>   &                                   & A \otimes B                                     \\  <br>\end{diagram}<br>Prove or disprove.<br></latex><br>	true. pg 8397/8398<br><br>todo: add impostor?<br>
What is a <i>symmetric monoidal category</i>?	pg 8398<br>
What is a <i>symmetric monoidal closed category</i>?<br>	pg 8399<br>
Let <b>Rel</b> be the category of sets and relations, with cartesian product (which is <i>not</i>) the categorical product.<br><br>Consider the following statement:<br><br><b>Rel</b> is a symmetric monoidal closed category.<br><br>Prove or disprove.<br>	true. pg 8399.<br><br><br>
<latex>~\\<br>Consider the following statement:<br>\\~\\<br>The monoidal category $(\mathbb N, \leq, +, 0)$ is a symmetric monoidal closed category.<br>\\~\\<br>Prove or disprove.<br></latex><br>	<latex><br>Impostor. A pair of objects (natural numbers) $A$ and $B$ only has a psuedo-exponential when<br>$A \leq B$, in which case $A \multimap B = A - B$. However, $A \leq B$ is not true<br>for all pairs of natural numbers $A$ and $B$, and so this category \emph{is not closed}.<br></latex><br>based on a modification of exercise 119, pg 8399<br>
<latex>~\\<br>How do we interpret a linear sequent $A_1, \ldots, A_k \vdash A$ in a symmetric monoidal closed category?<br></latex>	pg 8399, near bottom
<latex>~\\<br>How do we interpret the exchange rule of $\otimes, \multimap$-logic in a symmetric monoidal closed category?<br></latex>	pg 8400, top of page
<latex>~\\<br>Interpret the rules of $\otimes, \multimap$-logic in a symmetric monoidal closed category.<br></latex><br>	pg 8400
What is <i>coherence</i>, as it relates to monoidal categories?<br>	pg 8396<br>
<latex>~\\<br>Let $\mathcal C$ be a symmetric monoidal closed category. Give the interpretation of the $\multimap$-left rule<br>in $\mathcal C$:<br><br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \vdash A \\ B,\Delta \vdash C}<br>  {\Gamma, A \multimap B, \Delta \vdash C}<br>\end{mathpar}<br><br></latex>	pg 8400, exercise 120<br>
Give the proof rules for the logical connective for <i>additive conjunction</i> &.<br>	pg 8401, def 122<br>
What kind of categorical structure is necessary to interpret additive conjunction &?<br>	pg 8401<br>
In linear logic, what is the <b>bang</b> ! rule? Give its associated deduction rules.<br>	pg 8401, near bottom<br>spills over to pg 8402<br><br>
Do parts a,b, and c to exercise 1 on page 8402<br>	<br>
Do parts d and e to exercise 1 on page 8402<br>	<br>
Do exercise 2, part a, on page 8402, 8403<br>	<br>
Do exercise 2, part b, on page 8403<br>	<br>
<latex>~\\<br>Show that the condition $l_I = r_I$ in the definition of monoidal categories is redundant. Moreover, show that the condition $id_A \otimes l_B = a_{A,I,B} \circ r_A \otimes id_B$ in the definition of symmetric monoidal categories is redundant.<br></latex>	pg 8403
Give a brief, intuitive description (rather than a formal definition) of monads.<br>	pg 8403<br>
What is a monad?<br>	pg 8404<br>
Explain how monads can be used to model exceptions. Prove that whatever you claim is a monad is actually a monad.<br><br>	pg 8404
<latex>~\\<br>Draw the monadic diagram for the monad derived from the adjunction $$F : \mbf{Mon} \pile{\lTo \\ \rTo} \mbf{Set} : U$$ (F is the free monoid functor, U is the forgetful functor). Draw the diagram "concretely", in a way that shows what's actually going on.<br></latex>	pg 8405<br>
What is a comonad?	pg 8406<br>
<latex>~\\<br>Give an explicit description of the comonad on $\mbf{Mon}$ with functor $Q := MList \circ U$<br></latex>	pg 8406, exercise 127<br>
Explain how implicit parameters can be represented as a coeffect. Give a ML-pseudocode datatype definition and implementations of the counit and cobind operators.<br>	<latex>~\\<br>From Tomas Petricek's coeffect playground:<br>\\~\\<br>Data type for implicit parameters is a tuple of the value $'a$ together with a lookup function that returns the value of an implicit parameter with the given name:<br><br>\begin{lstlisting}<br>type IP<'a> = IP of 'a * (string -> obj)<br>\end{lstlisting}<br><br>The $counit$ function returns the value (and ignores the implicit parameters). In $cobind$, we duplicate the implicit parameters into $p1$ and $p2$, we call the function $f$ with the first set and we return a comonad with the resulting value and the second set of implicit parameters:<br><br>\begin{lstlisting}<br>let counit (IP(v, _)) = v<br>let cobind f (IP(v, p)) =<br>  let p1, p2 = p, p<br>  IP(f (IP(v, p1)), p2)<br>\end{lstlisting}<br><br>The $merge$ operation combines the two lookup functions it gets and $split$ creates two copies. We also need a special $lookup$ function to get the value of an implicit parameter:<br><br>\begin{lstlisting}<br>let lookup name (IP(_, f)) = f name<br>\end{lstlisting}<br><br>The coeffect annotations tell us what implicit parameters are available and all the operations of the coeffect algebra are $\bigcup$. <br><br>counit and cobind refresher:\\<br>$$counit : C^{use} \tau \to \tau$$<br>$$cobind : (C^r \tau_1 \to \tau_2) \to C^{r \oast s} \tau_1 \to C^s \tau_2$$<br></latex>
Explain how comonad behind the "dataflow computations" coeffect system, which tracks how many levels of <b>prev</b> that a variable is nested inside of. Give a ML-psuedocode for a datatype definition, and also implementations of the counit and cobind functions.<br><br>	<latex>~\\<br>From Tomas Petricek's coeffect playground:<br>\\~\\<br>Data type for dataflow computations is a non-empty list, but to keep the example simpler, we'll write it just as a list:<br>\begin{lstlisting}<br>type DF<'a> = DF of list<'a><br>\end{lstlisting}<br>The $counit$ operation returns the head, which is why we need a non-empty list! The $cobind$ operation takes a list and produces a list of the same length. It is done by applying $f$ to all the suffixes:<br>\begin{lstlisting}<br>let counit (DF(v::_)) = v<br>let rec cobind f = function<br>  | DF [] -> DF []<br>  | DF (x::xs) -><br>      let (DF tl) = cobind f (DF xs)<br>      DF(f (DF xs) :: tl)<br>\end{lstlisting}<br>\\~\\<br>$cobind~f~[1;2;3]$ produces $[f~[1;2;3];~f~[2;3];~f~[3]]$. The $merge$ operation is $zip$ and $split$ simply duplicates the list. A special operation $prev$ shifts the list by 1 element to the past:<br>\\~\\<br>counit and cobind refresher:\\<br>$$counit : C^{use} \tau \to \tau$$<br>$$cobind : (C^r \tau_1 \to \tau_2) \to C^{r \oast s} \tau_1 \to C^s \tau_2$$<br></latex>
How can we derive a monad from an adjunction? (Just define the monad, no need to prove that it is actually a monad).<br>	pg 8406
<latex>~\\<br>Let $(T, \eta, \mu)$ be a monad on a category $\mbf C$. Define the \emph{Kleisli category} $\mbf C_T$,<br>and prove that it is actually a category. What, intuitively, does a Kleisli category represent?<br></latex><br>	pg 8408<br>
<latex>~\\<br>Start reading at 8364, and make flashcards for section 1.5.2\\~\\<br>Let $\mbf C$ be a category, and $(T, \eta, \mu)$ a monad on $\mbf C$. Build an adjunction between $\mbf C$ and $\mbf C_T$ whose underlying monad is $(T, \eta, \mu)$.<br></latex>	pg 8408/8409 (see page 8364 for information on adjunctions)<br>
<latex>~\\<br>Let $\mbf C$ be a category and let $(Q, \epsilon, \delta)$ be a comonad on $\mbf C$. Give the definition of the coKleisli category $C_Q$, and prove that it is indeed a category.<br></latex><br><br>	they do not include a proof of composition associativity or identity idempotence. here is my proof of composition associativity:<br><br><latex>~\\<br>Let $f_Q : A \to B, g_Q : B \to C, h_Q : C \to D$. Then $(h_Q \circ g_Q) \circ f_Q =<br>(h \circ Qg \circ \delta_B)_Q \circ f_Q = ((h \circ QG \circ \dela_B) \circ Qf \circ \delta_A)_Q$\\<br>... by associativity we have ...\\<br>$= (h \circ Qg \circ (\delta_B \circ Qf) \circ \delta_A)_Q$\\<br>... by naturality of $\delta$ we have ... \\<br>$= (h \circ Qg \circ (Q^2 f \circ \delta_{QA}) \circ \delta_A)_Q$\\<br>... by functorality of Q we have ... \\<br>$= (h \circ Q(g \circ Qf) \circ \delta_QA \circ \delta_A)_Q$\\<br>... by the comonad "square law" we have ...\\<br>$= (h \circ Q(g \circ Qf) \circ Q \delta_A \circ \delta_A)_Q$\\<br>... by functorality of Q we have ...\\<br>$= (h \circ Q(g \circ Qf \circ \delta_A) \circ \delta_A)_Q$\\<br>$= (h \circ Q(g_Q \circ f_Q) \circ \delta_A)_Q$\\<br>$= (h_Q \circ (g_Q \circ f_Q))$.<br></latex><br>pg 8409<br>
<latex>~\\<br>Let $\mbf C$ be a category and let $(Q,\epsilon,\delta)$ be a comonad on $\mbf C$. Consider the following statement:\\~\\<br>If $\mbf C$ has binary products, then so does the coKleisli category $\mbf C_Q$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8409, prop 130<br>
<latex>~\\<br>Let $\mbf C$ be a category and let $(Q, \epsilon, \delta)$ be a comonad on $\mbf C$. Consider the following statement:\\~\\<br>The Kleisli category $\mbf C_Q$ has a terminal object if and only if $\mbf C$ does.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8410, exercise 141<br>todo: add impostor?<br><br>
What is the <i>weak bang</i> operator of linear logic? Give its proof rules.<br>How do we interpret these proof rules using a symmetric monoidal closed category?<br><br>	pg 8410<br>
Why is it that using a symmetric monoidal closed category with a comonad is not sufficient for modelling the ! operator of linear logic? What do we need to fix this?<br>	pg 8410/8409<br>might also be instructional to glance at def 123 on the bottom of pg 8401<br>
<latex>~\\<br>Let $(F,m),(G,n) : \mbf C \to \mbf C'$ be symmetric monoidal functors. What does it mean for a natural transformation $\phi : F \to G$ to be \textbf{monoidal}? <br></latex>	pg 8411<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The constant endofunctor $K_I$, which maps each object to I and each arrow to $id_I$,<br>is symmetric monoidal.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 8411, near bottom<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The endofunctor $\otimes \circ \langle Id_{\mbf C}, Id_{\mbf C} \rangle$, which takes each object A<br>to $A \otimes A$ and each arrow $f$ to $f \otimes f$, is symmetric monoidal.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 8411, near bottom<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $F : \mbf C \to \mbf D$, $G : \mbf D \to \mbf E$ are symmetric monoidal functors then so is $G \circ F$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8412.<br>todo: add impostor<br><br>
<latex>~\\<br>What does it mean for a comonad $(Q, \epsilon, \delta)$ on a SMCC $\mbf C$ to be a \textbf{monoidal comonad}?<br></latex><br>	pg 8412, def 135<br>
Do exercise 132 on pg 8410	<latex>~\\<br>The proof for the arrow $Q_{\delta_A} \circ \delta_A$ is:<br>\begin{prooftree}<br>\AxiomC{}<br>\RightLabel{$id_{QC}$}<br>\UnaryInfC{$!C \vdash !C$}<br>\RightLabel{$\small{!R}$}<br>\UnaryInfC{$!C \vdash !!C$}<br>\RightLabel{$\small{!R}$}<br>\UnaryInfC{$!C \vdash !!!C$}<br>\end{prooftree}<br>The proof for the arrow $\delta_{QA} \circ \delta_A$ is:<br>\begin{prooftree}<br>\AxiomC{}<br>\RightLabel{$id_{QC}$}<br>\UnaryInfC{$!C \vdash !C$}<br>\RightLabel{$!R$}<br>\UnaryInfC{$!C \vdash !!C$}<br><br>\AxiomC{}<br>\RightLabel{$id_{Q^2 C}$}<br>\UnaryInfC{$!!C \vdash !!C$}<br>\RightLabel{$!R$}<br>\UnaryInfC{$!!C \vdash !!!C$}<br><br>\RightLabel{$Cut$}<br>\BinaryInfC{$!C \vdash !!!C$}<br><br>\end{prooftree}<br></latex>
Give the right rule for linear logic's bang operator. Also, give its categorical interpretation; what kind of a category is necessary for this interpretation?<br><br>	categorical interpretation on pg 8412<br><latex>~\\<br>\begin{mathpar}<br>\inferrule<br>  {!\Gamma \vdash A}<br>  {! \Gamma \vdash !A}<br>\end{mathpar}<br>note that $! (A_1, A_2, \ldots)$ means $! A_1, ! A_2, \ldots$.<br></latex><br>The above right rule is given on page 8401<br>
What is a <i>linear exponential comonad</i>? Why are these comonads useful for modelling certain linear logic operators?	definition 136, pg 8412/8413<br>motivation is described in the text on pg 8412 under "contraction and weakening"
What is a <i>commutative comonoid</i>, and how are commutative comonoids relevant to linear exponential comonads?<br> 	pg 8413<br>
Exercise 137, pg 8413<br>	<br>
Exercise 138, pg 8413<br>	<br>
<latex>~\\<br>Let $\mbf C$ be a SMCC with finite products and let $(Q, \epsilon, \delta, m, d, e)$ be a linear exponential comonad on $\mbf C$. Consider the following statement:\\~\\<br>There exists an isomorphism $i : Q1 \to I$ and a natural isomorphism $j : Q(- \times -) \to Q(-) \otimes Q(-)$.\\~\\<br>Prove or disprove. <br></latex>	true. prop 8414.<br>todo: add impostor.<br>
<latex>~\\<br>Let $\mbf C$ be a SMCC with finite products and let $(Q, \epsilon, \delta, m, d, e)$ be a linear exponential comonad on $\mbf C$. Consider the following statement:\\~\\<br>$C_Q$ is cartesian closed, with the exponential of objects $B, C$ being $QB \multimap C$.\\~\\<br>Prove or disprove. <br></latex>	true. pg 8414, prop 139 (c)<br>todo: add counterexample?<br>
Exercise 140, pg 8415<br>	<br>
Exercise 1, pg 8415<br>	<br>
Exercise 2 (a), pg 8415<br>	<br>
Exercise 2 (b), pg 8416<br>	<br>
Exercise 3, pg 8416<br>	<br>
Give the hypothesis and substitution rules of intuitionistic contextual modal logic. Why are they fundamentally different "kinds" of rules?<br>	pg 8422.<br>The hypothesis rule is is primitive while the substitution rule is admissible.<br>
Give the implication introduction and elimination rules for intuitionistic contextual modal logic.	pg 8422/8423<br>
Explain the proof theoretic notion of <i>local reduction</i>. What is its motivation?	pg 8423 (see "local reduction for implication")<br>
Explain the proof-theoretic notion of <i>local expansion</i>. What is its motivation?<br>	pg 8423, see "local expansion for implication"<br><br>
What is a <i>categorical judgment</i>?<br>	pg 8423, section 2.2<br>
<latex>~\\<br>What does a judgment of the form "$\Delta;\Gamma \vdash A~\text{valid}$" mean?<br>How are such judgments derived?<br></latex>	pg 8424, "definition of validity"<br>
Consider the following statement:<br><br>We can reduce the goal of proving "A true" in a particular context to that of proving "A valid".<br><br>Prove or disprove.<br>	IMPOSTOR. a proposition may be true in a context without being true in all contexts.<br><br>pg 8424, paragraph above "substitution principle for validity"<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>We can reduce the goal of proving "A valid" to "A true", given that we can <br>choose the validity context $\Delta$ and the truth context $\Gamma$ in the reduced goal.\\~\\<br>Prove or disprove.<br></latex>	pg 8424, paragraph above "substitution principle for validity"
State the "Substitution Principle for Validity".<br>	pg 8424<br>
<latex>~\\<br>What does a judgment of the form $"A~\text{valid}[\Psi]"$ mean?<br></latex>	pg 8424, section 2.3<br>
Provide the definition an motivation for <i>contextual validity</i>. How do we derive a contextual validity judgment?	pg 8425 top<br>pg 8424, section 2.3<br>
<latex>~\\<br>Give the \emph{contextual entailment} rule for deriving judgments of the form $\Delta ; \Gamma \vdash \Psi$.<br></latex>	pg 8425, rule "ctx"
Give the <i>contextual hypothesis rule<i>. 	pg 8425, ctxt-hyp<br>
<latex>~\\<br>Explain the roles of the two categories $\mathbb C$ and $\mathbb I$ underlying the semantics of a coeffect system.<br></latex>	pg 4070 (interpreting contexts and judgments)<br>
<latex>~\\<br>How is a type and coeffect judgment $\Gamma @ R \vdash e : \tau$ interpreted?<br></latex>	pg 4070, bottom right corner<br>
How are types interpreted semantically in coeffect systems? In particular, how are function types interpreted?<br><br>	pg 4071, top left
<latex>~\\<br>How are contexts $\Gamma$ interpreted semantically in coeffect systems, and in particular, how does this differ between flat and structural coeffect systems?<br></latex>	pg 4071, free-variable contexts<br>
Describe the indexed comonad used to semantically model the contexts of the structural coeffect system for bounded reuse.	pg 4071, example 15/18<br><br>
Provide the definition of an <i>indexed comonad</i>. Make sure to include the indexed analogues of the usual commutative diagrams for comonads.<br><br>	pg 4071, def 17<br>
What is the indexed comonad equivalent of a Kleisli category?<br>	<latex>~\\<br>pg 4071, below def. 17: "An indexed comonad $F : \mathbb I \to [\mathbb C, \mathbb C] \ldots$"<br></latex>
Explain how the "stream variables" of structural dataflow coeffect systems can be modeled using indexed comonads.<br>	pg 4071, remark 19 near bottom right corner<br>
What is a <i>structural indexed comonad</i>? Make sure to give the commutative diagrams for structural indexed comonads.<br>	pg 4072, def 21<br>
What is the equivalent of the coKleisli category for structural indexed comonads?	pg 4072, right above example 22<br>
Explain the structural indexed comonad structure corresponding to the bounded reuse coeffect system.<br>	pg 4072<br>
Explain the <i>structural</i> indexed comonad for the bounded reuse coeffect system.<br>	pg 4072, example 22<br>
<latex>~\\<br>What does it mean for a functor $D : \Pi_{n : \mathcal S}.(\mathbb I^n \to [\mathbb C^n, \mathbb C])$ to be an \emph{indexed lax (semi)monoidal functor}? What about an \emph{indexed colax (semi)monoidal functor}? <br></latex>	pg 4072, def 23<br>
<latex>~\\<br>Explan how the comonad functor for the bounded reuse coeffect system is both an indexed lax and indexed colax semimonoidal functor.<br></latex><br>	pg 4072, example 24
Draw the associativity coherence diagrams for the natural transformations of indexed lax monoidal functors and indexed colax monoidal functors.<br>	pg 4072, def 23. the diagrams aren't shown in the paper, but it would be a useful exercise.<br>
Give categorical denotational semantics for the base coeffect system typing rules (leaving out the rules for Let and Const).<br><br>(Hint: there are 4 rules)<br><br>	figure 5, pg 4073<br>
Give categorical denotational semantics for the base coeffect system's context/coeffect reductions (i.e. structural rules). (no need to give the semantics for Sub)<br><br>(Hint: there are three rules besides Sub)<br><br>	pg 4073, figure 5
<latex>~\\<br>Consider the following term-in-context for the bounded resuse coeffect system:<br>$$ f : \mathbb Z \rTo^2 \mathbb Z, x : \mathbb Z @ \langle 2 , 4 \rangle \vdash (\lambda z.~z + z) $$<br>The denotation of the function body, prior to contraction, is <br>$$ g = \sem{x : \mathbb Z, y : \mathbb Z @ \langle 1, 1 \rangle \vdash (+ x) y : \mathbb Z}$$<br>Note that the full semantics has $\sem{+} : D^0_{\langle \rangle} 1 \to (D^1_1~\mathbb Z \Rightarrow (D_1^1~ \mathbb Z \Rightarrow \mathbb Z))$\\<br>Give the denotational semantics for the term-in-context shown at the top of this card.<br>"Run" this semantics on an input, taking reduction steps until we reach a normal form.<br></latex>	pg 4073, example 26<br>
<latex>~\\<br>Given a graph $\mathcal X$, how do we construct the positive intuitionistic calculus $\mathcal D(\mathcal X)$?<br>How do we construct $\mathcal F(\mathcal X)$, the cartesian closed category freely generated by $\mathcal X$?<br></latex><br>	pg 8080, chpt 4 intro<br>
<latex>~\\<br>Give definitions for the categories \textbf{Grph} and \textbf{Cart}.<br></latex>	pg 8080/8081<br>
<latex>~\\<br>Let $\mathcal F : \mbf {Grph} \to \mbf {Cart} $ be the functor that takes a graph to the cartesian closed category freely generated by that graph. Let $ \mathcal U : \mbf {Cart} \to \mbf {Grph} $ be the obvious forgetful functor. Consider the following statement: $F \dashv U$. Prove or disprove.<br></latex>	true. pg 8081, prop 4.1<br>
<latex>~\\<br>Do the exercise at the top of pg 8082, which is reproduced here for no particular reason.<br>Show that the deductive system $\mathcal L(x)$ in section 2 (top of pg 8076) is $\mathcal D(\mathcal L_x)$, where $\mathcal L_x$ is the graph obtained from $\mathcal L$ by adjoining a new edge $x$ between the old vertices $T$ and $A$.<br></latex>	pg 8082
<latex>~\\<br>Given objects $A_0$ and $A$ of a (cartesian, cartesian closed) category $\mathcal A$, how does one adjoin an indeterminate arrow $x:A_0 \to A$ to $\mathcal A$? Explain two alternative approaches.<br></latex>	pg 8082, section 5<br>
What does it mean for an arrow to be a <i>polynomial</i>?<br>	pg 8082<br>
What is a cartesian closed functor?<br>	pg 8083<br>This is kind of ambiguous. What does "on the nose mean"?<br>It either means that it preserves the structure, or it preserves the structure up to isomorphism.
<latex>~\\<br>Let $\mathcal A$ be a (cartesian, cartesian closed) category, and let $x : A_0 \to A$ be an indeterminate<br>over $\mathcal A$.<br>Let $H_x : \mathcal A \to \mathcal A$ be the (cartesian, cartesian closed) functor which sends<br>$f : B \to C$ onto the 'constant' polynomial with the same name. Consider the following statement:\\~\\<br>Given any (cartesian, cartesian closed) functor $F : \mathcal A \to \mathcal B$ and any arrow <br>$b : F(A_0) \to F(A)$ in $\mathcal B$, there is a unique (cartesian, cartesian closed) functor $F' : \mathcal A[x] \to \mathcal B$ such that F'(x) = b and $F'H_x = F$.\\~\\<br>Prove or disprove.<br></latex>	true pg 8083, prop 5.1<br>todo: add impostor<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Given a (cartesian, cartesian closed) category $\mathcal A$, an indeterminate $x : A_0 \to A$ over $\mathcal A$ and an arrow $a : A_0 \to A$ in $\mathcal A$, these is a unique (cartesian, cartesian closed) functor $S^A_x : \mathcal A[x] \to \mathcal A$ such that $S^a_x(x) = a$ and $S^a_x H_x = 1_{\mathcal A}$. <br></latex>	pg 8084<br>
exercise, pg 8084	<br>
What is a dcpo?<br>	pg 7435, def 02-.1 (i)<br>
What is a <i>directed complete semilattice</i>?<br>	pg 7435, def 0-2.1 (ii)<br><br>
What is a <i>complete lattice</i>?	pg 7435, def 0-2.1 (iii)
What is a <i>complete semilattice</i>?<br>	pg 7435, def 0-2.1 (iv)<br><br>
What does it mean for a poset to be <i>bounded complete</i>?<br>	pg 7435, def 0-2.1 (v)<br><br>
Consider the following statement:<br><br>A poset is a complete lattice iff it is both a dcpo and a sup semilattice with a smallest element.<br><br>Prove or disprove.<br>	pg 7435, below def 0-2.1<br>
Let L be a poset. Consider the following statement:<br><br>For L to be a complete lattice it is sufficient to assume the existence of arbitrary sups (or infs)<br><br>Prove or give a counterexample.<br>	true. pg 7435, prop 0-2.2 (i)<br>todo: add impostor?<br><br>
Let L be a poset. Consider the following statement:<br><br>For L to be a complete lattice it is sufficient to assume the existence sups of finite sets and of directed sets (or the existence of finite infs and filtered infs).<br><br>Prove or disprove.<br>	true. pg 7436, prop 0-2.2 (ii)<br>todo: add impostor?<br><br>
Let L be a poset. Consider the following statement:<br><br>If L is a unital semilattice, then for completeness it is sufficient to assume the existence of filtered infs.<br><br>Prove or disprove.<br>	true. pg 7435, prop 0-2.2, (iii)<br>todo: add impostor?<br><br>
Let L be a poset. Consider the following statement:<br><br>L is a complete semilattice iff L is a bounded complete <b>dcpo</b>.<br><br>Prove or disprove.<br>	true. pg 7435, prop 0-2.2<br>
Read the paragraph below the proof at the top of pg 7436, do the proposed exercise at the bottom of the paragraph.<br>	pg 7436<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Let $f : L \to L$ be a monotone self-map on a complete lattice L. Then the set $fix(f) = \{ x \in L \mid x = f(x) \}$ of fixed-points of $f$ forms a complete lattice in itself.<br>\\~\\<br>Prove or disprove.<br></latex>	true. pg 7436/7437<br>
State and prove the Tarski Fixed-Point Theorem.<br>	pg 7436/7437, theorem 0-2.3<br>
Use the Tarski fixed-point theorem to argue that the lattice of open sets in a topological space is complete.<br>	pg 7437, paragraph below proof<br>
<latex>~\\<br>Let $f : L \to M$ be a map between complete lattices preserving sups. Consider the following statement:\\~\\<br>Then $f(L)$ is closed under sups in $M$ and is a complete lattice in itself.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 7437, remark 0-2.4<br>todo: add impostor?<br>
<latex>~\\<br>What does it mean for a self-map $p : L \to L$ on a poset to be a \emph{projection}?<br></latex>	pg 7437, below proof of remark 0-2.4<br>
<latex>~\\<br>Let $p$ be a projection on a poset $L$. Consider its image $p(L)$ in $L$ with the induced ordering. Consider the following statement:\\~\\<br>If $X$ is a subset of $p(L)$ which has a sup in $L$, then $X$ has a sup in $p(L)$ and<br>$$sup_{p(L)} X = p(sup_L X)$$<br>Prove or disprove.<br></latex><br><br>	true. pg 7437, remark 0-2.5 (i)<br>
<latex>~\\<br>Let $p$ be a projection on a poset $L$. Consider its image $p(L)$ in $L$ with the induced ordering. Consider the following statement:\\~\\<br>If $L$ is a semilattice, a lattice, a \textbf{dcpo}, a bounded complete \textbf{dcpo}, a complete lattice,<br>respectively, the same holds for $p(L)$.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 7438, (ii) at top<br>
Let V be a vector space. Argue that the convex subsets of V form a complete lattice, ordered by set inclusion.<br>	pg 7438, below the proof<br>
What is a <i>Boolean algebra</i>? A <i>complete Boolean algebra</i>? A <i>frame</i>?<br>	pg 7438, def 0-2.6<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If X is a topological space, then $\mathcal O(X)$, its collection of open sets, is a frame.\\~\\<br>Prove or disprove.<br></latex><br><br>	true. pg 7439, (3) at bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If X is a topological space and $\mathcal O(X)$ is the poset of its open sets ordered by set inclusion, <br>then $\mathcal O(X)^{Op}$ (the opposite of $\mathcal O(X)$) is a frame.\\~\\<br>Prove or disprove.<br></latex><br><br>	IMPOSTOR. pg 7439/7440, example O-2.7 (3)<br>
<latex>~\\<br>If $\mathcal A$ is a lattice, let $Cong~\mathcal A$ be the poset of all congruence relations on $\mathcal A$<br>(i.e. those relations preserved across $\vee$ and $\wedge$), ordered by inclusion. Consider the following statement\\~\\<br>$(Cong~\mathcal A, \subseteq)$ is a frame.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 7440. Example 4 (iii)<br><br>
Read example (9) on pg 7441<br>	<br>
Read example (10), pg 7441<br>	<br>
<latex>~\\<br>Let L be a poset. Consider the following statement.\\~\\<br>The family of all \emph{lower sets} of L is a complete lattice under $\subseteq$.\\~\\<br>Prove or disprove.<br></latex><br>	pg 7442<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In any poset $L$, $Filt_0~L$ and $Filt~L$ are \textbf{dcpo}s.\\~\\<br>Prove or disprove.<br></latex> 	true. pg 7442, example 2<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In any poset $L$, $Filt~L$ is a complete lattice.\\~\\<br>Prove or disprove.<br></latex> 	IMPOSTOR. this is only true when L is unital (has a top element). <br>pg 7442, example 2<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a lattice, both $Filt_0~L$ and $Filt~L$ are complete lattices.\\~\\<br>Prove or disprove.<br></latex>	true, pg 7442. example 3<br><br>
<latex>~\\<br>The function $x \mapsto \downarrow x : L \to Id L$ is called the \emph{principal ideal embedding}. Consider the following statement:\\~\\<br>The principal ideal embedding preserves arbitrary infs and finite sups.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7442, example (4)<br>question: is this embedding a left adjoint? If so, coRAPL can be used to argue that it preserves arbitrary infs.<br>
<latex>~\\<br>The function $x \mapsto \downarrow x : L \to Id L$ is called the \emph{principal ideal embedding}. Consider the following statement:\\~\\<br>The principal ideal embedding preserves all infs and sups.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. only finite sups. pg 7442, example (4)<br>
What is a <i>actor state</i> according to the formalization of Syndicate?	<br>pg 8712/8713<br>
What is an <i>event</i>, according to syndicate's formalism?<br>What is an <i>action</i>?<br>	See pg 8713, fig 3<br>See pg 8707, fig 1.<br><br><latex>~\\<br>Events: $e \in \mathbb E ::= \langle c \rangle \mid \pi$\\<br>Actions: $a \in \mathbb A ::= \langle c \rangle \mid \pi \mid P$\\~\\<br>Programs: $P \in \mathbb P ::= \mbf{actor}~f~u~\vec{a} \mid \mbf{net}~\vec{P}$\\<br>Assertion sets: $\pi$\\<br>Assertions: $c,d \in \mathbb S ::= u \mid ?c \mid \downharpoonleft c$\\<br>Values: $u$<br></latex>
According to Syndicate's formalism, what is a <i>configuration<i> C?	pg 8713/8713<br>
According to syndicate's formalism, what is the "state and behavior" of leaf actor?<br>What is the "state and behavior" of a network actor?<br>	pg 8712<br>
Give the syntax for syndicate programs. This will include syntactic categories for:<br>-Programs<br>-Leaf functions<br>-Values<br>-Events<br>-Actions<br>-Assertions<br>-Assertion sets<br>	pg 8707, figure 1<br><br>
Each queued action in a configuration is marked with a location. There are two fundamentally distinct kinds of labels. What are they?<br>	pg 8713, top paragraph<br>
What does it mean for an actor to be <i>quiescent</i>? What does it mean for an actor to be <i>inert</i>?<br>	pg 8713, second paragraph, figure 3 (b)<br><br>
What does the "boot" metafunction do in Syndicate's formalism?<br>	pg 8713<br><br>
<latex>~\\<br>What is the difference between action of the form $\langle c \rangle$ and actions of the form $\pi$?<br></latex><br>	pg 8708, fourth paragraph<br>
Give the (notify-leaf) and (exception) reduction rules for syndicate.	pg 8714, fig 4<br>
Give syndicate's (notify-net) rule. This rule utilizes an auxiliary metafunction called <b>inp</b>. What does <b>inp</b> do?<br>	pg 8714<br>
Give Syndicate's (gather) reduction rule.<br>	pg 8714<br>
<latex>~\\<br>What does Syndicate's (newtable) reduction rule do? It uses metafunctions called \textbf{bc}, \textbf{out}, and $\oplus$. What do these metafunctions do?<br></latex><br>	the rule is on pg 8714, but it won't make much sense without the explanation given at the bottom paragraph of 8713<br>
<latex>~\\<br>What does syndicate use the notation $Lift(\mathbb L)$ to denote?<br></latex>	<latex>~\\<br>It means that we are unioning locations with the special location $\downharpoonleft$.<br></latex><br>pg 8713, figure 3. <br>
Give Syndicate's (message) reduction rule. It uses a metafunction called <b>out</b>; what does this do?<br>	pg 8714<br>
Give the categorical definition of a type refinement system.<br>	it's just a functor from one category to another.<br>pg 8778<br>
<latex>~\\<br>Let $\mathcal D$ and $\mathcal T$ be categories. What does it mean for an object $R \in \mathcal D$ to \textbf{refine} an object $A \in \mathcal T$ (denoted $R \sqsubset A$) with respect to some (type) refinement system $r$?<br></latex>	pg 8778, def 3.2.4<br>
<latex>~\\<br>Given a (type) refinement system $r : \mathcal D \to \mathcal T$, what is a typing judgment on this system?<br></latex><br>	pg 8778, def 3.2.5<br>
<latex>~\\<br>What does the notation $R \rImplies_{f} S$ mean?<br></latex>	pg 8778, def 3.2.5<br>
<latex>~\\<br>What does the notation $R \rImplies_A S$ mean?<br></latex><br><br>	pg 8778, def 3.2.5 "subtyping judgment"<br>
<latex>~\\<br>What is a \textbf{subtyping judgment} according to the categorical interpretation of refinement types?<br></latex>	pg 8778, def 3.2.5<br><br>
<latex>~\\<br>What does the notation $R \rImplies_{f}^\alpha S$ mean in the categorical interpretation of type refinement systems?<br></latex>	pg 8778, def 3.2.6<br><br>
Read example 3.2.7 on the top of page 8779<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The following rule is admissible for any refinement system.<br>\begin{mathpar}<br>\inferrule <br>  {R \rImplies_f S \\ S \rImplies_g T}<br>  {R \rImplies_{f;g} T}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	true. prop 3.2.8. todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The following rule is admissible for any refinement system.<br>\begin{mathpar}<br>\inferrule<br>  {~}<br>  {R \rImplies_{A} R}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	true. prop 3.2.8, pg 8780.<br>todo: add impostor?<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>According to the categorical interpretation of subtyping in refinement systems,<br>subtyping is reflexive and transitive.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8780, prop 3.2.9<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>According to the categorical interpretation of subtyping in refinement systems,<br>subtyping is anti-symmetric.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. should be easy to make a counterexample. pg 8780, prop 3.2.9<br>
<latex>~\\<br>Consider the following statement. The following rule is admissible in all type refinement systems.\\~\\<br>\begin{mathpar}<br>\inferrule<br>  {R \rImplies_f S_1 \\ S_1 \rImplies_B S_2}<br>  {R \rImplies_f S_2}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	true. pg 8780, prop 3.2.9<br>
<latex>~\\<br>Consider the following statement. The following rule is admissible in all type refinement systems.\\~\\<br>\begin{mathpar}<br>\inferrule<br>  {R_1 \rImplies_A R_2 \\ R_2 \rImplies_g T}<br>  {R_1 \rImplies_g T}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	true. pg 8780, prop 3.2.9<br>
<latex>~\\<br>Explain the meaning of the rule labeled $\sim$, of the form<br>\begin{prooftree}<br>\AxiomC{$R \rImplies_f S$}<br>\RightLabel{$\sim$}<br>\UnaryInfC{$R \rImplies_g S$}<br>\end{prooftree}<br>Which sometimes appears in refinement typing proofs.<br></latex> 	pg 8780, first REMARK<br>
<latex>~\\<br>For any category $\mathcal C$, there is a refinement system $! : \mathcal C \to 1$ mapping every object and morphism of $\mathcal C$ to the unique object and morphism of the terminal category 1. Explain some details of this system.<br></latex>	pg 8781, example 3.2.10 near bottom<br>
<latex>~\\<br>For any category $\mathcal C$, there is a refinement system $id : \mathcal C \to \mathcal C$ corresponding to the identity functor on $\mathcal C$. Explain some details of this refinement system.<br></latex><br>	pg 8782, example 3.2.11<br>
Explain how Floyd-Hoare logical can be modeled categorically as a refinement system.<br>	pg 8782, example 3.2.12<br>
<latex>~\\<br>Explain the properties of a refinement system formed from a functor onto a monoid category.<br>What popular computer science concept are such refinement systems useful for reasoning about, and how does this work?<br></latex>	pg 8782/8783, example 3.2.12<br><br>
<latex>~\\<br>Explain the "classic" refinement functor from $\mbf {Subset}$ to $\mbf {Set}$. Also, explain why it is significant.<br></latex><br>	pg 8783, example 3.2.14<br>
<latex>~\\<br>Explain how $\mbf {Subset} \to \mbf {Set}$ and its generalization $\mbf{Downset} \to \mbf{Poset}$ generalize to the refinement system $\mbf {Presheaves} \to \mbf {Categories}$.<br></latex><br>	pg 8783, example 3.2.15<br><br>
Explain the motivation for and definition of <i>pushforward refinements</i>.<br>Explain the motivation for and definition of <i>pullback refinements</i>.<br><br>	pg 8784, def 3.2.16<br>
Describe the nature of pushforward refinements and pullback refinements in the setting of "Hoare logic refinement systems". Do pushforwards and pullbacks always exist in these refinement systems? Prove your answer.<br><br>	pg 8785/8786, example 3.2.19<br>
What is a <i>fibration</i>? What is an <i>opfibration</i>? What is a <i>bifibration</i>?<br>	pg 8787, def 3.2.20<br><br>
<latex>~\\<br>Given a refinement system $r : \mathcal D \to \mathcal T$ and type $A \in \mathcal T$, what is the <br>\textbf{subcategory of refinements of} A? What is the shorthand notation for this subcategory?<br></latex> 	pg 8787, def 3.2.21<br><br>
<latex>~\\<br>Let $R_1, R_2 \sqsubset A$ be two refinements of the same type. What does it mean for $R_1$<br>and $R_2$ to be \textbf{strongly equivalent}?<br></latex>	pg 8787, def 3.2.22
Exercise 3.2.23, pg 8787<br><br><br>	<latex>~\\<br>Suppose we have to refinements $(f_{\diamond}R)_1$ and $(f_{\diamond}R)_2$ satisfying the<br>requirements of $f_{\diamond}$. Then we have.<br><br>\begin{prooftree}<br>\AxiomC{~}<br>\RightLabel{$f_\diamond I$}<br>\UnaryInfC{$R \rImplies_{f;id_B} (f_\diamond R)_2$}<br>\RightLabel{$f_\diamond E$}<br>\UnaryInfC{$(f_\diamond R)_1 \rImplies_B (f_\diamond R)_2$}<br>\end{prooftree}<br><br>A similar argument holds in the other direction.<br></latex>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any refinement system, whenever the corresponding pushforward and/or pullback refinements exist,<br>the following subtyping rules are admissible:\\<br>\begin{mathpar}<br>\inferrule<br>  {R_1 \rImplies_{A} R_2}<br>  {f_{\diamond} R_1 \rImplies_{B} f_{\diamond} R_2}<br>\and<br>\inferrule<br>  {S_1 \rImplies_{B} S_2}<br>  {f^{\square} S_1 \rImplies_{A} f^{\square} S_2}<br>\end{mathpar}<br>Also, there are strong equivalences<br>$$(g \circ f)_\diamond R \equiv g_\diamond f_\diamond(R)$$<br>$$id_\diamond R \equiv R$$<br>$$(g ; f)^{\square} S \equiv g^\square f^\square S$$<br>$$id^\square S \equiv S$$<br>Prove or disprove.<br></latex>	true. pg 8788.<br>TODO: add impostor!!!!!<br>
<latex>~\\<br>Exercise 3.2.25, pg 8788\\<br>Just show that $f_{\diamond}$ preserves identities.\\<br>Hint: you will have to use an equality that is not in def 3.2.16 (or 3.2.17 for that matter)<br></latex><br>	<latex>~\\<br>\newcommand{\fdi}[0]{f_{\diamond}}<br><br>Instantiating the proof of $\leq_{f_{\diamond}}$ using $R$ as both $R_1$ and $R_2$ gives<br><br>\begin{prooftree}<br>\AxiomC{~}<br>\LeftLabel{id}<br>\UnaryInfC{$R \rImplies_A R$}<br>\AxiomC{~}<br>\RightLabel{$\fdi I$}<br>\UnaryInfC{$R \rImplies_{f} \fdi R$}<br>\RightLabel{;}<br>\BinaryInfC{$R \rImplies_{f} \fdi R$}<br>\RightLabel{$\fdi E$}<br>\UnaryInfC{$\fdi R \rImplies_{B} \fdi R$}<br>\end{prooftree}<br><br>Which, by the equality on page 8781 under the text "while the unit laws imply that", <br>is equal to the derivation<br><br>\begin{prooftree}<br><br>\AxiomC{~}<br>\LeftLabel{$\fdi I$}<br>\UnaryInfC{$R \rImplies_{f} \fdi R$}<br>\AxiomC{~}<br>\RightLabel{id}<br>\UnaryInfC{$\fdi R \rImplies_B \fdi R$}<br>\RightLabel{;}<br>\BinaryInfC{$R \rImplies_{f} \fdi R$}<br>\RightLabel{$\fdi E$}<br>\UnaryInfC{$\fdi R \rImplies_{B} \fdi R$}<br>\end{prooftree}<br><br>Applying the second equality of def 3.2.16 on page 8784 equates this derivation to<br><br>\begin{prooftree}<br>\AxiomC{~}<br>\RightLabel{id}<br>\UnaryInfC{$\fdi R \rImplies_{B} \fdi R$}<br>\end{prooftree}<br><br>Thus showing that $f_{\diamond}$ preserves identity arrows.<br></latex>
What is a <i>Kleisli triple</i>? What does it mean for a Klesli triple to satisfy the <i>mono requirement</i>? Give intuition for these definitions.<br>	pg 8813, def 1.2<br>the intuition is given below the definition<br><br>
<latex>~\\<br>Given a Kleisli triple $(T, \eta, -^*)$ over $\mathcal C$, what is the \textbf{Kleisli category} $C_T$?<br></latex>	pg 8814, def 1.3<br>
Give the intuitive "inference rule" description of composition in the Kleisli category C<sub>T</sub>.<br>	pg 8814<br>
What is the simple, one-sentence explanation for the Kleisli triple axioms?<br>	"At this point we can give also a simple<br>justification for the three axioms of Kleisli triples, namely they are equivalent to the unit and<br>associativity axioms for C T :"...<br><br>pg 8814<br>
Show that partiality, nondeterminism, and side-effects can be described using Kleisli triples.<br>	pg 8814, example 1.4<br><br>
What is a <i>monad</i>?<br>	pg 8815<br>
Consider the following statement:<br><br>There is a one-one correspondence between Kleisli triples and monads.<br><br>Prove or disprove.	true. pg 8815, prop 1.6<br><br>
Give the definition of a <i>many-sorted monadic equational logic</i>. This should include a list of judgment forms, a definition for what a <i>signature</i> is, and four inference ruels.<br><br>	pg 8816/8817, section 2.1
Consider a term of a many sorted monadic logic. How many free variables might such a term have?	Exactly one. remark 2.2, pg 8817<br>
<latex>~\\<br>How do we interpret a many-sorted monadic equational logic in a category $\mathcal C$?<br></latex><br>	pg 8817, below remark 2.2<br><br>
<latex>~\\<br>Given a monadic equational theory $\mathcal T$, how do we define the category $\mathcal F(\mathcal T)$?<br></latex>	pg 8817/8818, def 2.4<br>
Give the five inference rules for many-sorted monadic equational logic.<br>	pg 8818, table 2 at top of page<br><br>
<latex>~\\<br>What is a theory $\mathcal T$ of a many sorted monadic equational language?<br></latex>	it's a set of equations closed w.r.t. the monadic equational inference rules, pg 8817, above def 2.4<br>
<latex>~\\<br>Consider extending the category $\mathcal F(\mathcal T)$ generated from a theory $\mathcal T$ of a simple many-sorted monadic logic with a monad $(T, \eta, -^*)$<br>Give the rules for type well-formedness and term typing, as well as the eq rule, and<br>also give interpretations for each rule in terms of the category $\mathcal F(\mathcal T)$ equipped with $T$.<br></latex>	pg 8819, table 3<br>
<latex>~\\<br>Consider extending the category $\mathcal F(\mathcal T)$ generated from a theory $\mathcal T$ of a simple many-sorted monadic logic with a monad $(T, \eta, -^*)$.<br><br>Now consider adding the $[-]$ and $let$ term constructors. Give the equational inference rules associated with these term constructors. Hint they are called:\\~\\<br>$[-].\xi$\\<br>$let.\xi$\\<br>$ass$\\<br>$T.\beta$\\<br>$T.\eta$<br></latex>	pg 8819, table 4<br>
<latex>~\\<br>Consider the following claim:\\~\\<br>In the category $\mathcal F(\mathcal T)$ of a many sorted monadic equational theory with monad T, $\eta_{TA}$ is a mono for all objects $A$\\~\\<br>Prove or disprove.<br></latex>	true. pg 8820<br>$\eta_{TA};\mu_A = id_{TA}$<br>todo: add impostor?<br>
<latex>~\\<br>Letting $\mathcal C$ be a category and T a monad on $\mathcal C$,<br>How is Moggi's simple programming language interpreted in $\mathcal C_T$?<br></latex>	pg 8820
operationally, the let construct corresponds to ____________<br>categorically, the let construct corresponds to ____________	sequential evaluation of programs<br>composition in the Kleisli category<br>pg 8820, remark 2.6<br>
<latex>~\\<br>What is the \emph{existence predicate} $e \downarrow$? How does it interact with typing and equivalence?<br></latex><br>	pg 8820, remark 2.6<br>pg 8821 (ex)<br>pg 8822 (E.x, E.congr)
<latex>~\\<br>Give the categorical interpretation of Moggi's simple programming language. The following symbols evoke the various constructs which the simple programming language includes.\\~\\<br>$A$\\<br>$T$\\<br>$var$\\<br>$p : \tau_1 \rightharpoonup \tau_2$\\<br>$[-]$\\<br>$\mu$\\<br>$let$\\<br>$eq$\\<br>$ex$<br></latex> 	pg 8821<br>
<latex>~\\<br>Moggi's simple programming language has <i>general inference</i> rules for terms denoting computations, but with<br>variables ranging over values. It also has other rules capturing properties of type and term constructors after interpretation of the programming language.<br><br>Give the \emph{general inference rules} of Moggi's simple programming language. The rules are named as follows:\\~\\<br>$refl$\\<br>$symm$\\<br>$trans$\\<br>$congr$\\<br>$E.x$\\<br>$E.congr$\\<br>$subst$<br></latex><br>	pg 8822<br>
The existence predicate has different meanings depending on the notion of computation being considered.<br>Besides meaning termination of partial computation, what meaning does existence take on in other notions of computation?	pg 8822
<latex>~\\<br>Given a signature $\Sigma$ for the programming language, let $\Sigma^\circ$ be the signature for the metalanguage with the same base types and a function $p : \tau_1 \to T\tau_2$ for each command $p : \tau_1 \rightharpoonup \tau_2$ in $\Sigma$. The translation $-^\circ$ from programs over $\Sigma$ to terms over $\Sigma^\circ$ is defined by induction on raw programs:\\~\\<br>Your task: give the clauses of the translation $-^\circ$.<br></latex>	pg 8822, def 2.7<br>
<latex>~\\<br>Moggi's simple programming language has general inference rules for terms denoting computations, but with<br>variables ranging over values. It also has \emph{other rules} capturing properties of type and term constructors after interpretation of the programming language.<br><br>Give these \emph{other rules} of Moggi's simple programming language. The rules are named as follows:\\~\\<br>$[-].\xi$\\<br>$E.[-]$\\<br>$\mu.\xi$\\<br>$\mu.\beta$\\<br>$\mu.\eta$\\<br>$let.\eta$\\<br>$unit$\\<br>$ass$\\<br>$let.\beta$\\<br>$let.p$<br></latex>	pg 8823<br>
What is the set of possible worlds used in the possible worlds model for storage support? How does the current world affect the semantics of variables, expressions, and commands?	It's the natural numbers. At world n there are n locations currently in use (on the runtime stack).<br>It affects the <i>types</i> of the interpretation functions for variables expressions, and commands.  <br><br>pg 8841/8842, section 2<br>
<latex>~\\<br><br>Consider the following equivlance:<br>$$ (new~\iota.~\iota := 0; C) \equiv C$$<br>note that on the lhs, C is in the scope of the $\iota$ binder<br>Why is this equivalence problematic?<br></latex>	It's problematic because commands are typically allowed to test whether locations are in-use or not.<br>on the left-hand side, location l may be in use (chosen as the location of iota) whereas on the rhs it is not.<br><br>pg 8841<br>
<latex><br>Describe the category $\mbf W$ of possible worlds used for storage support.<br></latex><br>	pg 8842
<latex>~\\<br>Define the interpretations of basic phrase types (\textbf {var}, \textbf {exp}, \textbf {comm}) as functors from the category \textbf{W} of possible worlds to the category \textbf{D} of directed-complete posets and continuous functions.<br></latex>	pg 8842<br>
<latex><br>Let $w$ and $x$ be possible worlds (i.e. objects of $\mbf W$), let $f : w \to x$ be an arrow of $\mbf W$.<br>How can $f$ be ``used'' to decompose a state in $S(x)$ into local and non-local parts?<br></latex>	pg 8842, very bottom<br>
<latex>~\\<br>How do we interpret typing derivations $\pi \vdash X : \theta$ in O'Hearn's possible worlds system for local variables?<br></latex><br>	as natural transformations.<br>see pg 8843, paragraph above diagram, and also the one below it<br><br>the typing rules on the next page are also relevant<br>
<latex>~\\<br>Give O'Hearn's syntax ``typing'' rules for the following syntactic forms\\<br>Assignment ($X := E$) \\<br>Sequencing ($C_1 ; C_2$) \\<br>New ($\mbf {new}~\iota.~C$) \\<br>Dereferencing ($X$) \\<br>Also give the denotational interpretations for Assignment, sequencing, and dereferencing.<br></latex>	pg 8844, table 1, table 2<br>
<latex>~\\<br>Give the denotational interpretation of typing derivations for ``new variable'' commands of the form\\<br>$$\pi \vdash \mbf{new}~\iota.~C : \mbf{comm}$$<br></latex>	pg 8844<br>
<latex>~\\<br>Discuss the naturality of<br>$\sem{\pi \vdash new~\iota .~C : \mbf{comm}}$.<br>In particular, prove that it is a natural transformation<br></latex>	the important point is to reduce this to the naturality of the interpretation of [[C]] with respect to (f + id_1)<br>That [[C]] is a natural transformation is an inductive hypothesis.<br><br>pg 8845, entire page<br><br><br>
<latex>~\\<br>Why does the category $\mbf{W}$ of worlds use all injective maps as arrows, and not just inclusions?<br></latex>	pg 8845, near bottom<br>
Consider the following statement:<br><br>A procedure declared in a world w can only be called in the same world w.<br><br>True or false?<br>	IMPOSTOR! pg 8846, section 3 "Procedures", first paragraph<br>
<latex>~\\<br>When using O'Hearn's many worlds approach to mutable state, why can't a procedure be categorically modeled<br>in the standard way as an exponent? What is the solution to this issue?<br></latex>	pg 8846, section 3, paragraph 1<br>
<latex>~\\<br>Let $F, G : \mbf W \to \mbf D$ and $w \in \mbf W_0$. What does $(F \to G)(w)$ denote?<br></latex>	pg 8846, bottom paragraph<br>make sure you get the uniformity condition in there<br>also note that it spills over into pg 8847<br>make sure to mention that this is a domain with a pointwise ordering.<br>
Give the type signature for the sized versions of Object-Oriented Agda's <i>do</i>, <i>return</i>,<br><i>_>>=_</i> functions.<br><br>	pg 7354
Give the source code for object-oriented Agda's _>>=_ operator (sized version). Intuitively explain why it is well-typed.<br>	pg 7354, near bottom<br><br>
Give the definition of the sized version of object-oriented agda's IOObject type. What is the practical significance of an IOObject's size? 	the size represents the number of successive methods we can call.<br>pg 7355<br>
Examine the code on pg 7351. Translate this code into object oriented agda with sized types.<br>	pg 7355<br>
<latex>~\\<br>Consider the following implementation of a read-write cell interface.<br>\begin{lstlisting}<br>data CellMethod A : Set where<br>  get : CellMethod A<br>  put : A $\to$ CellMethod A<br><br>CellResult : $\forall$ {A} $\to$ CellMethod A $\to$ Set<br>CellResult {A} get = A<br>CellResult (put _) = Unit<br><br>cellJ : (A : Set) $\to$ Interface<br>Method (cellJ A) = CellMethod A<br>Result (cellJ A) m = CellResult m<br>\end{lstlisting}<br><br>We extend this interface to track and print statistics (put count and get count) as follows<br><br>\begin{lstlisting}<br>data CounterMethod A : Set where<br>  super : (m : CellMethod A) $\to$ CounterMethod A<br>  stats : CounterMethod A<br><br>pattern $get^c$ = super get<br>pattern $put^c$ x = super (put x)<br><br>statsCellI : (A : Set) $\to$ Interface<br>Method (statsCellI A) = CounterMethod A<br>Result (statsCellI A) (super m) = Result (cellJ A) m<br>Result (statsCellI A) stats = Unit<br>\end{lstlisting}<br><br>How do we define an implementation of this interface?<br><br></latex>	pg 7358<br>
What forms of "inheritance" does object-oriented Agda have? Does it have code reuse, subtyping, or both?<br>	pg 7356, bottom paragraph<br>
Give object-oriented Agda's type definition for stateful interfaces. Implement a stack interface using this type.<br>	pg 7359/7360
<latex>~\\<br>Here is object-oriented agda's stateful interface type<br>\begin{lstlisting}<br>record $Interface^s$ : $Set_1$ where<br>  $State^s$ : Set<br>  $Method^s$ : (s : $State s$) $\to$ Set<br>  $Result^s$ : (s : $State^s$) $\to$ (m : $Method^s$ s) $\to$ Set<br>  $next^s$ : (s : $State^s$) $\to$ (m : $Method^s$ s) $\to$ (r : $Result^s$ s m) $\to$ $State^s$<br>\end{lstlisting}<br><br>Here is an implementation of a stack interface:<br>\begin{lstlisting}<br>data $StackMethod^s$ (A : Set) : (n : $StackState^s$) $\to$ Set where<br>  push : $\forall$ {n} $\to$ A $\to$ $StackMethod^s$ A n<br>  pop : $\forall$ {n} $\to$ $StackMethod^s$ A (suc n)<br>\end{lstlisting}<br><br>\begin{lstlisting}<br>$StackResult^s$ : (A : Set) $\to$ (s : $StackState^s$) $\to$ $StackMethod^s$ A s $\to$ Set<br>$StackResult^s$ A _ (push _) = Unit<br>$StackResult^s$ A _ pop = A<br>\end{lstlisting}<br><br>\begin{lstlisting}<br>$StackResult^s$ : (A : Set) $\to$ (s : $StackState^s$) $\to$ $StackMethod^s$ A s $\to$ Set<br>$StackResult^s$ A _ (push _) = Unit<br>$StackResult^s$ A _ pop = A<br>\end{lstlisting}<br><br>\begin{lstlisting}<br>$stackNext^s$ : $\forall$ A n (m : $StackMethod^s$ A n) (r : $StackResult^s$ A n m) $\to$ $StackState^s$<br>$stackNext^s$ _ n (push _) _ = suc n<br>$stackNext^s$ _ (suc n) pop _ = n<br>\end{lstlisting}<br><br>Give the definition for object-oriented Agda's state-dependent object type. Use it to provide an implementation<br>for the stack interface.<br><br></latex>	pg 7360/7361<br>
Define the following pieces of bloom terminology:<br>- table<br>- scratch<br><br>	scratch collections are useful for transient data like intermediate results and “macro” definitions that<br>enable code reuse. The contents of a table persist across consecutive<br>timesteps (until that persistence is interrupted via a Bloom statement<br>containing the <- operator described below). Although there are<br>precise declarative semantics for this persistence [3], it is convenient<br>to think operationally as follows: scratch collections are “emptied”<br>before each timestep begins, tables are “stored” collections (similar<br>to tables in SQL), and the <- operator represents batch deletion<br>before the beginning of the next timestep.<br><br>pg 8864, fig 1
Define the following pieces of bloom terminology:<br>- channel<br>- periodic<br><br><br>	The facts of the “real world,” including network messages and the<br>passage of wall-clock time, are captured via <b>channel</b> and <b>periodic</b><br>collections; these are scratch collections whose contents “appear” at<br>non-deterministic timesteps. The paper on Dedalus delves deeper<br>into the logical semantics of this non-determinism [3]. Note that<br>failure of nodes or communication is captured here: it can be thought<br>of as the repeated “non-appearance” of a fact at every timestep.<br>Again, it is convenient to think operationally as follows: the facts<br>in a channel are sent to a remote node via an unreliable transport<br>protocol like UDP; the address of the remote node is indicated by<br>a distinguished column in the channel called the location specifier<br>(denoted by the symbol @). The definition of a periodic collection<br>instructs the runtime to “inject” facts at regular wall-clock intervals<br>to “drive” further derivations. Lines 13 and 16 in Figure 2 contain<br>examples of channel and periodic definitions, respectively.<br><br>pg 8864, fig 1<br>
What does the bloom = operator do? What are/is its valid lhs type(s)?	pg 8864, fig 1
What does the bloom <= operator do? What are/is its valid lhs type(s)?	pg 8864, fig 1<br>
What does the bloom <+ operator do? What are/is its valid lhs type(s)?	pg 8864, fig 1<br>
What does the bloom <- operator do? What are its valid lhs types?<br>	pg 8864, fig 1<br>
What does the bloom <~ operator do? What are/is its valid lhs type(s)?	pg 8864, fig 1<br>
What does "fact" mean in Bloom terminology?	a fact is just a tuple<br>pg 8864<br><br>
What "effect" does a statement produce in Bloom?	The statements in a Bloom program<br>specify the derivation of additional facts, which can be declared to<br>exist either in the current timestep, at the very next timestep, or at<br>some non-deterministic time in the future at a remote node.<br><br>pg 8864<br>
List the five collection types of Bloom, briefly describing each one.	pg 8864<br>
Do collections in Bloom follow set semantics or multiset semantics, i.e. do they allow for duplicates?<br>	set semantics<br>pg 8864<br>
Line 15 on pg 8864, figure 2 defines a collection called send_buf.<br>table :send_buf, ['dst', 'src', 'ident'], ['payload']<br>What can be said about this collection? What is its primary key?<br>	its primary key is (dst,src,ident)<br>pg 8864, right column<br><br>
How does Bloom's operational model represent the loss and/or delay of messages sent in a network?<br>	Note that failure of nodes or communication is captured here: it can be thought<br>of as the repeated “non-appearance” of a fact at every timestep.<br><br>pg 8865<br>
The <~ operator sends facts along a remote node. How do we know <i>which</i> remote node these facts are sent along?	a channel is on the lhs<br><br>an example channel declaration is:<br>channel :ack_chan, [’@src’, ’dst’, ’ident’]<br><br>the column prefixed with @ is the location specifier<br><br>from pg 8865, top left column:<br>the facts in a channel are sent to a remote node via an unreliable transport<br>protocol like UDP; the address of the remote node is indicated by<br>a distinguished column in the channel called the location specifier<br>(denoted by the symbol @). <br>
What is the syntactic form of a Bloom statement?	<collection-variable> <op> <collection-expression><br>pg 8865, section 3.3<br>
Where do instances of the Ruby class BudCollection typically show up in a Bloom program?<br>What is BudCollection?	pg 8865, sec 3.3, third paragraph<br><br>
Why are Bloom programs decomposed into methods? How are methods used and what is their semantics?<br>	the methods of a class are unioned together; i.e. all statements across methods are active at once. Separating a class into a method allows its components to be reused through inheritance, for example.<br><br>pg 8865, top right column<br><br><br>
Bloom claims to be scalable despite being rule based. How does it try to justify this claim?	pg 8865<br>
Explain how mixins work in Bloom.<br>	pg 8865, right column, near the word <b>interface</b><br>
What is an <b>interface</b> in Bloom? What are the two types of interfaces?<br>	output interfaces, input interfaces<br>pg 8865, near the word <b>interface</b><br><br>
Write code for a basic key-value store class in Bloom.<br>	pg 8866, fig 4/5<br>
Explain the various node and edge styles in the "dataflow charts" that are used to represent Bloom programs.<br>	pg 8867, figure 8<br>read the text in section 4.4<br><br><br>
How can "points of order" be identified by looking at a Bloom dataflow graph?<br>	pg 8867, paragraph above section 4.5<br>
Go to page 8866.<br>Draw a dataflow diagram for the code in figure 4.<br>Also draw a dataflow diagram for the code in figure 5.<br>	pg 8868, fig 9/10<br><br>
Consider the rules<br><br>(1) p(X) :- q(X)<br>(2) q(X) :- r(X)<br><br>Suppose the domain of interest is the integers. Characterize the models of this rule set.<br>	<br>ullman pg 115, example 3.1<br>
How can a set of datalog rules be used to reason about a database?<br>	pg 115, bottom two paragraphs<br><br>
Suppose we have a set of datalog rules where a subset of the predicates involved have been identified as database predicates. What does it mean for a model to be a <i>minimal model</i> for this rule set?	pg 115, bottom paragraph / 116 top paragraph<br><br>
What do predicate symbols in datalag denote?<br>	relations.<br><br>pg 117, bottom paragraph of the intro to section 3.2 <br>
Explain the difference between extensional database relations (EDB) and intensional database relations (IDB).<br>	pg 117, bottom paragraph<br><br>
Concretely, how does an atomic formula denote a relation?<br>	pg 118 (see enumeration w/ 1. 2.)<br><br>
Briefly summarize the important distinctions between built-in predicates and ordinary predicates.<br>	pg 118 bottom/ 119 top<br>
What is a literal?<br>	pg 119<br>
What is a clause?<br>What is a horn clause?<br>	pg 119<br>
There are three kinds of horn clauses. List and briefly describe each one.<br>	pg 119<br>
What is datalog's notation for expressing horn clauses?<br>	q :- p1 & ... & pn<br>pg 119 near bottom<br>
What is the formal definition of a <i>logic program</i>?<br>	pg 119<br>
A horn clause has several components:<br>- The body<br>- The subgoals<br>- The head<br>How are these components defined?	pg 119, bottom paragraph<br>
Variables occuring within a datalog horn clause are implicitly quantified over. Explain how this quantification works.<br>	pg 119, bottom of page / pg 120, top of page<br><br>
How do we draw the <i>dependency graph</i> of a datalog program?<br>	pg 120<br>
What does it mean for a logic program to be <i>recursive</i>?	pg 120<br>
What does it mean for a predicate in a logic program to be recursive?<br>	pg 120<br>
Examine figure 1 on page 103<br><br>Draw a dependency graph for this program. Is this a recursive or non-recursive program? Which predicates (if any) are recursive?<br><br>	graph and explanation given on page 121
Is it okay to have a rule in a datalog program where a variable occurs only in the head of the rule?<br>Why or why not?<br>	pg 122, the "loves" rule in example 3.3<br>
Give the motivation and formal definition of <i>limited variables</i>.<br>	pg 122, below example 3.3<br>
What does it mean for a rule in a datalog program to be <i>safe</i>?<br>	all variables are limited<br>pg 122<br>
What is the critical issue in determining whether a datalog rule is safe?<br>	Whether variables appearing in the head and variables appearing in subgoals with built-in predicates either appear in some subgoal with an ordinary predicate, are equated to constants, or are equated to other limited variables.<br><br>pg 122<br>
Why are the two rules in example 3.3 on top of page 122 unsafe?	explained in example 3.4 at bottom of page 122<br>
Is rule (1) in figure 3.1 on page 120 safe?	yep. explained in example 3.4 on page 122<br>
How do we evaluate a non-recursive datalog program? Outline an approach.<br>	pg 123, section 3.3<br><br>
Let r be a datalog rule. What is the <i>relation</i> for rule r?<br> 	pg 124, first paragraph<br>
What does it mean for a subgoal S of a rule r to be <i>made true</i> by a substitution of values for r's variables?	pg 124<br>
Suppose the relations P and S for parent and sibling have been computed.<br>Translate rule 2 of fig 3.1, pg 120 into relational algebra.<br>	pg 124, example 3.5<br><br>
Express rule (1) in figure 3.1, pg 120 as relational algebra<br>	pg 125, near top<br><br>
Consider the following datalog rule:<br><br>p(X,Y) :- q(a, X) & r(X,Z,X) & s(Y,Z)<br><br>Suppose we have already computed the realtions Q, R, and S of the subgoals q, r, and s. <br>Translate this rule into relational algebra.<br>	pg 125<br>
What is a <i>time suffix</i>?<br>	Every dedalus predicate is required to have a natural-valued datalog attribute called the time suffix.<br>It is the last attribute of the relation/predicate.<br><br>pg 9112<br>
What is the difference between <i>deductive</i> and <i>inductive</i> dedalus rules?<br>	pg 9112<br>
<latex>~\\<br>Consider the following dedalus rule:\\~\\<br>$p(A, B, \mathcal S) \leftarrow e(A, B, \mathcal T), \mathcal S = \mathcal T$\\~\\<br>Is this rule deductive or inductive? <br></latex><br> 	deductive. pg 9112<br>
<latex>~\\<br>Consider the following dedalus rule:\\~\\<br>$q(A, B, \mathcal S) \leftarrow e(A, B, \mathcal T), successor(\mathcal T, \mathcal S)$\\~\\<br>Is this rule inductive or deductive?<br></latex>  	pg 9112<br>
For every extensional predicate r in a Dedalus<sub>0</sub> program P, a distinguished predicate r_pos is automatically added. Give the definition of r_pos. What is the fundamental difference between r_pos and r?<br><br>	r is extensional <br>r_pos is intensional, and additional facts can be added in<br>pg 9112 bottom/ 9113 top<br>
Dedalus<sub>0</sub> prohibits rules from mentioning extensional predicates, except for rules of a special form. Describe how this works.<br><br>	pg 9113, Guarded EDB (the text above should help)<br>
Dedalus<sub>0</sub> has various forms of syntactic sugar to avoid the tedium that the regularity of dedalus-style datalog rules entail. There are three basic forms of syntactic sugar. Describe them.<br>	pg 9113, section 2.2<br><br>also see example 2<br><br>
How do the constraints imposed on Dedalus<sub>0</sub> rules restrict how deductions may be made with respect to time?<br>	pg 9114, top three paragraphs<br><br>
What is a <i>simple persistence rule</i>?<br>	pg 9114<br>
If p is an extensional dedalus predicate. We can provide a corresponding intensional predicate p_neg. What is p_neg used for?	pg 9114, section 3.2 "mutable state"<br>
<latex>~\\<br>Consider the following $Dedalus_0$ program and ground facts:\\~\\<br>$p_{pos}(A,B) \leftarrow p(A, B);$\\<br>$p_{pos}(A,B)@next \leftarrow p_{pos}(A, B), \neg p_{neg}(A, B);$\\~\\<br>$p(1,2)@101;$\\<br>$p(1,3)@102;$\\<br>$p_{neg}(1,2)@300$\\~\\<br>Which of the following facts are true? Why or why not?\\<br>$p(1,2)@200$\\<br>$p(1,3)@200$\\<br>$p(1,2)@301$\\<br></latex><br><br>	pg 9115, example 3 at top of page<br>
How does Dedalus<sub>0</sub>'s persist macro work?<br>	pg 9115<br>
What is an <i>update</i> in Dedalus?<br>	pg 9115, second paragraph<br><br>
How do we represent a sequence, i.e. a monotonically increasing counter, as a dedalus<sub>0</sub> program?<br>	pg 9115<br>
Explain how to implement a priority queue in dedalus.<br>	<latex>~\\<br>pg 9116, entire page<br>\\~\\<br>note that the concrete aggregation ($\rho$) function used here is min, in the head of the omin rule.  <br>\\~\\<br>The first rule, for each user A, aggregates to the minimum priority C, and produces a set of user/min-priority pairs for the omin relation.<br>\\~\\<br>The second rule identifies only those rows (should be a singleton) of m\_priority\_queue with minimum priority,<br>and places it into priority\_queue.<br>\\~\\<br>The third rule removes the row of minimum priority from m\_priority\_queue.<br></latex>
Consider the following statement:<br><br>A Dedalus<sub>0</sub> program without negation has a unique minimal model.<br><br>Prove or disprove.	"it's a pure datalog program, and therefore has a unique minimal model"<br><br>some thoughts: this model may be infinite, and I'm not sure if that fits into the standard datalog framework<br>i need to revisit the proof of this... it should be analagous to one provided by ulman<br><br>pg 9117<br>
What does it mean for a Dedalus<sub>0</sub> program to be syntactically stratifiable?<br>	there exists no cycle with a negative edge in the program’s predicate dependency graph.<br>pg 9117
What is <i>stratum order</i> for the evaluation of datalog programs?<br>	TODO: link to an actual description<br>pg 9117<br>
What is a <i>locally stratifiable</i> datalog program?	find a link to this (ullman?)<br>it's mentioned pg 9117, but not defined
Given some Dedalus<sub>0</sub> program P, what is the <i>deductive reduction</i> of P?<br>	pg 9117
What does it mean for a Dedalus<sub>0</sub> program to be <i>temporally stratifiable</i>?<br>	its deductive reduction (i.e. its set of all deductive rules) is syntactically stratifiable (i.e. no cycles with negative edges in dependency graph)<br>pg 9117, definition 3<br>
Conside the following statement:<br><br>Any temporally stratifiable Dedalus<sub>0</sub> instance P has a unique perfect model.<br><br>Prove or disprove.	proof at very top of page 9118 -- not self contained, may have to link to ullman
<latex>~\\<br>Consider the following $Dedalus_0$ program. <br>\begin{lstlisting}<br>persist[p_pos, p_neg, 3]<br><br>p_pos(A, B, T) $\leftarrow$<br>  insert p(A, B, T);<br><br>p_neg(A, B, T) $\leftarrow$<br>  p_pos(A, B, T),<br>  delete p(T);<br>\end{lstlisting}<br>Is this program syntactically stratifiable? Is it temporally stratifiable?<br></latex>	<latex>~\\<br>pg 9118, example 4 near top<br><br>remember that the persist macro expands to:<br>\begin{lstlisting}<br>p_pos(A, B) $\leftarrow$ p(A, B);<br>p_pos(A, B)@next $\leftarrow$ p_pos(A, B), $\neg$ p_neg(A, B);<br>\end{lstlisting}<br></latex>
Discuss the traditional Datalog notion of safety, and why Dedalus violates it.<br>	pg 9118, section 4.2
What does it mean for a Dedlaus rule to be <i>instantaneously safe</i>? What does it mean for a dedalus program to be <i>instantaneously safe</i>?	pg 9118, def 4<br><br>note that an instantaneously safe program may contain rules which are not instantaneously safe, as long as they are inductive rather than deductive rules.
<latex>~\\<br>Consider the following $Dedalus_0$ program:<br><br>\begin{lstlisting}<br>persist[p_pos, p_neg, 2]<br>p(1, 2)@123<br>\end{lstlisting}<br><br>Is this program safe? If not, should we consider lack of safety a fundamental problem in this case?<br></latex><br><br>	pg 9119, example 5<br>
<latex>~\\<br>In $Dedalus_0$, what does it mean for two sets of ground atoms $\Gamma$ and $\Gamma'$ to be<br>equivalent module time?<br></latex>	pg 9119, def 5<br>
What does it mean for a Dedalus<sub>0</sub> instance to be <i>quiescent</i> at time T? 	pg 9119, def 6<br>btw. what is an instance? is it a program paired with a perfect model of the program?
<latex>~\\<br>Consider the following statement:\\~\\<br>A $Dedalus_0$ instance that is quiescent at time $T$ will be quiescent until <br>the timestamp of the next EDB fact $V$, i.e. for all $U \in \mathbb Z : V > U \geq T$.<br>If no EDB fact has a timestamp greater than T, then the instance will be henceforth quiescent.\\~\\<br>Prove or disprove.<br></latex>	pg 9119<br>
What does it mean for a Dedalus<sub>0</sub> instance with finite EDB to be <i>temporally safe</i>?<br>	pg 9120, definition 7<br>
<latex>~\\<br>What does it mean for an intensional predicate in a $Dedalus_0$ program to be an \emph{instantaneous}<br>predicate?<br></latex>	pg 9119, definition 8
Dedalus<sub>0</sub>'s conservative test for temporal safety consists of three parts. List them.<br>	pg 9120, top of page<br>
Consider the following statement:<br><br>A temporally stratifiable Dedalus<sub>0</sub> instance is temporally safe if it has a finite EDB and every rule is one of three kinds:<br>1. An instantaneously safe rule<br>2. An inductive rule in which the head predicate occurs also in the body with the same variable bindings for all attributes save the time suffix<br>3. An inductive rule that has at least one instantaneous predicate as a positive subgoal<br>in the body.<br><br>Prove or disprove.	pg 9120-9121, lemma 4<br>todo: add impostor<br>
<latex>~\\<br>What can be said about the safety of the following $Dedalus_0$ program?\\~\\<br>\begin{lstlisting}<br>flip_flop(B, A)@next $\leftarrow$ flip_flop(A, B);<br>flip_flop(0, 1)@1;<br>\end{lstlisting}<br></latex>	pg 9121, example 7<br><br>
Dedalus extends Dedalus<sub>0</sub> with a single construct. What is this construct, and what motivates it?<br>	pg 9121, section 5, 5.1<br><br>
What is a <i>horizontal partition</i>? How does Dedalus embody the concept?<br>	pg 9122, section 5.2<br><br>
What is a <i>location specifier</i> in Dedalus?<br>	pg 9122<br>
What is a <i>communication rule</i> in Dedalus?<br>	Finally, we constrain Dedalus rules in such a way that the location specifier variable<br>in each body predicate is the same—i.e., the body contains tuples from exactly one<br>partition of the database, logically colocated (on a single “machine”). If the head of the rule has the same location specifier variable as the body, we call the rule “local,”<br>since its results can remain on the machine where they are computed. If the head has<br>a different variable in its location specifier, we call the rule a communication rule. We<br>now proceed to our model of the asynchrony of this communication, which is captured<br>in a syntactic constraint on the heads of communication rules.<br><br>pg 9122<br>
What does it mean for a Dedalus rule to be <i>asynchronous</i>?	pg 9122, section 5.3<br><br>
<latex>~\\<br>In asynchronous rules, the head time suffix may take on a special value $\top$, rather than an integer.<br>What does $\top$ represent?<br></latex>	pg 9122, section 5.3<br><br>
For all Dedalus programs, a special predicate called <i>time</i> is defined. Give the two rules used to define <i>time</i>.<br>	pg 9122, section 5.3<br><br>note that this merely says that time is a set of unary tuples which contains (top), and also (z) for all integers z, since the set of all atoms having a successor is exactly the set of all integers. still not sure why integers rather than natural numbers are used for time.<br><br>the choose line means that the time S is nondeterministically dependent on A_1, ..., A_n, T, which<br>are the contents of the head predicate tupled with the body time.<br><br>
<latex>~\\<br>Desugar the following Dedalus rule:<br><br>\begin{lstlisting}<br>r(A, B)@async $\leftarrow$ e(A, B)<br>\end{lstlisting}<br><br></latex>	pg 9123, top of page<br>
In Dedalus, communication rules must be asynchronous. Discuss the ways in which this limits communication.	pg 9123, section 5.4<br>
Consider the following statement:<br><br>It is not possible for an agent to "receive" an asynchronous rule before the sender "sends" it.<br>i.e. the time in the head cannot be less than the time in the body<br><br>Prove or disprove	IMPOSTOR. pg 9123, section 5.5<br>
Consider the three asynchronous scenarios (a), (b), and (c) listed in the "Practical Implications" section on pg 9123.<br><br>Why are these scenarios of practical significance?<br>	answer is on top of pg 9124<br>
What does the term <i>entanglement</i> mean in the context of Dedalus?	pg 9124<br>
What, according to Martin-Lof, determines the meaning of a proposition?	the meaning is determined by what counts as a verification of it<br>pg 8676<br>
<latex>~\\<br>Given Martin-Lof-style meanings for propositions, how do we know that $\wedge$-elimination rules are sound? <br></latex>	pg 8677
What is a <i>local reduction</i>? What is <i>local soundeness</i>?<br>	pg 8677, bottom half of page
What would it mean for an elimination rule of a logical system to be <i>too strong</i>? How do we prove that the elimination rules of a logical system are not too strong?	pg 8677, bottom half of page
What does it mean for the elimination rules of a logical system to be <i>sufficiently strong</i>, and why is this important?	pg 8677, second to last paragraph
What does it mean for an elimination rule for a connective to be <i>locally complete</i>? Why is local completeness important? Show that conjunction is locally complete for standard intuitionistic logic.<br>	pg 8677, bottom paragraph<br>pg 8688, top paragraph<br>
What is <i>local expansion</i> and why is it important? 	pg 8678, near top<br>
What is a <i>hypothetical judgment</i>? What are the <i>antecedents</i>? What is the <i>succedent</i>?	pg 8678 bottom<br>pg 8679 top<br>
What is a <i>hypothetical proof</i>?	pg 8679 / top paragraph
State the <i>substitution principle for truth</i>.	pg 8679
Give the <i>hyp</i> rule for the us of hypotheses.<br>	pg 8679
<latex>~\\<br>Give the \emph{formation rule} "$\supset{F}$".<br></latex>	pg 8679, near bottom
<latex>~\\<br>Give the $\supset I$ rule.<br></latex>	pg 8679, near bottom<br>
<latex>~\\<br>Give the "$\supset E$" rule.<br></latex>	pg 8680, near top<br>
Show that the elimination rule for implication is locally sound.<br>	pg 8680<br>
Show that the elimination rule for implication is locally complete.	pg 8680
Give the axiomatic characterization of implication by means of modus ponens and the axiom schemas S and K.<br>	pg 8680, near bottom<br>
What does a judgment of the form "A valid" mean? How can such a judgment be used?	pg 8681<br>
<latex>~\\<br>What does a judgment of the form $\Delta;\Gamma \vdash J$ mean?<br></latex> 	delta is a set of validity judgments<br>gamma is a set of truth judgments<br>pg 8681, near middle<br>
What is the <i>substitution principle for validity</i>?	pg 8681<br>
Give the <i>generalized hypothesis rule</i> hyp*.<br>	pg 8681<br>
<latex>~\\<br>What is the meaning of the proposition $\square A$ ?<br></latex>	"A is valid"<br>pg 8681<br>
<latex>~\\<br>Give the $\square F$ rule.<br></latex>	pg 8681<br>
<latex>~\\<br>Give the $\square I$ rule.<br></latex>	pg 8681, at bottom
<latex>~\\<br>Consider the following attempt at an elimination rule for $\square$:<br>\begin{mathpar}<br>\inferrule<br>  {\Delta; \Gamma \vdash \square A~true}<br>  {\Delta; \cdot \vdash A~true}<br>\end{mathpar}<br>Is there anything wrong with this attempt?<br></latex>	yes. pg 8682<br>
<latex>~\\<br>Consider the following attempt at an elimination rule for $\square$:<br>\begin{mathpar}<br>\inferrule<br>  {\Delta; \Gamma \vdash \square A~true}<br>  {\Delta; \Gamma \vdash A~true}<br>\end{mathpar}<br>Is there anything wrong with this attempt?<br></latex>	yes. pg 8682
<latex>~\\<br>Give the rule $\square E$ and show that it is locally sound.<br></latex><br>	pg 8682<br>
<latex>~\\<br>Give the rule $\square E$ and show that it is locally complete.<br></latex><br>	pg 8682
Give the syntax and deduction rules for judgmental modal logic.<br>	pg 8683<br>
<latex>~\\<br>Let $\square \Gamma$ be a context of the form $\square A_1~true, \ldots, \square A_n~true$.<br>Parwitz's judgmental modal logic uses the following rules<br>\begin{matpar}<br>\inferrule[$\square I_1$]<br>  {\sqaure \Gamma \vdash A~true}<br>  {\square \Gamma, \Gamma' \vdash \square A~true}<br>\and<br>\inferrule[$\square E_1$]<br>  {\Gamma \vdash \square A~true}<br>  {\Gamma \vdash A~true}<br>\end{mathpar}<br>What is wrong with these rules?<br></latex>	pg 8683, near bottom "alternative formulations"<br>
<latex>~\\<br>Necessity can be characterized axiomatically by the inference rule of necessitation<br>\begin{mathpar}<br>\inferrule[nec]<br>  {\vdash A~true}<br>  {\vdash \square A~true}<br>\end{mathpar}<br>together with three axioms. List these three axioms.<br></latex>	pg 8684, bottom of page section 4.3<br><br>
<latex><br>How do hypotheses ($\Gamma$) and validity ($\square$) relate to the notion of \emph{possible worlds}?<br></latex><br>	pg 8685<br>
Give the intuition for "possibility" in judgmental modal logic.<br><br>Also give the official "Definition of Possibility"	pg 8685<br>
Give the "Definition of Possibility with Necessity"<br>	pg 8685, near bottom<br>
<latex>~\\<br>Give the $\diamond F$ rule<br></latex>	pg 8686<br>
<latex>~\\<br>Give the $\diamond I$ rule.<br></latex>	pg 8686<br>
<latex>~\\<br>Give the $\diamond E$ rule.<br></latex>	pg 8686<br>
<latex>~\\<br>Show that $\diamond E$ is locally sound.<br></latex>	pg 8686<br>
<latex>~\\<br>Show that $\diamond E$ is locally complete.<br></latex>	pg 8686
what is a <i>domain</i>?	pg 60<br>
What is a <i>column</i> of a relation?	pg 61, near top<br>
What is an <i>attribute</i> of a relation?	pg 61, near top<br>
What is a <i>relation scheme</i>?<br>	pg 61, near topish
What does the notation REL(A<sub>1</sub>,A<sub>2</sub>,...,A<sub>k</sub>) denote?<br><br>	pg 61<br>
<latex>~\\<br>Let $\mu$ be the tuple (Buffalo, W. Va., 831) and \{CITY, STATE, POP\} be the schema<br>for its relation. What does $\mu[\{CITY, POP\}]$ denote?<br></latex>	pg 62, above "representing entity-relationship diagrams"<br>
What does it mean for a set of attributes of a relation to be a <i>key</i>?<br>	pg 64<br>
Is it true that a relation may only have one key?	no. pg 65 "also observe that..."<br><br>
What is the <i>primary key</i> of a relation?	pg 65<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any refinement system, whenever the corresponding pushforward and/or pullback refinements exist,<br>the following subtyping rule is admissible:\\<br>\begin{mathpar}<br>\inferrule<br>  {S_1 \rImplies_{B} S_2}<br>  {f^{\square} S_1 \rImplies_{A} f^{\square} S_2}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	true. pg 8788<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any refinement system, whenever the corresponding pushforward and/or pullback refinements exist,<br>the following subtyping rule is admissible:\\<br>\begin{mathpar}<br>\inferrule<br>  {S_1 \rImplies_{B} S_2}<br>  {f^{\square} S_2 \rImplies_{A} f^{\square} S_1}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 8788<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any refinement system, whenever the corresponding pushforward exists,<br>there is a strong equivalence<br>$$(g \circ f)_\diamond R \equiv g_\diamond f_\diamond(R)$$<br>Prove or disprove.<br></latex>	true pg 8788<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any refinement system, whenever the corresponding pullbacks exist,<br>there is a strong equivalence<br>$$(g;f)^\square S \equiv g^\square f^\square(S)$$<br>Prove or disprove.<br></latex>	true. pg 8788<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any refinement system, whenever $id_{\diamond} R$ exist, there is a strong equivalence<br>$$id_{\diamond} R \equiv R$$<br>Prove or disprove.<br></latex>	true. pg 8788<br>
Consider the refinement system of example 3.2.10 on pg 8781.<br>Is it an opfibration? A fibration? A bifibration?<br><br>Now consider the refinement system of example 3.2.11 on pg 8782.<br>Is it an opfibration? A fibration? A bifibration?<br><br>	pg 8790, example 3.2.26 at top<br>
<latex>~\\<br>Consider the refinement system $\mbf{Downset \to Poset}$, as described on page 8783.<br>Is it an opfibration? A fibration? A bifibration?<br></latex>	pg 8790, example 3.2.27<br>
<latex>~\\<br>Consider the refinement system $\mbf{Psh \to Cat}$ described on page 8783, example 3.2.15.<br>Is it an opfibration? A fibration? A bifibration?<br></latex><br>	true. pg 8790, example 3.2.28<br>
<latex>~\\<br><br>Let $\mbf{Rel}$ be the category whose objects are sets $A,B$ and whose morphisms $A \to B$ are relations<br>between $A$ and $B$. The composition of two relations<br>$$ A \rTo^M B \rTo^N C$$<br>is defined by relational composition<br>$$ a(M;N)c \Leftrightarrow \exists b. aMb \wedge bNc$$<br>while the identities <br>$$ A \rTo^{id_A} A$$<br>are given by the equality relation:<br>$$ a_1~id_A~a_2 \Leftrightarrow a_1 = a_2 $$<br>Next let $\mbf{Rel_{\bullet}}$ be the category whose objects are pairs $(A, R \subseteq A)$ and<br>whose morphisms $(A,R) \to (B,S)$ are relations $M : A \to B$ such that $a \in R$ and $a M b$<br>implies $b \in S$ for all $a$ and $b$. (The name "$\mbf{Rel_{\bullet}}$" is because a subset<br>$R \subseteq A$ is the same thing as a morphism $R : 1 \to A$ in $\mbf{Rel}$, i.e.,<br>$\mbf{Rel_{\bullet}}$ can be seen as a "pointed" version of $\mbf{Rel}$.)\\~\\<br>Is $\mbf{Rel_{\bullet} \to Rel}$ a fibration? An opfibration? A bifibration?  <br></latex>	pg 8791, example 3.2.29<br>
Exercise 3.2.30, pg 8791<br>	<br>
Exercise 3.2.31, pg 8791 (near bottom)<br>	<br>
<latex>~\\<br>Let $R_1, R_2 \sqsubset A$. What does it mean for a refinement of $A$ to be a \emph{union} of $R_1$ and $R_2$.<br></latex><br>	pg 8792, def 3.2.32<br><br>
What does it mean for a refinement of a type A to be a <i>bottom refinement</i>?<br>	pg 8792, near bottom (no pun intended)<br>
<latex>~\\<br>Let $R_1, R_2 \sqsubset A$. What does it mean for a refinement of $A$ to be a \emph{intersection} of $R_1$ and $R_2$.<br></latex><br>	pg 8793, def 3.2.33<br>
What does it mean for a refinement of a type A to be a <i>top refinement</i>?<br>	pg 8793<br>
What does it mean for a refinement system to have <i>finite intersections</i>? What does it mean for a refinement system to have <i>finite unions</i>?<br>	pg 8793, def 3.2.34<br><br>
<latex>~\\<br>Consider the refinement system $\mbf{Subset \to Set}$ described in example 3.2.14, pg 8783.<br>Does this refinement system have finite intersections? Does it have finite unions?<br></latex><br>	yep. pg 8794<br>
<latex>~\\<br>Consider the refinement system $\mbf{Psh \to Cat}$ described in example 3.2.15, pg 8783.<br>Does this refinement system have finite intersections? Does it have finite unions?<br></latex>	yep. pg 8794.<br>
Exercise 3.2.36, pg 8794<br><br>	<br>
Exercise 3.2.37, pg 8794	<br>
Exercise 3.2.38, pg 8794	<br>
Exercise 3.2.39, pg 8794	<br>
<latex>~\\<br>Exercise 3.2.25, pg 8788\\<br>Just show that $f_{\diamond}$ preserves composition.\\<br></latex><br><br>	<br>
Consider the following claim about the lambda calculus.<br><br>An abstraction denotes a function.<br><br>Is this true or false? Why or why not?	pg 8973, right page, middle paragraph<br>
<latex>~\\<br>Let $e / \delta$ denote simultaneous substitution of $\delta$ into $e$.<br>Consider the following statement:\\~\\<br>If $\delta w = \delta' w$ for all $w \in FV(e)$ then $e/\delta = e/\delta'$<br>True or false? (no need to prove)<br></latex>	pg 8794, right side, prop 10.1, 
<latex>~\\<br>Let $e / \delta$ denote simultaneous substitution of $\delta$ into $e$. Let $I_{\langle var \rangle}$<br>denote the identity substitution of each variable for itself.<br><br>Consider the following statement:\\~\\<br>If $e/I_{\langle var \rangle} = e$ <br>True or false? (No need to prove)<br></latex>	pg 8974, right, prop 10.1<br><br>
<latex>~\\<br>Let $e / \delta$ denote simultaneous substitution of $\delta$ into $e$,<br>and suppose that $FV(e) \subseteq dom(\delta)$.<br>Consider the following statement:\\~\\<br>$FV(e/\delta) = \bigcup_{w \in FV(e)}FV(\delta w)$\\~\\<br>True or false? (No need to prove)<br></latex><br>	pg 8974, right, prop 10.1<br><br>
<latex>~\\<br>What does the notation $e/v \to e'$ mean? <br></latex>	pg 8974, right, below prop 10.1<br>
Explain the difference between <i>contractions</i>, <i>reductions</i>, and <i>reduction sequences</i><br>in the lambda calculus.<br>	pg 8974, bottom right corner<br>
<latex>~\\<br>Explain the lambda caclulus transition rules for $\beta$-reduction, renaming, and contextual closure.<br></latex><br>	pg 8975, left page<br><br>
State, but don't prove, the Church Rosser theorem.<br>	pg 8975, prop 10.2<br>
Argue that, because of the Church-Rosser Theorem, each lambda expression has at most one normal form up to alpha renaming.<br>	pg 8975, bottom right, prop 10.3<br>
Read the examples on the bottom right of pg 8975 and top left of pg 8976.<br>	<br>
What is the normal order reduction sequence of a lambda term?	pg 8976, top left, above prop 10.4<br>
State (but don't prove) the Standardization Theorem (regarding normal order reduction sequences)<br>	pg 8976, prop 10.4<br>
What is the difference between a <i>normal form</i>, as used by a pure lambda calculus, and a <i>canonical form</i>, as used by more practical calculi?<br>	a canonical form may have redexes <i>inside</i> an abstraction.<br>pg 8976, right page, second paragraph<br>
<latex>~\\<br>If $e$ is an expression, what do the notations $e \Rightarrow z$ and $e \uparrow$ mean?<br></latex>	pg 8976, right page, near bottom<br>
Consider the following statement:<br><br>A closed application cannot be a normal form.<br><br>Prove or disprove.	true. pg 8976, very bottom right corner<br>pg 8977, top right corner.<br>
Explain the three (not two!) possibilities for the normal order reduction sequence of a closed expression e.<br>	pg 8977, left<br><br>
Give the two big-step reduction rules, for canonical forms and application, of the lambda calculus.	pg 8977, bottom left<br><br>
<latex>~\\<br>Use these two rules<br>\begin{mathpar}<br>\inferrule<br>  {~}<br>  {\lambda v. e \Rightarrow \lambda v. e}<br>\and<br>\inferrule<br>  {e \Rightarrow \lambda v. \hat{e} \\ (\hat e / v \to e') \Rightarrow z}<br>  {ee' \Rightarrow z}<br>\end{mathpar}<br>to prove the following:<br>$$ (\lambda x.~x(\lambda y.~xyy)x) (\lambda z.~\lambda w.~z) \Rightarrow \lambda y.~(\lambda z.~ \lambda w.~z)yy$$<br></latex>	pg 8977, top right<br>
What is the advantage of big-step semantics over small-step semantics?<br>	pg 87978, bottom left (below proof)<br>entire right page<br>
<latex>~\\<br>What is a $\beta_E$-redex? What is a $\beta_E$-reduction? <br></latex>	note that E stands for eager<br>pg 8979<br>
Give the two big-step reduction rules for eager evaluation of lambda calculus.<br>	pg 8979, bottom left corner<br>
<latex>~\\<br>Write an "indented form" proof of the fact that <br>$$(\lambda x.~x~x)((\lambda y.~y)(\lambda z.~z)) \Rightarrow_E \lambda z.~z$$<br></latex> 	pg 8979, right page<br><br>
Discuss the "runtime performance" tradeoffs involved in normal-order evaluation vs. eager evaluation.<br>	pg 8979, bottom right.<br>
Discuss the reason that a denotational semantics for untyped lambda calculus was so difficult to develop.<br>	pg 8980, left page.<br>key paragraphs: <br>"To see this, we first note that,"<br>"The trouble with all this is that, if S..."<br><br>
What is the type of the interpretation of a lambda expression in Scott's semantics for the untyped lambda calculus?	<latex>~\\<br>The continuous functions of the following type:<br>D_{\infty}^{\langle var \rangle} \to D_{\infty}<br></latex><br><br>pg 8980, right page<br>
Give the semantic equations for variables, applications, and abstraction in Scott's denotational semantics for the untyped lambda calculus. 	pg 8980, bottom right corner.<br>
<latex>~\\<br>Suppose $P$ is a predomain and $v \in \langle var \rangle$. Consider the following statement:\\~\\<br>The function $get_{P_v}$ satisfying<br>$$get_{P_v} \eta = \eta v$$<br>is a continuous function from $P^{\langle var \rangle}$ to $P$.\\~\\<br>Prove or disprove.<br></latex>	predomain definition on pg 8890, bottom right<br>true. pg 8981<br>
<latex>~\\<br>Suppose $P$ is a predomain and $v \in \langle var \rangle$. Consider the following statement:\\~\\<br>The function $ext_{P_v}$ satisfying<br>$$ext_{P_v} \langle \eta, x \rangle = [ \eta \mid v : x ]$$<br>is a continuous function from $P^{\langle var \rangle} \times P$ to $P^{\langle var \rangle}$.\\~\\<br>Prove or disprove.<br></latex>	predomain definition: pg 8890<br>true. pg 8981, left page<br>todo: add impostor?<br>
<latex>~\\<br>Suppose $P$ and $P'$ are predomains. Consider the following statement:\\~\\<br>The function $ap_{PP'}$ satisfying<br>$$ap_{PP'} \langle f, x \rangle = f x$$<br>is a continuous function from $(P \to P') \times P$ to $P'$.\\~\\<br>Prove or disprove.<br></latex>	predomain definition: pg 8890<br>true. pg 8981, left, (c)<br>todo: add impostor?<br><br><br>
<latex>~\\<br>Suppose $P$, $P'$, and $P''$ are preorders. Let $f$ be a continuous function from <br>$P \times P'$ to $P''$. Consider the following statement:\\~\\<br>If $ab~f$ (sometimes called the "Currying" of f) satisfies <br>$$((ab~f)~x)~y = f \langle x, y \rangle$$<br>then $ab~f$ is a continuous function from $P$ to $P' \to P''$.<br>Prove or disprove.<br></latex>	definition of preorder and continuous function on pg 8890<br><br>true. pg 8981, left, (d)<br>
<latex>~\\<br>Consider the function defined by the semantic equations:\\~\\<br>$$ \sem{v} \eta = \eta v $$<br>$$ \sem{e_0e_1} \eta = \phi(\sem{e_0}\eta)(\sem{e_1}\eta) $$<br>$$ \sem{\lambda v.e} \eta = \psi(\lambda x \in D_{\infty}. \sem{e}[\eta \mid v : x])$$<br>Consider the following claim:\\~\\<br>This function is well-typed and satifies $\sem{-} \in \langle exp \rangle \to (D_{\infty}^{\langle var \rangle} \to D_{\infty})$\\~\\<br>Prove or disprove.<br></latex>	pg 8981 prop 10.8
<latex>~\\<br>Look at 10.2-10.4 on page 8980 and consider the following statement:\\~\\<br>If $\eta w = \eta' w$ for all $w \in FV(e)$, then $\sem{e} \eta = \sem{e} \eta'$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8982<br>todo: add impostor?<br>
<latex>~\\<br>Look at 10.2-10.4 on page 8980 and consider the following statement:\\~\\<br>If $\sem{\delta w} \eta' = \eta w$ for all $w \in FV(e)$, then $\sem{e/\delta}\eta' = \sem{e}\eta$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8982, right, prop 10.10<br>todo: add impostor?<br>
<latex>~\\<br>Look at 10.2-10.4 on page 8980 and consider the following statement:\\~\\<br>$\sem{e/v_0 \to e_0, \ldots v_{n-1} \to e_{n-1}}\eta' = \sem{e}[\eta' \mid v_0 : \sem{e_0} \eta ' \mid \ldots \mid v_{n-1} : \sem{e_{n-1}}\eta']$\\~\\<br>Prove or disprove.<br></latex>	pg 8982, right, prop 10.11<br>todo: add impostor?<br>
<latex>~\\<br>Look at 10.2-10.4 on page 8980 and consider the following statement:\\~\\<br>If<br>$$ v_{new} \not \in FV(e) - \{v \},$$<br>then<br>$$\sem{\lambda v_{new}.~(e/v \to v_{new})} = \sem{\lambda v.~e} $$<br>Prove or disprove.<br></latex>	true. pg 8982<br>todo: add impostor?<br>
<latex>~\\<br>Look at 10.2-10.4 on page 8980 and consider the following statement:\\~\\<br>$$ \sem{(\lambda v.~e)e'} = \sem{e/v \to e'} $$<br>Prove or disprove.<br></latex>	true. pg 8982, bottom right, prop 10.13<br>
<latex>~\\<br>Look at 10.2-10.4 on page 8980 and consider the following statement:\\~\\<br>If v does not occur free in $e$, then<br>$$\sem{\lambda v.~ev} = \sem{e}$$ <br>Prove or disprove.<br></latex>	true. pg 8982, bottom right, prop 10.14<br>todo: add impostor?<br>
<latex>~\\<br>Explain why the $D_{\infty}$ semantics is appropriate for interpreting reduction to normal form in the pure lambda calculus, but not for interpreting normal-order evaluation, in the sense described on pg 8976, right.<br></latex>	pg 8983, left<br>
In Reynold's terminology, what is the difference between a <i>value</i> and a <i>result</i>?<br>	pg 8983, bottom left<br><br>
<latex><br>Explain the following diagram and its relevance to normal-order evaluation.<br><br>\begin{diagram}<br>D = V_{\bot} & \pile{\rTo^{\phi_{\bot \! \bot}} \\ \lTo_{\iota^{\uparrow} \cdot \psi}} & D \to D<br>\end{diagram}<br></latex>	pg 8983, top right
Give the semantic equation for the denotational semantics of untyped lambda calculus with normal order evaluation. (hint: a diagram between semantic domains can be a helpful guideline)<br>	pg 8983, right (relevant diagram at top of page)<br><br>
What changes must we make to the basic denotational semantics of normal-order-evaluating lambda calculus in order to accomodate eager evaluation?	pg 8983, bottom right<br>pg 8984, top left<br>
Give the semantic equations for lambda calculus with eager evaluation. (hint : drawing an isomorphism diagram might be helpful)<br>	pg 8984, left<br>
In Reynolds' eager functional language, evaluation is a relation which relates ________ to _______.<br>Fill in the blanks.<br>	It relates closed expressions to canonical forms.<br>pg 8987, right, section 11.2<br>
What is so thorny about the ability to raise errors (exceptions) that Reynolds initially chooses to model them in a way that does not distinguish them from non-termination?<br>	pg 8988, left, near top<br>
In Reynolds' eager functional language, canonical forms all share a common behavior with respect to reduction. What is it?<br>	pg 8988, bottomish left<br><br>
<latex>~\\<br>What does the notation $\lfloor - \rfloor$ mean when used in the context of Reynolds' eager functional language?<br></latex><br>	pg 8988, right<br>
Give the big-step rules for unary and binary operators in Reynolds' eager functional language.	pg 8988, right<br>
Give the big-step evaluation rules for conditional expressions in Reynolds' eager functional language.<br>	pg 8988, bottom right<br><br>
Give the big-step reduction rule for lambda application in Reynolds' eager functional language.	pg 8989
Give the big-step evaluation rules for tuples in Reynolds' eager functional language.<br>Give the big-step evaluation rules for alternatives (sums) in Reynolds' eager functional language.<br><br>Give both introduction AND ELIMINATION rules.<br>	pg 8989, right<br><br>
What are the operational semantics for the <b>error</b> and <b>typeerror</b> constructs of Reynolds' eager functional language?<br>	trick question (kinda): they always diverge, a fact captured by giving them no inference rules (in big-step semantics) at all<br>pg 8989, bottom right<br>pg 8990, top left<br>
Read pg 8990, left side to learn about patterns in Reynolds' eager functional language.<br><br>	<br>
<latex>~\\<br>Recall that in Reynolds' eager functional language, the metavariable p is used to denote patterns.<br>How do we define the free-variables function FV on terms of the form $\lambda p.~e$, i.e.<br>how do we define<br>$$FV(\lambda p.~e)$$ <br></latex>	pg 8990, bottom left<br><br>
<latex>~\\<br>Show how definitions and patterns in Reynolds' eager functional language can be represented as patterns.<br>Desugar the expression<br>$$ \mathbf{let}~\langle x,y \rangle \equiv w, z \equiv 2 \times n~\mathbf{in}~x+y+z$$<br></latex><br>	pg 8990, top right
Explain how the syntax of a letrec expression is different from that of a let expression in Reynolds' eager functional language.<br>	pg 8990, right side<br>
Explain the big-step reduction rule for letrec in Reynolds' eager functional language.<br>	It's a bit subtle. Read all of page 8991, left side<br>and tiny chunk of text on top right<br><br>
Give the syntax and big-step operational semantics associated with lists.<br>Show how lists can be implemented in terms of sums and products.<br>	pg 8991, bottom right, pg 8992, top left<br>
Read pg 8992, section 11.5<br>	<br>
How is the predomain V<sub>⁎</sub> of <i>results</i> defined for Reynolds' eager functional language?<br>	pg 8993, right page.<br>
<latex>~\\<br>In the direct denotational semantics for Reynolds' eager functional language, if $f \in V \to V_{\ast}$,<br>how is $f_{\ast} : V_{\ast} \to V_{\ast}$ defined?<br></latex><br> 	pg 8993, right page<br>
Why does Reynolds' eager functional language contain two distinct error forms <b>error</b> and <b>typeerror</b>? What is the difference?	pg 8993, right page<br>
Give the isomorphism diagram for the denotational semantics of Reynolds' eager functional language.	note: a predomain is a partial order in which every chain has a join.<br>a domain is a predomain with bottom.<br><br>pg 8994, left side<br><br>for definition of predomain see pg 8890<br>
<latex>~\\<br>Explain the isomorphism diagram for Reynolds' eager functional language:<br>\begin{diagram}<br>V & \pile{\rTo^\phi \\ \lTo_{\psi}} & V_{int} + V_{bool} + V_{fun} + V_{tuple} + V_{alt}<br>\end{diagram}<br><br>Give definitions for each of the components.<br></latex>	pg 8994 left<br>
<latex>~\\<br>Recall that Reynolds uses the metavariable $\theta$ to range over the set $\{ int, bool, fun, tuple, alt \}$.<br>When $f \in V_{\theta} \to V_{\ast}$, what does $f_{\theta}$ denote?<br>What does $f_{\theta \ast}$ denote?<br></latex><br>	pg 8994, bottom left, top right<br>
<latex>~\\<br>Let $E = \langle var \rangle \to V$ be the predomain of environments.<br>How is $E$ used to define the semantics of expressions?<br></latex>	pg 8994, right page<br>
Give the denotational semantics for <b>error</b> and <b>typeerror</b> in Reynolds' eager functional language?<br>	pg 8994, right page<br>note that the constants <i>err</i> and <i>tyerror</i> are defined on page 8993<br>
Give the denotational semantics for arithmetic constants, arithmetic unary operators, and arithmetic binary operators in Reynolds' eager functional language.<br>	pg 8994, bottom right<br><br>
Give denotational semantics for conditional expressions, variables, application, and abstraction in Reynolds' eager functional language.<br>	pg 8995, left page<br>
Give the denotational semantics for tuples and alternatives in Reynolds' eager functional language.	pg 8995, bottom left<br><br>
On the bottom right paragraph of pg 8890, Reynolds explains that the expressions bound to variables in a letrec definition must be function abstractions. Why is this necessary, even though non-recursive let can bind arbitrary expressions?	The justification is given on the right side of pg 8995:<br>it's necessary for the denotational semantics of letrec.<br><br>
Give denotational semantics for letrec in Reynolds' eager functional language.<br>	pg 8995, right<br>pg 8996, left<br><br>
Discuss the advantages of denotational semantics over operational semantics.<br>	pg 8996, bottom left, top right<br>
<latex>~\\<br>Define the domain of continuations $V_{cont}$.<br>Give the type of the function $\sem{-}$, which interprets expressions.<br>Give the type of the domain $V_{fun}$ of functional values for Reynolds' continuation semantics of an eager functional language.<br></latex>	pg 9001, right<br>pg 9002, left<br><br>
<latex>~\\<br>Read the definitions of the constants $\iota$, $err$, and $tyerr$, as well as the isomorphism diagram, etc.<br>on pg 9002 left.<br></latex>	pg 9002 (duh)<br><br>
<latex>~\\<br>Give continuation semantics for $\mathbf{error}$, $\mathbf{typeerror}$, integer constants,<br>unary operations, and binary operations in Reynolds' eager functional language.<br></latex>	pg 9002, right page<br>
In which style of semantics is evaluation order more obvious: direct denotational semantics, or continuation denotational semantics?<br>	pg 9002, bottom right says continuation semantics<br>for comparison, see pg 8894, bottom right<br><br>
<latex>~\\<br>Give continuation semantics for conditional expressions, variables, application, and abstraction in<br>Reynolds' eager functional language.<br></latex>	pg 9003, left page<br>
<latex>~\\<br>Give the continuation semantics for tuples and alternatives in Reynolds' eager functional language.<br></latex><br>	pg 9003, bottom left<br><br>
<latex>~\\<br>Give continuation semantics for letrec in Reynolds' eager functional language.<br></latex><br>	pg 9003, top right<br><br>
<latex>~\\<br>How do we update the isomorphism diagram for the denotational semantics of Reynolds' eager functional language to take "continuations as values" into account?<br></latex>	pg 9003, right<br>
<latex>~\\<br>Give continuation-based denotational semantics for the \textbf{callcc} and \textbf{throw} constructs.<br></latex> 	pg 9004, top left<br><br>
<latex>~\\<br>Show that the expression $\textbf{callcc}~(\lambda k.~2 + \textbf{throw}~k~(3 \times 4))$ denotes the value 12<br></latex>	pg 9004, left<br>
<latex>~\\<br>What does the following expression denote?<br>$$\mathbf{let}~f \equiv \mathbf{callcc}~\lambda k. \lambda x. \mathbf{throw}~k~(\lambda y. x + y)~\mathbf{in}~f~6$$ <br></latex>	pg 9004, top right<br>
<latex>~\\<br>Consider the following chunk of code. What does it do?<br>\begin{verbatim}<br>let multlist = λx. calcc (λk. <br>    letrec mt = λx. listcase x of (1,<br>        λi. λr. if i = 0 then throw k 0 else i × mt r)<br>    in mt x) ...<br>\end{verbatim}<br></latex>	pg 9004, bottom left<br>
<latex>~\\<br>Consider the following chunk of code<br>\begin{verbatim}<br>let multlist = λx. <br>  letrec mt = λx. listcase x of (1,<br>    λi. λr. i × mt r)<br>  in mt x ...<br>\end{verbatim}<br>Convert this to continuation passing style, so that it immediately aborts if it finds the list<br>to contain 0.<br></latex>	pg 9004, bottom right,<br>pg 9003, top left<br>
<latex>~\\<br>We must change the following three definitions for a "defunctionalized" semantics of Reynolds' eager functional language.\\~\\<br>V_{cont} = V \to V_{\ast}<br>V_{fun} = V \to V_{cont} \to V_{\ast}<br>E = \langle var \rangle \to V\\~\\<br>How? <br></latex>	pg 9005 right<br>
<latex>~\\<br>How do we interpret a continuation $\sem{-e} \eta \kappa$ using defunctionalized semantics?<br></latex>	pg 9006, top left<br>
<latex>~\\<br>How do we define defunctionalized semantics for the binary operation\\~\\<br>\sem{e + e'}?<br></latex>	pg 9006, left<br>
<latex>~\\<br>Consider the formal system of modal logic with necessity and possibility. Its syntax is:~\\<br>Propositions A ::= $P \mid A_1 \supset A_2 \mid \square A \mid \diamond A$\\<br>True Hypotheses $\Gamma$ ::= $\cdot \mid \Gamma, A~true$\\<br>Valid Hypotheses $\Delta$ ::= $\cdot \mid \Delta, A~valid$ \\<br>Give all judgment rules associated with this system.<br></latex><br>	pg 8687<br>
Give all five substitution rules for modal logic with necessity and possibility.<br>	pg 8687, bottom<br>
What is the difference between an <i>analytic</i> and a <i>synthetic</i> judgment? Give examples.	pg 8689.<br>
Show that standard product type elimination rules are both locally sound and locally complete.<br>	pg 8689, near bottom<br>
Explain local reduction and expansion for arrow types in a typical typed programming language.	<latex>~\\<br>pg 8690, middle\\<br>note that $\supset$ is used instead of $\to$<br></latex>
What does the notation x::A mean in Pfenning and Davies' system?	pg 8690<br>
Show how "substitution of validity hypotheses" works in the terms and types formulation of Pfenning and Davies' system. 	pg 8690, the hyp* rule and the substitution principle to its right.<br>
Give the introduction and elimination rules for modal necessity in the terms-and-types formulation of Pfenning and Davies' system. Also show local soundness and completeness.<br><br>	pg 8690<br>
To incorporate modal possibility into Pfenning and Davies' term-and-type formulation of modal logic, a new syntacic class E of <i>proof expressions</i> is introduced. Explain the motivation for $E$ and give its definition.<br>	pg 8691, near top<br><br>
Give the introduction and elimination rules for modal possibility in Pfenning and Davies' term-and-type system for modal logic. Also demonstrate local soundness and completeness.	<latex>~\\<br>pg 8691, see $\diamond I$ and $\diamond E$ and the below rewrite rules.<br></latex><br>
<latex>~\\<br>In Pfenning and Davies' term-and-type formulation of modal logic, a special substitution operator $\langle \! \langle E /x \rangle \! \rangle$ is necessary for dealing with modal possibility. Give its definition and explain its motivation.<br></latex>	pg 8691, middle<br>
<latex>~\\<br>Explain the derived elimination rule $\square E_p$, in both its purely logical form and its term-and-type form.<br></latex><br>	pg 8686, near bottom<br>pg 8691, near bottom<br>
<latex>~\\<br>Give Pfenning and Davies' definition of \emph{lax truth}, i.e. judgments of the form <br>$\Gamma \vdash A~lax$<br></latex>	pg 8695, middle<br>
<latex>~\\<br>Give the introduction and elimination forms $\bigcirc I$ and $\bigcirc E$ for lax truth propositions<br>of the form $\bigcirc A$. Show local soundness and completeness.<br></latex><br>	pg 8695, bottomish
Give the three axioms which characterize lax logic.	pg 8696, near top<br>
<latex>~\\<br>Axiomatically, how is the lax modality $\bigcirc$ different than the possibility modality $\diamond$?<br></latex><br><br>	pg 8696, below axioms<br><br>
<latex>~\\<br>Give the translation $(-)^+$ from lax logic into intuitionistic modal logic.\\<br>You will need to handle the following syntactic forms:\\<br>$A \Rightarrow B$\\<br>$\bigcirc A$\\<br>$P$\\<br>$\cdot$  (empty~context)\\<br>$\Gamma, A~true$\\~\\<br>Prove that it is sound and complete:\\<br>$\Gamma \vdash^L A~true$ iff $\Gamma^+;\cdot \vdash^M A^+~true$<br></latex><br> <br>	pg 8696, near bottom<br><br>
<latex>~\\<br>Define the translation $(-)^-$ from intuitionistic modal logic into lax logic.\\<br>You must handle the following cases.\\<br>$A \supset B$\\<br>$\square A$\\<br>$\diamond A$\\<br>$P$ \\<br>$\cdot$ (empty context)\\<br>$\Delta, A~valid$\\<br>$\Gamma, A~true$\\~\\<br>Prove the two properties:\\<br>1. if $\Delta;\Gamma \vdash^M A~true$ then $\Delta^-,\Gamma^- \vdash^L A^-~true$, and\\<br>2. if $\Delta; \Gamma \vdash^M A~poss$ then $\Delta^-,\Gamma^- \vdash^L A^-~lax$<br></latex>	pg 8697, near top<br>
In one or two short sentences, what advantages does normal order evaluation provide over eager evaluation?<br>	Fewer expressions diverge, plus lazy lists<br>pg 9025, left, intro<br>also soundness: see "reduction revisited" on pg 9029<br><br>
Give big-step reduction rules for canonical forms, unary operators, binary operations, and conditional expressions. In Reynolds' normal order language.<br>	pg 9025, top-right<br><br>
Give the big-step rule for function application in Reynolds' normal-order language.	pg 9025, bottom right<br>
Give the big-step reduction rules related to tuples for Reynolds' normal-order language.<br>	note that all tuple constructors are canonical, so we don't need to give an explicit reduction rule for tuple constructors (that is handled by the "canonical forms" rule on the top right of pg 9025)<br><br>pg 9026, top left<br><br>
Give the big-step reduction rule for alternatives in Reynolds' normal order language.<br>	pg 9026, left<br><br>
<latex>~\\<br>In Reynolds' normal order language, recursion is handled much differently than in the eager language, using terms of the form $\mbf{rec}~e$. Give the big-step reduction rule for this form and explain why it would not be useful under eager evaluation.<br></latex>	pg 9026, left<br>
Show how letrec bindings can be defined in terms of syntactic sugar in Reynolds' normal-order language.<br>	pg 9026, right<br>
Explain how short-circuiting versions of common boolean operations can be defined in Reynolds' normal order language.	pg 9026, bottom right.<br>for definition of if expressions, see pg 9025, mid right<br>
Show how Reynolds' normal order language can be used to implement a short-circuiting multiplication operator.<br>	pg 9027, top left, scmult<br><br>
Consider the <i>search</i> example on the top-left of pg 8993.<br>How could this example be improved using normal order evaluation?	pg 9027, left toppish<br>
Show how to define the following infinite lists in Reynolds' lazy language:<br>1.) 0 :: 0 :: 0 :: 0 :: ...<br>2.) 0 :: 1 :: 2 :: 3 :: ...<br>	pg 9027, left<br>
Consider the following statement:<br><br>In Reynolds' normal order language, there are two types of lists.<br><br>True or false? Explain	FALSE! IMPOSTOR! HAHAHAHAHA!<br>there are also partial lists, i.e. accessing some element causes divergence.<br>pg 9027, bottom right<br><br>
<latex>~\\<br>Draw the isomorphism diagram for semantic domains in Reynolds' Normal-Order Language.<br></latex>	pg 9028, top-left<br><br>
How does the semantic domains for Reynolds' normal-order language differ from the semantic domains for Reynolds' eager language? 	pg 9028, mid left
Give the denotational semantics for variables, application, and abstraction in Reynolds' normal-order language.	pg 9028, right<br><br>
Give denotational semantics for tuples and alternatives in Reynolds' normal-order language.	pg 9028, bottom right<br><br>
Give denotational semantics for the syntactic form <b>rec</b> e in Reynolds' normal-order language.<br><br>	pg 9029, top left<br>
Give the "tuple pattern" typing rule for Reynolds' simple type system. 	pg 9036, left<br>
<latex>~\\<br>Give Reynolds' \emph{explicit} abstraction typing rule.<br></latex>	pg 9038, right. Note that Reynolds' abstractions bind patterns rather than variables.<br>
Explain Haskell Curry's <i>extrinsic</i> view of the meaning of types.<br>	pg 9039, right, section 15.4
Consider the following statement:<br><br>The meaning of a type should be a set of results that a term of that type may normalize to.<br><br>Is there anything wrong with this statement? How would you revise it?<br>	pg 9039, bottom right<br>pg 9040, top left<br><br>make sure to read the paragraph about the "real" type. it's kind of interesting.<br>
What is a partial equivalence relation, and how are partial equivalence relations relevant to denotational semantics?	pg 9040. bottom left<br>
Read the second to bottom paragraph of pg 9040 left.<br>	pg 9040<br>
<latex>~\\<br>Recall that Reynolds uses the metavariable $\theta$ to represent types.<br>What does $\mathcal P(\theta)$ denote?<br></latex>	pg 9040, bottom left (partial equivalence relations are defined over the course of the left page; start reading from the top if you need a refresher)<br>
<latex>~\\<br>Give the definitions for partial equivalence in Reynolds' eager language. Specifically,<br>define $\mathcal P(int)$, $\mathcal P(bool)$, $\mathcal P(\theta \to \theta')$,<br>$\mathcal P(\mbf{prod}(\theta_0, \ldots, \theta_{n-1}))$<br>and $\mathcal P(\mbf{sum}(\theta_0, \ldots, \theta_{n-1}))$<br></latex>	pg 9040, top-right<br>
<latex>~\\<br>One of the essential properties of Reynolds' partial equivalence relation is that for all types $\theta$,<br>$\mathcal P(\theta)$ is "chain-complete". What does this mean, and why does it matter?<br></latex><br>	pg 9040, right page, prop 15.1 (b)<br><br>
For extrinsic, Curry-style semantics, state the theorem regarding soundness of non-binding (i.e. non-abstraction) typing rules.<br><br>Then state the "soundness of typing" theorem in its general form.<br>	pg 9041, top left<br>pg 9042, top left<br><br>
<latex>~\\<br>There are three important properties other than soundness for the partial equivalence relation in Reynolds' extrinsic type semantics. For all types $\theta$, they are:\\~\\<br>1.) $\mathcal P(\theta)$ is a partial equivalence relation\\<br>2.) $\mathcal P(\theta)$ is "chain-complete" \\<br>3.) ????\\~\\<br>What is the third property and why is it important?<br></latex> 	It is important because:<br>- It rules out the possibility that well-typed terms are interpreted as type errors<br>- It allows for the possibility that well-typed terms of any type diverge<br><br>pg 9040 / bottom right<br>
Explain how the naive version of soundness (where a type denotes a set of values) can be framed as a special case of the partial equivalence relation version of soundness.<br>	pg 9042, right, prop 15.4<br>
What is the <i>intrinsic</i> view of the denotational semantics of typed languages?	pg 9043, top left<br>
<latex>~\\<br>The first step in defining an intrinsic semantics of a typed language is to define the meaning of each type $\theta$ to be a domain. Give the domains for int, bool, and the type constructors<br>$\theta \to \theta'$, $\mbf{prod}(\theta_0, \ldots, \theta_{n-1})$, $\mbf{sum}(\theta_0, \ldots, \theta_{n-1})$ <br></latex>	pg 9043, bottom left<br>
<latex>~\\<br>For intrinsic denotational semantics, how is the semantics $\mathcal D^*(\pi)$ of a context $\pi$ defined?<br></latex>	pg 9043, bottom right<br>
<latex>~\\<br>In intrinsic denotational semantics of typed languages, how is the semantics of an expression defined?<br></latex>	pg 9043 right<br>
Give intrinsic denotational semantics for the integer constant 0 and the binary operator +.<br><br> 	pg 9044 left<br>
Give intrinsic denotational semantics for<br>-conditional expressions <br>-variables<br>-abstractions<br>-applications<br><br>	pg 9044<br>
Give intrinsic denotation semantics for<br>-product introduction<br>-product elimination<br>-sum introduction<br>-sum elimination<br>	pg 9044, bottom left<br>
Give intrinsic denotational semantics for recursive terms <b>rec</b> e.<br> 	pg 9044, right page<br>
What does the term <i>coherence</i> mean, regarding intrinsic denotational semantics for typed languages? Why is it important?<br>	pg 9045, top left<br><br>
<latex>~\\<br>How are the following terms interpreted in Reynolds' intrinsic denotational semantics?\\<br>$\mbf{rec}~(\lambda f.~f)$\\<br>$\lambda x.~(\mbf{rec}~(\lambda f.~f)~x)$\\<br>Why might this pose a problem for \emph{soundness}, as defined on page 8900, right page?<br></latex>	pg 9045, left, bottom half<br><br>
<latex>~\\<br>There exists a value in $\mbf{B}_{\bot} \to \mbf{B}_{\bot} \to \mbf{B}_{\bot}$, called<br>\emph{parallel or}, which is not the meaning of any closed expression in any of Reynolds' languages.<br>Give the definition of parallel or, and explain why it does not serve as the denotation of some term in any of Reynolds' semantics.<br></latex>	pg 9045, top right<br><br>
<latex>~\\<br>Let $\mathcal C$ and $\mathcal D$ be fixed categories with finite products, and let M be any model of a fixed algebraic thoery \emph{Th} in $\mathcal C$. How is the family of \emph{modelling} functors<br>$Ap_M$ defined? <br></latex>	pg 4180, top right
<br>An algebraic theory freely generates a __________.<br><br>	classifying category<br>pg 4180, right, discussion 3.8.1.<br>
<latex>~\\<br>Let \emph{Th} be an algebraic theory.<br>What does it mean for a category \emph{Cl(Th)} with finite products to be the \emph{classifying} category of \emph{Th}? <br></latex>	pg 4180, bottom right<br>
What does it mean for a model of a theory to be <i>generic</i>?	pg 4180, bottom right<br>
<br>A model of a theory is kind of like a "heterogeneous functor" from a ________ to a __________.<br>A model homomorphism is therefore like a _________.<br>	Theory, category, natural transformation.<br>This isn't in the book, but I find the analogy important.<br>The relevant material is on pg 4180 left<br>
<latex>~\\<br>Let \emph{Th} be an algebraic theory and \emph{Cl(Th)} a category with finite products for which there is a model $\mbf{G}$ of \emph{Th} in \emph{Cl(Th)}. Suppose that given any category $\mathcal D$ with finite products there is an equivalence <br>$$Ap_{\mbf{G}} : \mathcal{FP}(Cl(Th),D) \to \mathcal{M}od(Th,\mathcal{D})$$<br>Consider the following statement:\\~\\<br>Whenever \emph{Cl(Th)'} and $\mathbf{G}'$ also have the above property, there is an equivalence $Eq : Cl(Th) \simeq Cl(Th)'$ for which $Eq_{\ast} \mbf{G} \cong \mbf{G}'$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 4180, bottom right. pg 4181, top left.<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>For any model M of an algebraic theory \emph{Th} in a category $\mathcal D$ with finite products, there is a functor $F : Cl(Th) \to \mathcal D$ which preserves finite products, for which the composition of the semantics of \emph{Th} given by the generic model $\mbf{G}$ in \emph{Cl(Th)} with the functor $F$ yields the semantics given to \emph{Th} by the model $\mbf{M}$, up to isomorphism.\\~\\<br>Prove or disprove.<br></latex>	pg 4181, left, corollary 3.8.3<br>todo: add impostor?<br><br>
Why is <i>Cl(Th)</i> considered the "smallest" category with finite products in which there is a model of <i>Th</i>. Draw a diagram.<br>	pg 3181, left, near bottom<br>
<latex>~\\<br>Explain the category $\mathcal{FSMR}$ of finite sets and multirelations. Does it have finite products?<br></latex><br>	pg 4181, top right<br><br>
Consider the algebraic theory of commutative monoids described on pg 4178 left.<br>Give a classifying category for this theory, along with its generic model.<br>	pg 4181 right
What are the operands of relational algebra?	Either constant relations or variables denoting relations of a fixed arity.<br>pg 72, near bottom above numbered points<br><br>
There are five basic operations that serve to define relational algebra. List them here.<br>	union, set difference, cartesian product, projection, selection<br>pg 72 bottom, pg 73<br><br>
Explain the relational union operator.	pg 72<br>
Explain the relational "set difference" operator.	pg 72 bottom / 73
Explain the cartesian product operator of relational algebra.<br>	pg 73, 3.<br><br>
Explain the projection operator of relational algebra.	pg 73 4.)<br>
Explain the selection operator of relational algebra.	pg 73. 5)<br>
<latex>~\\<br>Examine the relations in figure 2.9 at the bottom of page 73.<br>Give $R \cup S$, $R - S$, $R \times S$, $\pi_{A,C} R$, and $\sigma_{B=b}(R)$.<br></latex>	pg 74, example 2.15<br><br>
<latex>~\\<br>If $R$ and $S$ are relations, what does $R \underset{i \theta j}{\bowtie} S$ denote?<br></latex>	pg 76, text under "join"<br>
What is an <i>equijoin</i>?	pg 76, text under "Join"
<latex>~\\<br>If $R$ and $S$ are relations with named attributes, what does $R \bowtie S$ denote?<br></latex>	the natural join, pg 77 bottom<br>
<latex>~\\<br>If $R$ and $S$ are relations with named attributes, what is the \emph{semijoin} of $R$ and $S$?<br></latex>	pg 77, near bottom<br>
<latex>~\\<br>Give some algebraic properties of the natural join operator $\bowtie$, and intuitively justify them.<br></latex><br>	pg 79, thm 2.2<br>
What is a universal construction, and why are universal constructions significant?	pg 9540<br>
What logical proposition does the categorical construct of a terminal object correspond to?	constant truth<br>pg 9542<br>
Consider the following statement:<br>When they exist, products of objects are unique up to a unique projection-preserving isomorphism.<br>Prove or disprove.	true. pg 9546<br>
Give a brief summary of the Yoneda prinicple. It is a generalization of a statement pertaining to a preorded set: which one?	pg 9567, near bottom
<latex>~\\<br>Let $F_1, F_2 : \mathbb A \pile{\rTo \\ \rTo} \mathbb{B}$.<br>Let $G_1, G_2 : \mathbb B \pile{\rTo \\ \rTo} \mathbb{C}$.<br>Let $\alpha : F_1 \to F_2$, $\beta : G_1 \to G_2$.<br>How is the parallel composition $\alpha \cdot \cdot \beta$ defined?<br></latex>	pg 9573<br>
<latex>~\\<br>Let $F_1, F_2 : \mathbb A \pile{\rTo \\ \rTo} \mathbb{B}$.<br>Let $G_1, G_2 : \mathbb B \pile{\rTo \\ \rTo} \mathbb{C}$.<br>Let $\alpha : F_1 \to F_2$, $\beta : G_1 \to G_2$.<br>Consider the following statement:\\~\\<br>$G_1(\alpha(A)) \cdot \beta(F_2(A)) = \beta(F_1(A)) \cdot G_2(\alpha(A))$\\~\\<br>Prove or disprove.<br></latex>	true. pg 9573.<br>todo: add impostor?<br>
<latex>~\\<br>Let $F_1, F_2 : \mathbb A \pile{\rTo \\ \rTo} \mathbb{B}$.<br>Let $G_1, G_2 : \mathbb B \pile{\rTo \\ \rTo} \mathbb{C}$.<br>Let $\alpha : F_1 \to F_2$, $\beta : G_1 \to G_2$.<br>Consider the following statement:\\~\\<br>$\alpha \cdot \cdot \beta$, defined as follows, is indeed a natural transformation.\\~\\<br>$(\alpha \cdot \cdot \beta)(A) = G_1(\alpha(A)) \cdot \beta(F_2(A)) = \beta(F_1(A)) \cdot G_2(\alpha(A))$\\~\\<br>Prove or disprove.<br></latex>	cube diagram on pg 9574<br>
Give the definition of a 2-category.	pg 9575
Give an example of a 2-category.<br>	The category Cat of small categories, functors between them, and natural transformations between the functors.<br><br>pg 9575<br>
2-categories satisfy an <i>interchange law</i>. Give the interchange law.<br>	pg 9575<br>
<latex>~\\<br>Let $F, G, H : \mathbb A \pile{\rTo \\ \rTo} \mathbb{B}$.<br>Let $I, J, K : \mathbb B \pile{\rTo \\ \rTo} \mathbb{C}$.<br>Let $\alpha : F \to G$, $\beta : G \to H$, $\gamma : I \to J$, $\delta : J \to K$.<br>\\~\\<br>Draw a string diagram representing the interchange law $(\alpha \cdot \beta) \cdot \cdot (\gamma \cdot \delta) = (\alpha \cdot \cdot \gamma) \cdot (\beta \cdot \cdot \delta)$<br></latex>	pg 9575<br>
Examine diagram 4.1 at the top of pg 9574.<br>Draw a string diagram depicting this situation.	pg 9576, bottom
Explain the concept of "naturality as independence", possibly providing some sort of diagram depicting the concept.	pg 9576, bottom<br>
Do exercise 4.2.2.1, pg 9577<br>	<br>
There is a handy "trick" for transforming diagrams within a category into string diagrams using global elements.<br>Explain, and draw a string diagram to support the explanation.<br>	pg 9577 top<br>
Give the behavioral ("zig-zag") definition of an adjunction. Also draw string diagrams corresponding to this definition.<br>	pg 9577 bottom/9578 top<br>
Give the "natural bijection of hom-sets" definition of adjunctions.<br>	pg 9578, near bottom<br>
With respect to an adjunction $F \dashv G$, what is an adjoint complement?	pg 9578, bottom<br>
What does it mean for a bijection of hom sets to be <i>natural</i>?<br>	pg 9579, near top<br><br>
Explain how the categorical nature of propositional implication relates to its local soundness/reduction.<br>	the important part is the bottom half of the adjunction, its equation, and the structure of the local reduction.<br>pg 9582<br>
What is the categorical concept corresponding to eta expansion?<br>	it is "identity expansion", the equation given on the bottom of pg 9582. see also top of pg 9583<br><br>
Do exercise 3.4.1.5 on pg 9564<br>(yes, this is not part of chapter 4, but it's interesting)<br>	pg 9564<br>
<latex>~\\<br>How is the diagonal functor $\Delta : \mathbb C \to \mathbb C \times \mathbb C$ defined?<br>Does it have a right adjoint?<br></latex>	pg 9584, bottom<br>pg 9585, top<br>
The universal property of the products is just the universal property of ___________.<br>	The counit of the adjunction between Delta and - x -.<br>pg 9585, center<br>
<latex>~\\<br>By connective harmony, negatively presented propositional connectives ($\supset$, $\wedge$, $\top$) have the property that there is an adjunction $F \dashv G$ such that:\\~\\<br>\begin{itemize}<br>\item their introduction rule is interpreted by \underline{~~~~~~~~~~~~~~~~~~~}<br>\item their elimination rule is interpreted by \underline{~~~~~~~~~~~~~~~~~}<br>\item their local reduction is interpreted by \underline{~~~~~~~~~~~~~~~~~~~}<br>\item their local expansion is interpreted by \underline{~~~~~~~~~~~~~~~~~~~~}<br>\end{itemize} <br></latex>	pg 9583 near bottom<br><br>for the last one, the lemma statement at the bottom of pg 9561 <br>and its proof at the top of pg 9562 are extremely helpful.<br>
<latex>~\\<br>Explain the $\wedge$ propositional connective through the lens of connective harmony.<br></latex>	pg 9585<br>
<latex>~\\<br>Modulo \emph{context distributivity}, for positively-presented propositional connectives ($\vee$ and $\bot$),<br>there is an adjunction $F \dashv G$ such that:\\~\\<br>\begin{itemize}<br>\item their introduction rule is interpreted by \underline{~~~~~~~~~~~~~~~~~}<br>\item their elimination rule is interpreted by \underline{~~~~~~~~~~~~~~~~}<br>\item their local reduction is interpreted by \underline{~~~~~~~~~~~~~~~~~~~~~}<br>\item their identity local expansion is interpreted by \underline{~~~~~~~~~~~~~~~~~~~~}<br>\end{itemize} <br></latex>	pg 9584<br>
Explain coproducts through the lens of connective harmony.	pg 9586, near bottom<br>
A cartesian closed category is not restricted enough to interpret the elimination rule for propositional disjunction. What extra restriction is needed, and why?<br>	<br>setup is on bottom of pg 9559<br>explanation is on top of pg 9560<br><br>the full rule, as opposed to the preliminary rule, as a background context Gamma<br>the key is that the background context (Gamma is identified with X) is used in each case of the eliminator<br>
Explain the truth propositional connective (i.e. nullary product) T through the lens of connective harmony.<br>	pg 9588<br>
What is a presheaf?	pg 9592/9593
What does it mean for a presheaf to be <i>representable</i>?	pg 9592/9593
What is an <i>indexed category</i>? What is a <i>fiber</i>? What is a <i>reindexing functor</i>?<br>What is an <i>indexed bicartesian closed category</i>?	pg 9593, def 5.1.3.1<br>
When interpreting predicate logic categorically, terms are interpreted over some cartesian closed category, and predicates are interpreted over ________.	some indexed category over a base category interpreteing typing contexts and terms.<br>pg 9596<br>
Give the subtyping rules for intersection types.	pg 9053, bottom left<br>
<latex>~\\<br>Give the subtyping rule for distributivity of intersection and $\to$.<br></latex><br>	pg 9054, left<br><br>
<latex>~\\<br>Give a subtyping rule which demonstrates how intersection types relate to named product types.<br></latex><br>	pg 9054, left "Named Products as Intersections"<br><br>
Give the "distributivity of intersection and named products" subtyping rule.<br>	pg 9054, left<br><br>
Give Reynolds' "Distributivity of intersection and named sums" subtyping rule.	pg 9054<br>
Explain Reynolds' "nonsense type" <b>ns</b>. What are its typing and subtyping rules?<br>	pg 9054 right<br>
Discuss the pros and cons of including a "nonsense type" in a language.	pg 9054, bottom right quadrant<br>
State the "conservation of typing judgments" property that Reynolds' system with typing judgments has.<br>	pg 9054, bottom right<br>pg 9055, top left<br><br>
What basic changes are used to update the extrinsic semantic domains to account for subtyping and intersection types?	pg 9055, bottom left / top right<br>
Give the semantic equations for named tuple introduction and elimination, in Reynolds' type system with subtyping and intersection types.	pg 9055, right<br><br>
Give the semantic equations for the introduction and elimination of named alternatives.	pg 9055, bottom right<br>
For Reynolds' type system with subtyping and intersection types, give PER definitions<br>for named product types, intersection, and nonsense (<b>ns</b>) types.<br> 	pg 9056, left<br><br>
<latex>~\\<br>Look at the semantics given on pg 9056, top left. Consider the following theorem:\\~\\<br>For all types $\theta$, $\mathcal P(\theta)$ is a partial equivalence relation.\\~\\<br>Prove or disprove.<br></latex>	true. see text below semantics on pg 9056<br>
<latex>~\\<br>Look at the semantics given on pg 9056, top left. Consider the following theorem:\\~\\<br>For all types $\theta$, $\mathcal P(\theta)$ is a "chain-complete" relation, that is, for all chains <br>$x_0 \sqsubseteq x_1 \sqsubseteq \cdots$ and $x'_0 \sqsubseteq x'_1 \sqsubseteq \cdots$ <br>of members of $V_{\ast}$:<br>$$ If \langle x_i, x'_i \rangle \in \mathcal P(\theta) \text{ for all } i \geq 0, \text{ then } <br>\langle \bigsqcup_{i=0}^{\infty} x_i, \bigsqcup_{i=0}^{\infty} x_i \rangle \in \mathcal P(\theta)$$<br>Prove or disprove.<br></latex>	true. see text below semantics on pg 9056<br>
<latex>~\\<br>Look at the semantics given on pg 9056, top left. Consider the following theorem:\\~\\<br>For all types $\theta$, $\bot \in dom(\mathcal P(\theta))$, but tyerr $\not \in dom(\mathcal P(\theta))$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. see text below semantics on pg 9056 (this theorem statement was taken from pg 9040)<br>
Recall that a boolean algebra is a bounded distributive lattice. In what way can a boolean algebra be viewed as an algebra of "propositions"? Under this interpretation, what is the order-theoretic analog of a "theory"?<br>	pg 7442, example (5) at bottom<br>
Exercise O-2.9, pg 7443<br>	<br>
Exercise O-2.10, pg 7443<br>	<br>
Exercise O-2.11, pg 7444<br>	<br>
Exercise O-2.12, pg 7444<br>	<br>
Exercise O-2.13, pg 7444<br>	<br>
Exercise O-2.14, pg 7445<br>	<br>
Exercise O-2.15, pg 7445<br>	<br>
Exercise O-2.16, pg 7445<br>	<br>
Exercise O-2.17, pg 7445<br>note that this exercise refers to example 5 at the bottom of pg 7442<br>	<br>
Exercise O-2.19, pg 7446<br>refers to example (10) on pg 7441<br>	<br>
Exercise O-2.20, pg 7446	<br>
Exercise O-2.21, (i) and (ii), pg 7446	<br>
Exercise O-2.21, (iii) and (iv), pg 7446/7447	<br>
Exercise O-2.22, pg 7447<br>	<br>
Let S and T be posets. What is a <i>Galois connection</i> between S and T?	pg 7448, def O-3.1<br>
How do we remember intuitively which component of a Galois connection is an <i>upper</i> adjoint and which component is a <i>lower adjoint</i>?	pg 7449, top of page.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Let $g : S \to T$ and $d : T \to S$ be functions between posets. Then the following conditions are equivalent:<br>\begin{enumerate}<br>\item $(g,d)$ is a Galois connection;<br>\item g is monotone and $d(t) = min~g^{-1}(\uparrow t)$ for all $t \in T$;<br>\item d is monotone and $g(s) = max~d^{-1}(\downarrow s)$ for all $s \in S$<br>\end{enumerate}  <br>Prove or disprove.<br></latex>	true. pg 7449, theorem O-3.2<br>todo: add impostor?
Consider the following statement:<br><br>Any upper adjoint preserves infs, any lower adjoint, sups.<br><br>Prove or disprove.	true. pg 7450, thm 0-3.3<br>todo: add impostor?
<latex>~\\<br>What does it mean for a function $g : S \to T$ to be \emph{cofinal}?<br></latex>	pg 7450, text above thm 0-3.4<br>
Consider the following statement:<br>If g has a lower adjoint, then it is cofinal.<br>Prove or disprove.	true. see text above thm 0-3.4 on pg 7450.
Consider the following statement:<br>If g has an upper adjoint, then it is cofinal.<br>Prove or disprove.	IMPOSTOR. see text above thm 0.3-4 on pg 7450.<br>
<latex>~\\<br>Let $g : S \to T$ be a function between posets. Assume that the following hypotheses are satisfied:<br>\begin{itemize}<br>\item $S$ is a complete lattice, or $S$ is a complete semilattice and $g$ is cofinal, and<br>\item $g$ preserves all existing infs <br>\end{itemize}<br>Then consider the following statement: $g$ has a lower adjoint $d : T \to S$ given by either of the two formulae<br>\begin{enumerate}<br>\item $d(t) = inf~g^{-1}(\uparrow t)$<br>\item $d(t) = min~g^{-1}(\uparrow t)$<br>\end{enumerate}<br>Prove or disprove.<br></latex>	true. pg 7450, thm O-3.4, near bottom.<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Let $g : S \to T$ be a function between posets of which $S$ is a complete lattice. Then $g$ preserves infs iff $g$ is monotone and has a lower adjoint.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7451, corollary O-3.5<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Let $d : T \to S$ be a function between posets of which $T$ is a complete lattice. Then $d$ preserves sups iff $d$ is monotone and has an upper adjoint.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7451. might also want to cross-reference this with Awodey's section on adjunctions.<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement. For every pair of order preserving functions between posets, $g : S \to T$ and $d : T \to S$, the following conditions are equivalent:\\~\\<br>(1) $(g,d)$ is an adjunction\\<br>(2) $gd \leq 1_S$ and $1_T \leq gd$\\~\\<br>Moreover, these conditions imply\\~\\<br>(3) $d = dgd$ and $g = gdg$\\<br>(4) $gd$ and $dg$ are idempotent\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 7451, thm O-3.6<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement. For an adjunction $(g,d)$ between posets $S$ and $T$, the following conditions are equivalent:\\~\\<br>(1) $g$ is surjective;\\<br>(2) $d(t) = min~g^{-1}(t)$ for all $t \in T$;\\<br>(3) $gd = 1_T$;\\<br>(4) $d$ is injective\\~\\<br>Likewise, the following statements are equivalent:\\~\\<br>(1*) $g$ is injective;\\<br>(2*) $g(s) = max~d^{-1}(s)$ for all $s \in S$;\\<br>(3*) $dg = 1_S$;\\<br>(4*) $d$ is surjective\\~\\<br>Prove or disprove.<br></latex>	true. pg 7452, prop O-3.7<br>todo: add impostor?<br>
What is a <i>projection operator</i> on a poset? What is a <i>closure operator</i> on a poset?<br>What is a <i>kernel operator</i> on a poset?	pg 7452, def O-3.8, near bottom<br><br><br>
<latex>\\~\\<br>Let $f : A \to B$ be any function. What does $f^{\circ}$ denote? What about $f_{\circ}$?<br></latex>	pg 7453, notation O-3.9.<br>(seems similar, if not exactly the same, as Zeilberger's pushforwards and pullbacks in his OPLSS lecture notes on refinement types)<br>
<latex>~\\<br>Let $L$ be a poset and $f : L \to L$ an order preserving self-map of $L$. Consider the following statement:<br>the below conditions are equivalent.<br>\begin{enumerate}<br>\item $f$ is a projection operator,<br>\item $f^{\circ}$ is a retraction of $L$ onto $f(L)$ with $f_{\circ} : f(L) \to L$ as co-retraction<br>  (that is, $f^{\circ} f_{\circ} = 1_{f(L)}$)<br>\item there is a poset $T$ and a monotone surjection $q : L \to T$ and a monotone injection<br>  $i : T \to L$ such that $f = iq$ and $1_T = qi$.<br>\end{enumerate}<br>Prove or disprove.<br></latex>	true. pg 7453, prop O-3.10<br>todo: add impostor?<br>
<latex>~\\<br>Let $L$ be a poset and $f : L \to L$ an order preserving self-map of $L$. Consider the following statement:<br>the below conditions are equivalent.<br>\begin{enumerate}<br>\item $f$ is a closure operator,<br>\item ($f_{\circ}$, $f^{\circ}$) is an adjunction between $f(L)$ and $L$,<br>\item there is an adjunction $(g,d)$ between some $S$ and $L$ where $f = gd$<br>\end{enumerate}<br>Prove or disprove.<br></latex>	true. prop O-3.10, pg 7453<br>todo: add impostor?<br>
<latex>~\\<br>Let $p$ be a projection on a poset $L$. We set <br>$$L_c = \{ x \in L \mid x \leq p(x) \} \text{ and } L_k = \{ x \in L \mid p(x) \leq x \}$$<br>Consider the following statement:\\~\\<br>$p$ maps $L_c$ and $L_k$ into themselves and if $p_c : L_c \to L_c$ and $p_k : L_k \to L_k$<br>are the two restrictions of $p$, then $p_c$ is a closure operator and $p_k$ is a kernel operator with<br>$$ im~p_c = im~p_k = im~p = L_c \cap L_k $$ <br>Prove or disprove.<br></latex>	true. pg 7454, lemma O-3.11.<br>todo: add impostor?<br>
<latex>~\\<br>Let $p$ be a projection on a poset $L$. We set <br>$$L_c = \{ x \in L \mid x \leq p(x) \} \text{ and } L_k = \{ x \in L \mid p(x) \leq x \}$$<br>Consider the following statement:\\~\\<br>$L_c$ is closed under all existing sups and $L_k$ under all existing infs.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7454, lemma O-3.11.<br>todo: add impostor?<br>
<latex>~\\<br>Let $p$ be a projection on a poset $L$. We set <br>$$L_c = \{ x \in L \mid x \leq p(x) \} \text{ and } L_k = \{ x \in L \mid p(x) \leq x \}$$<br>Consider the following statement:\\~\\<br>if $p$ preserves (filtered) infs, then $L_c$ and $im~p$ are closed under existing (filtered) infs; analogously, if $p$ preserves (directed) sups, then $L_k$ and $im~p$ are closed under existing (directed) sups.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7454, lemma O-3.11<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The image of a closure operator is closed under the formation of infs, and that of a kernel operator is closed under the formation of sups (to the extent they exist).\\~\\<br>Prove or disprove.<br></latex>	true. pg 7454, prop O-3.12.<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The co-restriction $c^{\circ} : L \to c(L)$ of a closure operator preserves arbitrary sups; hence, $sup_{c(L)}~X = c(sup_{L}~X)$ for $X \subseteq c(L)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7455, top, (ii).<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The co-restriction $k^{\circ} : L \to k(L)$ of a kernel operator preserves arbitrary infs; hence, $inf_{k(L)}~X = k(inf_{L}~X)$ for $X \subseteq k(X)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7455, top (iii)<br>todo: add impostor?<br>
One useful way to think of closures is through the lens of a <i>closure system</i>.<br>What is a closure system?<br>	pg 7455, above prop O-3.13<br>
<latex>\\~\\<br>Consider the following statement.\\~\\<br>The function which assigns to a closure operator $c$ on a poset $L$ its image $c(L)$ is an order isomorphism from the set of closure operator (under the pointwise order) onto $\mathcal C(L)^{op}$. Its inverse function $S \mapsto c_S$ associates with a closure system $S \in \mathcal C(L)$ the upper adjoint of the inclusion $S \to L$ followed by the inclusion $S \to L$ itself.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7455, prop O-3.13<br>
What is a <i>morphism of refinement systems</i>? What judgment rules and equational axioms does the existence of such a morphism imply?<br>	pg 8795, def 3.2.40<br>read the whole page<br><br>
<latex>~\\<br>Let $r$ and $p$ be refinement systems, and let $F : r \to p$ be a morphism of refinement systems.<br>If $r$ is an opfibration, does that imply that $p$ is an opfibration? Why or why not?<br></latex>	No. See bottom of<br>pg 8795<br>
What is an <i>adjunction of refinement systems</i>?<br>	pg 8795, near bottom<br>pg 8796, near top<br>
<latex>~\\<br>Consider the following statement.\\~\\<br>If $F \dashv G : p \to r$ is an adjunction of refinement systems, then $F$ preserves pushforwards and finite unions, while $G$ preserves pullbacks and finite intersections.\\~\\<br>True or false (no need to prove).<br></latex>	true.pg 8796, prop 3.2.41<br><br>
<latex>~\\<br>Consider the following statement.\\~\\<br>If $F \dashv G : p \to r$ is an adjunction of refinement systems, then $F$ preserves pullbacks and finite intersections, while $G$ preserves pushforwards and finite unions.\\~\\<br>True or false (no need to prove).<br></latex>	pg 8796<br>
Explain how we can use a morphism of refinement systems to provide a "model" for a Hoare refinement system, in two ways:<br><br>1. A model with a deterministic semantics<br>2. A model with a non-deterministic semantics	pg 8796, middle to bottom<br>
In a complete lattice L, closure systems S can be characterized very simply. Explain how.<br>	pg 7455, Remark near bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The correspondence $c \mapsto c(L)$ between closure operators and closure systems on $L$ maps the set of closure operators preserving directed sups bijectively onto the set of those closure systems which are closed under directed sups.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7455, corollary O-3.14 at bottom.<br>todo: add impostor?<br>
<latex>~\\<br>Let $L$ be a $\mbf{dcpo}$. Consider the following statement:\\~\\<br>the map $I \mapsto sup~I : Id~L \to L$ is a lower adjoint of the principal ideal map $x \mapsto \downarrow x : L \to Id~L$; in particular, it preserves sups.\\~\\<br>Prove or disprove.<br></latex> 	true. pg 7456, prop O-3.15 (i)<br>todo: add impostor?<br>
<latex>~\\<br>Let $L$ be a $\mbf{dcpo}$. Consider the following statement:\\~\\<br>the map $I \mapsto~\downarrow{sup~I} : Id~L \to Id~L$ is a closure operator whose image is isomorphic to $L$.<br>Prove or disprove.<br></latex> 	true. pg 7456, prop O-3.15 (ii)<br>todo: add impostor?<br>
<latex><br>Consider the following statement:\\~\\<br>In a semilattice $S$ the following two conditions are equivalent:<br>\begin{enumerate}<br>\item for all $x \in S$, the function $s \mapsto x \wedge s : S \to S$ has an upper adjoint;<br>\item $max \{s \in S \mid (x \wedge s) \leq t \}$ exists for all $x, t \in S$<br>\end{enumerate}<br>Prove or disprove<br></latex>	true. pg 7456, lemma O-3.16.<br>todo: add impostor?<br><br><br>
What is a <i>Heyting algebra</i>?	pg 7456, definition O-3.17 at bottom<br>read top of pg 7457 as well<br><br>
Some Heyting algebras have an operation called <i>negation</i>. What is negation?	pg 7457, near top<br>
<latex>~\\<br>Let $L^1$ denote the poset obtained from an arbitrary poset $L$ by adjoining a new "virtual" top element $1$ and, for an order preserving map $g : L \to M$, let $g^1 : L^1 \to M^1$ denote the "virtual" extension of $g$ with $g(1) = 1$. Consider the following statement:\\~\\<br>For an order preserving map $g : L \to M$, the following conditions are equivalent.\\<br>(1) the corestriction $g^{\circ} : L \to \downset g(L)$ has a lower adjoint.\\<br>(2) the "virtual" extension $g^1 : L^1 \to M^1$ has a lower adjoint.\\~\\<br>Prove or disprove.<br></latex>	true. pg 7457. todo: add impostor?<br><br>
Exercise O-3.19, pg 7457, bottom<br><br>	<br>
Exercise O-3.20, pg 7458<br>	<br>
Exercise O-3.21, pg 7458<br>	<br>
Exercise O-3.22, pg 7459<br>	<br>
Exercise O-3.23, pg 7459<br>	<br>
<latex>~\\<br>What does it mean for a map $f : L \to M$ between frames to be a \emph{homomorphism of frames}?<br></latex>	pg 7460, def O-3.24<br><br>
<latex>~\\<br>What does it mean for a subset $L$ of a frame $M$ to to be a \emph{subalgebra}?<br></latex>	pg 7460, def O-3.24<br><br>
Exercise O-3.25, pg 7460<br>	<br>
Exercise O-3.26, pg 7460<br>	<br>
Exercise O-3.27, pg 7460<br>	<br>
Exercise O-3.28, pg 7460<br>	<br>
Exercise O-3.29, pg 7461<br>	<br>
If $x$ and $s$ are two elements of a semilattice $S$, what does $x s$ mean?	answer: it means $x \wedge s$.<br>pg 7462, intro section<br><br>
<latex>~\\<br>What does it mean for a semilattice $L$ to be \emph{meet continuous}?<br></latex><br>	pg 7462, def O-4.1<br>
<latex>~\\<br>Let $L$ be a lattice. Consider the following statement:\\~\\<br>The following conditions are equivalent:\\~\\<br>(1) $L$ is a frame;\\<br>(2) $L$ is a meet continuous and distributive\\~\\<br>Prove or disprove.<br></latex>	true. pg 7464. todo: add impostor?<br><br>
<latex>~\\<br>Let $L$ be a directed complete semilattice. Consider the following statement:\\~\\<br>The following two conditions are equivalent.\\~\\<br>(1) the sup map for ideals $I \mapsto sup~I : Id~l \to L$ is a homomorphism of meet semilattices\\<br>(2) for two ideals $I_1$ and $I_2$ we have (sup I_1) (sup I_2) = sup (I_1 I_2)\\~\\<br>Prove or disprove.<br></latex>	true. pg 7463, thm O-4.2<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a directed complete semilattice, the following two conditions are equivalent.\\~\\<br>(1) for two ideals $I_1$ and $I_2$ we have $(sup~I_1)~(sup~I_2) = sup~(I_1~I_2)$\\<br>(2) for two directed sets $D_1$, $D_2$ we have $(sup~D_1) (sup~D_2) = sup~(D_1~D_2)$\\~\\<br>Prove or disprove.<br></latex>	true, pg 7462, thm O-4.2<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a directed complete semilattice, (1) implies (2):\\~\\<br>(1) For each directed set $D$ and each $x \leq sup~D$ we have $x \leq sup~x~D$ (hence, $x = sup~x~d)$\\<br>(2) the inf operation $(x, y) \mapsto x y : L \times L \to L$ preserves directed sups \\~\\<br>Prove or disprove.<br></latex>	true. pg 7463, theorem O-4.2 (5 implies 6)<br>todo: add impostor?<br>
Carefully read over Theorem O-4.2 at pg 7462 bottom / pg 7463 top<br>	<br>
State and prove the "greatest fixed point theorem" for monotone operators. (hint: you may need some lemmas)<br>	pg 3444, thm 15.3<br><br>
<latex>~\\<br>Let $\Gamma$ be monotone and let $\Gamma^* = \bicup \{ a \mid \text{a is } \Gamma\text{-correct} \}$.<br>Consider the following statement:\\~\\<br>Let $a \subseteq \Gamma^*$. Then there is some $\Gamma$-correct set $b$ such that $a \subseteq b$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3444, lemma 15.4 (1)<br>todo: add impostor?<br>
<latex>~\\<br>Let $\Gamma$ be monotone and let $\Gamma^* = \bicup \{ a \mid \text{a is } \Gamma\text{-correct} \}$.<br>Consider the following statement:\\~\\<br>Let $a \subseteq G$ where $G$ is $\Gamma$-correct. Then there is some set $b \subseteq G$ such that $a \subseteq \Gamma(b)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3444, lemma 15.4 (2)<br>todo: add impostor?<br>
Exercise 15.5, pg 3445<br>	<br>
Exercise 15.6, pg 3445<br>(operators list on pg 3440)<br><br>	<br>
<latex><br>Let $\Gamma$ be a monotone operator. State and prove the coinduction principal for $\Gamma^*$.<br></latex><br>	pg 3446, near top<br>
Relate the induction principle discussed in this chapter to the induction principle on natural numbers.	pg 3446<br>
Exercise 15.7, pg 3446<br>	<br>
Exercise 15.8, pg 3447<br>	<br>
Exercise 15.9, pg 3447<br>	<br>
Exercise 15.10, pg 3447<br>	<br>
Exercise 15.11, pg 3447<br>	<br>
<latex>~\\<br>If $\Gamma$ is a montone class operator, then what the definition of the \emph{dual}<br>$\hat{\Gamma}$ of $\Gamma$?<br></latex>	pg 3447 (duals of operators)<br><br>
Exercise 15.12, pg 3447<br>	<br>
Exercise 15.13, pg 3447<br>	<br>
<latex>~\\<br>Explain how the "Flat Solution Lemma" formulation of the AFA can be viewed as a way of formulating <br>$V_{afa}[X \cup A]$ as a greatest fixpoint.<br></latex>	pg 3452, example 16.1<br>
Exercise 16.1, pg 3452<br>	solution on pg 3592<br>
Exercise 16.2, pg 3452<br>	<br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator.<br>What is the (idosyncratic Barwise and Moss) definition of $\Gamma$-\emph{coalgebra}?<br></latex>	pg 3454, near bottom<br><br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator. What does it mean for a set $X \subseteq \mathcal U$ to be<br>\emph{new for} $\Gamma$?<br></latex><br> 	pg 3455, definition near top. Make sure to also read example 16.3 right below it.<br><br><br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator. What is a \emph{flat} $\Gamma$-\emph{coalgebra}?<br></latex>	pg 3455, near bottom. note that central to this definition is the notion of a set being <i>new for</i> a monotone operator, which is defined at the top of the page.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Define the monotone operator $\Gamma$ as $\Gamma(a) = a \rightharpoonup a$, i.e. it maps a set $a$ to the set of partial functions from $a$ to $a$.<br>Then any set of urelements $X \subseteq \mathcal U$ is new for $\Gamma$.\\~\\<br>Prove or disprove.<br></latex><br>	IMPOSTOR<br>pg 3455, example 16.3<br><br>
Exercise 16.2, pg 3455<br>	<br>
<latex>~\\<br>Letting $\mathcal P$ be the powerset class operator, what is a \emph{flat} $\mathcal P$\emph{-coalgebra}? <br></latex>	<latex>~\\<br>pg 3456, top\\<br>this is an instance of the notion of a \emph{flat $\Gamma$-coalgebra} defined at the bottom of pg 3455<br></latex><br>
<latex>~\\<br>Let $r$ be any substitution, and let $b$ be any set. What does $[r]_b$ denote?<br></latex>	pg 3456 - the restriction of r to b.<br><br>
Read the interesting an nuanced discussion of morphisms that starts on pg 3456 and spills onto pg 3457.<br><br>	pg 3456
<latex>~\\<br>Let $\Gamma$ be a monotone operator, let $\mathcal E = \langle a, e \rangle$ and $\mathcal E' = \langle b, e \rangle$ be $\Gamma$-coalgebras.\\~\\<br>What is a \emph{$\Gamma$-morphism} from $\mathcal E$ into $\mathcal E'$?<br></latex>	pg 3457, definition<br>
<latex>~\\<br>Let $\Gamma$ be a monotone operator, let $\mathcal E = \langle a, e \rangle$ and $\mathcal E' = \langle b, e \rangle$ be $\Gamma$-coalgebras.\\~\\<br>What is a \emph{reorganization of $\mathcal E_1$ onto $\mathcal E_2$}?<br></latex>	pg 3457, definition part (2)<br>
<latex>~\\<br>Let $A = \{ p, q \} \subseteq \mathcal U$, and let $\Gamma(c) = \mathcal P(c \cup A)$. Consider two flat $\Gamma$-coalgebras $\mathcal E$ and $\mathcal E'$ given by<br>\begin{multicols}{2}\\~\\<br>x = \{ p, y, z \} \\<br>y = \{ q, z\} \\<br>z = \{ p, x, y \}<br>\columnbreak \\~\\<br>v = \{ q, w \} \\<br>w = \{ p, v, w \}<br>\end{multicols}<br>Let $r$ be the substitution that maps $x$ and $z$ to $w$ and $y$ to $v$. Consider the following statement:\\~\\<br>$r$ is a reorganization of $\mathcal E$ onto $\mathcal E'$\\~\\<br>Prove or disprove.<br></latex>	true. pg 3457, near bottom<br>
<latex>~\\<br>Let $A = \{ p, q \} \subseteq \mathcal U$, and let $\Gamma(c) = \mathcal P(c \cup A)$. Consider two flat $\Gamma$-coalgebras $\mathcal E$ and $\mathcal E'$ given by<br>\begin{multicols}{2}\\~\\<br>x = \{ p, y, z \} \\<br>y = \{ q, z\} \\<br>z = \{ p, x, y \}<br>\columnbreak \\~\\<br>v = \{ q, w \} \\<br>w = \{ q, v, w \}<br>\end{multicols}<br>Let $r$ be the substitution that maps $x$ and $z$ to $w$ and $y$ to $v$. Consider the following statement:\\~\\<br>$r$ is a reorganization of $\mathcal E$ onto $\mathcal E'$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 3457, example 16.4 near bottom
Exercise 16.3, pg 3458 top	<br>
Exercise 16.4, pg 3458 top	<br>
<latex>~\\<br>What does it mean for an operator to be \emph{proper}? Why is the notion of a proper operator important?<br></latex><br>	pg 3458, see discussion directly above definition for clarification.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The identity operator $\Gamma(a) = a$ is proper.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 3458<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The powerset operator $\mathcal P$ is proper.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3458, text below definition of <i>proper</i> operator.<br>
Consider the following statement:<br><br>The proper operators are closed under composition.<br><br>Prove or disprove.<br>	pg 3458<br>
<latex>~\\<br>What does it mean for a $\Gamma$-coalgebra to be a \emph{canonical coalgebra}? Give an example of a canonical coalgebra.<br></latex>	pg 3458, second definition, near bottom<br>
<latex>~\\<br>Let $\Gamma$ be a monotone, proper operator, and let $\mathcal E = \langle X, e \rangle$ be a flat $\Gamma$-coalgebra. Let $s$ be a substitution. Consider the following statment:\\~\\<br>Examine the definition of the $\star$ operator on substitutions on page 3328. If we have<br>\begin{enumerate}<br>\item s is the solution to $\mathcal E$: $dom(s) = X$, and for all $x \in X$, $s_x = e_x[s]$.<br>\item $s \star e = s$<br>\end{enumerate}<br>then (1) $\Rightarrow$ (2)\\~\\<br>Prove or disprove.<br></latex>	pg 3458, near bottom<br>
<latex>~\\<br>Let $\Gamma$ be a monotone, proper operator, and let $\mathcal E = \langle X, e \rangle$ be a flat $\Gamma$-coalgebra. Let $s$ be a substitution. Consider the following statment:\\~\\<br>Examine the definition of the $\star$ operator on substitutions on page 3328. If we have<br>\begin{enumerate}<br>\item $s \star e = s$.<br>\item $dom(s) = X$, and $\mathcal E[s]$ is a canonical $\Gamma$-coalgebra<br>\end{enumerate}<br>then (1) $\Rightarrow$ (2)\\~\\<br>Prove or disprove.<br></latex>	true. pg 3458<br>todo: add impostor?<br>
<latex>~\\<br>Let $\Gamma$ be a monotone, proper operator, and let $\mathcal E = \langle X, e \rangle$ be a flat $\Gamma$-coalgebra. Let $s$ be a substitution. Consider the following statment:\\~\\<br>If we have<br>\begin{enumerate}<br>\item $dom(s) = X$, and $\mathcal E[s]$ is a canonical $\Gamma$-coalgebra<br>\item s reorganizes $\mathcal E$ onto some canonical $\Gamma$-coalgebra<br>\end{enumerate}<br>then (1) $\Rightarrow$ (2)\\~\\<br>Prove or disprove.<br></latex>	true. pg 3458, lemma 16.1<br>todo: add impostor?
<latex>~\\<br>Let $\Gamma$ be a monotone, proper operator, and let $\mathcal E = \langle X, e \rangle$ be a flat $\Gamma$-coalgebra. Let $s$ be a substitution. Consider the following statment:\\~\\<br>If we have<br>\begin{enumerate}<br>\item s reorganizes $\mathcal E$ onto some canonical $\Gamma$-coalgebra<br>\item s is a $\Gamma$-morphism of $\mathcal E$ into $\langle \Gamma^*, t \rangle$<br>\end{enumerate}<br>then (1) $\Rightarrow$ (2)\\~\\<br>Prove or disprove.<br></latex>	true. pg 3458, lemma 16.1<br>thm 15.3 on pg 3444
State and prove the Solution Lemma for Operators.<br>	pg 3460, prop 16.2<br>
<latex>~\\<br>Let $\Gamma$ be a proper operator, let $\mathcal E = \langle X, e \rangle$ and $\mathcal E' = \langle Y, e' \rangle$ be flat $\Gamma$-coalgebras, and let $r : \mathcal E \to \mathcal E'$ be a $\Gamma$-morphism with domain $X$. Let $s$ be the solution to $\mathcal E'$. Consider the following statement:\\~\\<br>$s \circ r$ is the solution to $\mathcal E$. Hence if $r$ is a reorganization, then $\mathcal E$ and $\mathcal E'$ have the same solution sets.\\~\\<br>Prove or disprove.<br></latex>	pg 3460, proposition 16.3
Exercise 16.5, pg 3460<br>	<br>
<latex>~\\<br>What does it mean for an operator $\Gamma$ to \emph{commute with almost all substitutions}?<br>What does it mean for a set $X_\Gamma$ of urelements to be an \emph{avoidance set for $\Gamma$}?<br>What does it mean for an operator $\Gamma$ to be \emph{uniform}?<br></latex>	pg 3461, definition.<br>
<latex>~\\<br>Consider the operators on page 3440. Which of these operators are uniform and which are not?<br></latex>	pg 3461, example 16.5<br>
<latex>~\\<br>Let $a$ be a set of sets. Consider the following statement:\\~\\<br>The constant operation $\Gamma(b) = a$ is uniform.\\~\\<br>Prove or disprove.<br></latex>	pg 3461, prop 16.4 bottom of page<br><br>
<latex>~\\<br>Let $a$ be a set of sets. Consider the following statement:\\~\\<br>If $\Gamma$ is monotone and commutes with almost all substitutions and $\Delta$ is uniform,<br>then $\Delta \circ \Gamma$ is uniform. So if $\Gamma$ and $\Delta$ are both uniform operators,<br>then so is $\Delta \circ \Gamma$.\\~\\<br>Prove or disprove.<br></latex>	pg 3461, prop 16.4, bottom of page 
<latex>\\~\\<br>Consider the following statement:\\~\\<br>If $\Gamma$ and $\Delta$ are uniform operators then so is $\Gamma \times \Delta$, where<br>$$ (\Gamma \times \Delta)(b) = \Gamma(b) \times \Delta(b)$$<br>Prove or disprove.<br></latex><br><br>	pg 3462, (3) at top<br><br>
<latex>\\~\\<br>Consider the following statement:\\~\\<br>If $\Gamma$ and $\Delta$ are uniform operators then so is $\Gamma \cup \Delta$, where<br>$$ (\Gamma \cup \Delta)(b) = \Gamma(b) \cup \Delta(b)$$<br>Prove or disprove.<br></latex><br><br>	pg 3462<br>
<latex>~\\<br>Consider the operator $\Gamma(a) = a \times a$. What are the fixed points $\Gamma_*$ and $\Gamma^*$? Is $\Gamma$ uniform?<br></latex>	pg 3462, exercise 16.7<br><br>
pg 3462, exercise 16.8<br>	<br>
pg 3462, exercise 16.9<br>	<br>
<latex>~\\<br>Let $\mathcal E = \langle b, e \rangle$ be a $\Gamma$-coalgebra, let $Y$ be a set of new urelements for $\Gamma$, and let $t : Y \to b$ be a surjective map. Consider the following statement:\\~\\<br>There is a map $e' : Y \to \Gamma(Y)$ such that t reorganizes $\langle Y, e' \rangle$ onto $\mathcal E$.\\~\\<br>Prove or disprove.<br></latex>	pg 3462, prop 16.5<br>todo: add impostor?<br>
<latex>~\\<br>State and prove the "Representation Theorem for $\Gamma^*$".<br></latex>	pg 3463, thm 16.6<br>
Exercise 16.10, pg 3463<br>	<br>
<latex>~\\<br>Let $\Gamma$ be a uniform operator and let $X \subseteq \mathcal U$. What is a \emph{parametric $\Gamma$-object over $X$}?<br></latex>	pg 3463, definition at bottom. part 1 (spills onto the next page)<br>
<latex>~\\<br>What is a \emph{general $\Gamma$-coalgebra}?<br></latex>	pg 3464, definition at top of page, part 2. (for full context part 1 on the previous page should be examined)<br>
<latex>~\\<br>What is a \emph{general $\mathcal P$-coalgebra}?<br>Define $\Gamma_3(a) = A \times a$. What is a \emph{general $\Gamma_3$-coalgebra}?<br></latex>	example 16.6, pg 3464<br>
State and prove "The Solution Lemma" for uniform operators.	statement on pg 3464, proof extends to the bottom of 3466<br>
<latex>~\\<br>Let $\Gamma$ be a uniform operator. Let $X$ and $Y$ be disjoint sets of urelements that are new for $\Gamma$. $\mathcal E = \langle X \cup Y, e \rangle$ be a $\Gamma$-coalgebra, and let $s$ be its solution. Let $\mathcal E_0 = \langle Y, e \upharpoonleft Y \rangle$ be the general system of equations obtained by restricting $e$ to $Y$, and let $t$ be the solution to $\mathcal E_0$. Let $\mathcal E_1 = \langle X, e_1 \rangle$, where $e_1(x) = e(x)[t]$. Let $s'$ be the solution to $\mathcal E_1$. Consider the following statement:\\~\\<br>$s$ is given by<br>\[  s(z) = \left\{<br>\begin{array}{ll}<br>      s'(z) & if~$z \in X$  \\<br>      t(z)[s'] & if~$z \in Y$ \\<br>\end{array} <br>\right. \]<br>In particular, the solution to $\mathcal E_1$ is the restriction to $X$ of the solution to $\mathcal E$.\\~\\<br>Prove or disprove<br></latex>	true. pg 3465, lemma 16.8<br>todo: add impostor?<br>
Exercise 16.11, pg 3467<br>	<br>
Exercise 16.12, pg 3467 (you will need to read the discussion in the above two paragraphs to understand)<br>	<br>
Exercise 16.13, pg 3467<br>	<br>
<latex>~\\<br>Let $\mathcal F$ be a set of set-theoretic operations (like union, intersection, etc.), and assume that each $f \in \mathcal F$ comes with some natural number $arity(f)$. What is an $\mathcal F-term$?<br></latex>	pg 3467, definition at bottom of page<br>
<latex>~\\<br>Let $\mathcal F$ be a set of set-theoretic operations (like union, intersection, etc.). Let $s$ be a substitution. Consider the following statement:\\~\\<br>There is a unique operation $[s]_{\mathcal F}$ such that $[s]_{\mathcal F}$ agrees with $s$ on urelements, and for all sets $a$,\\~\\<br>\begin{tabular}{lcl}<br>a[s]_{\mathcal F} & = & $\{ f(x_1[s]_{\mathcal F}, \ldots, x_n[s]_{\mathcal F}) \mid \langle f^*, x_1, \ldots, x_n \rangle\text{ is an } \mathcal F\text{-term in a} \}$ \\<br>~&~&$\cup \{ b[s]_{\mathcal F} \mid b \in a \text{ is not an } \mathcal F\text{-term}\}$<br>\end{tabular}\\~\\<br>Prove or disprove.<br></latex>	true. pg 3468. <br>todo: add impostor?<br>
<latex>~\\<br>Let $\mathcal F$ be a set of set-theoretic operators (like union, intersection, etc). Consider the following statement.\\~\\<br>If each $f \in \mathcal F$ commutes with almost all substitutions, then almost all sets $X \subseteq U$ are new for each $f \in \mathcal F$.\\~\\<br>Prove or disprove.<br></latex>	pg 3468, lemma 16.10<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $\mathcal F$ be a set of set-theoretic operators (such as union, intersection, etc.). What is a \emph{flat $\Gamma_{\mathcal F}$-coalgebra?} What is an \emph{$\mathcal F$-solution} to a $\Gamma_{\mathcal F}$-coalgebra?<br></latex>	pg 3468, definition near bottom.<br><br>
Read example 16.7 at the bottom of page 3468.<br>	<br>
<latex>~\\<br>Let $\mathcal F$ be a set of set-theoretic operators (such as union, intersection, etc.). Suppose that every $f \in \mathcal F$ commutes with almost all substitutions. Consider the following statement:\\~\\<br>Every flat $\Gamma_{\mathcal F}$-coalgebra has a unique $\mathcal F$-solution.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3469, thm 16.11<br>todo: add impostor?<br>
<latex>~\\<br>Read the statement of the $\mathcal F$-solution Lemma on page 3469, and also the discussion directly below its proof (on page 3470).<br></latex><br>	pg 3469<br>
Exercise 16.14 (1), pg 3470<br><br>	<br>
Exercise 16.14 (2), pg 3470<br><br>	<br>
<latex>~\\<br>Let $s$ and $t$ be substitutions. How is the substitution $t \star s$ defined?<br></latex>	pg 3328, definition near bottom<br><br>
Exercise 8.7, pg 3329, top<br>	<br>
Exercise 8.8, pg 3329, top <br>	<br>
What does it mean for a substitution to be <i>proper</i>?	pg 3329, below exercises at top<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>AFA is equivalent to the assertion that for every proper $e$ there is a unique proper $s$ such that $s = s \star e$.\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 3329<br>
Do exercise 8.9 on page 3329, near bottom<br><br>	<br>
Explain the preordered monoid used for effect annotations in the "exception effects" introductory example.<br>What are the various effect annotations? How is their composition operator defined?<br><br>	pg 9669, top left corner<br>
<latex>~\\<br>Give the typing rules for return ($~\langle t \rangle~$) and composition ($~\mbf{let}~\langle x \rangle = t_1~\mbf{in}~t_2~$) for a graded-monad-based effect system.<br></latex>	pg 9669, top left, right below the definition of the bullet operator on effect annotations<br>
Give the deriliction and promotion rules for the bang modality of linear logic.<br>What categorical notion do we use to model the bang modality?<br>	pg 9669, left, sec 2.2<br>
What are 0-monoidality and 1-monoidality?<br>	pg 9669, left, second-to-last paragraph<br>
Give the type signature (i.e. domain and codomain) for contraction and weakening of the bang modality of linear logic.<br>	pg 9669, left, second-to-last-paragraph<br>
Give the derlicition and promotion rules for the bang modality *extended with bounded reuse coeffect annotations*.<br>	pg 9669, top right<br>
<latex>~\\<br>Explain the meanings of the notations $[A]_r$ and $D_r A$<br></latex>	pg 9669, right side, above the let rule<br>
Give the let typing rule for coeffect composition (i.e. composing a capability with a requirement)<br>	pg 9669, right<br>
Describe the two naive kinds of composition involving effects and coeffects. Why are they unsatisfying? 	pg 9669, bottom right<br>
What is a <i>distributive law</i> between a monad and a comonad? Give the non-graded case and then the graded case.<br>	pg 9670, top left<br>
<latex>~\\<br>Define the $\iota$ operation for combining bounded reuse coeffect scalars and exception effect scalars.<br></latex>	pg 9670, left<br>
<latex>~\\<br>How do we compose two arrows of the form $D_{r} A \to T_{e} B$?<br></latex>	<latex>~\\<br>pg 9670, bottom left<br>figure out the arrows by looking at their domains and codomains. For example, $\sigma$ denotes the dist arrow.<br></latex><br><br>
What is a <i>preordered monoid</i>?	pg 9671, left "Effects" section
What is a <i>preordered semiring</i>?<br>	pg 9671, left, "Coeffects" section<br><br>
Why is there an asymmetry between the semantics of effects and coeffects?	pg 9671, left, bottom paragraph of section "Coeffects"<br>
What is a <i>distributive law format</i>?<br>	pg 9671, Definition 1<br> 
<latex>~\\<br>Let $\mathcal R$ and $\mathcal E$ be preordered monoids $(\mathcal E, \leq, 1, \bullet)$<br>and $(\mathcal R, \leq, 1, \ast)$. What is an $\mathcal R, \mathcal E$-matched pair?<br></latex>	pg 9671, bottom left / top right corners<br>
<latex>~\\<br>If $\mathcal E$ denotes a preordered monoid, what does $\overline{\mathcal E}$ denote?<br></latex>	pg 9671 / top right<br>
<latex>~\\<br>Let $\mathcal R$ and $\mathcal E$ be preordered monoids, $\iota : R \times E \to R$ and<br>$\kappa : R \times E \to E$ be monotone functions and $\phi$ be a distributive law format.<br>What does it mean for $(\iota, \kappa)$ to be a $M \phi$-matched pair?<br></latex>	pg 9671, right, definition 3<br>
Let P(x) be a predicate on sets. What does it mean for P(x) to hold for <i>almost all sets</i> in a class G?	<latex><br>It means that there is a set $y \subseteq G$ such that for all $z \subseteq G$ with $z \cap y = \emptyset$,<br>we have $P(z)$.\\~\\<br>See the definition on pg 3461 for an application of this notion.<br></latex>
<latex>~\\<br>In lawvere's notation, if $A$ is an "object" and $f : A \to B$ is an arrow, what does <br>$Af$ mean? <br></latex>	Lawvere identifies objects with their identity maps. So there aren't actually any objects:<br>Af is the composition of A's identity arrow with f.<br>pg 9172<br>
What is the "category of categories"?<br>	pg 9172, bottom paragraph<br>
What is the <i>first-order theory of the category of categories</i>?<br>	pg 9172 bottom / 9173 top<br>
How do we reason about the objects of an object (i.e. category) of the category of categories, 	by using global points, arrows (functors) from the terminal category 1.<br>pg 9173, middleish<br><br>
What is a <i>constant functor</i>, defined in terms of the category of categories? (we're trying to define a class of "constant" arrows in the category of categories.)<br><br><br>	It's a functor (arrow) that factors through the terminal category 1.<br>pg 9173<br>
Describe that simplest category that is a <i>generator</i> for the category of categories.<br>	The category 2.<br>pg 9173<br>
<latex>~\\<br>Let $\mathbb A$ be a category. What does the notation $u \in \mathbb A$ mean?<br></latex><br>	note that this notation is pronounced "u is a map of A" or "u is a member of A"<br>pg 9173<br>
<latex>~\\<br>Let $\mathbb A \rTo^{f} \mathbb B$ be a functor. Explain what the following formula, written in Lawvere's notation, means:\\~\\<br>$$\forall x[x \in \mathbb A \Rightarrow \exists ! y [y \in \mathbb B \wedge y = xf]]$$<br>Also, why is it true?<br></latex><br>	pg 9173, near bottom<br>
Does the category of categories have equalizers? Why or why not?<br>	Yes. It isn't explained in the paper, but its not hard to see on consideration.<br>pg 9174<br>
Describe and characterize coequalizers in the category of categories.<br>	pg 9174, near bottom<br><br>
<latex>~\\<br>What is the coequalizer of $\mbf{1} \pile{\rTo^0 \\ \rTo_1} \mbf{2}$?<br></latex>	pg 9174, near bottom, spills onto next page<br>
<latex>~\\<br>How does Lawvere use the notation \{ f \}?<br></latex>	to denote currying. pg 9175<br>
In what sense is the categorical notion of exponentiation functorial?	pg 9175 bottom / 9176 top<br>
<latex>~\\<br>Given a theory $\mathcal T$ of the simple programming language, how do we define the category $\mathcal F(\mathcal T)$?<br></latex>	pg 8824<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every theory $\mathcal T$ of the simple programming language, viewed as a category $\mathcal F(\mathcal T)$, is equipped with a Kleisli triple $(T, \eta, -^*)$ satisfying the mono requirement.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8824, prop 2.9<br>
Explain the motivation behind the need for <i>strong monads<i>.<br>	pg 8825, near middle -- read to bottom<br><br>
Give the formal definition of <i>strong monad</i> over a category with finite products. This should include three commutative diagrams.<br>	pg 8826<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $(T, \eta, \mu)$ is a monad over a category $\mathcal C$ with finite products and enough points, then $(T, \eta, \mu, t)$ is a strong monad over $\mathcal C$ if and only if $t_{A,B}$ is the unique family of morphisms s.t. for all points $a : 1 \to A$ and $b : 1 \to TB$<br>$$\langle a, b \rangle; t_{A,B} = b ; T(\langle !_B;a,id_B \rangle)$$<br>where $1_B : B \to 1$ is the unique morphism from $B$ to the terminal object.\\~\\<br>Prove or disprove.<br></latex>	true. pg 8827.<br>todo: add impostor?<br><br>
What is the <i>tensorial strength</i> of a strong monad? 	It is the natural transformation t.<br>pg 8826<br>
Give tensorial strengths for the following strong monads:<br>-The partiality monad<br>-The non-determinism monad<br>-The side-effect monad<br>	pg 8827 / 8828<br>
How are finite products defined in Moggi's metalanguage for algebraic terms?<br>	pg 8828<br>
Give the interpretation rules for types in Moggi's metalanguage for algebraic terms.<br>	pg 8829, table 8<br>
Read proposition 3.8 on pg 8829, and maybe prove it if you're up to it.<br>	pg 8829<br>
How do we model function types categorically for a moggi-style monadic language?	pg 8829, near bottom<br>
<latex>~\\<br>Give the following term interpretation rules for Moggi's algebraic metalanguage:\\<br>- $var_i$\\<br>- $\ast$ ("unit" value of terminal object) \\<br>- $\langle -, -\rangle$ \\<br>- $\pi_i$ for $i \in 1..2$<br></latex>	pg 8830<br>
<latex>~\\<br>Give these rules for interpreting terms in Moggi's algebraic metalanguage\\~\\<br>- Function application\\<br>- Monadic unit\\<br>- Let\\<br>- Eq<br></latex>	pg 8830<br>
Give the five <i>general</i> equational inference rules for Moggi's many-sorted equational logic for algebraic systems.<br>	pg 8831, "inference rules of many sorted equational logic"<br><br>
Give the (4) equational inference rules for product types in Moggi's algebraic metalanguage.<br>	pg 8831<br>
Give the five equational inference rules for monadic constructs in Moggi's algebraic metalanguage.	pg 8831, table 10<br>
Give the four equational rules for function types in Moggi's algebraic metalanguage.	pg 8831<br>
Consider two closed, well-typed terms t : A and t' : A', where A is less dynamic than A'. What does it mean for t to be less dynamic than t'?	pg 9172, below "A logic of dynamism and casts"
<latex>~\\<br>Explain the notation behind the cast forms $\langle B \leftarrowtail A \rangle$ and $\langle A \twoheadleftarrow B \rangle$. What restrictions are placed on $A$ and $B$ and the way they are related for these two cast forms?<br></latex>	pg 9712, near bottom<br><br>
<latex>~\\<br>What does $\mho$ denote?<br></latex><br>	type error<br>pg 9712<br>
What is a <i>presupposition</i> in a judgment system? Give the presupposition rules for preorder type theory.<br>	pg 9714, figure 1 at top<br><br>
What types does one find in bare preorder type theory?	base types only<br>pg 9714<br>
Give all non-presupposition judgments (type well-formedness, context well-formedness, and typing rules) of preorder type theory.<br>	pg 9714, figure 2<br><br>
Give the type and context dynamism rules for preorder type theory.<br>	pg 9715<br>
Give the primitive rules for term dynamism in preorder type theory.	pg 9715<br>
Explain the intuitive role of the <i>signature</i> in preorder type theory.<br>	pg 9715, bottom paragraph<br><br>
What is a <i>PTT Signature</i>? <br>Note that its definition depends on definitions of many simpler structures, i.e.:<br>- The definition of 0-PTT signature<br>- The definition of 1-PTT signature<br>- The definition of 2-PTT signature<br>- The definition of 3-PTT signature<br><br><br>	pg 9716<br>
What is a <i>term dynamism axiom</i>?	pg 9716, def 1, pt 6<br>
What is a <i>type dynamism axiom</i>? 	pg 9716, pt 3
Give a brief overview of the GUILev1Command datatype.<br>	WxGraphicsLib.agda<br>
What is the basic idea behind definitional interpreters?	pg 9741, first paragraph<br>
What two broad categories of programming language features does Reynolds define?	pg 9741, bottom<br>
What does it mean for a programming language to be <i>higher order</i>?<br>	pg 9742, middle paragraph<br>
What are the four classes of interpreters, as defined by Reynolds?<br>	pg 9743, diagram<br>
<latex>~\\<br>Supose $x_1, \ldots, x_n$ are variables, $v_1, \ldots, v_n$ are values, and $e$ and $e'$ are environments.<br>What does it mean for $e'$ to be \emph{the extension of } $e$ \emph{ that binds the } $x_i's$ \emph{to the } $v_i's$.<br></latex>	pg 9744, second paragraph.<br>
Give a step-by-step description of how application expressions are evaluated.<br>	pg 9744, bottom half of page.<br>
<latex>~\\<br>Let $S_0$, $S_1$, $S_n$, $\ldots$ be upper-case letter strings and $a_1, \ldots, a_n$ be lowercase letter strings. What does a \emph{record equation}<br>$$S_0 = [a_1 : S_1, \ldots, a_n : S_n]$$<br>mean?<br></latex>	pg 9749<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any category $\mathbb A$, there exists a \emph{set} $|\mathbb A|_0$ and a functor $|\mathbb A|_0 \rTo^{i} \mathbb A$ such that<br>$$\forall \mathbb S~\forall f~[\mathbb S \cong \mathbb S^2 \wedge \mathbb S \rTo^{f} \mathbb A \Rightarrow \exists ! h [hi = f]]$$<br>Prove or disprove.<br></latex>	true. pg 9177, middle<br>todo: add impostor?
How does lawvere define the notion of a <i>set</i> in the category of categories?<br>	pg 9177<br>
<latex>~\\<br>How does Lawvere justify his "abuse of notation" where $A \in |\mathbb A|_0$ means $1 \rTo^{A} \mathbb A$?<br></latex>	pg 9177, below diagram<br>
<latex>~\\<br>Let $\mathbb A$ be a category. What is the \emph{set of components} $|\mathbb A|_1$ of $\mathbb A$.<br></latex>	pg 9177
<latex>~\\<br>What does it mean for a category $\mathbb A$ to be \emph{connected}?<br></latex>	pg 9177, at very bottom<br><br>
<latex>~\\<br>Let $\mathb A$ be a category. What does $|\mathbb A|$ mean?<br></latex> 	pg 9178, top
<latex>~\\<br>What is the \emph{meet} of two functors $\mathbb A \rTo^{f} \mathbb B$ and $\mathbb A' \rTo^{f'} \mathbb B$ sharing a common codomain?<br></latex>	note that <i>meet</i> here is just another word for pullback.<br>pg 9178, near top<br><br>
<latex>~\\<br>Define the category $\mbf{3}$ as a comeet.<br></latex>	pg 9178<br>
What does it mean for a category in the category of categories to be a <i>preorder</i>?<br>	pg 9179<br>
<latex>~\\<br>Let $\mathbb A$ be a category and let $x,a$ be functors $2 \rTo \mathbb A$.<br>What does the following statement mean?\\~\\<br>$a$ is the $\mathbb A$-domain of $x$<br></latex>	pg 9179, bottom<br>
<latex>~\\<br>Let $\mathbb A$ be a category and let $x,b$ be functors $2 \rTo \mathbb A$.<br>What does the following statement mean?\\~\\<br>$b$ is the $\mathbb A$-codomain of $x$<br></latex>	pg 9179, bottom<br>
<latex>~\\<br>Let $\mathbb A$ be a category and let $x,y,u$ be functors $2 \rTo \mathbb A$.<br>What does the following statement mean?\\~\\<br>$u$ is a $\mathbb A$-composition of $\langle x,y \rangle$<br></latex>	pg 9180, top<br>
<latex>~\\<br>What does it mean for two functors $\mathbb A \pile{\rTo^f \\ \rTo_g} \mathbb B$ to be equivalent?<br></latex>	pg 9180<br>
<latex>~\\<br>What does it mean for two categories $\mathbb A$ and $\mathbb B$ to be equivalent?<br></latex>	pg 9180, bottom<br><br>
<latex>~\\<br>What special objects do $\mathcal C_1$ and $\mathcal C_2$ denote in the category of categories?<br></latex>	pg 9181, near top<br>
<latex>~\\<br>What special objects do $\mathcal C_0$ and $\mathcal S_0$ denote in the category of categories?<br></latex><br>	pg 9181, middle<br>
<latex>~\\<br>Give the formation rules for the $\Pi$ propositional form (i.e. cartesian product of a family of sets).<br></latex>	pg 6500 bottom<br>
<latex>~\\<br>What is the role of \emph{introduction rules} in Martin-Lof's framework? Give the introduction rules for the propositional constructor $\Pi$ (i.e. cartesian product of a family of sets)<br></latex>	pg 6501, top<br>
<latex>~\\<br>Consider the rule for $\Pi$-formation:\\~\\<br>\begin{prooftree}<br>\AxiomC{$A = C$}<br>\AxiomC{$(x \in A)$}<br>\noLine<br>\UnaryInfC{$B(x) = D(x)$}<br>\BinaryInfC{$(\Pi x \in A) B(x) = (\Pi x \in C) D(x)$}<br>\end{prooftree}<br>Derive this rule using rules for $\Pi$-introduction, symmetry of set equality, and possibly some other rules.<br></latex>	pg 6501<br>
<latex>~\\<br>Consider the rule for $\Pi$-formation:<br>\begin{prooftree}<br>\AxiomC{$A = C$}<br>\AxiomC{$(x \in A)$}<br>\noLine<br>\UnaryInfC{$B(x) = D(x)$}<br>\BinaryInfC{$(\Pi x \in A) B(x) = (\Pi x \in C) D(x)$}<br>\end{prooftree}<br>Show that when the premises of this rule are assumed, we can prove<br>\begin{prooftree}<br>\AxiomC{$(\lambda x)~b(x) = (\lambda x)~d(x) \in (\Pi x \in A)~B(x)$}<br>\doubleLine<br>\UnaryInfC{$(\lambda x)~b(x) = (\lambda x)~d(x) \in (\Pi x \in C)~D(x)$}<br>\end{prooftree}<br></latex>	pg 6502, top<br><br>
<latex>~\\<br>Give the two elimination rules for the $\Pi$ propositional constructor (i.e. cartesian product of a family of sets)<br></latex>	pg 6502<br>
<latex>~\\<br>What is the term constructor \textbf{Ap} used for in Martin-Lof's logic?<br>Assuming that $$c \in (\Pi x \in A) B(x)$$ and $$a \in A$$ perform Martin-Lof's "thought experiment"<br>of evaluating \textbf{Ap}$(c,a)$.<br></latex>	pg 6502, below Pi-elimination<br>
<latex>~\\<br>Give the two equality rules for the $\Pi$ propostional constructor (i.e. cartesian product of a family of sets).<br></latex>	pg 6502, bottom. explanation on pg 6503<br><br><br>
What is definitional equality? How does it differ from other forms of equality. What is its purpose? Discuss.	pg 6503<br>
<latex>~\\<br>Explain how the $\forall$ connective can be derived from the $\Pi$ connective.<br></latex><br>	pg 6503, bottom of page,<br>pg 6504, entire page,<br>pg 6505, to middle<br>important point: proofs of a formula, unlike programs of a type, are interchangeable, and so we just write "A true" rather than naming the proof.<br><br>
<latex>~\\<br>Explain how the implication connective $\supset$ can be derived from the cartesian product of sets connective $\Pi$.<br></latex>	pg 6505<br>might be helpful to reference against the definition of Pi on pg 6500-6502<br>
<latex>~\\<br>Present the I and K combinators using intuitionistic type theory.<br></latex>	pg 6506<br>
<latex>~\\<br>Give the formation rule for the $\Sigma$ connective in intuitionistic type theory.<br></latex>	pg 6507<br>
<latex>~\\<br>Give the introduction form for the $\Sigma$ connective of intuitionistic type theory.<br></latex>	pg 6508<br>
<latex><br>Prove the following derived rule in intuitionistic type theory:\\~\\<br>\begin{prooftree}<br>\AxiomC{$A=C$}<br>\AxiomC{$(x \in A)$}<br>\noLine<br>\UnaryInfC{$B(x) = D(x)$}<br>\BinaryInfC{$(\Sigma x \in A)~B(x) = (\Sigma x \in C)~D(x)$}<br>\end{prooftree}<br></latex>	pg 6508, "top section: Sigma introduction"<br>hint: the rules of equality on pg 6495 may be useful<br><br>
<latex>~\\<br>Give the elimination rule for the $\Sigma$ connective in intuitionistic type theory.<br></latex>	pg 6508<br>
<latex>~\\<br>Give the equality rule for the $\Sigma$ connective in intuitionistic type theory.<br></latex>	pg 6508/6509<br>
<latex>~\\<br>Explain how the $\exists$ connective can be derived from the $\Sigma$ connective in intuitionistic logic.<br></latex>	pg 6509. should be compared against the definition of the Sigma connective on pg 6508<br><br>
<latex>~\\<br>Derive the \& connective from the $\Sigma$ connective in intuitionistic logic.<br>Give formation, introduction, and elimination rules.<br></latex>	pg 6510. compare against Sigma definition on pg 6508<br>
<latex>~\\<br>How does Martin-Lof define the constant \textbf{E}, for working with disjoint unions?\\~\\<br>Consider the elimination rule for $\Sigma$:<br>\begin{prooftree}<br>\AxiomC{$c \in (\Sigma x \in A)~B(x)$}<br>\AxiomC{$(x \in A, y \in B(x))$}<br>\noLine<br>\UnaryInfC{$d(x,y) \in C((x,y))$}<br>\BinaryInfC{$\mbf{E}(c, (x,y)~d(x,y)) \in C(c)$}<br>\end{prooftree}<br> Perform Martin-Lof's<br>thought experiment of "executing" a term of the form $\mbf{E}(c, (x,y)~d(x,y))$.<br></latex>	pg 6508, below Sigma-elimination.<br>
Define the left projection operator for disjoint sums. Give its elimination and equality rules.<br>	pg 6510 bottom,<br>pg 6511 top<br>
<latex>~\\<br>Define the right projection rule for the $\Sigma$ connective. Give both its "specialized elimination" and "specialized equality" rules, and justify them in terms of the $\Sigma$ rules.<br></latex> 	pg 6511 bottom / 6512 top
There are three forms of syntax equations. What are they?	-record equations<br>-union equations<br>-function equations<br><br>pg 9749/9750<br><br>
Read the set of syntax equations on the bottom half of pg 9750 and the middle of pg 9751.<br>	<br>
Give code for a Reynolds' meta-circular interpreter. Remember that its language features are:<br>- constants<br>- variables<br>- applications<br>- lambdas<br>- conditionals (if then else)<br>- letrec<br>	pg 9752<br>
Read the last two paragraphs of pg 9752<br>	<br>
What does it mean for an interpreter to be "meta-circular"?	pg 9753, top, "We have coined the word..."<br>
Is the defined language in Reynolds' meta-circular interpreter on pg 9752 call-by-value or call-by-name?	It is cbv if the definining language is cbv and cbn if the defining language is cbn.<br>pg 9753
What are the three basic problems with Reynolds' naive meta-circular interpreter shown on page 9752?<br>	pg 9753/9754, points 1, 2, and 3<br>
Explain the basics of the "defunctionalization" transformation (just the motivation, not the details) of Reynolds' metacircular interpreter.<br>	pg 9754/9755, section 6<br>compare against pg 9752<br>
The "defunctionalized" version of Reynolds' metacircular interpreter has a utility function "apply" which the original naive version does not have. What is the motivation for the apply function, and how is it implemented?<br>	pg 9755 bottom half / pg 9756<br>
Give the type-syntax of their PCF variant.<br>	pg 9857, near bottom<br>
Give the letrec typing rule and explain its various premises.<br>	pg 9858<br>
What is the difference between $\beta$, $\iota$, and $\mu$ reduction rules?	pg 9858, near top<br>
Give the set-theoretic interpretation of their variant of PCF. Also, state their "soundness of set-theoretic semantics" theorem.  	pg 9858 bottom / pg 9859 top<br>
Give the grammar of higher-order logic assertions.	pg 9859<br>
The predicates of higher order logic "come equipped with an axiomatization". What does this mean?	pg 9859 "For instance, the predicate All(l, ..."<br>
What is the "link" that connects higher-order logic to PCF?<br>	the predicates of higher-order logic take PCF terms as arguments.<br>pg 9859 P(t<sub>1</sub>,...,t<sub>n</sub>)<br>
<latex>~\\<br>What is the meaning of a HOL judgment $\Gamma \mid \Psi \vdash \phi$?<br></latex><br>	pg 9859, "we define well-typed assertions"<br><br>
<latex>~\\<br>In HOL, what does a judgment of the form $\Gamma \vdash \phi$ mean?<br></latex>	pg 9859, "We define well-typed assertions using..."<br>
<latex>~\\<br>Give the $AX$, $CONV$, $SUBST$, $\Rightarrow_I$ and $\Rightarrow_E$ rules of HOL.<br></latex>	pg 9859, fig 1<br>
<latex>~\\<br>Give the $\forall_I$, $\forall_E$, $\top_I$, and $\bot_E$ rules of HOL.<br></latex>	pg 9859, fig 1<br>
<latex>~\\<br>Give the $LIST$, $NC$, $CONS_i$, and $SLIST$ rules of HOL.<br></latex>	pg 9859<br>
<latex>~\\<br>Give the set-theoretical interpretation of formulas of HOL. State the soundness theorem for judgments fo the form $\Gamma \mid \Psi \vdash \phi$.<br></latex>	pg 9860<br>
What does it mean to say the HOL is <i>consistent</i>?	<latex>~\\<br>It means that there is no derivation of $\Gamma \mid \emptyset \vdash \bot$ for any $\Gamma$.<br></latex><br>pg 9860, right above section 4<br>
<latex>~\\<br>Explain UHOL typing judgments, which have the form $\Gamma \mid \Psi \vdash t : \tau \mid \phi$.<br></latex><br>	pg 9860<br>
<latex>~\\<br>Give the $VAR$, $ABS$, $APP$, and $NIL$ typing rules for UHOL (for judgments of the form $\Gamma \mid \Psi \vdash e : \tau \mid \psi$)<br></latex>	pg 9861<br>
<latex>~\\<br>Give the UHOL typing rules $CONS$, $PROJ_i$, $PAIR$, and $SUB$. (hint: These rules are for judgments of the form $\Gamma \mid \Psi \vdash e : \tau \mid \psi$.<br></latex>	pg 9861, figure 2
<latex><br>Give the UHOL typing rules $LISTCASE$ and $LETREC$. (Hint: These rules are for judgments of the form $\Gamma \mid \Psi \vdash e : \tau \mid \phi$.)<br></latex>	pg 9861, figure 2<br>
State the theorem witnessing an "equivalence" between HOL and UHOL.	pg 9860, theorem 3 at bottom<br>
State the "set-theoretical soundness and consistency" theorem for the UHOL type system.	pg 9861, corollary 4<br>
State the "subject conversion" theorem for UHOL.<br>	pg 9861, corollary 5 at bottom<br>
What is relational higher-order logic (RHOL)? How does it relate to UHOL? Describe the form of RHOL typing judgments.<br>	pg 9862, near top<br>
Explain the difference between two-sided rules and one-sided rules in RHOL.<br>	"The type system combines two-sided rules (Figure 3), which apply when the two terms have the<br>same top-level constructors and one-sided rules (Figure 5), which analyze either one of the two<br>terms."<br><br>pg 9862<br>refer to pg 9863 for the rules<br>
<latex>~\\<br>Give the $ABS$, $APP$, $VAR$, and $TRUE$ rules for RHOL.<br></latex><br>	pg 9863, fig 3<br><br>
<latex>~\\<br>Give the NIL, CONS, and LISTCASE typing rules for RHOL.<br></latex>	pg 9863, fig 3<br>
<latex>~\\<br>Give the $PAIR$ and $PROJ_i$ two-sided rules for RHOL.<br></latex>	pg 9863<br>
<latex>~\\<br>Give the $SUB$ and $\wedge_I$ structural rules for RHOL.<br></latex>	pg 9863<br>
<latex>~\\<br>Give the $\Rightarrow_I$ and $UHOL-L$ structural rules for RHOL.<br></latex>	pg 9863, figure 4<br>
<latex>~\\<br>Give the ABS-L, APP-L, VAR-L, and NIL-L one-sided rules for RHOL.<br></latex><br>	pg 9864, figure 5<br><br>
<latex>~\\<br>Show that the two following standard implementations of factorial, with and without an accumulator,<br>are functionally equivalent.\\~\\<br>$$fact_1 \doteq \mbf{letrec}~f_1~n_1 = \mbf{case}~n_1~\mbf{of}~0 \mapsto 1; S \mapsto \lambda x_1. (S~x_1) * (f_1~x_1)$$<br>$$fact_2 \doteq \mbf{letrec}~f_2~n_2 = \lambda acc. \mbf{case}~n_2~\mbf{of}~0 \mapsto acc; S \mapsto \lambda x_2. f_2~x_2~((S~x_2) * acc)$$<br></latex><br>	pg 9876, example 7.1<br><br>
Carry out the proof outlined in section 7.2, pg 9876<br>	<br>
Carry out the proof described in section 7.3, pg 9877<br>	<br>
Explain the 'Peano postulate' and the object N of the category of categories.	pg 9182 top<br>
<latex>~\\<br>If $\mathbb A$ is an object in the category of categories, what does $\mathbb A^*$ denote?<br></latex>	pg 9182
<latex><br>Let $\mathbb A \rTo^{f} \mathbb B$ and $\mathbb A' \rTo^{f'} \mathbb B$. What does $(f,f')$ denote?<br></latex>	pg 9182 bottom
Let X be a topological space. What is a <i>separation</i> of X? What does it mean for X to be <i>connected</i>?	pg 4426, definition<br>
Consider the following statement:<br><br>A toplogical space X is connected if and only if the only subsets of X that are both open and closed in X are the empty set and X itself.<br><br>Prove or disprove.	pg 4426<br>
Consider the following statement:<br><br>If Y is a subspace of X, a separation of Y is a pair of disjoint nonempty sets A and B whose union is Y, neither of which contains a limit point of the other. The space Y is connected if there exists no separation of Y.<br><br>Prove or disprove.	true. pg 4426, lemma 23.1<br>todo: add impostor<br>
What does it mean for a stream to be <i>productive</i>? What is the <i>depth</i> of a stream?	pg 9883, middle paragraph<br><br>
How do we define a constant-valued stream using copatterns?	pg 9884 bottom / 9885 top<br>
What, precisely, is a <i>copattern</i>?	pg 9885, "A copattern consists of a hole, ..."<br>
Why are copatterns superior to other forms of coinductive programming (i.e. ones with syntactic productivity checking)?<br>	pg 9885, last paragraph / pg 9886 top<br>
<latex>~\\<br><br>Explain how the termination of the following definitions is verified.<br><br>\begin{verbatim}<br>zipWith f s t .head = f (s .head) (t .head)<br>zipWith f s t .tail = zipWith f (s .tail) (t .tail)<br><br>fib .head = 0<br>fib .tail .head = 1<br>fib .tail .tail = zipWith (+) fib (fib .tail)<br>\end{verbatim}<br><br></latex>	pg 9886, bottom paragraph,<br>pg 9887, top paragraph<br>
Implement a stream of fibonacci numbers 0,1,1,2,3,5,8,13,... using copatterns.<br>You will need to define an auxiliary function zipWith.<br>	pg 9886
<latex>~\\<br>Suppose that someone accidentally misimplements the fibonacci sequence 0,1,1,2,3,5,8,13,... as follows<br><br>\begin{verbatim}<br>zipWith f s t .head = f (s .tail.head) (t .tail.head)<br>zipWith f s t .tail = zipWith f (s .tail) (t .tail)<br><br>fib .head = 0<br>fib .tail .head = 1<br>fib .tail .tail = zipWith (+) fib (fib .tail)<br>\end{verbatim}<br>Why doesn't this terminate, and what lesson can be learned from this mistake?<br><br></latex>	pg 9886<br>
<latex>~\\<br>What does the notation $\forall i < a. B$ desugar to?<br></latex>	pg 9887 "Size quantification for coinductive types"<br>
<latex>~\\<br>Explain these two typing rules for stream projections.<br>\begin{mathpar}<br>\inferrule<br>  {s : Stream^a A}<br>  {s.head : \forall i < a^\uparrow. A}<br>\and<br>\inferrule<br>  {s : Stream^a A}<br>  {s.tail : \forall i < a^\uparrow. Stream^i A}<br>\end{mathpar}<br></latex>	pg 9887
<latex>~\\<br>If $a$ is an ordinal, what does $a^\uparrow$ denote? What is the motivation for the $-^\uparrow$ operation?<br></latex>	Not mentioned in this paper, but it might be useful for subtyping, since it turns all ordinals strictly greater than inf into an equivalence class w.r.t. the subtyping preorder.<br>pg 9887<br>
How are coinductive types represented in their general form, and what is the typing rule for field projection?<br>How are inductive types represented, and what is the typing rule for their constructors?	pg 9887, very last paragraph (occupies only two lines)<br>pg 9888, top section<br>
<latex>~\\<br>In the following code, what does the notation $|i|$ mean? Give a high-level overview of how the <br>type checker uses it to prove termination. <br><br>\begin{lstlisting}<br>zipWith : $\forall i \leq \infty$. |i| $\Rightarrow$ $\forall A:\ast$. $\forall B:\ast$. $\forall C:\ast$.<br>  (A $\to$ B $\to$ C) $\to$ $Stream^i$ A $\to$ $Stream^i$ B $\to$ $Stream^i$ C<br><br>zipWith i A B C f s t .head j = f (s .head j) (t .head j)<br>zipWith i A B C f s t .tail j = zipWith j A B C f (s .tail j) (t .tail j)<br>\end{lstlisting}<br><br></latex>	pg 9888, bottom two sections, the latter of which spills over onto the next page.<br>
<latex>~\\<br>What do Abel and Pientka use the abbreviations $\forall A$ and $\forall i$ for?<br></latex>	pg 9889, top<br>
<latex>~\\<br>If S is a symbol set and $\Phi$ is a set of S-sentences, what does $\Phi^{\vDash}$ denote?<br></latex>	<latex>\\~\\<br>The set of S-sentences which are consequences of $\Phi$.\\~\\<br>pg 5693<br></latex><br>
<latex>~\\<br>What is a \emph{sequent}?<br></latex>	pg 5694, bottom paragraph<br>
<latex>~\\<br>Explain the meaning of the following rule:\\~\\<br>\begin{prooftree}<br>\AxiomC{$\Gamma$}<br>\noLine<br>\UnaryInfC{$\Gamma$}<br>\AxiomC{$\neg \phi$}<br>\noLine<br>\UnaryInfC{$\neg \phi$}<br>\AxiomC{$\psi$}<br>\noLine<br>\UnaryInfC{$\neg \psi$}<br>\TrinaryInfC{$\Gamma~~~~~\phi$}<br>\end{prooftree}<br></latex>	pg 5695<br>
<latex>~\\<br>What does the notation $\vdash \Gamma \phi$ mean?<br></latex>	pg 5695<br>
<latex>~\\<br>What does it mean for a formula $\phi$ to be \emph{formally provable} or \emph{derivable} from a set $\Phi$ of formulas?<br></latex>	pg 5695, definition 1.1<br>
<latex>~\\<br>What does it mean for a sequent $\Gamma \phi$ to be \emph{correct}?<br></latex>	pg 5695, bottom paragraph<br>
Give the antecendent rule of sequent calculus.	pg 5696<br>
Give the <i>assumption rule</i> of sequent calculus. Argue that it is <i>correct</i>.	pg 5696<br>
Give the "Proof by cases" rule of sequent calculus, and argue its correctness.<br>	pg 5696, near bottom<br><br>
Give the "Contradiction Rule" of sequent calculus, and argue its correctness.<br>	pg 5697, top<br><br>
<latex>~\\<br>Give the "$\vee$-Rule for the Antecedent" of sequent calculus. Argue its correctness.<br>Give the "$\vee$-Rule for the Succedent" of sequent calculus. <br></latex>	pg 5697, kinda near top<br><br>
Do exercise 2.7 on pg 5697<br>	<br>
<latex>~\\<br>Use the rules $(Assm)$, $(\vee S)$, and $(PC)$ to show that sequents of the form $(\phi \vee \neg \phi)$ are derivable.<br></latex>	pg 5697 bottom<br>
<latex>~\\<br>What is a \emph{derivable rule} of sequent calculus?<br></latex>	pg 5698, top two paragraphs<br>
<latex>~\\<br>Justify the following \emph{Second Contraction Rule} $(Ctr')$ as a derived sequent calculus rule:\\~\\<br>\begin{center}<br>\begin{array}{ll}<br>\Gamma & \phi \\<br>\Gamma & \neg \phi \\<br>\hline<br>\Gamma & \psi<br>\end{array}<br>\end{center}<br><br></latex>	pg 5698<br>
Give and justify the derived rule called the "chain rule" of sequent calculus.<br>	pg  5698, 3.2 (proof in book!)
Give and justify the four "Contraposition Rules" (Cp) of sequent calculus.	pg 5698<br>
Exercise 3.6, (a1) (a2) (b), pg 5699 bottom<br><br>	<latex>~\\~\\<br>(a1)\\<br>\begin{tabular}{llll}<br>1.) & $\Gamma$ & ~~~~ & $\varphi$ (assm) \\<br>2.) & $\Gamma$ $\neg \varphi$ & & $\varphi$ (ant) applied to 1 \\<br>3.) & $\Gamma$ $\neg \varphi$ & & $\neg \varphi$ (assm) \\<br>4.) & $\Gamma$ & & $\neg \neg \varphi$ (contr) applied to 2,3\\<br>\end{tabular}<br></latex>
Exercise 3.6, (c) (d1) (d2), pg 5699 bottom<br>	<latex>~\\<br>(c)\\<br>\begin{tabular}{lllll}<br>1.) & $\Gamma$ $\varphi$ & ~~~~ & $\psi$ & (hyp)\\<br>2.) & $\Gamma$ $\neg \varphi$ & & $\neg \varphi$ & (assm) \\<br>3.) & $\Gamma$ & & $\neg \varphi \vee \psi$ & (PC) applied to 1 and 2<br>\end{tabular}<br></latex>
<latex>~\\<br>Give the rule for "$\exists$-Introduction in the Succedent" ($\exists$ S). Argue its correctness.<br></latex>	pg 5700
<latex>~\\<br>Give the "Rule for $\exists$-Introduction in the Antecedent" ($\exists$ A). Argue its correctness. <br></latex>	pg 5700, three paragraphs above section 4.2, section 4.2.<br>
<latex>~\\<br>Give the "Reflexivity Rule for Equality" ($\equiv$) and the "Substitution Rule for Equality" ($Sub$).<br>Argue the correctness of these rules.<br></latex>	pg 5701, 4.3, 4.4<br>
Exercise 4.5, bottom of pg 5701<br>	<br>
<latex>~\\<br>Derive the following rule:\\<br>\begin{array}{ll}<br>\Gamma & \varphi \\<br>\hline<br>\Gamma & \exists x \varphi<br>\end{array}<br>when x is not free in $\varphi$<br></latex>	pg 5702, see pg 5700 for 4.1 and 4.2<br>
<latex>~\\<br>Derive the following rule:\\<br>\begin{array}{lll}<br>\Gamma & \phi & \psi \\<br>\hline<br>\Gamma & \exists x \phi & \psi<br>\end{array}<br></latex>	pg 5702. see pg 5700 for 4.1 and 4.2<br>
<latex>~\\<br>Derive the following rule:\\~\\<br>\begin{array}{lll}<br>\Gamma & ~ & \varphi \\<br>\hline<br>\Gamma & x \equiv t & \varphi \frac{t}{x}<br>\end{array}<br></latex>	pg 5702, 5.2<br><br>
<latex>~\\<br>Derive the following sequent calculus rule:\\~\\<br>\begin{array}{ll}<br>\Gamma & t_1 \equiv t_2 \\<br>\hline<br>\Gamma & t_2 \equiv t_1<br>\end{array}<br></latex>	pg 5702, 5.3 (a)<br>
<latex>~\\<br>Derive the following sequent calculus rule:\\~\\<br>\begin{array}{ll}<br>\Gamma & t_1 \equiv t_2 \\<br>\Gamma & t_2 \equiv t_3 \\<br>\hline<br>\Gamma & t_1 \equiv t_3<br>\end{array}<br></latex>	pg 5702, 5.3 (b)<br>
<latex>~\\<br>Derive the following sequent calculus rule, which applies for any n-ary $R \in S$:\\~\\<br>\begin{array}{ll}<br>\Gamma & R t_1 \ldots t_n \\<br>\Gamma & t_1 \equiv t'_1 \\<br>\vdots & ~ \\<br>\Gamma & t_n \equiv t_n' \\<br>\hline<br>\Gamma & R t'_1 \ldots t'_n<br>\end{array}<br></latex>	pg 5702, 5.4 (a)<br>
<latex>~\\<br>Derive the following sequent calculus rule, which applies for any n-ary $f \in S$:\\~\\<br>\begin{array}{ll}<br>\Gamma & t_1 \equiv t'_1 \\<br>\vdots & ~ \\<br>\Gamma & t_n \equiv t_n' \\<br>\hline<br>\Gamma & f t_1 \ldots t_n \equiv f t'_1 \ldots t'_n<br>\end{array}<br></latex>	pg 5702, 5.4 (b)<br>
<latex>~\\<br>Show that the following rules are derivable in sequent calculus:\\~\\<br>\begin{array}{ll}<br>\Gamma & \forall x \varphi \\<br>\hline<br>\Gamma & \varphi \frac{t}{x} \\<br>\end{array}<br>\\~\\~\\<br>\begin{array}{ll}<br>\Gamma & \forall x \varphi \\<br>\hline<br>\Gamma & \varphi<br>\end{array}<br></latex>	pg 5703, exercise 5.5 (a1) and (a2)<br>
<latex>~\\<br>Show that the following rules are derivable in sequent calculus, where $x$ is not free in $\Gamma$:\\~\\<br>\begin{array}{lll}<br>\Gamma & \varphi & \psi \\<br>\hline<br>\Gamma & \forall x \varphi & \psi \\<br>\end{array}<br>\\~\\~\\<br>\begin{array}{ll}<br>\Gamma & \varphi \\<br>\hline<br>\Gamma & \forall x \varphi<br>\end{array}<br></latex>	REMEMBER: Forall is treated as being derived from exists. Replace "forall x phi" with "not exists x. not phi"<br>pg 5703, exercise 5.5, (b3) and (b4)
Give the (Assm) (Ant), (PC), and (Ctr) rules of sequent calculus (no need to justify).<br>	pg 5703, section 6<br>
<latex>~\\<br>Give the $\vee A$, $\vee S$, $\exists A$, and $\exists S$ rules of sequent calculus.\\<br>Note that there are actually TWO $\vee S$ rules!!<br></latex><br>	pg 5703, section 6<br><br>
<latex>~\\<br>Give the $\equiv$ and $Sub$ rules of sequent calculus.<br></latex>	pg 5703, section 6<br><br>
<latex>~\\<br>Give syntax for Abel and Pientka's sizes, measures, size variable contexts, and any syntactic categories these depend on.<br></latex>	pg 9893, fig 2 at bottom<br>explanation on pg 9894 top<br>
<latex><br>In Abel and Pientka's notation, what \emph{kinds} do the notations $\leq a$ and $size$ desugar to?<br></latex>	pg 9894, middle of page<br>
<latex>~\\<br>Given a size context $\Psi$, what do Abel and Pientka use the notation $\fbox{\overset{~}{\hat{\Psi}}}$ to denote?<br></latex>	the variables bound by Psi.<br>pg 9894<br>
Take a gander at the "Size-related judgments" of Figure 3, pg 9894,<br>described in full detail on pg 9931<br><br>	<br>
<latex>~\\<br>What do Abel and Pientka mean when they say that size contexts $\Psi$ are always consistent?<br></latex>	For every size context, there exists some valuation of that context (by natural numbers even)<br>pg 9894<br>
<latex>~\\<br>What do judgments of the form $\Psi \vdash \exists \Psi'$ mean?<br></latex>	pg 9894, paragraph below fig 3<br>
<latex>~\\<br>Let $\eta$ be a finite map from size variables to natural numbers. Note that for size variables $a \in dom(\eta)$,<br>$\eta(a)$ is an extended size expression. What does $\eta \vDash \Psi$ mean?<br>What consitutes a \emph{minimal valuation} $val_\eta(\Psi)$ for $\Psi$ above $\eta$?<br></latex>	pg 9895, top<br>
<latex>~\\<br>Explain how propositions of the form $\Psi \vdash \exists \Psi'$ can be tested via the concept of \emph{minimal  <br>valuations}.<br></latex>	pg 9894 bottom paragraph,<br>pg 9895 top part<br>
Give the syntax of "simple kinds" (i.e. non-variance-annotated kinds).<br>	note that the kind "o" is for sizes.<br>pg 9895, figure 4, "SKind". also see first paragraph of section 3.2<br>
<latex>~\\<br>Give the "refined" kind syntax of $F^{cop}_{\omega}$.<br></latex>	<latex>~\\<br>pg 9895, near bottom<br>$\kappa ::= ...$<br></latex>
<latex>~\\<br>What do the four variance symbols $+,-,\top$,and $\circ$ mean? What partial ordering is defined upon them?<br></latex>	pg 9895 bottom / pg 9896 top<br>
Take a gander at figure 5 on pg 9896<br>	<br>
<latex>~\\<br>Describe the relation between kinding contexts $\Delta$ and size contexts $\Psi$.<br></latex>	pg 9896, middle paragraph<br>
<latex>~\\<br>Explain the meaning of a judgment $\Delta \vdash \exists \Delta'$.<br></latex>	pg 9896, second-to-bottom paragraph.<br>
<latex>~\\<br>Give the ``type-level lambda calculus'' syntax.<br></latex>	pg 9896, bottom paragraph. (figure 4 is on pg 9895)<br><br>
Take a gander at the short-hand notations at the top of pg 9897.<br>	<br>
<latex>~\\<br>Explain the notation $F~@^\iota~G$.<br></latex>	pg 9897, second paragraph<br>
<latex>~\\<br>Sized inductive $\mu^a S$ and coinductive types $\nu^a R$ are given in terms of \emph{variant rows} $S$ and \emph{record rows} $R$. What are variant rows and record rows?<br></latex>	pg 9897, middle<br>
<latex>~\\<br>What is a \emph{constrainted type} $\forall \Psi.~m < m' \Rightarrow A$? What are constrained types used for? What are \emph{measured types} and how do they relate to constrained types?<br></latex>	pg 9897<br>
Exercise 7.5, pg 5686<br>	<br>
<latex>~\\<br>What does the notation <br>$\varphi \frac{t_0 \ldots t_r}{x_0 \ldots x_r}$ mean?<br></latex>	pg 5687, near bottom<br>pg 5688, defs 8.1, 8.2<br><br><br><br>
Take a gander at the examples on pg 5688 bottom.<br>	pg 5688<br>
<latex>~\\<br>State the substitution lemma (no need to prove). The following notations may be helpful.<br><br>\[  \beta \frac{a_0 \ldots a_r}{x_0 \ldots x_r}(y) := \left\{<br>\begin{array}{ll}<br>      \beta(y) & \text{if } y \neq x_0, \ldots, y \neq x_r \\<br>      a_i & \text{if } y = x_i<br>\end{array} <br>\right. \]  <br><br>$$\mathcal J \frac{a_0, \ldots, a_r}{x_0, \ldots, x_r} := (\mathcal A, \beta \frac{a_0,\ldots,a_r}{x_0, \ldots, x_r})$$<br><br></latex>	pg 5689, lemma 8.3<br><br>
Take a gander at lemma 8.4, pg 5690 bottom / 5691 top<br>	<br>
<latex>~\\<br>Suppose $free(\varphi) \subset \{ x_0, \ldots, x_r \}$, where we assume that $x_0, \ldots, x_r$ are distinct.<br>Consider the following statement:\\~\\<br>For terms $t_0,\ldots,t_r$ such that $var(t_i) \subset \{ v_0, \ldots, v_{n-1} \}$, the formula $\varphi\frac{t_0 \ldots t_r}{x_0 \ldots x_r}$ is in $L_n^S$. In particular,<br>$\varphi \frac{c_0 \ldots c_r}{x_0 \ldots x_r}$ is a sentence.\\~\\<br>Prove or disprove<br></latex>	true. pg 5691, corollar 8.5
What is the <i>rank</i> of a first-order formula? Give an inductive definition.	pg 5691, def 8.6<br>
<latex>~\\<br>Let $\varphi$ be a formula, $t_0 \ldots t_r$ be terms, and $x_0 \ldots x_r$ be variables.<br>Consider the following statement:\\~\\<br>$rk(\varphi \frac{t_0 \ldots t_r}{x_0 \ldots x_r}) = rk(\varphi)$\\~\\<br>Prove or disprove.<br></latex>	pg 5692 top, lemma 8.7<br>todo: add impostor?
Exercise 8.8, ph 5692<br>	<br>
Exercise 8.9 (a) and (b), pg 5692 	<br>
Exercise 8.9 (c) and (d), pg 5692	<br>
Exercise 8.10, pg 5692<br>	<br>
Exercise 8.11, pg 5692<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $\Phi$ and $\varphi$, $\Phi \vdash \varphi$ if and only if there is a finite subset $\Phi_0$ of $\Phi$ such that $\Phi_0 \vdash \varphi$\\~\\<br>Prove or disprove<br></latex>	pg 5704, lemma 6.1<br>todo: add impostor
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $\Phi$ and $\varphi$, if $\Phi \vdash \varphi$ then $\Phi \vDash \varphi$.\\~\\<br>Is this true or false? Why? (No need to provide a full proof.)<br></latex>	pg 5704, theorem on the corectness of G<br>todo: add impostor<br>
<latex>~\\<br>What does it mean for the sequent calculus $\frak{G}$ to be \emph{correct}?<br></latex>	pg 5704, theorem on the correctness
<latex>~\\ <br>The semantic concept $\vDash$ of the consequence relation corresponds to the syntactic concept $\vdash$ of derivability. What is the syntactic counterpart to satisfiability, and why?<br></latex>	pg 5706 top
<latex>~\\<br>Let $\Phi$ be a set of formulas. What does it mean for $\Phi$ to be \emph{consistent}? What does it mean for $\Phi$ to be \emph{inconsistent}?<br></latex>	pg 5706, def 7.1 
<latex>~\\<br>Let $\Phi$ be a set of formulas. Consider the following statement:\\~\\<br>The following are equivalent:<br>\begin{enumerate}<br>\item Inc~$\Phi$<br>\item For all $\varphi$: $\Phi \vdash \varphi$<br>\end{enumerate}<br>Prove or disprove.<br></latex>	true. pg 5706, lemma 7.2<br>todo: add impostor.<br>
<latex>~\\<br>Let $\Phi$ be a set of formulas. Consider the following statement:\\<br>The following are equivalent:<br>\begin{enumerate}<br>\item Con $\Phi$<br>\item There is a formula $\varphi$ which is not derivable from $\Phi$<br>\end{enumerate}<br>Prove or disprove.<br></latex>	true. pg 5706, cor 7.3 near bottom.<br>todo: add impostor<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $\Phi$, Con $\Phi$ if and only if Con $\Phi_0$ for all finite subsets $\Phi_0$ of $\Phi$.\\~\\<br>Prove or disprove.<br></latex>	true. lemma 7.4 at bottom of pg 5706<br>todo: add impostor<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every satisfiable set of formulas is consistent.\\~\\<br>Prove or disprove.<br></latex>	true. pg 5707, lemma 7.5 at top.<br>todo: add impostor
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $\Phi$ and $\varphi$ with Con $\Phi$ the following holds:\\<br>$\Phi \vdash \varphi$ iff Inc $\Phi \cup \{ \neg \varphi \}$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5707, lemma 7.6 (a)
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $\Phi$ and $\varphi$ with Con $\Phi$ the following holds:\\<br>$\Phi \vdash \neg \varphi$ iff Inc $\Phi \cup \{ \varphi \}$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5707, lemma 7.6 (b)
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $\Phi$ and $\varphi$ with Con $\Phi$ the following holds:\\<br>Con $\Phi \cup \{ \varphi \}$ or Con $\Phi \cup \{ \neg \varphi \}$\\~\\<br>Prove or disprove.<br></latex>	pg 5707, lemma 7.6 (c)<br>todo: add impostor<br>
<latex>~\\<br>For $n \in \mathbf{N}$, let $S_n$ be symbol sets such that <br>$$S_0 \subset S_1 \subset S_2 \subset \ldots$$<br>and let $\Phi_n$ be sets of $S_n$-formulas such that $Con_{S_n}~\Phi_n$ and<br>$$\Phi_0 \subset \Phi_1 \subset \Phi_2 \ldots$$ <br>Let $S = \bigcup_{n \in \mbf{N}} S_n$ and $\Phi = \bigcup_{n \in \mbf{N}} \Phi_n$<br>Consider the following statement:\\~\\<br>Con_S $\Phi$\\~\\<br>Prove or disprove.<br></latex>	true. lemma 7.7, pg 5708<br>todo: add impostor?<br>
Exercise 7.8, pg 5708<br>	<br>
<latex>~\\<br>What does it mean for a set $\mathbb S$ to be \emph{equipollent with a set of $\mathcal C_i$}?<br></latex>	<latex>~\\<br>pg 9184\\<br>For definition of $\cong$, see bottom of pg 9180, top of pg 9181<br></latex><br>
<latex>~\\<br>Let $\mathbb A \rTo^{f} \mathbb B$ be a functor. Consider the following statement:\\~\\<br>For every pair of objects $\mbf{1} \pile{\rTo^{a} \\ \rTo_{a'}}  \mathbb A$ in $\mathbb A$,<br>there is an induced map<br>$$(a, a') \rTo (af,a'f')$$<br>Elaborate on this.<br></latex>	<latex>~\\<br>pg 9184\\<br>not really explained, but (a,a') is the homset of all arrows from a to a' in $\mathbb A$,<br>and (af,a'f') is the homset of all arrows between af and a'f' in $\mathbb B$.<br></latex>
<latex>~\\<br>Let $\mathbb A \rTo^f \mathbb B$ be a functor in the category of categories. What does it mean for $f$ to be $\mbf{full}$? $\mbf{faithful}$? $\mbf{dense}$?<br></latex>	pg 9184, second definition<br>
<latex>~\\<br>If $\mathbb A \rTo^{f} \mathbb B$ and $\mathbb B \rTo^g \mathbb A$, what does it mean for $g$ to be \emph{adjoint to} $f$?<br></latex>	pg 9185, definition near bottom<br>
<latex>~\\<br>If $\langle x, b, a, x' \rangle$ is a typical map in $(\mathbb B, f)$ (i.e. bx' = x(af)), then  <br>is $\langle x,b,a,x' \rangle \overline{f} = \underline{~~~~~~~~~~}$\\<br>Fill in the blank.<br></latex>	<latex>~\\<br>$\langle b,a \rangle$<br>pg 9185\\<br>this is essentially the definition of $\overline{f}$<br></latex><br>
<latex>~\\<br>We would like to prove:\\<br>(*) For all $\Phi$ and $\varphi$: If $\Phi \vDash \varphi$ then $\Phi \vdash \varphi$\\~\\<br>Suppose we know:\\<br>(**) Every consistent set of formulas is satisfiable\\~\\<br>Show that $(**) \Rightarrow (*)$\\<br></latex>	use contrapositive<br>pg 5709, introduction<br><br>
<latex>~\\<br>Let $\Phi$ be a consistent set of formulas. Suppose that we're trying to find an interpretation $\frak J = (\frak A, \beta)$ satisfying $\Phi$. We have at our disposal only the "syntactical" information given by the consistency of $\Phi$. Hence, we shall try to obtain a model using syntactical objects as far as possible. A first idea is to take as domain $A$ the set $T^S$ of all $S$-terms, to define $\beta$ by $$\beta(v_i) := v_i~(i \in \mbf{N})$$ <br>and to interpret, for instance, a unary function symbol $f$ by $$f^{\frak A}(t) := ft$$<br>and a unary relation symbol $R$ by $$R^{\frak A} := \{ t \in A \mid \Phi \vdash R t \}$$<br>Then, for a variable $x$ we have $\frak J(fx) = f^{\frak A}(\beta(x)) = f x$. What is wrong with<br>this approach?<br></latex>	pg 5710, top
<latex>~\\<br>Let $\Phi$ be a set of formulas. To define an interpretation $\frak J^\Phi = (\frak T^\Phi, \beta^\Phi)$,<br>we use a helper binary relation $\sim$ on the set $T^S$ of $S$-terms, defined as:\\~\\<br>$t_1 \sim t_2~~~~~\text{:iff}~~~~~\Phi \vdash t_1 \equiv t_2$\\~\\<br>Consider the following statement:\\~\\<br>$\sim$ is an equivalence relation\\~\\<br>Prove or disprove<br></latex>	true. pg 5710<br>
<latex>~\\<br>Let $\Phi$ be a set of formulas. To define an interpretation $\frak J^\Phi = (\frak T^\Phi, \beta^\Phi)$,<br>we use a helper binary relation $\sim$ on the set $T^S$ of $S$-terms, defined as:\\~\\<br>$t_1 \sim t_2~~~~~\text{:iff}~~~~~\Phi \vdash t_1 \equiv t_2$\\~\\<br>Consider the following statement:\\~\\<br>$\sim$ is compatible with the symbols in $S$ in the following sense:\\<br>If $t_1 \sim t'_1, \ldots, t_n \sim t'_n$ then for n-ary $f \in S$<br>$$f t_1 \ldots t_n \sim f t'_1 \ldots t'_n $$<br>and for $n$-ary $R \in S$<br>$$\Phi \vdash R t_1 \ldots t_n~~~~~\text{iff}~~~~~\Phi \vdash R t'_1 \ldots t'_n$$\\<br>Prove or disprove<br></latex>	true. pg 5710.<br>todo: add impostor?<br>
<latex>~\\<br>Let $\Phi$ be a set of formulas. How do we define the interpretation $\frak J^\Phi = (\frak T^\Phi, \beta^\Phi)$?<br></latex>	pg 5710 near bottom (1.3, 1.4)<br>pg 5711 near top (1.5, 1.6)<br>note that this refers to 1.1 and 1.2 on pg 5710<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $t$, $\frak J^\Phi(t) = \overline{t}$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5711<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For every atomic formula $\varphi$,<br>$$\frak J^\Phi \vDash \varphi~~~~~\text{iff}~~~~~\Phi \vdash \varphi$$<br>Prove or disprove.<br></latex>	true. pg 5711<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For every formula $\varphi$ and pairwise distinct variables $x_1, \ldots, x_n$,<br>\begin{enumerate}<br>\item $\frak J^\Phi \vDash \exists x_1 \ldots \exists x_n \varphi~~~~~\text{iff}~~~~~<br>  \text{there are } t_1, \ldots, t_n \in T^S \text{ with } \frak J^\Phi \vDash \varphi\frac{t_1 \ldots t_n}{x_1 \ldots x_n}$<br>\item $\frak J^\Phi \vDash \forall x_1 \ldots \forall x_n \varphi~~~~~\text{iff}~~~~~\text{for all terms } t_1, \ldots, t_n \in T^S, \frak J^\Phi \vDash \varphi \frac{t_1 \ldots t_n}{x_1 \ldots x_n}$<br>\end{enumerate}<br>Prove or disprove.<br></latex>	true. pg 5711<br>
<latex>~\\<br>What does it mean for a set of formulas $\Phi$ to be \emph{negation complete}?<br></latex><br>	pg 5712, def 1.8 (a)<br>
<latex>~\\<br>What does it mean for a set of formulas $\Phi$ to \emph{contain witnesses}?<br></latex>	pg 5712, def 1.8 (b)<br>
<latex>~\\<br>Suppose that $\Phi$ is consistent and negation complete and that it contains witnesses. Let $\varphi$ be a formula. Consider the following statement:\\~\\<br>$\Phi \vdash \neg \varphi$ iff not $\Phi \vdash \varphi$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5712, lemma 1.9 (a)<br>todo: add impostor?<br>
<latex>~\\<br>Suppose that $\Phi$ is consistent and negation complete and that it contains witnesses. Let $\varphi$ and $\psi$ be formulas. Consider the following statement:\\~\\<br>$\Phi \vdash \varphi \vee \psi$ if and only if $\Phi \vdash \varphi$ or $\Phi \vdash \psi$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5712 1.9 (b)<br>todo: add impostor?<br>
<latex>~\\<br>Suppose that $\Phi$ is consistent and negation complete and that it contains witnesses. Let $\varphi$ be a formula. Consider the following statement:\\~\\<br>$\Phi \vdash \exists x \varphi$ if and only if there is a term $t$ with $\Phi \vdash \varphi\frac{t}{x}$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5712, lemma 1.9 (c)<br>todo: add impostor?<br>
State and prove Henkin's Theorem.<br>	pg 5712, 1.10 near bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Let $\Phi$ be a set of formulas. Then for all $\varphi$,<br>$$\frak J^\Phi \vDash \varphi~~~~~\text{iff}~~~~~\Phi \vdash \varphi$$<br>Prove or disprove.<br></latex>	<latex><br>IMPOSTOR. This is only true when $\varphi$ is a primitive formula or when $\Phi$ is <br>negation complete and contains witnesses. see pg 5712<br></latex>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\Phi$ is a consistent set which is negation complete and contains witnesses, then $\frak J^{\Phi} \vdash \Phi$, and hence $\Phi$ is satisfiable.\\~\\<br>Prove or disprove. (Yes, you may reference other theorems)<br></latex>	pg 5713<br>
Exercise 1.12, pg 5713<br>	<br>
Exercise 1.13, pg 5713<br>	<br>
<latex>~\\<br>Let $S$ be at most countable, $\Phi \subset L^S$ be consistent, and let $free(\Phi)$ be finite. Consider the following statement:\\~\\<br>There is a consistent set $\Psi$ such that $\Phi \subset \Psi \subset L^S$ and $\Psi$ contains witnesses.\\~\\<br>Prove or disprove.<br></latex>	true. lemma 2.1, pg 5714.<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $S$ be at most countable, and $\Psi \subset L^S$ be consistent. Consider the following statement:\\~\\<br>There is a consistent, negation complete set $\Theta$ with $\Psi \subset \Theta \subset L^S$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 5714, lemma 2.2<br>todo: add impostor?<br>
<latex>~\\<br>Let $\Phi$ be consistent and let $free(\Phi)$ be finite. Consider the following statement:\\~\\<br>$\Phi$ is satisfiable\\~\\<br>Prove or disprove.<br></latex>	true. pg 5714, corollary 2.3<br>todo: add impostor?<br>
<latex>~\\<br>Let $S$ be at most countable and $\Phi \subset L^S$ be consistent. Consider the following statement:\\~\\<br>$\Phi$ is satisfiable.\\~\\<br>Prove or disprove.<br></latex>	true. pg 5715, thm 2.4<br>todo: add impostor?<br>
Exercise 2.5, pg 5716<br>	<br>
<latex>~\\<br>Assume $\Phi \subset L^ S$ with $Con_S \Phi$. Consider the following statement:\\~\\<br>There is an $S' \supset S$ and a set $\Psi$ such that $\Phi \subset \Psi \subset L^{S'}$<br>and $Con_{S'} \Psi$, and $\Psi$ contains witnesses with respect to $S'$ (i.e. for every formula of the form<br>$\exists x \varphi \in L^{S'}$ there is a term $t \in T^{S'}$ such that $\Psi \vdash (\exists x \varphi \to \varphi \frac{t}{x})$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5717, lemma 3.1<br>
<latex>~\\<br>Let $\Psi \subset L^S$ with $Con_S \Psi$. Consider the following statement:\\~\\<br>There is a set $\Theta$ such that $\Psi \subset \Theta \subset L^S$ and<br>$\Theta$ is consistent and negation complete with respect to $S$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 5717, lemma 3.2<br>todo: add impostor?
<latex>~\\<br>Let $\Phi \subset L^S$ and $Con_S \Phi$. Consider the following statement:\\~\\<br>$\Phi$ is satisfiable.\\~\\<br>Prove or disprove.<br></latex>	pg 5717, cor 3.3
<latex>~\\<br>Let $S$ be an arbitrary symbol set. Associate with every $\varphi \in L^S$ a constant $c_{\varphi}$ which is not in $S$. For $\varphi \neq \psi$ let $c_{\varphi} \neq c_\psi$. We set<br>$$S^* := S \cup \{ c_{\exists x \varphi} \mid \exists x \varphi \in L^S \}$$<br>and<br>$$ W(S) := \{ (\exists x \varphi \to \varphi \frac{c_{\exists x \varphi}}{x}) \mid \exists x \varphi \in L^S \} $$<br>Consider the following statement\\~\\<br>For $\Phi \subset L^S$, if $Con_S \Phi$ then $Con_S^* \Phi \cup W(S)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 5717 3.4<br>todo: add impostor<br>
<latex>~\\<br>Derive $A \supset (B \supset (A~\&~B))$ using intuitionistic type theory.<br></latex>	pg 6512, example near bottom<br>
<latex>~\\<br>The rule of $\Sigma$-elimination says that any function $d(x,y)$ with arguments in $A$ and $B(x)$ gives<br>also a function (with the same values, by $\Sigma$-equality) with a pair in $(\Sigma x \in A)~B(x)$ as a single argument. Let's prove an axiom corresponding to this rule.\\~\\<br>Assume $A~set$, $B(x)~set~(x \in A)$, $C(z)~set~(z \in (\Sigma x \in A)~B(x))$ and let $f \in (\Pi x \in A) (\Pi y \in B(x)) c((x,y))$.\\~\\<br>Demonstrate an element of <br>$$(\Pi x \in A) (\Pi y \in B(x)) C((x,y)) \to (\Pi z \in (\Sigma x \in A) B(x)) C(z)$$<br>The convenient definition $Ap(f,x,y) \equiv Ap(Ap(f,x),y)$ will be useful.<br></latex>	pg 6513, example.<br>
State the axiom of choice in the language of intuitionistic type theory. Give a proof of the axiom of choice in intuitionistic type theory.	pg 6514<br>
In ZF set theory, there is an axiom called the "comprehension axiom". Explain how the comprehension axiom manifests in intuitionistic type theory.	pg 6515 ("the notion of such that")<br>
Give the formation rule for disjoint unions in intuitionistic type theory.	pg 6516, +-formation<br><br>
Give the four introduction rules for disjoint union (+) in intuitionstic type theory.	pg 6516<br>
Give the elimination rule for disjoint union (+) in intuitionistic type theory. Explain its "execution strategy".	pg 6517<br>
Give the two equality rules for disjoint union (+) in intuitionistic type theory.<br>	pg 6517, +-equality<br><br>
<latex>~\\<br>We define disjunction by including in our definitional equality the equation<br>$$A \vee B \equiv A + B$$<br>Derive $\vee$-formation, $\vee$-introduction, and $\vee$-elimination from the corresponding<br>rules for disjoint sums.<br></latex>	pg 6517 bottom half,<br>pg 6518 top<br>
<latex>~\\<br>What does $I(A,a,b)$ denote in intuitionistic type theory?<br></latex>	pg 6518, "propostional equality"<br>
Enumerate the four kinds of equality of intuitionistic type theory and discuss the differences between them.<br>	pg 6519, top<br><br>
Give the I-formation rule.<br>	pg 6519<br>
Give and explain the I-introduction rule.	pg 6519, I-introduction
Give and explain the I-elimination rule.	pg 6519 (make sure to read the description of what r is if you weren't able to explain it)<br>
Give and explain the I-elimination rule.<br>	pg 6519, near bottom<br><br>
Give and explain the I-equality rule.<br>	pg 6519, near bottom (if you're wondering what r is, read the pagraph below I-formation)<br>
Indexed families of sets of the form B(x) arise frequently in intuitionistic type theory. How do we construct such sets in the first place?	pg 6519 bottom paragraph<br>
Read the "introductory axiom of identity" at the top of pg 6520.<br>	<br>
<latex><br>Leibniz's principle of indescernibility says that equal elements satisfy the same properties. It can be stated in intuitionistic type theory as<br>$$(\forall x \in A) (\forall y \in A) (I(A,x,y) \supset (B(x) \supset B(y)))~true$$<br>Prove this in intuitionisitic type theory.<br></latex>	pg 6520<br>
<latex>~\\<br>Eta-equality for pairs is stated in intuitionistic type theory with the following rule.<br>\begin{mathpar}<br>\inferrule<br>  {c \in (\Sigma x \in A) B(x)}<br>  {c = (p(c),q(c)) \in (\Sigma x \in A) B(x)}<br>\end{mathpar}<br>Derive this rule.<br></latex>	pg 6520 bottom / 6521 top<br>
<latex>~\\<br>There are two ways of expressing subsets of a set $B$ in intuitionistic type theory. State these two ways and prove them equivalent.<br></latex>	pg 6521, near bottom<br>
<latex>~\\<br>Give the formation rule for $\mathbb N_n$, which is a finite set of n elements.<br></latex>	pg 6522... it's trivial, there are no premises<br>
<latex>~\\<br>Give the introduction rule for elements of the set $\mathbb N_n$.<br></latex>	pg 6522<br>
<latex>~\\<br>Give a "definitional equality definition" for $\bot$ in intuitionistic type theory.<br>Also explain its elimination rule.<br></latex>	pg 6522/6523<br>
<latex>~\\<br>Give a "definitional equality" definition of $\top$. Derive the following inference rule<br>\begin{mathpar}<br>\inferrule<br>  {c \in \top}<br>  {c = \ast \in \top}<br>\end{mathpar}<br>Where $\ast$ represents the sole element of $\top$.<br></latex>	pg 6523, lower half<br><br>
<latex><br>How do we represent the set of booleans in intuitionistic type theory?<br></latex>	pg 6542 top<br>
<latex><br>How do we represent propositional negation in intuitionistic type theory?<br></latex>	pg 6524, "Example (negation)"<br><br>
<latex><br>Explain the difference between "metamathematical consistency" and "simpleminded consistency", as defined by Martin-Lof. Which view of consistency did Martin-Lof use for intuitionistic type theory, and why?<br></latex>	pg 6524/6525<br>Simple-minded consistency is ultimately more significant, because the buck has to stop somewhere.<br><br>
<latex><br>Give the formation and introduction rules for the set of natural numbers $\mathbb N$<br></latex><br>	pg 6525<br>
<latex><br>Give the two equality rules for the set of natural numbers $\mathbb N$.<br></latex>	pg 6526<br>
<latex>~\\<br>Give the elimination form for the set of natural numbers $\mathbb N$, and give its "execution strategy".<br></latex>	pg 6525, N-elim<br>
<latex>~\\<br>"In intuitionistic type theory, recursion an induction turn out to be the same concept when propositions are interpreted as sets"<br>Give a formal justification for this claim.<br></latex>	pg 6526 "mathematical induction"<br>
<latex><br>Give a "definitional equality" definition for the predecessor function on natural numbers.<br>Use this definition to derive the third Peano axiom:<br>\begin{mathpar}<br>\inferrule<br>  {a' = b' \in \mathbb N}<br>  {a = b \in \mathbb N}<br>\end{mathpar}<br></latex>	pg 6526/6525<br><br>
<latex>~\\<br>Give the "definitional equality" definition of addition. Use this definition to derive the following rules:<br>\begin{mathpar}<br>\inferrule<br>  {a \in \mathbb N \\ b \in \mathbb N}<br>  {a + b \in \mathbb N}<br>\and<br>\inferrule<br>  {a \in \mathbb N}<br>  {a + 0 = a \in \mathbb N}<br>\and<br>\inferrule<br>  {a \in \mathbb N \\ b \in \mathbb N}<br>  {a + b' = (a + b)' \in \mathbb N}<br>\end{mathpar}<br></latex>	pg 6527, "Example (addition)"<br>
<latex>~\\<br>Give a "definitional equality" definition of addition on elements of the set $\mathbb N$, and then give another "definitional equality" definition of multiplication on top of this.<br></latex>	pg 6527, "Example (addition)" and "Example (multiplication)"<br>
<latex>~\\<br>Read and understand "the bounded $\mu$ operator" section on pg 6527/6528<br></latex><br>	pg 6527/6528<br>todo: with a better understanding of what this stuff even is, it may be worthwhile to create some additional cards on the topic...maybe<br>
<latex>~\\<br>Give the formation rule for the set $List(A)$.<br></latex>	pg 6529<br>
<latex>~\\<br>Give the two introduction rules for the set $List(A)$.<br></latex>	pg 6529<br>
<latex>~\\<br>Give the elimination rule for $List(A)$, along with its "execution strategy".<br></latex><br>	pg 6529<br>
<latex>~\\<br>Give the two $List$-equality rules.<br></latex>	pg 6529, near bottom<br>
<latex>~\\<br>Give the $\mathcal W$-formation rule. \\<br>What does it mean for $c$ to be an element of the set $(\mathcal W x \in A) B(x)$?<br></latex>	pg 6530<br>
<latex>~\\<br>Give the $\mathcal W$-introduction rule. Explain how the notation $sup(a,b)$ is used to develop intuitionistic ordinals.<br></latex>	pg 6530<br>
<latex>~\\<br>Discuss some of the fundamental differences between Martin-Lof's intuitionistic ordinals and standard set theoretic ordinals.<br></latex>	the set theoretic ordinals are totally ordered, while intuitionistic ordinals are partially ordered.<br>pg 6530<br>
<latex>~\\<br>Give the $\mathcal W$-elimination rule and explain its "execution strategy".<br></latex>	pg 6531 -- you'll want to start reading at the top of the page.<br>the first inference rule listed is an intuitive, readable version of the formal rule.<br>
<latex>~\\<br>Give and explain the $\mathcal W$-equality rule.<br></latex>	pg 6532 top<br>you will probably have to read the entirety of pg 6531 if you've forgotten how this works.<br>
<latex>~\\<br>What is Cantor's "first number class", and how can it be encoded in Martin-Lof-style intuitionistic ordinals?<br></latex>	pg 6532, "Example (the first number class)"<br>
<latex>~\\<br>Give the $\mathcal O$-formation rule.<br></latex>	pg 6532<br>
<latex>~\\<br>Give the three $\mathcal O$-introduction rules. Explain how to derive the rules in terms of rules for $\mathcal W$.<br></latex>	pg 6533<br>
<latex>~\\<br>Give the $\mathcal O$-elimination rule, and give its "execution strategy". Then derive it in terms of $\mathcal W$ rules.<br></latex>	pg 6533<br>
<latex>~\\<br>Consider the following judgment:\\<br>$$(\exists x \in A) \neg B(x) \to (\mathcal W x \in A) B(x)~true$$<br>Explain this judgment intuitively and then provide a formal proof.<br></latex>	pg 6534, "Example (initial elements of wellorderings)"<br>
<latex>~\\<br>Consider the following statement:\\<br>$$(\mathcal W x \in A) B(x) \to \neg(\forall x \in A) B(x)$$<br>Explain this statement intuitively and then give a formal proof.<br></latex>	pg 6534<br>
<latex>~\\<br>It's useful in mathematics to have sets of sets, for instance, in category theory. How does intuitionistic type theory accomodate sets of sets? Martin-Lof presents two alternative solutions, give a brief summary of each.<br></latex>	pg 6535<br>
<latex>~\\<br>Give and explain the Tarski-style U-formation rule.<br></latex>	pg 6535, near bottom<br><br>
<latex>~\\<br>Give the Tarski-style $U$-introduction rules for:<br>\begin{itemize}<br>\item $\Pi$-sets<br>\item $\Sigma$-sets<br>\item $+$-sets<br>\end{itemize}<br></latex>	pg 6536, near top<br>
<latex>~\\<br>Using Tarski-style universes, in order to transition from level 1 (sets of sets) to level 2 (sets of sets of sets), we must add two new introduction rules and equality rules. Give and explain these rules.<br></latex>	pg 6536<br>
<latex>~\\<br>Give the $U$-formation rule for Russel-style universes.<br></latex><br>	pg 6536, bottom<br>
<latex>~\\<br>Give the $U$-introduction rules for Russel-style universes.<br></latex>	pg 6537
<latex>~\\<br>What does it mean for a set in intuitionistic type theory to be \emph{small}?<br></latex>	pg 6537<br>
<latex>~\\<br>Derive Peano's fourth axiom ($(\forall x \in \mathbb N) \neg I(\mathbb N, 0, x')~true$) in intuitionistic type theory, using Tarski-style universes.<br></latex>	pg 6537<br>
<latex>~\\<br>Suppose that for some functor $\mathbb A \rTo^f \mathbb B$, there exists a functor $\mathbb B \rTo^g \mathbb A$ such that $g$ is adjoint to $f$. Consider the following statement:\\~\\<br>For every object $B \in |\mathbb B|$ there exists an object $A \in |\mathbb A|$ and a map $B \rTo^{\varphi} Af$ in $\mathbb B$ such that for every object $A' \in |\mathbb A|$ and every map $B \rTo^x A'f$ in $\mathbb B$, there exists a unique map $A \rTo^y A'$ in $\mathbb A$ such that $x = \varphi(yf)$ in $\mathbb B$:<br>\begin{diagram}<br>B & \rTo^{\varphi} & Af \\<br>   & \rdTo_{x}   & \dDashto>{yf} \\<br>   &                  & A'f<br>\end{diagram}<br>Prove or disprove.<br></latex>	true. pg 9186, down to the start of the last paragraph<br>todo: add impostor?<br>
<latex>~\\<br>Suppose that $\mathbb A$ and $\mathbb B$ are categories, and $\mathbb A \rTo^f \mathbb B$ is a functor.<br>Further suppose that for every object $B \in |\mathbb B|$ there exists an object $A \in |\mathbb A|$ and a map $B \rTo^{\varphi} Af$ in $\mathbb B$ such that for every object $A' \in |\mathbb A|$ and every map $B \rTo^x A'f$ in $\mathbb B$, there exists a unique map $A \rTo^y A'$ in $\mathbb A$ such that $x = \varphi(yf)$ in $\mathbb B$:<br>\begin{diagram}<br>B & \rTo^{\varphi} & Af \\<br>   & \rdTo_{x}   & \dDashto>{yf} \\<br>   &                  & A'f<br>\end{diagram}<br>Consider the following statement\\~\\<br>There exists a functor $\mathbb B \rTo^g \mathbb A$ such that $g$ is adjoint to $f$.\\~\\<br>Prove or disprove<br></latex>	true. pg 9816 bottom paragraph / pg 9187 to end of proof<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any functor $f$, there is up to equivalence at most one $g$ such that $g$ is adjoint to $f$.<br>If $g$ is adoint to $f$ and $g'$ is adjoint to $f'$ where <br>$$\mathbb A \rTo^f \mathbb B \rTo^{f'} \mathbb C$$<br>then $g'g$ is adjoint to $ff'$. Further if $g$ is adjoint to $f$ and $t$ is co-adjoint to $g$, then<br>$t$ is equivalent to $f$.\\~\\<br>Prove or disprove.<br></latex>	This is a corollary to Theorem 1 on pg 9186.<br>The corollary is stated on pg 9187.<br>
<latex>~\\<br>Suppose that $\mathbb A$ and $\mathbb B$ are categories, and $\mathbb A \rTo^f \mathbb B$ is a functor.<br>Further suppose that for every object $B \in |\mathbb B|$ there exists an object $A \in |\mathbb A|$ and a map $B \rTo^{\varphi} Af$ in $\mathbb B$ such that for every object $A' \in |\mathbb A|$ and every map $B \rTo^x A'f$ in $\mathbb B$, there exists a unique map $A \rTo^y A'$ in $\mathbb A$ such that $x = \varphi(yf)$ in $\mathbb B$:<br>\begin{diagram}<br>B & \rTo^{\varphi} & Af \\<br>   & \rdTo_{x}   & \dDashto>{yf} \\<br>   &                  & A'f<br>\end{diagram}<br>We define a functor $\mathbb B \rTo^g \mathbb A$ as follows:<br>For each $B \in |\mathbb B|$, choose a pair $\langle A, \varphi \rangle$ satisfying the above conditions,<br>define $Bg \doteq A$. Then the above conditions uniquely determine $g$'s mapping on arrows. Explain.<br></latex>	<latex><br>\begin{diagram}<br>B         & \rTo^\varphi      & Af \\<br>\dTo<z &                        & \dDashto>{y_{z \varphi_0}} f \\<br>B_0     & \rTo^{\varphi_0} &  A_0 f  <br>\end{diagram}<br>Set $gz \doteq y$.<br></latex><br><br>This question arose from the sentence at the very bottom of pg 9186.<br>(search tags: extension)<br>
<latex><br>According to Lawvere, if $\mathbb A \rTo^f \mathbb B$ and $\mathbb B \rTo^g \mathbb A$, then we say $g$ is \emph{adjoint} to $f$ (and $f$ is \emph{coadjoint} to g) iff there exists an isomorphism $h$ rendering commutative the triangle of functors<br>\begin{center}<br>\begin{tikzcd}<br>(\mathbb{B}, f) \arrow[rr, "h", dashrightarrow] \arrow[dr, "\overline{f}" below]  & & \arrow[dl, "\overline{g}" below] (g, \mathbb{A}) \\<br>   &   \mathbb{B} \times \mathbb{A} &                <br>\end{tikzcd}<br>\end{center}<br>Why is this equivalent to the "two triangles" definition of adjunction used by Awodey?<br></latex>	<latex><br>This is a straightforward consequence of Theorem 1, at the top of pg 9186. It would almost be evident looking at the diagram; however, the problem is that $A$'s identity (in the sense of masked superheroes) is not revealed until the proof. \\~\\<br>The identity of $A$ is...... $Bg$! But then theorem 1 is clearly Awodey's version of adjunctions, and $\varphi$ is the unit of the adjunction at object $B$. $g$ is the left adjoint and $f$ is the right adjoint.<br></latex>
Describe the <i>class definition expression</i>.	pg 9938<br>
Give the type and term syntaxes of the source language for tagged object calculus.<br>	pg 9938, fig 1<br>
Give source code (in tagged object calculus) for defining and instantiating a counter class with a single increment method.<br>	pg 9938<br>
In tagged object calculus, a variable rather than an expression is required in the parent position of an extends-style class expression. Why is this?	pg 9939<br>
Give source code for extending a counter class (called Counter, with a single increment method) with an additional reset method, which takes the counter back to 0.<br>	pg 9939<br>
Explain tagged object calculus' <i>new</i> expression form.<br>	pg 9939, below code snippet<br>
Explain how tagged object calculus' <i>match</i> expression form works.<br>	pg 9939, starting at middle of page<br>
The match expression form of tagged object calculus subsumes two constructs from Java-style object-oriented languages. What are these constructs? Explain.	pg 9939<br>
Explain how tagged object calculus can be used to implement a map datatype which statically prevents any entry from being shared by multiple maps. Give example code.	pg 9940<br>
Explain the <i>memento</i> design pattern. Give source code for implementation of the memento pattern in tagged object calculus, where a dynamically generated family of classes each has a separate, dynamically-generated memento class.<br><br>	pg 9940
What is a mixin? Consider a window-based GUI system. We want to have a mixin for making windows bordered and also a mixin for making windows scrollable. Give a rough outline of implementing these mixins in tagged object calculus.<br>	pg 9941<br>
Read the snippet at the bottom of pg 9941 / top of pg 9942.<br>It gives a good feel for why first-class classes are useful.<br>	pg 9941<br>
Why are dependent sum types included in the tagged object core syntax?<br>	pg 9942, bottom paragraph<br><br>
Why does the tagged object calculus core syntax include dependent function types?<br>	pg 9942, second-to-bottom paragraph<br>"Our function types are dependent so that we can define functions that act like functors, accepting a tag as an argument and producing a subtag of the argument as a result." (i.e. mixins, I think)<br>
Explain the <i>newtag</i> construct of the tagged object core calculus.<br>	pg 9943<br>
Explain how <i>tagged values</i> work in tagged object calculus.	pg 9943, second paragraph<br>
<latex><br>In tagged object core calculus, what is the $\Sigma$ environment used for?<br></latex>	pg 9943, in 4th paragraph<br>
What is the syntactic class of <i>names</i> used for in core tagged object calculus? Give its full syntax.<br>	pg 9943, 4th paragraph<br>pg 9942, figure 2
Explain core tagged object calculus' <i>subtag</i> expression form.	pg 9943, 4th paragraph.<br><br>
How does core tagged object calculus' <i>match</i> expression form work?	pg 9943<br>
Explain how "nullable" types (i.e. T + 1) can be implemented using core tagged object calculus.<br>	pg 9944, right below figure 3<br><br>
<latex>~\\<br>Give the syntax for tagged object core calculus. As a hint, the syntactic categories are:<br>$n, e, \tau, Tag(\tau), \Gamma, \Sigma, \Delta$<br></latex>	pg 9942, figure 2<br><br>
Give the typing rules (ST-Amber-1) and (ST-Amber-2) for core tagged object calculus' iso-recursive subtyping.<br>	pg 9944
Give the ST-Fun subtyping rule for core tagged object calculus.	( They have misnamed it (ST-App) )<br>pg 9944, figure 3<br>
Give the ST-Tag-1, ST-Tag-2, and ST-Tag-3 rules for subtyping in core tagged object calculus.<br>(knowning which one is which is not important)<br>	pg 9944<br>(second paragraph of the next page has an explanation)<br>
Give the typing rules for the <i>newtag</i>, <i>subtag</i>, and <i>new</i> expression forms of the tagged object core calculus.	pg 9946<br>
Give the typing rules for the <i>match</i> and <i>extract</i> expression forms of the tagged object core calculus.<br>	pg 9946<br>
<latex><br>Translate Lawvere's term "inverse limits" into modern terminology.<br></latex>	confusingly, "inverse limits" translates to "limits", and "direct limits" translates to "colimits".<br>probably has something to do with limits in order theory, analysis, etc. Things called "limits" are typically actually colimits.<br><br>
<latex>~\\<br>According to Lawvere's definition, when is a category $\mathbb A$ said to have \emph{limits} over $\mathbb D$? When is $\mathbb A$ considered to have \emph{colimits} over $\mathbb D$?<br></latex>	pg 9188, top<br>limits = inverse limits<br>colimits = direct limits
<latex>~\\<br>What does Lawvere use the notation $${\lim_{\leftarrow \mathbb D}^{}}^{~\mathbb A}$$ for?<br></latex>	<latex><br>The coadjoint to the constant functor generator $\mathbb A \rTo \mathbb A^{\mathbb D}$<br>pg 9188, top<br></latex>
Explain how Lawvere's definition of limits is equivalent to that presented by Awodey.	I'm going to try reproducing this explanation a few times before attempting to write it down.<br>
<latex><br>What does Lawvere mean by the notations $\underset{\mathbb D}{\Pi}$ and $\underset{\mathbb D}{\star}$?<br></latex>	pg 9188, limits and colimits over a set, i.e. products and coproducts.<br><br>
<latex><br>Let $S$ be a set, say $S = |\mathbb D| \cong \mathbb D$. Explain Lawvere's definition of the S-fold product:\\<br>$$A^S \doteq \underset{\leftarrow \mathbb D}{lim}(A \mathbb A^{\mathbb D \to 1})$$<br></latex>	pg 9188, near bottom<br><br>
<latex>~\\<br>Give Lawvere's definition of the category $\mathbb E$. Hint: this category should be defined as a \emph{pushforward}<br></latex><br>	pg 9189<br>
<latex>~\\<br>Let $a', a'' \in \mathbb A$ with $a'D_0 = a''D_0 \wedge a'D_1 = a''D_1$.<br>How does Lawvere define the map $a'Ea''$?<br></latex><br><br>	pg 9189<br>
<latex>~\\<br>What can be said about $\underset{\leftarrow 0}{lim}^{\mathbb A}$ and $\underset{\rightarrow 0}{lim}^{\mathbb A}$, if they exist?<br></latex>	<latex>~\\<br>they are the terminal and initial objects of $\mathbb A$\\<br>pg 9189, bottom<br></latex>
<latex>~\\<br>What does Lawvere mean by the terms "left complete" and "right complete"? What is the modern terminology for these concepts? What does Lawvere mean by the term "complete"? What does it mean for a category to "have finite limits"? <br></latex>	pg 9190, definition at top; translations are given in highlight annotations.<br>
<latex>~\\<br>Consider the folowing statement:\\~\\<br>A category $\mathbb A$ is complete iff $\mathbb A$ has equalizers and arbitrary small products.\\~\\<br>Prove or disprove.<br></latex>	hint: left-to-right is trivial, since equalizers and small products are small limits. hence the focus should be on right-to-left.<br>pg 9190<br><br>TODO: add impostor?<br>
In what way are tags like references?<br>	"tags are like references: values flow into a tagged value when it is created, and they flow out when the extract operation is used, so the types of first-class tags cannot be either covariant or contravariant in the type being wrapped."<br><br>pg 9945, 3rd full paragraph<br><br>
<latex>~\\<br>Two syntactic forms, $S$ and $p$, are used to describe hierarchical stores. Give their (rather short) BNF definitions. What do $S$ and $p$ \emph{represent}?<br></latex>	pg 9947, top (figure 5)<br><br>
Give the form of the core tagged object calculus' value judgments. Explain its meanining.	pg 9948 top<br>
Give the form of core tagged object calculus' small-step transitition relation. Explain its meaning.<br>	pg 9948, near top<br>
Give and explain the (New-V), (Lam-V), and (C-V) value judgment rules.<br>	pg 9949, top (figure 6)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A category $\mathbb A$ has all finite limits and colimits iff it has limits and colimits over the categories $\mbf 0$, $|\mbf 2|$, and $\mathbb E$.\\~\\<br>Prove or disprove.<br></latex>	pg 9192<br>TODO: add impostor?<br>
<latex>~\\<br>What does it mean for a functor $\mathbb A \rTo^{f} \mathbb B$ to \emph{commute with limits}?<br>What does it mean for a $f$ to be \emph{left exact}? \emph{Left continuous}?<br></latex>	pg 9193, definition near bottom<br>
<latex>~\\<br>What does it mean for a functor $\mathbb C \rTo^u \mathbb D$ to be a \textbf{left pacing}?<br></latex>	pg 9194, definition.<br>
<latex>~\\<br>Let $\mathbb A \rTo^{f} \mathbb B$ be a functor with $\mathbb A$, $\mathbb B$ complete (has all small limits--modern terminology). Consider the following statement:\\~\\ <br>If there exists a functor $g$ such that $g \dashv f$ then $f$ is left continuous and for every $B \in |\mathbb B|$, there exists a small category $\mathbb C_B$ and a left pacing functor $\mathbb C_B \rTo^{u} (B,f)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 9149/9150, theorem 3<br>todo: add impostor?<br><br><br>
<latex>~\\<br>Let $\mathbb A \rTo^{f} \mathbb B$ be a functor with $\mathbb A$, $\mathbb B$ complete (has all small limits--modern terminology). Consider the following statement:\\~\\<br>If $f$ is left continuous and for every $B \in |\mathbb B|$, there exists a small category $\mathbb C_B$ and a left pacing functor $\mathbb C_B \rTo^{u} (B,f)$ then there exists a functor $g$ such that $g \dashv f$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 9195, 2nd paragraph ("conversely, ..."). spills to pg 9156.<br>todo: add impostor?<br>
<latex>~\\<br>Let $\mathbb A \rTo^f \mathbb B$ be a functor with $\mathbb A$, $\mathbb B$ left complete.<br>Consider the following statement:\\~\\<br>$f$ has a right adjoint if and only if $f$ commutes with equalizers and all small products and for every $B \in |\mathbb B|$, there exists a small set $\mathbb S_{B}$ of objects in $\mathbb A$ and maps $B \rTo^{\nu_A} Af$, $A \in \mathbb S_B$, such that for every $A' \in |\mathbb A|$ and for every $B \rTo^x A'f$ in $\mathbb B$, there is some $A \in \mathbb S_B$ and a map $A \rTo^{y} A'$ in $\mathbb A$ such that $x = \nu_A(yf)$.\\~\\ Prove or disprove  <br></latex>	pg 9197, thm 4. todo: add impostor?<br>
<latex>~\\<br>What does it mean for a category to have \emph{pseudomeets}?<br>Let the category $\mathbb A$ be complete. Let $\mathbb A \rTo^f \mathbb B$ be a functor and<br>$B \in |\mathbb B|$. Why does the category $(B, f)$ have pseudomeets?<br></latex>	pg 9197, near bottom<br>
<latex>~\\<br>Define the property $\mathbf{(P)}$ as follows:\\~\\<br>For every object $x$ in the codomain of $u$, there is an object $\overline{x}$ in the domain of $u$ and a map $\overline{x}u \rTo^{\overline{y}} x$ in the codomain of $u$.\\~\\<br>Consider the following statement:\\~\\<br>Let $\mathbb C \rTo^u \mathbb D$ be a full functor with property $\mathbf{(P)}$ where $\mathbb C$ is small and $\mathbb D$ has psuedomeets. Then $u$ is left pacing.\\~\\<br>Prove or disprove.<br></latex>	pg 9197, at bottom<br><br>
State and prove the Lowenheim-Skolem theorem.<br>	pg 5720/5721<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There is an at-most-countable set $\Phi$ of sentences which characterizes the ordered field $\frak R^{<}$ of real numbers up-to-isomorphism (in the sense that exactly $\frak R^{<}$ and the structures isomorphic to $\frak R^{<}$ are models of $\Phi$).\\~\\<br>Prove or disprove. <br></latex>	IMPOSTOR: see the text below thm 1.2<br>pg 5721
Exercise 1.3, pg 5721<br>	<br>
<latex>~\\<br>State the compactness theorem, and prove it using the adequacy theorem (which--go ahead and look--is on pg 5719).<br></latex>	pg 5722, near top<br>pg 5721 bottom has some relevant info<br><br><br>
<latex>~\\<br>Let $\Phi$ be a set of formulas which is satisfiable over arbitrarily large finite domains (i.e. for every $n \in \mathbf{N}$ there is an interpretation satisfying $\Phi$ over a finite domain which contains at least n elements). Consider the following statement:\\~\\<br>$\Phi$ is also satisfiable over an infinite domain\\~\\<br>Prove or disprove.<br></latex>	true, pg 5722<br>todo: add impostor?<br>
Exercise 2.5, pg 5723 bottom<br>	<br>
<latex>~\\<br>Let $\Phi$ be a set of $S$-sentences. What does $Mod^S \Phi$ denote?<br></latex>	pg 5724, top<br>
<latex>~\\<br>Let $\frak K$ be a class of $S$-structures. What does it mean for $\frak K$ to be \emph{elementary}? What does it mean for $\frak K$ to be $\Delta$-elementary?<br></latex>	pg 5724<br>
Is the class of fields (described on pg 5682) elementary? What about the class of ordered fields (also described on pg 5682)?<br>	yes and yes.<br>pg 5724<br>
<latex>~\\<br>Consider the class of fields, whose axioms are described on pg 5682. Recall that a field is said to have characteristic p if the sum of p 1's is equal to 0. Also recall that a field F is said to have characteristic 0 if there exists no prime p such that F has characteristic p. \\~\\<br>For $p$ prime, is the class of fields of characteristic p elementary? Is it $\Delta$-elementary? What about the class of fields of characteristic 0?<br></latex>	The former is elementary and (then inevitably) delta-elementary.<br>The class of fields of characteristic 0 is delta-elementary but not elementary.<br>pg 5724<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The class of finite fields is $\Delta$-elementary\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. item 3.4, pg 5725<br>
<latex>~\\<br>Consider the theory of graphs described on pg 5682. A graph $(G, R^G)$ is said to be \emph{connected} if, for arbitrary $a,b \in G$ with $a \neq b$, there are $n \geq 2$ and $a_1, \ldots, a_n \in G$ with<br>$$a_1 = a \text{, } a_n = b \text{ and } R^G a_i a_{i+1} \text{ for } i = 1, \ldots, n - 1$$<br>(i.e. for any two points there is a path connecting them). For $n \in \mbf{N}$, the regular (n + 1)-gon $\frak G_n$ with the vertices $0, \ldots, n$ is a connected graph. More precisely, $\frak G_n$ is the structure $(G_n, R^{G_n})$ with $G_n := \{ 0, \ldots, n \}$ and<br>$$ R^{G_n} := \{ (i, i + 1) \mid i < n \} \cup \{ (i, i-1) \mid 1 \leq i \leq n \} \cup \{ (0,n), (n,0) \}$$<br>Prove that the class of connected graphs is not $\Delta$-elementary.<br></latex>	pg 5726, item 3.6<br>
Exercise 3.7, pg 5726<br>	<latex>~\\<br>$\frak K$ is equal to $Mod~\Phi$ for some set of sententces $\Phi$. We form a new set that is satisfied exactly by $\frak K^{\infty}$ by taking the union of $\Phi$ with $\{ \varphi_{\geq 2}, \varphi_{\geq 3}, \ldots \}$,<br>described on pg 5681.<br></latex>
Exercise 3.8, pg 5726<br>	<br>
Exercise 3.9, pg 5726<br>	<br>
Exercise 3.10, pg 5726<br>	<br>
Exercise 3.11, pg 5727<br>	<latex>~\\<br>There are about 12 vector space axioms, not all of which are listed in this book. The point is that we can conjunct them together to form a single sentence. \\~\\<br>For a.), we can conjunct an additional sentence to enforce $n$-dimensionality. To construct this sentence, we first define a family of sentences $span_n$: $span_n$ is satisfied by exactly those vector spaces such that there is a set of $n$ vectors which span the entire space. Then to enforce $n$-dimensionality, we construct the sentence $\neg span_1 \wedge \neg span_2 \wedge \ldots \wedge span_n$.<br>To enforce infinite dimensionality for part (b), we add all sentences of the form $\neg span_n$ into $\Phi$: since there are infinitely many of them, we can't conjunct them into a single sentence.<br>\\~\\<br>I haven't done part (c) yet.<br></latex>
Read pages 5732 and 5733<br>	<br>
<latex>~\\<br>Describe the category $(\{ \mathcal S_0 \}, \mathcal C_1)$.<br></latex>	pg 9207, see sticky note and diagram.<br>
<latex>~\\<br>Let $\mathcal S_0 \rTo^A \mathbb A$ be an object in $(\{ \mathcal S_0 \}, \mathcal C_1)$.<br>If $n$ is any object in $\mathcal S_0$, what does ${}_n A$ denote? What does $\pi_i^n$ denote?<br>What is an \emph{$n$-ary operation of $\mathbb A$}?<br></latex>	pg 9207, definition<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The category $(\{ \mathcal S_0 \}, \mathcal C_1)$ has products and coproducts. In fact, the codomain functor<br>$(\{ \mathcal S_0 \}, \mathcal C_1) \to \mathcal C_1$ is continuous, and binary coproducts in $(\{ \mathcal S_0\}, \mathcal C_1)$ are defined by comeet diagrams of the form:\\~\\<br>\begin{tikzcd}<br>\mathcal S_0 \arrow[rr, "B"]\arrow[dd, "A" left]  & & \mathbb B \arrow[dd] \\<br> & \mathcal C_1 & \\<br>\mathbb A \arrow[rr] & & \mathbb A \underset{\mathcal{S}_0}{\star} \mathbb B<br>\end{tikzcd} <br>\\~\\<br>Prove or disprove.<br></latex>	true. pg 9208.<br>todo: add impostor?<br>
<latex>~\\<br>What is the definition of \emph{the category $\mathcal T$ of algebraic theories}?<br></latex>	pg 9208, near bottom<br><br>
<latex>~\\<br>Let $\mathcal S_0 \to A$ be an algebraic theory. Consider the following statement:\\~\\<br>The map ${}_0 A {\rTo} {}_1 A$ is always a monomorphism, and if there exists $x$ such that<br>${}_1 A {\rTo^x} {}_0 A$ in $\mathbb A$ then ${}_0 A {\rTo} {}_1 A$ is a retract.\\~\\<br>Prove or disprove.<br></latex>	pg 9209<br>
<latex>~\\<br>Let $\mathcal S_0 \rTo^A \mathbb A$ be an algebraic theory. Consider the following statement:\\~\\<br>If there are $m \pile{\rTo^{\sigma} \\ \rTo_{\tau}} n'$ in $\mathcal S_0$, $\sigma \neq \tau$,<br>such that $\sigma A = \tau A$, then the theory is inconsisetent.\\~\\<br>Prove or disprove.<br></latex>	pg 9209, proposition 3.<br>
What does it mean for an algebraic theory to be <i>inconsistent</i>?	pg 9209<br>
What is a <i>Peano structure</i>, and how are Peano structures relevant to questions about the expressive power of first-order logic?	pg 5736, near top<br><br>
State Dedekind's theorem.	pg 5736<br>
Read pg 5736-5737<br>	<br>
Read pgs 5738-5739-5740<br>	<br>
What does Jacobs mean when he says that "A logic is always a logic over a type theory"?	Read pages 9980-9981
How does Jacobs' slogan "a logic is always a logic over a type theory" apply to propositional logic?	pg 9981
Explain the motivation behind <i>fibred category theory</i>.	pg 9983, second paragraph to bottom
<latex><br>How does Jacobs define the categories $\mbf{Pred}$ and $\mbf{Pred}_I$?<br></latex>	section 0.2,<br>pgs 9990-9991
How are weakening and contraction special cases of substitution?	pg 9991
Each fibre category is a ________ algebra.<br>Fill in the blank and explain.	pg 9991, near bottom
How do we model universal and existential quantifiers in fibred category theory?	pg 9992
<latex>~\\<br>For a set (or type) $I$, equality $i = i'$ forms a predicate on $I$. How do we capture equality categorically using fibred categories?<br></latex>	pg 9992, middle paragraph
<latex>~\\<br>For a predicate $X \subseteq I$, we can define the predicate $Eq(X)$ on $I \times I$ by<br>$$ Eq(X) = \{ (i, i') \mid i = i' \text{ and } i \in X \} $$<br>Does this functor $Eq : P(I) \to P(I \times I)$ have a right adjoint?<br></latex>	pg 9992.<br>bonus question: does this adjunction somehow justify the equality judgments described by Martin Lof on pg 6159?<br>(Morehouse describes how adjunctions justify logical judgments on pg 9583)<br>
Explain how set comprehension (i.e. subset selection) can be descibed as a functor, using the ideas of fibred categories.<br>	pg 9992 bottom / 9993 top<br><br>
<latex>~\\<br>Define the category $\mbf{Rel}$.<br></latex>	pg 9993, near bottom<br>
Describe how the concept of quotient sets can be described in terms of adjunctions.<br>	pg 9993<br>
Give three commonly-known examples of fibred categories. Describe how substitutions work in each of these fibred categories.	pg 9998<br>
Suppose we wish to consider a family of sets, ranging over some index set I. Describe the two ways of doing this.<br>	pg 9999, bottom<br>pg 10000, top<br>
Weigh the pros and cons of split indexing against display indexing.	pg 9999 bottom,<br>pg 10000<br>They both have the same expressive power, but display indexing generalizes to arbitrary categories.<br>
<latex>~\\<br>Jacobs often describes a family of sets as a function $\varphi : X \to I$. What does this mean? A function isn't a family of sets... is it? Explain.<br></latex><br>	pg 10001
What is a <i>constant family</i> of sets, in terms of fibred category theory. Why are constant families of sets called constant families of sets?<br>	pg 10001.<br>
<latex>~\\<br>Provide the definition of the slice category $\mbf{Sets}/I$.<br></latex>	pg 10001<br>
<latex>~\\<br>Provide the definition of the arrow category $\mbf{Sets}^{\to}$.<br></latex>	pg 10001, bottom<br>
<latex>~\\<br>We can define a functor relating the category $\mbf{Sets}/I$ to $\mbf{Sets}^{\to}$. What is this functor?<br></latex>	It's an inclusion functor.<br>pg 10002<br>
Explain how substitution works in fibred category theory.	pg 10002<br>
<latex><br>Suppose $\psi$ is a family over a set $J$. Suppose $u$ is an element $j \in J$, that is, $u$ is of the form $j : 1 \to J$ where $1 = \{ \ast \}$ is a one-element set. Describe the substitution $u^*(\psi)$.<br></latex>	pg 10003, 1.1.1 (i)
Describe how substitution of ordinary (non-indexed) sets over the singleton set 1 works in fibred category theory.<br>	pg 10003, 1.1.1 (ii)<br>
<latex>~\\<br>Describe substition along a projection $u = \pi : J \times I \to J$ in the framework of fibred category theory.<br></latex> 	pg 10003 (iii)<br>
<latex>~\\<br>Explain substitution along a diagonal $\delta : J \to J \times J$ in the context of fibred category theory.<br></latex>	pg 10003, (iv), near bottom<br>
What is the "substitution morphism", aka the "cartesian morphism"? What is its universal property?<br>	pg 10003, very bottom<br>pg 10004<br><br>note that this is an instance of a cartesian morphism, as described on pg 10006, def 1.1.3<br>the functor p is the cod functor.<br>
<latex>~\\<br>Let $p : \mathbb E \to \mathbb B$ be a functor. It can be seen as a (display) family $\disp{\mathbb E}{p}{\mathbb B}$ of categories: for an object $I \in \mathbb B$, there is a \textbf{fibre} or \textbf{fibre category} $\mathb{E}_I$. Define this category, both internally and in the category of categories.<br></latex>	pg 10005 gives internal definition<br><br>in the category of categories, it is a pullback.<br>
<latex>~\\<br>Let $\disp{\mathbb E}{p}{\mathbb B}$ be a display and object $I \in \mathbb B$. What does it mean for an object $X \in \mathbb E$ to be \emph{above} $I$? Let $f$ be a morphism of $\mathbb E$ and $u$ a morphism of $\mathbb B$. What does it mean for $f$ to be \emph{above} $u$?<br></latex>	pg 10005, near top<br><br>
<latex>~\\<br>Let $\disp{\mathbb E}{p}{\mathbb B}$ be a family of categories. What does it mean for an arrow in $\mathbb E$ to be \emph{vertical}?<br></latex>	pg 10005<br>
<latex>~\\<br>When dealing with a family of categories $\disp{\mathbb E}{p}{\mathbb B}$, what does the notation $\mathbb E_u (X, Y)$ mean?<br></latex>	pg 10005<br>
<latex>~\\<br>When dealing with a family of categories $\disp{\mathbb E}{p}{\mathbb B}$, what is the \emph{base category} and what is the \emph{total category}? <br></latex>	pg 10005, above 1.1.2<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a functor $p : \mathbb E \to \mathbb B$, the fibre category $\mathbb E_I$ over $I \in \mathbb B$ can be constructed via a pullback.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10005 (ii) -- at the veeery bottom<br>pg 10006, top<br><br>
<latex>~\\<br>Let $p : \mathbb E \to \mathbb B$ be a functor. What does it mean for an arrow $f : X \to Y$ in $\mathbb E$ to be \emph{Cartesian over} $u : I \to J$ in $\mathbb B$?<br></latex>	pg 10006<br>
<latex>~\\<br>What does it mean for a functor $p : \mathbb E \to \mathbb B$ to be a \emph{fibration}?<br></latex>	pg 10006<br>this definition may seem a bit abstract. but we can make it more concrete by realizing that this is the material that inspired "refinement systems are functors" (see definition 3.3.20 on pg 8787)<br>a fibration is just a refinement system (functor) which for every refinement Y and every term u going into Y's  underlying type pY has a weakest precondition.<br><br>A cartesian morphism is a derivation (morphism in E) whose precondition is optimally weak (given its postcondition) and whose postcondition is optimally strong (given its precondition).
<latex>~\\<br>Let $\disp{\mathbb E}{p}{\mathbb B}$ be a family of categories. What does it mean for an arrow $f : X \to Y$ in the total category $\mathbb E$ to be \emph{Cartesian?}<br></latex>	pg 10006<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Cartesian liftings are unique up-to-isomorphism (in a slice): if $f : X \to Y$ and $f' : X' \to Y$ with $cod~f = cod~f' = Y$ are both Cartesian over the same map, then there is a unique vertical isomorphism $\varphi : X \overset{\cong}{\to} X'$ with $f' \circ \varphi = f$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10007<br>todo: add impostor?<br>
<latex>~\\<br>Let $cod : \mbf{Sets^{\to}} \to \mbf{Sets}$ be the codomain functor. <br>With respect to $cod$, what are the Cartesian arrows in $\mbf{Sets}^{\to}$?<br></latex>	pg 10007, text below prop 1.1.4
<latex><br>Give the fibrational generalizations of the arrow category $\mathbb C^{\to}$ and the slice category $\mathbb C/I$.<br></latex>	pg 10007, def 1.1.5<br>
What does it mean for an S-formula to be <i>term-reduced</i>?	pg 5748, def 1.1.<br>hmm: seems like the logician's equivalent of A-normal form!<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For every S-formula $\psi$ there is a logically equivalent, term-reduced S-formula $\psi^*$ with $free(\psi) = free(\psi^*)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 5749, top, thm 1.2<br>
What does it mean for a symbol set to be <i>relational</i>, and how can one obtain a relational symbol set from an ordinary one?	pg 5749 bottom / 5750<br>
<latex>~\\<br>Explain how we can obtain a relational symbol set $L^{S^r}$ from an ordinary symbol set $L^{S}$.<br>Then explain how we can associate with every $S$-structure $\frak A$ an $S^{r}$-structure $\frak A^r$.<br>Then consider the following statement:\\~\\<br>For every $\psi \in L^S$ there is $\psi^r \in L^{S^r}$ such that for all $S$-interpretations $\frak J = (\frak A, \beta)$,<br>$$ (\frak A, \beta) \vDash \psi\text{     iff     }(\frak A^{r}, \beta) \vDash \psi^r$$<br>Prove or disprove.<br></latex>	pg 5750, thm 1.3 (a)<br><br>
<latex>~\\<br>Explain how we can obtain a relational symbol set $L^{S^r}$ from an ordinary symbol set $L^{S}$.<br>Then explain how we can associate with every $S$-structure $\frak A$ an $S^{r}$-structure $\frak A^r$.<br>Then consider the following statement:\\~\\<br>For every $\psi \in L^{S^r}$ there is $\psi^{-r} \in L^{S}$ such that for all $S$-interpretations $\frak J = (\frak A, \beta)$,<br>$$ (\frak A, \beta) \vDash \psi^{-r} \text{     iff     }(\frak A^{r}, \beta) \vDash \psi$$<br>Prove or disprove.<br></latex>	pg 5750, thm 1.3 (b)<br>todo: add impostor?<br>
<latex>~\\<br>Explain how we can obtain a relational symbol set $L^{S^r}$ from an ordinary symbol set $L^{S}$.<br>Then explain how we can associate with every $S$-structure $\frak A$ an $S^{r}$-structure $\frak A^r$.<br>Consider the following statement. For two $S$-structures $\frak A$ and $\frak B$,<br>$$ \frak A \equiv \frak B \text{   iff   } \frak A^r \equiv \frak B^r$$<br>Prove or disprove.<br></latex>	pg 5750, bottom.<br>todo: add impostor<br>
<latex>~\\<br>The book defines $S_{grp}$ as $\{ \circ, -^{-1}, e \}$, and provides some axioms $\phi_{grp}$ as well, which characterize groups. Is this alphabet "minimal"? I.e., is there a smaller alphabet and corresponding set of axioms which also fully characterizes group theory?<br></latex>	yes. pg 5751, example A<br>
<latex>~\\<br>We can define some axioms over the first-order language generated by the alphabet $\{ <, \leq \}$ to represent the theory describing a strict total ordering and its weak counterpart. Is this the minimal alphabet capable of describing this concept, or is there a way to do it with fewer symbols?<br></latex>	pg 5751<br>
<latex>~\\<br>Consider the Theory of Fields of section 6.5 at the top of page 5682. If we remove the axiom $\forall x (\neg x \equiv 0 \to \exists y~x \cdot y \equiv 1)$, about the existence of a multiplicative inverse, and the commutative law for multiplication, we obtain the axiom system $\phi_{rg}$ for \emph{rings with 1}. Consider the following statement:\\~\\<br>Every ring has a unique unit.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. any invertible matrix is a unit.<br>pg 5752, while you're here, read the entirety of section C.<br>
<latex>~\\<br>Consider the Theory of Fields of section 6.5 at the top of page 5682. If we remove the axiom $\forall x (\neg x \equiv 0 \to \exists y~x \cdot y \equiv 1)$, about the existence of a multiplicative inverse, and the commutative law for multiplication, we obtain the axiom system $\phi_{rg}$ for \emph{rings} (more specifically, rings with 1).\\~\\<br>Let $\frak A$ be a ring. Define \emph{the group $\frak E(\frak A)$ of units in $\frak A$}, and explain how we can "talk about" $\frak E(\frak A)$ in $\frak A$.<br></latex>	pg 5752, C (at top)<br>
<latex>~\\<br>Explain the concept of relativization as it regards formulating a system of axioms.<br></latex>	pg 5752, near bottom<br>pg 5753<br><br>
<latex>~\\<br>Let $S$ and $S'$ be symbol sets. What is a \emph{syntactic interpretation of S' in S}?<br></latex>	pg 5753, definition 2.1... see the text below for a helpful description of why the definition is what it is.<br>
<latex>~\\<br>Let $S$ and $S'$ be symbol sets and consider an arbitrary syntactic interpretation $I$ of $S$ in $S'$. <br>Give a set $\Phi_I$ of $S$-sentences which say that $\varphi_{S'}(v_0)$ defines the domain of an $S'$-structure. Then, for an $S$-structure $\frak A$ with $\frak A \vDash \Phi_I$, define the $S'$-structure $\frak A^{-I}$.<br></latex>	pg 5753 bottom<br>pg 5754 toppish<br><br>
What is a <i>database schema</i>?	pg 10742, sec 2.1<br><br>
How many times may a relation name occur in a database schema?	At most once. pg 10742, sec 2.1<br>
What does the symbol <b>dom</b> denote, as used by Ameloot et al.? 	Some infinite universe of atomic data values.<br>pg 10742<br>
<latex>~\\<br>What is a \emph{database instance} I over a database schema $\mathcal D$?<br></latex>	pg 10742
<latex><br>Let $I$ be a database instance over $\mathcal D$ and let $Z$ be a subset of relation names in $\mathcal D$. What does $I \mid_Z$ denote? For a function $h : \mbf{dom} \to \mbf{dom}$, what does $h(I)$ denote? What is the \emph{active domain} of $I$?<br></latex>	pg 10742, sec 2.1, second paragraph.<br>
<latex>~\\<br>What is a \emph{query} $\mathcal Q$ \emph{over input database schema} $\mathcal D$ \emph{and output database schema} $\mathcal D'$?<br></latex>	pg 10742, sec 2.1, third paragraph.<br>
<latex>~\\<br>What does it mean for a query $\mathcal Q$ to be \emph{generic}? And what does it mean that generic queries are \emph{domain preserving}?<br></latex>	pg 10742, sec 2.1, third paragraph<br>
<latex>~\\<br>What is a \emph{transducer schema}?<br></latex>	pg 10743<br>
<latex>~\\<br>What is a \emph{transducer state} for a database schema $\Upsilon$?<br></latex><br>	pg 10743<br>
For a transducer state I, what does notation along the lines of I|<sub>(in,sys)</sub> mean?	pg 10743<br>
<latex>~\\<br>What is an \emph{(epidemic) relational transducer} $\Pi$ over a transducer schema $\Upsilon$?<br></latex>	pg 10743<br>
<latex>~\\<br>What does it mean for an (epidemic) relational transducer to be an $\mathcal L$-transducer?<br></latex>	L is the generic query language used to define the transducer's queries.<br>pg 10743<br>
<latex><br>Let $\Pi$ be a transducer over schema $\Upsilon$. What is a \emph{message instance} for $\Upsilon$?<br>What is a \emph{local transition} of $\Pi$?<br></latex>	pg 10743<br>
What is a PPO?	Preferred Provider Organization<br><br>Available through UPMC or Highmark<br><br>PPO plans give you the flexibility to use in- or out-of-network providers without referrals. A higher level of benefits is provided when in-network providers are used, resulting in lower out-of-pocket costs for you.
What is an HRA?	Health Reimbursement Account<br><br>Available through UPMC or Highmark<br><br>The High-Deductible PPO has a higher deductible and a lower monthly premium. CMU funds a Health Reimbursement Account (HRA) that you can use to help pay for eligible deductible expenses. Once your health care expenses for the year exceed your deductible, the PPO plan begins paying benefits. Unused HRA funds can be rolled over to the following year up to a maximum of three years’ accumulation.
What is an HMO?	Health Maintenance Organization<br><br>Available through Aetna<br><br>﻿HMOs have low out-of-pocket expenses (no deductible or coinsurance) but do not provide benefits if you use out-of-network providers (except in the case of an emergency). Referrals to specialist care and related services are not required in most circumstances.
What is a deductible?	In an insurance policy, the deductible is the amount that must be paid out of pocket by the policy holder before an insurance provider will pay any expenses. In general usage, the term deductible may be used to describe one of several types of clauses that are used by insurance companies as a threshold for policy payments.
What is coinsurance?	a type of insurance in which the insured pays a share of the payment made against a claim.
What is an <i>insurance claim</i>?	An insurance claim is a formal request to an insurance company for coverage or compensation for a covered loss or policy event. The insurance company validates the claim and, once approved, issues payment to the insured or an approved interested party on behalf of the insured.
What does "withholding" mean, as it applies to taxes?	In order to understand how allowances work, it might help to understand the concept of withholding. Whenever you get paid, a certain amount of income tax is automatically withdrawn (or withheld) from your check and turned over to the IRS.<br><br>Withholding tax can also be collected from individuals who receive earnings from gambling, bonuses and commissions. There can be tax withheld from pensioners as well. If you’re a business owner or an independent contractor, you withhold your own income taxes by paying estimated taxes.<br><br>Tax withholding becomes an issue whenever you’re filling out a W-4 form at the start of a new job or whenever you’ve experienced a significant event in your life that affects your tax-filing status, like the adoption of a child or a marriage.
What is a tax allowance?	Withholding allowances directly affect how much money is withheld from your pay. Claiming more allowances will lower the amount of income tax that’s taken out of your check. Conversely, if the total number of allowances you’re claiming is zero, that means you’ll have the most income tax withheld from your take-home pay.<br><br>Allowances matter. If you don’t claim enough of them and you have too much money sent to the government, you’ll end up with a tax refund. But if you claim too many allowances, you’ll probably owe the IRS some money at the end of the tax year and possibly pay a penalty for your mistake.<br><br>The value of a single allowance and how it impacts your salary is based on your tax bracket and how frequently you receive a paycheck. The exact amount of tax that your employer is expected to withhold also takes into account whether you’re filing as a single person, a married person or the head of your household.<br>
<latex>~\\<br>Assume $\mathbb{C}$ is an arbitrary category/ Define the category $\mbf{Fam}(\mathbb C)$ of set-indexed families of objects and arrows of $\mathbb C$.<br></latex>	pg 10010, near bottom<br><br>
<latex>~\\<br>Define the projection functor $p : Fam(\mathbb C) \to \mbf{Sets}$. Is this functor a fibration? Why or why not?<br></latex>	pg 10011
<latex><br>Letting $\mathbb C$ be an arbitrary category, what is the \emph{family fibration} of $\mathbb C$?<br></latex>	pg 10011, def 1.2.1<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There is an equivalence of categories in (the top line of) a commuting triangle\\~\\<br>\begin{tikzcd}<br>Fam(\mbf{Sets}) \ar[rr, "\cong"] \ar[dr] & & \mbf{Sets^{\to}} \ar[dl, "cod"] \\<br> & \mbf{Sets} & <br>\end{tikzcd}\\~\\<br>where the functor $Fam(\mbf{Sets}) \to \mbf{Sets^{\to}}$ sends\\~\\<br>$$ (X_i)_{i \in I} \mapsto \text{the projection} \ddisp{\coprod_{i \in I} X_i}{\pi}{I}$$<br>Prove or disprove.<br></latex>	pg 10012, prop 1.2.2<br>todo: add counterexample?<br><br>
What are the five essential features of the informal notion of "algorithm".	pg 10807, left column, near bottom<br>
What does Rogers mean by <i>P-symbolisms</i> and <i>L-P specifications</i>?	pg 10807<br>
Here are some questions for formulating a theory of computability:<br>- Is there to be a fixed finite bound on the size of the inputs?<br>- Is there to be a fixed finite bound on the size of a set of instructions?<br>- Is there to be a fixed finite bound on the amount of "memory" storage space available?<br><br>How do we answer these?	pg 10807, right column<br><br>
Consider this question:<br><br>Is there to be, in any way, a bound on the length of a computation? More specifically, should we require that the length of a particular computation be always less than a value which is "easily calculable" from the input and from the set of instructions P? To put it more informally, should we require that, given any input and given any P, we have some idea, "ahead of time," of how long the computation will take?<br><br>How does Rogers answer this question?<br>	pg 10808, right column, item 10<br><br>
Give Rogers' definition of the class of <i>primitive recursive functions</i>.	pg 10809<br>
What is a <i>derivation</i> of a primitive recursive function?	pg 10809 bottom / pg 10810 top<br>
Read the right column of page 10809<br>	<br>
What is the Ackermann function, and why is it relevant to recursion theory?	pg 10810<br>
<latex>~\\<br>Consider the function:<br>\[<br>f(x) = \left \{ <br>\begin{array}{ll}<br>1, & \text{if a consecutive run of exactly x 5's occurs in the decimal expansion of } \pi; \\<br>0, & \text{otherwise}<br>\end{array}<br>\]<br>Is there a known algorithm for computing $f$? <br></latex>	We don't even know if such an algorithm exists.<br>pg 10810, right column<br>
<latex>~\\<br>Consider the function:<br>\[<br>g(x) = \left \{ <br>\begin{array}{ll}<br>1, & \text{if a consecutive run of at least x 5's occurs in the decimal expansion of } \pi; \\<br>0, & \text{otherwise}<br>\end{array}<br>\]<br>Is there a known algorithm for computing $g$? Do we know if such an algorithm even exists? <br></latex>	We do know that such an algorithm exists, but not necessarily what it is.<br>pg 10810, right column<br>
<latex>~\\<br>Consider the function:<br>\[<br>h(x) = \left \{ <br>\begin{array}{ll}<br>1, & \text{if Goldbach's conjecture is true} \\<br>0, & \text{if it is false}<br>\end{array}<br>\]<br>Does an algorithm exist for computing h? <br></latex>	Yes. see top-left of pg 10811 (if only we know what the algorithm is)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>All algorithmically computable functions are primitive recursive.\\~\\<br>Prove or disprove.<br></latex>	false. The "diagonalization" section on pages 10811, left and right pages, explains<br>
Why does diagonalization at first seem to bring the entire endevour of recursion theory into question? What is the solution to this?	pg 10811, right page, 10812 left page<br><br>
What is the <i>consistency restriction</i> on Turing machines?	pg 10813, top left<br>pg 10812, bottom right
What is the most significant way in which the Turing machine presentation of Hartley differs from that of Sipser?	probably that the tape alphabet contains only the symbols "1" and "B" (for blank)<br>pg 10812, 10813<br>
What is an <i>instantaneous description</i> of an executing Turing machine?	pg 10813 right<br>
How does Kleene define a <i>computation</i>?	pg 10814, left<br>
Explain the notion of <i>auxiliary function symbols</i> in Kleene's characterization of computation.	pg 10814, left page<br>
<latex>~\\<br>If $n$ and $m$ are natural numbers, what does the notation $n \cdot m$ mean?<br></latex>	pg 9978. Take the nth encoded recursive function and apply it to m.<br><br><br>
<latex>~\\<br>What does the Kleene equality symbol $\simeq$ mean?<br></latex>	pg 9978. Note that capital lambda must denote "the encoding of this lambda abstraction". We can infer this from the surrounding text. See pg 10817 for a definition of the snm theorem.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Turing's formalization of computation is more powerful than Kleene's\\~\\<br>Prove or disprove.<br></latex>	FALSE: they are equivalent.<br>pg 10815, basic result, part I<br>
What is a <i>recursive function</i>? What is a <i>partial recursive function</i>?	pg 10815<br>
What is Church's Thesis? 	pg 10816 left<br>
<latex><br>Let $P$ be a set of ``turing machine instructions''. What is the \emph{Godel number} of $P$?<br></latex>	pg 10816, right page, section 1.8<br>
<latex>~\\<br>What does Roger's typically mean by the notation $\varphi_{x}^{(k)}$?<br></latex>	pg 10816, bottom right<br>
<latex>~\\<br>Consider the following claim:\\~\\<br>The fact that a Godel numbering exists is not as important as the \emph{particular} Godel numbering that is chosen.\\~\\<br>Is this true or false? (No need to justify.)<br></latex>	pg 10817, top left<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There are exactly $\aleph_0$ (a countable infinity of) partial recursive functions, and there are exactly $\aleph_0$ recursive functions.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10817, top left, theorem I<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>All functions are recursive.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 10817, theorem II<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Each partial recursive function has $\aleph_0$ distinct indices. (An index being a natural number associated with a turing machine which computes the function.) \\~\\<br>Prove or disprove.<br></latex>	true. pg 10817 left, Theorem III<br>
<latex>~\\<br>What is a \emph{Universal partial function}?<br></latex>	pg 10817, bottom left<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For every $m,n \geq 1$, there exists a recursive function $s_{n}^m$ of $m+1$ variables such that for all $x, y_1, \ldots, y_m$,<br>$$ \lambda z_1 \cdots z_n [\varphi_{x}^{m + n} (y_1 , \ldots , y_m, z_1 , \ldots , z_n)] = \varphi^{(n)}_{s_{n}^m (x,y_1,\ldots,y_m)}$$<br>Prove or disprove.<br></latex>	<latex>~\\<br>pg 10817, right page, $Theorem~V$<br></latex><br>
<latex>~\\<br>How can we use Turing machines to represent partial functions of $k$ variables, where we have $k > 1$?<br></latex> 	pg 10813, right page - "we can associate a function of k variables..."<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There is a recursive function $g$ of two variables such that for all $x,y,$<br>$$ \varphi_{g(x,y)} = \varphi_x \varphi_y~~~~(i.e., = \lambda z [\varphi_x(\varphi_y(z))])$$<br>Prove or disprove.<br></latex>	true. pg 10818.<br><br>
<latex>~\\<br>Do there exist any recursive functions $g$ such that for all $x, y,$ <br>$$ g(x) = \left \{ \pile{~1,~~~\text{if }\varphi_{x}(y)\text{ convergent} \\0,~~~\text{if }\varphi_{x}(y)\text{ divergent}}$$<br>Informally prove or disprove.<br></latex>	pg 10818, bottom left<br><br>
What are <i>codings</i>? What are <i>code numbers</i>?	pg 10819. bottom right.<br><br>
Read the left page of pg 10820.<br>	<br>
State and prove the <i>Mu theorem</i>.<br>	pg 10820, left page, theorem IX<br><br>
<latex>~\\<br>For a partial recursive function $f : \mathbb N^n \times \mathbb N \to \mathbb N$, what does $\Lambda y. f(\vec{x}, y)$ denote?.<br></latex>	f partially applied to n arguments<br>pg 9978<br>see pg 10817 for an explanation of the smn theorem.<br>
<latex>~\\<br>What is an $\mbf{\omega\text{-}set}$? What constitutes a morphism in the $\mbf{\omega\text{-}sets}$ category?<br></latex>	pg 10012, def 1.2.3<br>
<latex>~\\<br>There is one functor that is particularly relevant to the category $\omega\text{-}sets$? What is it?<br></latex>	<latex>~\\<br>The forgetful functor $\mbf{\omega\text{-}Sets} \to \mbf{Sets}$.\\<br>pg 10013 top<br></latex>
<latex>~\\<br>Consider the following statement:\\~\\<br>The category $\mbf{\omega\text{-}Sets}$ has finite limits and exponents.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10013, prop 1.2.4<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The codomain functor $\vrt{\mbf{\omega\text{-}sets^{\to}}}{\mbf{\omega\text{-}sets}}$ is a fibration.\\~\\<br>Prove or disprove.<br></latex>	pg 10013. <br>text below proof of prop 1.2.4<br><br>
<latex>~\\<br>What is a $\textbf{partial equivalence relation}$ on $\mathbb{N}$? Give a definition.<br></latex>	pg 10014, def 1.2.5<br><br>
<latex>~\\<br>What do the following notations mean, with respect to a partial equivalence relation $R$?\\~\\<br>$|R|$\\<br>$[n]$\\<br>$\mathbb N / R$<br></latex>	pg 10014, def 1.2.5 near bottom<br>
Explain how the PERs form a complete lattice. How is its join operator defined?<br><br>	pg 10015, top<br>
<latex>~\\<br>Define the cateogry of $\mbf{PER}$. What are its objects and arrows?<br></latex>	pg 10015
<latex>~\\<br>Consider the following statement:\\~\\<br>The category $\mbf{PER}$ has finite limits and exponentials.\\~\\<br>Prove or disprove.<br></latex>	pg 10015<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The category $\mbf{PER}$ is a full subcategory of the category $\mbf{\omega\text{-}sets}$.\\~\\<br>Prove or disprove.<br></latex>	pg 10015, near bottom<br>
What is a reflective subcategory?	See pg 6822 (yes, it's a different book - Riehl's Category Theory in Context)
<latex>~\\<br>Define the left adjoint $\mbf{r}(\text{-}) : \mbf{\mbf{\omega\text{-}Sets} \to \mbf{PER}}}$<br>to the inclusion functor $\mbf{Per} \hookrightarrow \mbf{\omega\text{-}Sets}$<br></latex>	pg 10016<br>
<latex>~\\<br>How does Ameloot define a \emph{network} $\mathcal N$?<br></latex>	pg 10744<br>
<latex>~\\<br>If $x \in nodes(\mathcal N)$ then what does $neighbors(x, \mathcal N)$ denote?<br></latex>	pg 10744, end of first paragraph in section 3.<br>
<latex>~\\<br>What is a \emph{(homogeneous) transducer network}? <br></latex>	pg 10744, second non-trivial paragraph of section 3
<latex>~\\<br>For a query language $\mathcal L$, what does it mean for a transducer network to be an $\mathcal L$-transducer network? <br></latex>	pg 10744<br>
<latex>~\\<br>What is a \emph{distributed database instance over a network $\mathcal N$ and a database schema \mathcal D}? <br></latex>	"a total function that assigns to each node of N an ordinary database instance over D."<br>pg 10744<br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N, \Upsilon, \Pi \rangle$ be a transducer network. Any distributed database instance over $\mathcal N$ and $\Upsilon_{in}$ can be given as input to $\mathcal T$. Let<br>$H$ be such an instance. What is a \emph{configuration of $\mathcal T$ on H}?<br></latex>	pg 10744, sec 3.1<br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N, \Upsilon, \Pi \rangle$ be a transducer network. Any distributed database instance over $\mathcal N$ and $\Upsilon_{in}$ can be given as input to $\mathcal T$. Let<br>$H$ be such an instance. What is the \emph{start configuration of $\mathcal T$ on H}?<br></latex>	pg 10744<br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N, \Upsilon, \Pi \rangle$ be a transducer network. Any distributed database instance over $\mathcal N$ and $\Upsilon_{in}$ can be given as input to $\mathcal T$. Let<br>$H$ be such an instance. What is a \emph{global transition of $\mathcal T$ on H}?<br></latex>	pg 10744, kinda near bottom<br><br>
What is the <i>active node</i> and what are the <i>delivered messages</i> of a global transition?	pg 10744, bottom<br>
What is the difference between a <i>heartbeat</i> global transition and a <i>delivery</i> transition?	pg 10745<br>
<latex>~\\<br>What is a \emph{run} of a transducer network $\mathcal T$ on a distributed input database instance H?<br></latex>	pg 10745, second paragraph<br><br>
Does Ameloot's transducer model allow for multiple nodes to transition concurrently? If not, why?	pg 10745, above "fairness" section<br><br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N , \Upsilon, \Pi \rangle$ be a transducer network. What does it mean for a run of $\mathcal T$ on some input distributed database instance to be \emph{fair}?<br></latex>	pg 10745, section 3.2<br><br>
<latex>~\\<br>Let $\mathcal T$ be a transducer network. What does \emph{k-delivery semantics} for $\mathcal T$ mean?<br></latex>	We only consider runs where multisets of cardinality at most k are delivered.<br><br>pg 10745, sec 3.3<br><br>
In Ameloot's transducer model, is it possible for a node to send a message to a specific neighbor rather than all neighbors?	pg 10746, top paragraph.<br>
What does it mean for a transducer to be <i>oblivious</i>?	pg 10746<br>
What does it mean for a transducer to be <i>inflationary</i>?<br>	A transducer is called inflationary if it never deletes facts from its memory relations. That is, the deletion queries for the memory relations return the empty set of facts on all inputs.<br><br>pg 10746
What does it mean for a transducer to be <i>monotone</i>?<br>	A transducer is called monotone if all its queries are monotone. Seems a bit odd that the memory deletion query is requred to be monotone, doesn't it? And can't sending messages trigger deletion queries? Why do the message send queries need to to be monotone?<br><br>This is indeed a valid worry: monotonicity is only a helpful property of transducers if they are <i>oblivious</i>, which is explained by Ameloot.<br><br>pg 10746<br>
<latex>~\\<br>What does it mean for a distributed database instance H over $\mathcal N$ and $\Upsilon_{in}$ to be a \emph{horizontal partition} of a database instance $I$ (over $\Upsilon_{in}$)<br></latex>	pg 10746, section 4.2<br><br>
Discuss some of the primary functionalities of database management systems (dbms).<br>	pg 11071, bottom<br>pg 11072<br>
Read section 1.3 "complexity and diversity" on pg 11073<br>	<br>
If R is a binary relation and P is a set of properties of binary relations, what is the P-Closure of R?<br>	pg 1107<br>
If R is a binary relation, then what does R<sup>+</sup> denote?<br>	pg 1107<br>
What is an <i>automorphism</i> on a graph G?<br>	pg 11078, near bottom<br><br>
What is a permutation, and what does it mean for one permutation to be derived from another?	pg 11079, top<br>
What is a DDL, and what is a DML?<br>	pg 11094, top<br><br>
DMLs provide two fundamental capabilities. What are they?	DMLs provide two fundamental capabilities: querying to support the extraction of data<br>from the current database; and updating to support the modification of the database state.<br>There is a rich theory on the topic of querying relational databases that includes several<br>languages based on widely different paradigms.<br><br>pg 11094<br>
In the relational model of databases, what are <i>tables</i>?	pg 11095, sec 3.1<br>
What is a <i>database schema</i>? What is a <i>database instance</i>?<br>	pg 11095, sec 3.1, near bottom<br>
Explain the sets <b>att</b>, <b>dom</b>, and <b>relname</b> pertaining to the relational model of databases.<br>	pg 11096/11097<br><br>
Explain the role of the <i>sort</i> metafunction, as pertaining to the relational model of databases.<br>	pg 11097<br>
What is a <i>relation schema</i>?	pg 11097, second paragraph<br><br>
What is a <i>database schema</i>?	pg 11097, second paragraph<br>
Discuss the tradeoffs between the <i>named</i> and <i>unnamed</i> perspectives on relation names.<br>	pg 11097, near bottom<br>
In the <i>named perspective</i> of relations, in the relational model of databases, how is the notion of a <i>tuple</i> formalized? <br>	First full paragraph, pg 11098.
In the unnamed perspective of relational databases, how do we formalize the notion of a <i>tuple</i>?	the standard way, as a cartesian product.<br>pg 11098, third full paragraph.<br>
How is the notion of a <i>relation</i> formalized in the <i>conventional</i> prespective of relational databases?<br>	pg 11098<br>
In the <i>conventional</i> perspective of relational databases, how many instances are there over the empty set of attributes?	2. pg 11098, sec 3.3<br>
How is the notion of a <i>database instance</i> formalized under the <i>conventional<i> perspective of relational databases?	pg 11098, sec 3.3<br>
How is the notion of a <i>relation</i> formalized under the <i>logic programming</i> perspective of relational databases?	pg 11098<br>
Under the <i>logic programming</i> perspective of relational databases, how is the notion of a <i>database instance</i> formalized?	pg 11098, near bottom<br><br>
Consider a database represented in the Named and Logic Programming perspective as<br><br>{ R(A : a, B : b), R(A : c, B : b), R(A : a, B : a), S(A : d) }<br><br>Define the same database using the other three perspectives:<br>- Named and Conventional<br>- Unnamed and Conventional<br>- Unnamed and Logic programming<br>	pg 11099<br>
Why have multiple perspectives on relational databases (i.e. named, unnamed, conventional, logic programming)?<br>	pg 11099, second paragraph.<br>
Consider the following query (note that this references the CINEMA database of pg 11096):<br><br>List the names and addresses of theaters featuring a Bergman film.<br><br>Give a formal specification of this query, both using tuple calculus and domain calculus. <br>	pg 11105, example 4.1.1<br>
<latex>~\\<br>Translate the following domain calculus into a set of rule-based conjunctive queries:<br><br>\begin{lstlisting}<br>if there are tuples $\langle x_{ti} , "Bergman", x_{ac} \rangle$, $\langle x_{th}, x_{ti}, x_{s} \rangle$, and $\langle x_{th}, x_{ad}, x_p \rangle$, respectively, in relations Movies, Pariscope, and Location<br>then include the tuple $\langle Theater : x_{th}, Address : x_{ad} \rangle$ in the answer<br>\end{lstlisting}<br><br></latex><br> 	pg 11105<br>
In a rule-based conjunctive query, what is an <i>anonymous variable</i>?<br>	pg 11105 near bottom of example<br>
Let <b>R</b> be a database schema. What is a <i>rule-based conjunctive query</i> over <b>R</b>?	pg 11107<br>
Which part of a conjunctive query is called the <i>body</i> and which part is called the <i>head</i>?<br>	pg 11107, paragraph below definition<br><br>
What does it mean for a rule to be <i>range restricted</i>?	pg 11107, paragraph below definition.<br>
If q is a conjunctive query rule, <b>R</b> is a database schema, and <b>I</b> is an instance of <b>R</b>. What is the <i>image</i> of <b>I</b> under <i>q</i>?<br>	pg 11107, centered part in middle<br><br>
If <b>I</b> is a database instance, what does <i>adom</i>(<b>I</b>) denote?<br>	pg 11107, fourth to last paragraph<br>
What is the difference between an <i>extensional</i> relation and an <i>intensional</i> one?	pg 11107, bottom paragraph<br>pg 11108, top paragraph<br>
What does it mean for a query <i>q</i> over a database schema <b>R</b> to be <i>monotonic</i>?<br>	pg 11108
What does it mean for a query <i>q</i> to be <i>satisfiable</i>?	pg 11108<br>
Consider the following statement:<br><br>Conjunctive queries are monotonic and satisfiable.<br><br>Prove or disprove.	pg 11108<br>
The monotonicity of the conjunctive queries points to limitations in their expressive power. Discuss these limitations.	pg 11108, near bottom<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B} p$ be a fibration. What does $|p|$ denote?<br></latex>	pg 10009, below item (ii) at top
What is a <i>tableau</i> over a schema <b>R</b>? What is a <i>tableau query</i>? What is a <i>summary</i> of a tableau query?	pg 11109, def 4.2.3<br><br>
Express the following query using a <i>tableau query</i>:<br><br>List the names and addresses of theaters featuring a Bergman film.<br><br>It should use the following (CINEMA) schema:<br>Movies: TItle, Director, Actor<br>Pariscope: Theatre, Title, Schedule<br>Location: Theater, Address, Phone Number<br>	pg 11109, example 4.2.4<br>
What is an <i>embedding</i> of tableau <b>T</b> into instance <b>I</b>?<br>	pg 11109<br>
We can use tableaux to query instances. Define the output of (<b>T</b>, u) on input <b>I</b>.<br>	pg 11109, near bottom<br>
What does it mean for a tableau to be <i>typed</i>?<br>	pg 11110, near top<br>
<latex>~\\<br>Consider the conjunctive query<br>$$ans(e_1 , \ldots , e_m) \leftarrow R_1(u_1) , \ldots , R_n(u_n)$$<br>Give a conjunctive calculus query (i.e. first order logic) with the same semantics.<br></latex>	pg 11110<br>
Express the following query in the conjunctive calculus paradigm:<br><br>List the names and addresses of theaters featuring a Bergman film.<br><br>Use the following schema:<br>Movies: Title, Director, Actor<br>Pariscope: Theater, Title, Schedule<br>Location: Theater, Address, Phone Number<br>	pg 11110, example 4.2.5 at bottom<br>
Let <b>R</b> be a database schema. What is a <i>(well-formed) formula</i> over <b>R</b> for the conjunctive calculus?<br>	pg 11111, def 4.6<br>
What is a <i>conjunctive calculus query</i> over a database schema <b>R</b>?	pg 11111, def 4.2.7<br>
<latex>~\\<br>Let $\mbf{R}$ be a database schema, $\varphi$ a conjunctive calculus formula over $\mbf{R}$, and<br>$\nu$ a valuation over \emph{free}($\varphi$). What does it mean for $\mbf{I}$ to \emph{satisfy} <br>$\varphi$ under $\nu$?<br></latex>	pg 11112, near top<br><br>
<latex>~\\<br>Let $q = \{ e_1, \ldots, e_m \mid \varphi \}$ be a conjunctive calculus query over $\mbf{R}$. For an instance $\mbf{I}$ over $\mbf{R}$, what is the \emph{image} of $\mbf{I}$ under q?<br></latex>	<latex><br>$q(\mbf{I}) = \{ \nu(\langle e_1, \ldots, e_n \rangle ) \mid I \vDash \varphi[\nu] \text{ and } \nu \text{ is a valuation over } free(\varphi) \}$\\~\\<br>pg 11112<br></latex><br><br><br>
What is the <i>active domain</i> of a conjunctive calculus formula?	pg 11112<br>
What does it mean for two conjunctive calculus formulas over the same schema <b>R</b> to be <i>equivalent</i>?	pg 11112<br>
What does it mean for a conjunctive calculus query to be in <i>normal form</i>?<br>	<latex>~\\<br>A conjunctive calclulus query $q = \{ u \mid \varphi \}$ is in \emph{normal form} if $\varphi$ has the form<br>$$\exists x_1, \ldots, x_n (R(u_1) \wedge \ldots \wedge R(u_n))$$<br>pg 11112<br></latex><br>
State and explain the variable substitution rewrite rule for conjunctive calculus queries.<br>	pg 11112 bottom / 11113 top<br>
Give and explain the merge-exists rewrite rule for conjunctive calculus queries.<br>	pg 11113 top
Consider the following statement:<br><br>Every conjunctive calculus query is equivalent to a conjunctive calculus query in normal form.<br><br>Prove or disprove.<br>	true. pg 11113, lemma 4.2.8<br>
<latex>~\\<br>Let $\mathcal Q_1$ and $\mathcal Q_2$ be two query languages (with associated semantics). What does <br>$\mathcal Q_1 \sqsubseteq \mathcal Q_2$ denote? What does it mean for $\mathcal Q_1$ and $\mathcal Q_2$ to be equivalent?<br></latex>	pg 11113<br>
Express the following query using conjunctive queries with variable equality constraints:<br><br>List the pairs of persons such that the first directed the second in a movie and vice versa.<br><br>Use the following schema:<br>Movies: title, director, actor<br>Pariscope: theater, title, schedule<br>Location: theater, address, phone number<br>	pg 11113, bottom (it's query 4.6)<br><br><br>
Discuss two complications that arise when we introduce equality constraints into our rule-based conjunctive query language. How do we deal with these complications?	potentially infinite models require range restriction.<br>the query could become unsatisfiable.<br>pg 11114<br>
How hard or easy is it to check whether a conjunctive query with equality is satisfiable?<br>	Finally, note that one can easily check if the<br>equalities in a conjunctive query with equality are unsatisfiable (and hence if the query is<br>equivalent to q<sup>∅</sup>). This is done by computing the transitive closure of the equalities in the<br>query and checking that no two distinct constants are required to be equal. Each satisfiable<br>rule with equality is equivalent to a rule without equality<br><br>pg 11114<br>
What is a <i>conjunctive query program</i>?	pg 11115, at top<br><br>
What is an <i>edb</i> relation? What is an <i>idb</i> relation?<br>	pg 11115<br>
<latex>~\\<br>Let $\mbf{R} = \{ Q, R \}$ and consider the conjunctive query program\\~\\<br>$S_1(x,z) \leftarrow Q(x, y), R(y, z, w)$\\<br>$S_2(x, y, z) \leftarrow S_1(x,w), R(w,y,v), S_1(v,z)$\\~\\<br>Rewrite this program into a one-rule program whose rule has head $S_2$; the effect<br>on $S_2$ should be preserved.<br></latex>	pg 11115, example 4.3.1<br>
<latex>~\\<br>Consider the following program $P$:\\~\\<br>$T(a,x) \leftarrow R(x)$\\~\\<br>$S(x) \leftarrow T(b, x)$\\~\\<br>Is this program equivalent to any rule-based conjunctive query without equality?<br></latex>	pg 11116, example 4.3.2<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If conjunctive query program $P$ defines final relation $S$, then there is a conjunctive query $q$, possibly with equality, such that on all input instances $\mbf{I}$, $q(\mbf{I}) = [P(\mbf{I})](S)$. Furthermore, if $P$ is satisfiable, then $q$ can be expressed without equality.\\~\\<br>Prove or disprove.<br></latex>	pg 11116, thm 4.3.3. see example on pg 11116<br>todo: add impostor<br>
What is the difference between a <i>materialized</i> and a <i>virtual</i> user view? Read the "Composition and User Views" section, including the example.<br><br>	pg 11117<br>
What are the three algebraic operators that comprise the <i>unnamed conjunctive algebra</i> (aka the <i>SPC algebra</i>)?	pg 11118, near bottom (right above example)<br><br>
Express the following query using the SPC algebra:<br><br>List the names and addresses of theaters featuring a Bergman film.<br><br>Use the following schema:<br>Movies: 1=title, 2=director, 3=actor<br>Pariscope: 1=theater, 2=title, 3=schedule<br>Location: 1=theater, 2=address, 3=phone number<br> <br> 	pg 11118, example at bottom<br>spills to pg 11119<br>
<latex>~\\<br>The selection operator $\sigma$ has two primitive forms. Provide the formal definition of each.<br></latex>	pg 11119, bottom<br><br>
<latex>~\\<br>Provide the formal definition of the general form of the projection operator $\pi$ of the SPC algebra.<br></latex><br>	pg 11120, at top<br>
Give the formal definition of the <i>cross-product</i> operator of the SPC algebra.<br>	pg 11120<br>
Give the formal, inductive, definition of the SPC algebra. 	pg 11120, near bottom.<br>
Provide the formal definitions of the <i>positive conjunctive selection operator</i> and the <i>equi-join operator</i> of the <i>generalized SPC algebra</i>.<br> 	Note that these are both specified as derived forms of the standard SPC algebra.<br>pg 11121<br>
What does it mean for an SPC algebra expression to be in <i>normal form</i>?	pg 11121, kinda near bottom<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For each (generalized) SPC query $q$ there is a generalized SPC query $q'$ in normal form such that $q \equiv q'$.\\~\\<br>Prove or disprove.<br></latex>	pg 11121<br>
What does it mean for a set of rewrite rules to be <i>sound</i>?	pg 11122<br>
<latex>~\\<br>How can we check whether an SPC query is $q^{\emptyset}$?<br></latex>	pg 11122, (see pg 11121 for the definition of SPC normal form)<br>
Read "The Named Perspective: The SPRJ Algebra" at the bottom of pg 11122,<br>and also read example 4.4.3, pg 11123	<br>
What are the four primitive operators of the SPRJ algebra (aka the named conjunctive algebra)? Give their formal definitions.<br><br>	pg 11123 near bottom, 11124 near top<br>
Read examples 4.4.4 and 4.4.5 on pg 11124, and compare them to figure 4.4 on pg 11125.<br>	<br>
What does it mean for an SPRJ algebra expression to be in <i>normal form</i>?	pg 11125<br>
What is the <i>satisfiable SPRJ algebra</i>?	pg 11125<br>
Give an informal ("crux") proof that the SPC and SPRJ algebras are equivalent.	pg 11126, top<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The rule-based conjunctive queries, tableau queries, conjunctive calculus queries, satisfiable SPC algebra, and satisfiable SPRJ algebra are equivalent.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11126 bottom / pg 11127<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The rule-based conjunctive queries, tableau queries, conjunctive calculus queries, SPC algebra, and SPRJ algebra are equivalent.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. This should say <i>satisfiable</i> SPC algebra and <i>satisfiable</i> SPRJ algebra.<br>pg 11126 bottom<br><br>
Express the following query in the unnamed relational algebra:<br><br>What are the Hithcock movies in which Hitchcock did not play?<br><br>Use the following schema:<br>Movies: title, director, actor<br>Pariscope: theater, title, schedule<br>Location: theater, address, phone number<br><br>	pg 11137, example 5.1.1
What is the <i>unnamed relational algebra</i>?	pg 11137
Can we express the following query as a conjunctive query?<br><br>Where can I see "Annie Hall" or "Manhattan"?<br><br>Why or why not?	pg 11127, bottom<br>make sure to read full example, which spills through most of pg 11128
What is the <i>SPCU algebra</i>? What is the <i>SPRJU algebra</i>?<br>	pg 11128<br>
What is a <i>nonrecursive datalog program</i>?<br>	pg 11128 bottom / pg 11129 top three paragraphs or so<br>
What is a <i>non-recursive datalog rule</i>? What does it mean for such a rule to be <i>range restricted</i>?<br>	pg 11138<br>
<latex>~\\<br>A \emph{nonrecursive datalog$^{\neg}$} rule $q$ has the form:\\~\\<br>$S(u) \leftarrow L_1,\ldots,L_n$\\~\\<br>where $S$ is a relation name, u is a free tuple of appropriate arity, and each $L_i$ is a \emph{literal} [i.e., an expression of the form $R(v)$ or $\neg R(v)$ where $R$ is a relation name and $v$ is a free tuple of appropriate arity and where $S$ does not occur in the body]\\~\\<br>How do we give semantics to such a rule?<br></latex>	pg 11138<br>
<latex>~\\<br>What is a \emph{nonrecursive datalog$^\neg$ program}?<br></latex>	pg 11138 bottom / 11139 top<br>
<latex>~\\<br>Try expressing the following queries in non-recursive datalog$^{\neg}$ (if possible)\\~\\<br>- What are the Hitchcock movies in which Hitchock did not play?\\<br>- What movies are featured at the Gaumont Operat but not at the Gaumont les Halles?\\<br>- List those movies for which all actors of the movie have acted under Hitchcock's direction.\\~\\<br>Using the following schema:\\<br>Movies: Title, Director, Actor\\<br>Pariscope: Theater, Title, Schedule\\<br>Location: Theater, Address, Phone Number\\<br>\textbf{Assume that each movie in \emph{Movies} has one director}<br></latex>	pg 11139, example 5.2.1<br><br>
Adding negation into the query calculus paradigm yields an extremely flexible query language. But what is the downside of this flexibility?	pg 11139, bottom<br>
Give the formal definition of the <i>relational calculus</i>. 	it's just first-order predicate logic without function symbols.<br>pg 11140, bottom<br><br>
What is a <i>relational calculus query</i>?<br>	pg 11141<br>
Express the following queries in relational calculus.<br><br>-What are the Hitchcock movies in which Hitchcock did not play?<br>-List those movies for which all actors of the movie have acted under Hitchcock's direction.<br><br>Use the following schema:<br>Movies: Title, Director, Actor<br>Pariscope: Theater, Title, Schedule<br>Location: Theater, Address, Phone Number<br><br><b>Assume that each movie has one director.</b>	pg 11141, example 5.3.1<br><br>
<latex>~\\<br>Let $\mathbb B$ be an arbitrary category with Cartesian products. Define the category $s(\mathbb B)$.<br></latex>	pg 10020
<latex>~\\<br>Give the definition of $s_{\mathbb B} : s(\mathbb B) \to \mathbb B$, the \emph{simple fibration on } $\mathbb B$. Prove that it is actually a fibration.<br></latex>	pg 10020
<latex>~\\<br>Recall the definition of the \emph{simple fibration} on $\mathbb B$.<br>Intuitively, what are maps in the fibre $s(\mathbb B)_I$ over $I \in \mathbb B$?<br></latex>	pg 10020<br>
<latex>~\\<br>Let $\mathbb B$ be a category with Cartesian products. Let $I$ be an object of $\mathbb B$. What does $\mathbb B \sslash I$ denote?<br></latex>	pg 10020, def 1.3.1<br><br>
<latex>~\\<br>Give the definition of the functor $I^* : \mathbb B \to \mathbb B \sslash I$.\\<br>Give the definition of the functor $I^* : \mathbb B \to \mathbb B / I$.\\~\\<br>Note that these two distinct functors have the same name because they have much in common.<br></latex>	pg 10020<br>
<latex>~\\<br>What is a \emph{CT-structure}? What does it mean for a CT-structure to be \emph{non-trivial}? <br></latex>	pg 10021, def 1.3.2<br><br>
<latex>~\\<br>Why are CT-structures called CT-structures? (i.e. what do 'C' and 'T' stand for)?<br></latex>	pg 10021<br>
<latex>~\\<br>Give an example of a CT-structure.<br></latex>	<latex>~\\<br>An example of a CT-structure is $\mathbb B = \omega$-$\mbf{Sets}$ and $T = $ objects of the form $\triangledown X$, where $X$ is a set.\\~\\<br>pg 10021<br></latex><br>
<latex>~\\<br>Let $(\mathbb B, T)$ be a CT-structure. Then how is the category denoted by $s(T)$ defined?<br></latex>	pg 10021, def 1.3.3<br>
<latex>~\\<br>Let $(\mathbb B, T)$ be a CT-structure. Provide the definition for the fibration $\ddisp{s(T)}{sT}{\mathbb B}$.\\<br></latex>	pg 10021, below def 1.3.3<br>
<latex>~\\<br>Provide the definition of $s_{\Omega} : s(\Omega) \to \mathbb B$.<br></latex>	<latex>~\\<br>It's $s(T)$, where $T = \{ \Omega \}$. \\<br>pg 10021, near bottom<br></latex>
<latex>~\\<br>Let $\mathbb B$ be a category. Give the definition of the category $Mono(\mathbb B)$.<br></latex>	pg 10022<br>
<latex>~\\<br>If $\mathbb B$ is a category with pullbacks, what is the \emph{fibration of monos} of $\mathbb B$?<br></latex>	pg 10022<br>
<latex>~\\<br>What is a \emph{fibred preorder}? Given an example of a fibred preorder. <br></latex>	a fibration of monos is a fibred preorder<br>pg 10022<br>
<latex>~\\<br>Let $\mathbb B$ be a category with pullbacks and $I$ an object of $\mathbb B$. What does Sub(I) denote?<br></latex>	The poset of subobjects of I.<br>pg 10022<br>
<latex>~\\<br>Give the definition of the category $Sub(\mathbb B)$.<br></latex>	pg 10022. second to last paragraph.<br>Note that here the term "subobject" refers to an equivalence class of monos rather than an individual mono.<br>
<latex>~\\<br>What is a fibration of subobjects? Give a concrete example of a fibration of subobjects.<br></latex>	pg 10022, second-to-last-paragraph<br><br>
<latex>~\\<br>List the two \emph{type theoretic fibrations}? Why are they called \emph{type theoretic fibrations}?<br></latex>	pg 10023, top paragraph<br>
<latex>~\\<br>Provide the definition for the category $Rel(\mathbb B)$.<br></latex>	pg 10023
<latex>~\\<br>What is a (binary) \emph{relation} on an object $I$ in a category $\mathbb B$ with finite limits?<br></latex>	pg 10023<br>
<latex>~\\<br>Categorically, what does it mean for a relation $R \rightarrowtail I \times I$ to be \emph{reflexive}?<br></latex>	pg 10023<br>
<latex>~\\<br>Categorically, what does it mean for a relation $R \rightarrowtail I \times I$ to be \emph{symmetric}?<br></latex><br>	pg 10023
<latex>~\\<br>Categorically, what does it mean for a relation $R \rightarrowtail I \times I$ to be \emph{transitive}?<br></latex>	pg 10024<br>
<latex>~\\<br>Explain the problem with this relational calculus query:~\\~\\<br>$\{ x \mid \neg Movies(\text{"Cries and Whispers"}, \text{"Bergman"}, x) \}$\\~\\<br>How can we address this problem?<br></latex>	pg 11142<br><br>We can address the problem by requiring the variable to have types: "An intuitively appealing approach..."<br><br><br>
<latex>~\\<br>Explain the problem with this relational calculus query:~\\~\\<br>$\{ x, y \mid \neg Movies(\text{"Cries and Whispers"}, \text{"Bergman"}, x) \vee Movies(y, "Bergman", "Ullman") \}$\\~\\<br>How can we address this problem?<br></latex>	pg 11142<br><br>We can address the problem by requiring the variable to have types: "An intuitively appealing approach..."
<latex>~\\<br>Explain the problem with this relational calculus query:~\\~\\<br>$\{ x \mid \forall y R(x,y) \}$\\~\\<br></latex>	pg 11142<br>
<latex>~\\<br>Is the following relational calculus query domain independent?~\\~\\<br>$\{ x_t \mid \forall y_a (\exists y_d Movies(x_t, y_d, y_a) \to \exists z_t Movies(z_t, "Hitchcock", y_a)) \}$\\~\\<br>Why or why not?<br></latex>	it's dependent<br>pg 11143, example 5.3.2<br><br>
<latex>~\\<br>What is a \emph{relativized instance} ($\mbf{d}$, $\mbf{I}$) over a schema $\mbf{R}$?<br></latex>	pg 11143<br>
<latex>~\\<br>What does it mean for a relational calculus formula $\varphi$ to be \emph{interpretable over} a relativized instance $(\mbf{d}, \mbf{I})$?<br></latex>	pg 11143<br>
<latex>~\\<br>If $(\mbf{d},\mbf{I})$ is a relativized instance over a schema $\mbf{R}$, $\varphi$ is interpretable over<br>$(\mbf{d}, \mbf{I})$, and $v$ is a valuation over $free(\varphi)$, then what does $\mbf{I} \vDash_{\mbf{d}} \varphi[v]$ mean?<br></latex>	pg 11143<br>
<latex>~\\<br>Let $\mbf{R}$ be a schema, $q = \{ e_1, \ldots, e_n \mid \varphi \}$ a relational calculus query over $\mbf{R}$, and $(\mbf{d}, \mbf{I})$ a relativized instance over $\mbf{R}$. Then what is the \emph{image} of $\mbf{I}$ under $q$ \emph{relative to} $\mbf{d}$?<br></latex>	pg 11144, at top<br><br>
<latex>~\\<br>Consider the query<br>$$q = \{ x \mid R(x) \wedge \exists y (\neg R(y) \wedge \forall z(R(z) \vee z = y)) \}$$<br>Provide the following:\\~\\<br>$q_{\mbf{dom}}(I)$\\<br>$q_{\{ 1,2,3,4\} }(J_1)~\text{for } J_1 = \{ \langle 1 \rangle, \langle 2 \rangle \} \text{ over R}$\\<br>$q_{\{ 1,2,3,4 \} }(J_2)~\text{for } J_2 = \{ \langle 1 \rangle, \langle 2 \rangle, \langle 3 \rangle \} \text{ over R}$\\<br>$q_{\{ 1,2,3,4 \} }(J_3)~\text{for } J_3 = \{ \langle 1 \rangle, \langle 2 \rangle, \langle 3 \rangle, \langle 4 \rangle \} \text{ over R}$ <br></latex>	pg 11144, example 5.3.3<br><br>
<latex>~\\<br>For calculus query $q$ and input instance $\mbf{I}$, what does $q_{nat}(\mbf{I})$ denote?<br></latex>	pg 11144<br>
<latex>~\\<br>For a relational calculus query $q$ and input instance $\mbf{I}$, what does $q_{adom}(\mbf{I})$ denote?<br></latex>	pg 11145, def 5.3.5<br><br>
<latex>~\\<br>Consider the following query:\\~\\<br>$$\{ x, y \mid Movies(\text{"Cries and Whispers"}, \text{"Bergman"}, x) \vee Movies(y, \text{"Bergman"}, \text{"Ullman"}) \} $$~\\<br>What is the natural interpretation of this query? What is the active domain interpretation of this query?<br></latex>	pg 11145, example 5.3.6<br>
<latex>~\\<br>What does it mean for a relational calculus query $q$ to be \emph{domain independent}?<br></latex>	pg 11145, def 5.3.7<br><br>
Give one or more examples of database queries that are not expressible in relational algebra or relational calculus, due to lack of recursion.<br>	pg 11340<br><br>
Give a datalog program for expressing the transitive closure of a graph. (Yes, you should also come up with an appropriate database schema.)<br>	pg 11340, bottom<br><br>
What is a datalog program interpreted as?<br>	pg 11341, second paragraph<br><br>
Explain how the <i>model theoretic</i> semantics for datalog interprets the example on the bottom of pg 11340 computing the transitive closure of a graph.<br>	pg 11341<br>
Consider the example on the bottom of pg 11340, which computes the transitive closure of a graph. If the graph relation is G(a,b), G(b,c), G(c,d) then the fact T(a,d) is in the minimal model of this program. Explain this fact using the <i>proof-theoretic</i> approach to datalog semantics.<br>	pg 11341, near bottom<br><br>
What is a <i>datalog rule</i>? What is a <i>datalog program</i>?	pg 11342<br>
Given a valuation v, what is an <i>instantiation</i> of a datalog rule with v?	pg 11343, top<br>
Which relations of a datalog program are considered <i>extensional</i>, and which relations are considered <i>intensional</i>?	pg 11343<br>
Given a datalog program P, what do edb(P), idb(P), and sch(P) denote?	pg 11343, near top<br><br>
Give a datalog program which computes the answers to queries (12.1), (12.2), and (12.3) on pg 11339?<br>Use the database schema containing the single relation name <i>links</i> shown on pg 11340.<br><br>	pg 11343 example 12.1.3<br>
What is the major difference between datalog and logic programming?<br>List some additional differences between datalog and logic programming.<br>	Logic programming permits function symbols, whereas datalog does not.<br>pg 11344 top, see also example 12.1.4 on the same page.<br>See also the paragraph below the aforementioned example.<br><br><br>
<latex>~\\<br>Give the logical sentence associated with the following datalog rule:\\~\\<br>R_1(u_1) \leftarrow R_2(u_2), \ldots, R_n(u_n)<br></latex>	pg 11345, near top<br><br>
<latex>~\\<br>For a datalog program $P$, what does $\Sigma_P$ denote?<br></latex>	the conjunction of the logical sentences associated with P<br>pg 11345<br>
<latex>~\\<br>There are alternative ways to write the sentences associated with rules of programs. In particular, consider that the formula<br>$$ \forall x_1,\ldots,x_m(R_1(u_1) \leftarrow R_2(u_2)\wedge \cdots R_n(u_n))$$<br>is equivalent to<br>$$ \forall x_1, \ldots, x_q (\exists x_{q+1}, \ldots, x_m (R_2(u_2) \wedge \cdots \wedge R_n(u_n)) \to R_1(u_1))$$<br>where $x_1,\ldots,x_q$ are the variables occurring in the head. Also, consider that it is equivalent to<br>$$ \forall x_1, \ldots, x_m (R_1(u_1) \vee \neg R_2(u_2) \vee \cdots \vee \neg R_n(u_n))$$<br>There is a particular name for formulas having the form of the body (i.e. the part inside the quantifiers) of the last formula. What is it?<br></latex>	pg 11345, near bottom<br><br>
<latex>~\\<br>Let $P$ be a datalog program and $\mbf{I}$ an instance over $edb(P)$. What is a \emph{model} of $P$? What does $P(\mbf{I})$ denote?<br></latex>	pg 11345, definition 12.2.1 at bottom<br>
<latex>~\\<br>For a given datalog program $P$ and instance $\mbf{I}$ of $edb(P)$, what is denoted by $\mbf{B}(P,\mbf{I})$? What is the purpose of $\mbf{B}(P, \mbf{I})$?<br></latex>	pg 11346, see the paragraph above lemma 12.2.2<br>
<latex>~\\<br>Let $P$ be a datalog program, $\mbf{I}$ an instance over $edb(P)$, and $\mathcal X$ the set of models of $P$ containing $\mbf{I}$. Consider the following statement:\\~\\<br>$\cap \mathcal X$ is the minimal model of $P$ containing $\mbf{I}$, so $P(\mbf{I})$ is defined.\\~\\<br>Prove or disprove.<br></latex>	pg 11347, thm 12.2.3 (1).<br>todo: add impostor?<br>
<latex>~\\<br>Let $P$ be a datalog program and $\mbf{I}$ an instance over $edb(P)$. Consider the following statement:\\~\\<br>$adom(P(\mbf{I})) \subseteq adom(P, \mbf{I})$\\~\\<br>Prove or disprove.<br></latex>	pg 11347. thm 12.2.3 (2)<br>TODO: add impostor?<br>
<latex>~\\<br>Let $P$ be a datalog program, $\mbf{I}$ an instance over $edb(P)$, and $\mathcal X$ the set of models of $P$ containing $\mbf{I}$. Consider the following statement:\\~\\<br>For each $R$ in $edb(P)$, $P(\mbf{I})(R) = \mbf{I}(R)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11347, thm 12.2.3 (3)<br>todo: add impostor?<br>
Of all of the models of a recursive datalog program P, why do we choose the minimal one as P's meaning?	read the following section:<br>pg 11347/11348 "Why choose the minimal model?"
<latex><br>What is the \emph{closed world assumption}? Explain why a datalog (with negation) program holding the single fact $\{ p \vee q \}$ presents a dilemma to the closed world assumption.<br></latex>	pg 11348, paragraph above "Herbrand Interpretation"<br><br>
<latex>~\\<br>Let $P$ be a datalog program. What does $T_P$ denote, and why is it important?<br></latex>	pg 11349, second-to-top paragraph. (it's important because taking its fixpoint gives us a minimal model)<br><br>
<latex>~\\<br>Let $P$ be a datalog program. Consider the following statement:\\~\\<br>An instance $\mbf{K}$ of $sch(P)$ is a model of $\Sigma_P$ iff $T_P(\mbf{K}) \subseteq \mbf{K}$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11349, lemma 12.3.1 (ii)<br>todo: add impostor?<br>
<latex>~\\<br>Let $P$ be a datalog program. Consider the following statement:\\~\\<br>Each fixpoint of $T_P$ is a model of $\Sigma_P$; the converse does not necessarily hold.\\~\\<br>Prove or give a counterexample.<br></latex>	pg 11349, leamm 12.3.1<br><br>
In the "datalog with recursion and negation" paradigm, there are two flavors of languages: inflationary and noninflationary. Explain the difference between these two flavors.	read the example on pg 11409
Consider the following statement:<br><br>Recursive datalog with negation queries can be evaluated in polynomial space.<br><br>Prove or disprove.<br>	true... explanation below the example on pg 11409<br>todo: add impostor?<br>
Give an overview of the <i>while</i> language. The while language has two statement forms: assignment and while. Explain these forms and their semantics.<br><br>	pg 11411<br>
Give source code for a <i>while</i> program which, given a binary relation G[AB], computes the transitive closure T[AB] of G.<br>	pg 11411, example 14.1.1<br>
Read example 14.1.2 on pg 11412<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a pair $(P,\mbf{I})$ where $P$ is a \emph{while} program, it is undecidable to determine whether $P$ haltes on input $\mbf{I}$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 11412. We can decide by memoizing states, since there are only polynomially many states.<br><br>
<latex>~\\<br>What is the difference between \emph{while}$^+$ and \emph{while}?<br></latex>	pg 11412/11413 "Inflationary Semantics"<br>
Read example 14.2.1 on pg 11414<br>	todo: can I make some question cards from this example?<br>
What is the <i>partial fixpoint operator</i>?	pg 11415<br>
<latex>~\\<br>Give a description of the language CALC+$\mu$.<br></latex>	pg 11415, "Partial Fixpoint Logic"<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Given an instance $\mbf{I}$ over $\mbf{R}$ and a sentence $\sigma$ in CALC+$\mu$, $\sigma$ is either true under $\mbf{I}$ or false under $\mbf{I}$.\\~\\<br>Prove or disprove.<br></latex><br>	<latex>~\\<br>IMPOSTOR: CALC+$\mu$ relations can be undefined if they contiain undefined fixpoint applications.<br>pg 11415, near bottom<br></latex> 
What is a <i>Codd table</i>? (Or <i>table</i> for short)<br>	pg 11554
<latex>~\\<br>Given a table $T$, how do we define the incomplete database $rep(T)$ that $T$ represents?<br></latex>	pg 11555, near top<br><br>
Read pg 11555<br>	<br>
<latex>~\\<br>If $\mathcal L$ is a query language, what is a \emph{strong representation system} for $\mathcal L$?<br></latex>	pg 11555, near bottom<br>
<latex>~\\<br>Consider the query $\sigma_{A=3}(T)$ where $T$ is the table shown in figure 19.1 on pg 11554.<br>Can the result of this query be represented as a table?<br></latex>	Nope. pg 11555, example 19.1.1 near bottom.<br><br>
<latex>~\\<br>For a table $T$ and a query $q$, how is $sure(q, T)$, the set of sure facts, defined?<br></latex>	pg 11556<br>
<latex>~\\<br>Consider the table $T$ shown in figure 19.1 on page 11554.\\<br>Let $q$ be the query $\sigma_{A=2}$.\\<br>Let $q'$ be the query $\pi_{AB}$.\\<br>What is the value of $sure(q, T)$?\\<br>What is the value of $q'(sure(q, T))$?\\<br>What is the value of $sure(q' \circ q, T)$?<br></latex>	see middish paragraph on pg 11556 "One might be tempted to require of a weak system..."<br>
<latex>~\\<br>If $\mathcal L$ is a query language and $\mathcal I$ and $\mathcal J$ are incomplete databases, then what does $\mathcal I \equiv_{\mathcal L} \mathcal J$ mean?<br></latex>	pg 11556<br>
<latex>~\\<br>Let $\mathcal L$ be a query language. What does it mean for a representation system to be \emph{weak} for $\mathcal L$?<br></latex>	pg 11557, very top<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Tables form a weak representation system for selection-projection (SP) [i.e., relation algebra limited to selection (involving only equalities and inequalities) and projection]. But if union or join are added, tables no longer form a weak representation system.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11557<br>todo: add impostor?<br>
Give Jacobs' contraction and exchange rules.	pg 10101<br>
<latex>~\\<br>What is the \emph{term calculus} of a signature $\Sigma$?<br></latex>	pg 10102<br>
Give the substitution rule for Jacobs' basic calculus.<br>	pg 10102<br>
<latex>~\\<br>Given a signature $\Sigma$, how does Jacobs defined the \emph{classifying category}, or \emph{term model}, of $\Sigma$?<br></latex>	pg 10103, def 2.1.1 near bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The classifying category $\mathcal{C}l(\Sigma)$ of a signature $\Sigma$ has finite products.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10104, prop 2.1.2<br>
Pg 10104, exercise 2.1.1 (i), (ii)<br>	<br>
Pg 10104, exercise 2.1.1 (iii), (iv)	<br>
pg 10104 (spills over to 10105), exercise 2.1.2	<br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N , \Upsilon, \Pi \rangle$ be a transducer network, $H$ a distributed database instance, and $\rho = (s, b)$ a configuration of $\mathcal T$ on input $H$. What does $out(\rho)$ denote?<br></latex>	pg 10746, near bottom<br><br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N , \Upsilon, \Pi \rangle$ be a transducer network, and $\mathcal R$ a run of $\mathcal T$ on some input. What does it mean for some natural number $i \geq 1$ to be a \emph{quiescence point} for $\mathcal R$? What does it mean for a configuration $\rho_i$ of $\mathcal R$ to be a \emph{quiescence configuration}?<br></latex>	pg 10746, near bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For every transducer network, on every input, every run contains a quiescence configuration.\\~\\<br>Prove or disprove.<br></latex>	It's stated as obvious on pg 10747. I think it has something to do with the transducer network being monotone, inflationary, and oblivious, as described on pg 10746, section 4.1<br>
<latex>~\\<br>Let $\mathcal R$ be a run of a transducer network on some input. Define the \emph{output} of $\mathcal R$.<br></latex>	pg 10747, near top, below prop 4.1<br>
<latex>~\\<br>What does it mean for a transducer network $\mathcal T = \langle \mathcal N, \Upsilon, \Pi \rangle$ to be <br>\emph{consistent}?<br></latex>	pg 10747, sec 4.3<br><br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N, \Upsilon, \Pi \rangle$ be a consistent transducer network and $I$ a database instance over $\Upsilon_{in}$. What does $\mathcal T(I)$ denote?<br></latex>	pg 10747, "4.3 Consistency"<br><br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N , \Upsilon, \Pi \rangle$ be a consistent transducer network and $I$ a database instance over $\Upsilon_{in}$. Consider the following statement:\\~\\<br>The function $\mathcal T(-)$ from instances over $\Upsilon_{in}$ to instances over $\Upsilon_{out}$ can be viewed as a generic query.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 10747 "4.3 Consistency"<br>
<latex>~\\<br>Let $\mathcal T = \langle \mathcal N , \Upsilon , \Pi \rangle$ be a consistent transducer network. Let $\mathcal Q$ be a query over input schema $\Upsilon_{in}$ and output schema $\Upsilon_{out}$. What does it mean for $\mathcal T$ to \emph{compute the query} $\mathcal Q$?<br></latex>	pg 10747, "4.3. Consistency"<br><br>
<latex>~\\<br>Give a transducer network specification $(\Upsilon, \Pi)$ which takes as input a set of pairs and produces as output the set of all pairs whose components are equal (i.e. it computes the selection $\sigma_{1=2}(R)$.<br></latex>	pg 10747, example 4.3 near bottom<br>
<latex>~\\<br>Give a transducer network specification $(\Upsilon, \Pi)$ for computing the transitive closure of a graph.<br></latex>	pg 10747/10748, example 4.4 near bottom of 10747
Read example 4.5 on pg 10748<br>	<br>
<latex>~\\<br>Let $\Pi$ be a transducer over a schema $\Upsilon$. What does it mean for $\Pi$ to be \emph{network-independent}?<br></latex>	pg 10748, "4.5 Network-independence"<br>
Read example 4.6 on pg 10748-10749<br>	<br>
<latex>~\\<br>Let $\mathcal D$ be a database schema. Consider the following statement:\\~\\<br>There is a transducer schema $\Upsilon$ with $\Upsilon_{in} = \mathcal D$ and an oblivious, inflationary, monotone UCQ-transducer $\Pi$ over $\Upsilon$ such that for every transducer network for $\Pi$, for every instance $I$ of $\mathcal D$, on every horizontal partition of $I$, every fair run reaches a configuration where very node has a local copy of the entire instance $I$ in its memory.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10749 (a network is necessarily connected, so it's fairly obvious)<br>todo: add impostor?
<latex>~\\<br>Let $\mathcal D$ be a database schema. Consider the following statement:\\~\\<br>There is a transducer schema $\Upsilon$ with $\Upsilon_{in} = \mathcal D$ and an $UCQ^{\neg}$-transducer $\Pi$ over $\Upsilon$ such that for every transducer network for $\Pi$, for every instance $I$ of $\mathcal D$, on every horizontal partition of $I$, every fair run reaches a configuration where every node has a local copy of the entire instance of $I$ in its memory, and an additional flag 'ready' is true (implemented by a nullary memory relation). Moreover, the flag 'ready' does not become true at a node before that node has the entire instance I in its memory.<br><br>The transducer $\Pi$ is not oblivious, but can be made inflationary when using locally the language $NrDatalog^{\neg}$ instead of $UCQ^{\neg}$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10749, lemma 4.8, near bottom.<br>todo: add impostor?<br>
<latex>~\\<br>Let $\mathcal L$ be a language containing $UCQ^{\neg}$. Consider the following statement:\\~\\<br>Every query expressible in $\mathcal L$ can be distributedly computed by an $\mathcal L$-transducer. In particular, if $\mathcal L$ is a computationally complete query language, every partial computable query can be distributedly computed by an $\mathcal L$-transducer.\\~\\<br>Prove or disprove.<br></latex>	pg 10750, thm 4.9<br>todo: add impostor
<latex>~\\<br>Let $\mathcal L$ be a query language containing UCQ. Consider the following statement:\\~\\<br>Every monotone query expressible in $\mathcal L$ can be distributedly computed by an oblivious $\mathcal L$-transducer. In particular, if $\mathcal L$ is computationally complete, every partial computable monotone query can be distributedly computed by an oblivious $\mathcal L$-transducer. Morerover, these oblivious transducers can be made inflationary and monotone.\\~\\<br>Prove or disprove.<br></latex>	pg 10750, thm 4.10<br>todo: add impostor?<br>
State Hellerstein's "CALM Conjecture"<br>	pg 10750, near bottom<br>
Discuss the intuition behind the notion of "coordination" in a distributed system. Give some examples of distributed algorithms which require coordination.	pg 10751, top four paragraphs<br><br>
Read pg 10751<br>	<br>
<latex>~\\<br>Let $\Pi$ be a transducer over a schema $\Upsilon$. Let $\mathcal T$ be a transducer network for $\Pi$. What does it mean for $\mathcal T$ to be \emph{coordination-free}?<br></latex>	pg 10751, bottom paragraph above example 5.2<br>
<latex>~\\<br>Let $\Pi$ be a transducer over a schema $\Upsilon$. What does it mean for $\Pi$ to be \emph{coordination-free}?<br></latex>	pg 10751<br>
<latex>~\\<br>Read example 4.4 on pg 10747/10748. Is the given transducer coordination free, according to the formal definition of coordination-freeness? Why or why not?<br></latex>	pg 10751, example 5.2 at very bottom<br>
<latex>~\\<br>Let $\mathcal L$ be a query language containing $UCQ$. Consider the following statement:\\~\\<br>Every monotone query $\mathcal Q$ expressible in $\mathcal L$ can  be distributedly computed by a coordination-free $\mathcal L$-transducer.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10752.<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>A coordination-free transducer will always reach a quiescent state using only heartbeats if run on the horizontal partition which provides all inputs to all nodes.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. see example 5.4 on pg 10752<br>
Consider the following query Q, having as input two nullary relations A and B, and a nullary output relation T : create the non-empty output (representing “true”) if at least one of A and B is nonempty. This query is monotone. Consider the following (contrived) transducer Π to compute Q. If the network has only one node (which can be tested by looking at the relation All), the transducer simply outputs the answer to the query. Otherwise, it first tests if its local input fragments of A and B are both nonempty. If this is the case, nothing is output locally yet, but a nullary fact C is sent out. Any node that receives the message C will output it. When precisely one of A and B is nonempty locally, the transducer simply outputs the correct output directly.<br><br>Is this transducer network independent? Is it coordination-free? If so, which horizontal partitions can be used to demonstrate coordination-freedom?<br>	pg 10752, example 4.5<br><br>the important thing about this example is that providing all information to all nodes does NOT lead to a quiescence state.<br>
Give an example of a transducer that is network-independent, but not coordination free.<br>	pg 10752, exercise 5.5<br><br>
Consider the following transducer:<br><br>The transducer has two unary input relations R and S, and it has a unary output relation T . Using relations Id and All, the transducer can detect if there is only one node, or if there are more nodes. If there is just one node, the single node outputs the union of R and S. If there are at least two nodes, then all nodes will copy their local inputs into their memory; they also broadcast their input facts to each other, so that all nodes accumulate all inputs of the network; and, the nodes will continuously output the intersection of the accumulated R-facts with the accumulated S-facts.<br><br>Is this transducer consistent? Is it coordination-free? Is it network-independent?<br>	pg 10753, example 5.6<br><br>
There is a class of easily-identifiable relational transducers that is guaranteed to be coordination free. What is this class? Prove your answer.<br>	pg 10754, prop 5.8<br>
Hellerstein's "CALM conjecture" was stated as follows:<br><br>"A program has an eventually consistent, coordination-free execution strategy if and only if it is expressible in (monotonic) Datalog."<br><br>How do Ameloot et al. formalize the notion of a "program"? How do they formalize the notion of "having an execution strategy"? <br>	Program is taken to mean "query" and "having an execution strategy" is taken to mean "being distributedly computed by a transducer".<br><br>pg 10754, conjecture 5.9<br><br>
<latex>~\\<br>Let $\mathcal L$ be a query language. Consider the following statement:\\~\\<br>Every query that is distributedly computed by a coordination-free $\mathcal L$-transducer is monotone.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10755, thm 5.10<br>todo: add impostor?<br>
<latex>~\\<br>Let $\mathcal L$ be a query language containing UCQ. Consider the following statement:\\~\\<br>For every query $\mathcal Q$ that is expressible in $\mathcal L$, the following are equivalent:<br>\begin{enumerate}<br>\item $\mathcal Q$ can be distributedly computed by a coordination-free $\mathcal L$-transducer.<br>\item $\mathcal Q$ can be distributedly computed by an oblivious $\mathcal L$-transducer; and,<br>\item $\mathcal Q$ is monotone.<br>\end{enumerate}<br>Prove or disprove.<br></latex>	true. pg 10755, thm 5.11<br>todo: add impostor?<br>
Read theorem 5.11's statement on pg 10755. Then read the discussion 5.2.1, which is about the practical implications of theorem 5.11.<br>	pg 10755/10756
<latex>~\\<br>Consider example 14.1.2 on page 11412. How do we express this query using CALC+$\mu$, without using simultaneous induction?<br></latex>	pg 11416, example 14.2.3<br>
<latex>~\\<br>Consider the following nested use of fixpoint operators:~\\<br>$$\mu_P(G(x,y) \wedge \mu_{Q}(\varphi(P, Q))(x, y))$$<br>Discuss the semantics of such a formula: what is the meaning of this \emph{nesting}?<br></latex>	pg 11417, top of the "simultaneous induction" section
<latex>~\\<br>In terms of $CALC+\mu$ languages, what does the following notation mean?<br>$$\mu_{P,Q}(\varphi(P, Q), \psi(P,Q))$$<br></latex>	pg 11417, "In contrast, we now consider a generalization..."<br>
<latex>~\\<br>Consider example 14.1.2 on page 11412. How do we express this query using CALC+$\mu$ with simultaneous induction?<br></latex>	pg 11417, example 14.2.4, near bottom<br>
<latex>~\\<br>For some $n$, let $\varphi_i(R_1,\ldots,R_n)$ be CALC formulas, i in [i..n], such that $\mu_{R_1, \ldots, R_n}(\varphi_1(R_1, \ldots, R_n), \ldots, \varphi_n(R_1, \ldots, R_n))$ is a correct formula. Consider the following statement:\\~\\<br>For each $i \in [1,n]$ there exist CALC formulats $\varphi'_i(Q)$ and tuples $\vec{e_i}$ of variables or constants such that for each $i$,<br>$$\mu_{R_1, \ldots, R_n}(\varphi_1(R_1,\ldots,R_n),\ldots,\varphi_n(R_1,\ldots,R_n))(R_i) \equiv \mu_Q(\varphi'_i(Q))(\vec{e_i})$$<br>Prove or disprove.<br></latex>	pg 11418, leamma 14.2.5<br><br>
<latex>~\\<br>How are the semantics of an inflationary fixpoint $\mu^+_{T}(\varphi(T))$ defined?<br></latex>	pg 11419, near top<br>
<latex>~\\<br>How is the query language $CALC+\mu^{+}$ defined?<br></latex>	pg 11419
<latex>~\\<br>Give a query expression for obtaining the transitive closure of a graph using the query language $CALC+\mu^+$.<br></latex>	pg 11419
<latex>~\\<br>Consider the following statement:\\~\\<br>An inflationary simultaneous induction of the form $\mu^+_{P,Q}(\varphi(P,Q), \psi(P, Q))$ is equivalent to a system of equational definitions of the form:<br>$$P = \varphi(P, Q)$$<br>$$Q = \psi(P,Q)$$<br>Prove or disprove<br></latex>	pg 11419, near bottom<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The only approach for guaranteeing polynomial-time termination for fixpoint operation is by using inflationary fixpoints.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. monotonicity is another one.<br>pg 11420
<latex>~\\<br>Consider the following statement:\\~\\<br>In $CALC+\mu$ with a positive (monotone) fixpoint constraint is more expressive than $CALC+\mu^+$.\\~\\<br>True or false?<br></latex>	false. there's an exercise that explains why.<br>pg 11420<br>
<latex>~\\<br>Given an input graph relation $G(X,Y)$, we would like to compute the relation $closer(x,y,x',y')$ which is true if the distance (in hops) between $x$ and $y$ is smaller than the distance between $x'$ and $y'$. Give a query for this, in $Datalog^{\neg}$.<br></latex>	pg 11421, example 14.3.1, near bottom<br><br>
<latex>~\\<br>Provide the definition of a $Datalog^{\neg}$ \emph{rule}.<br></latex>	pg 11422<br>
<latex>~\\<br>Let $P$ be a $Datalog^{\neg}$ rule and $\mbf{K}$ an instance of $P$. What does it mean for a fact $A'$ to be an \emph{immediate consequence} of $\mbf{K}$ and $P$?<br></latex>	pg 11422<br>
<latex>~\\<br>Let $P$ be a $Datalog^{\neg}$ program and $\mbf{K}$ an instance of $sch(P)$. How is the immediate consequence operator $\Gamma_P(\mbf{K})$ defined?<br></latex>	pg 11422<br>
<latex>~\\<br>Let $P$ be the following program:<br>$$R(0) \leftarrow Q(0), \neg R(1)$$<br>$$R(1) \leftarrow Q(0), \neg R(0)$$<br>Let $\mbf{I} = \{ Q(0) \}$. What is $P(\mbf{I})$? Is $P(\mbf{I})$ a minimal model of $P$ among those models of $P$ containing $\mbf{I}$?<br></latex>	pg 11423, ex. 14.3.2<br><br>
<latex>~\\<br>What is datalog^{\neg \neg}?<br></latex>	pg 11423, "Noninflationary Semantics"<br>
<latex>~\<br>Consider example 14.1.2 on pg 11412. Express this query in $Datalog^{\neg \neg}$.<br></latex>	pg 11423, example 14.3.3 at bottom.<br>
<latex>~\\<br>For $datalog^{\neg}$, how is the immediate consequence operator $T_P$ defined, and how does it differ from $\Gamma_P$?<br></latex>	pg 11441, "Fixpoint Semantics: Problems"<br>Gamma_P is defined on pg 11422, near the bottom of the page<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a $datalog^{\neg}$ program $P$, the immediate consequence operator always has a fixpoint.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 11441, example 15.1.1 (a)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a $datalog^{\neg}$ program $P$, for any input $\mbf{I}$ the immediate consequence operator $T_P$ has a unique minimal fixpoint containing $\mbf{I}$.\\~\\<br>Prove or disprove. <br></latex>	IMPOSTOR. pg 11441, example 15.1.1 (b)<br>
<latex>~\\<br>Consider the sequence $\{ T_P^i(\emptyset) \}_{i > 0}$ for a given $datalog^{\neg}$ program $P$. Assume that $T_P$ has a least fixpoint. Consider the following statement:\\~\\<br>If $T_P$ has a least fixpoint then $\{ T_P^i(\emptyset) \}_{i > 0}$ converges.\\~\\<br>Prove or disprove.<br></latex>	no. pg 11441, example 15.1.1
<latex>~\\<br>Consider the sequence $\{ T_P^i(\emptyset) \}_{i > 0}$ for a given $datalog^{\neg}$ program $P$. Consider the following statement:\\~\\<br>If $\{ T_P^i(\emptyset) \}_{i > 0}$ converges, then it converges to a minimal fixpoint of $T_P$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 11442, item 2 near top<br>
<latex>~\\<br>For a $datalog^{\neg}$ program $T_P$, what is the connection between $T_P$ and models of $\Sigma_P$?<br></latex>	<latex>~\\<br>An instance $\mbf{K}$ over $sch(P)$ is a model of $\Sigma_P$ iff $T_P(\mbf{K}) \subseteq \mbf{K}$.<br></latex><br>pg 114422
<latex>~\\<br>What does it mean for a $datalog^{\neg}$ relation to be \emph{semipositive}?<br></latex>	Only edb relations can be negated.<br>pg 11443
<latex>~\\<br>Why are semipositive $datalog^\neg$ programs not much different from standard $datalog$ programs?<br></latex>	pg 11443, below def 15.2.1<br><br>
<latex>~\\<br>Let $P$ be a semipositive $datalog^{\neg}$ program. Consider the following statement:\\~\\<br>For every instance $\mbf{I}$ over $edb(P)$, $\Sigma_P$ has a unique minimal model $\mbf{J}$ satisfying $\mbf{J}|edb(P) = \mbf{I}$.\\~\\<br>Prove or disprove.<br></latex>	pg 11443, thm 15.2.2 (i)<br>
<latex>~\\<br>Let $P$ be a semipositive $datalog^{\neg}$ program. Let $\mbf{I}$ be an instance over $edb(P)$. Consider the following statement:\\~\\<br>$T_P$ has a unique minimal fixpoint $\mbf{J}$ satisfying $\mbf{J}|edb(P) = \mbf{I}$ \\~\\<br>Prove or disprove.<br></latex>	pg 11443, thm 15.2.2 (ii)<br>
In what way can the complement of a graph's transitive closure be computed using the "composition" of two semipositive datalog programs?	pg 11444, above "Syntactic Restriction for Stratification"<br>
<latex><br>Give a brief overview discussion of the concept of \emph{stratification} in $datalog^{\neg}$.<br></latex>	pg 11444 "Syntactic Restriction for Stratification"<br>
<latex>~\\<br>What is a \emph{stratification} of a $datalog^{\neg}$ program $P$? What is a \emph{stratum}? What is a \emph{stratification mapping}?<br></latex>	pg 11444, def 15.2.4, near bottom, spills onto pg 11445<br><br>
<latex>~\\<br>Consider the program defined by<br>\begin{itemize}<br>\item $S(x) \leftarrow R_1'(x) , \neg R(x)$ <br>\item $T(x) \leftarrow R_2'(x) , \neg R(x)$ <br>\item $U(x) \leftarrow R_3'(x) , \neg T(x)$<br>\item $V(x) \leftarrow R_4'(x) , \neg S(x) , \neg U(x)$<br>\end{itemize}<br>Consider the following statement:\\~\\<br>There is a unique stratification of this program.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. example 15.2.5, pg 11445<br>
<latex>~\\<br>What is a \emph{precedence graph} of a $datalog^\neg$ program?<br></latex>	pg 11446<br>
<latex>\\~\\<br>Let $P$ be a program with stratification $\sigma$. Consider the following statement:\\~\\<br>If there is a path from $R'$ to $R$ in $G_P$, then $\sigma(R') \leq \sigma(R)$; and if there is a path from $R'$ to $R$ in $G_P$ containing some negative edge, then $\sigma(R') < \sigma(R)$.\\~\\<br>Prove or disprove. <br></latex>	true. pg 11446, lemma 15.2.6<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A $datalog^{\neg}$ program $P$ is stratifiable iff its precedence graph $G_P$ has no cycle containing a negative edge.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11446, prop 15.2.7<br>todo: add impostor?
<latex>~\\<br>Given a program $P$ with stratification $\sigma = P^1, \ldots, P^n$, and an instance $\mbf{I}$ over $edb(P)$, how are the semantics $\sigma(\mbf{I})$ of this stratification defined?<br></latex>	pg 11447<br>
<latex>~\\<br>Let $P$ be a semipositive $datalog^\neg$ program and $\sigma$ a stratification for $P$. Consider the following statement:\\~\\<br>$P^{semi-pos}(\mbf{I}) = \sigma(\mbf{I})$ for each instance $\mbf{I}$ over $edb(P)$.\\~\\<br>Prove or disprove.<br></latex>	pg 114488<br>
<latex>~\\<br>Let $P$ be a stratifiable $datalog^{\neg}$ program. Consider the foolowing statement:\\~\\<br>All stratifications of $P$ are equivalent.\\~\\<br>Prove or disprove.<br></latex>	pg 11448<br>
<latex><br>Let $P$ be a $datalog^{\neg}$ program. What is a 3-valued model of $P$, and what does it mean for a 3-valued model to be \emph{3-stable}?<br></latex>	<latex><br>pg 11451, "a declarative semantics for datalog^{\neg}"<br></latex>
<latex>~\\<br>Define the "win-moves" game. Give its definition in $datalog^{\neg}$, assuming well-founded semantics.<br></latex>	pg 11452, example 15.3.1<br>
In three-valued logic, there are three different rational numbers that are used to denote <i>true</i>, <i>false</i>, and <i>unknown</i>. What are they?	1, 0, and 1/2<br>pg 11452, at the very bottom<br><br>
<latex>~\\<br>Let $P$ be a $datalog^{\neg}$ program and $\mbf{I}$ a database instance. What does $P_{\mbf{I}}$ denote?<br></latex>	pg 11453, top<br>
<latex>~\\<br>Let $P$ be a $datalog^{\neg}$ program. What is a \emph{3-valued instance} $\mbf{I}$ over $sch(P)$?<br></latex>	pg 11453, second paragraph<br>
<latex>~<br>Let $\mbf{I}$ be a 3-valued database instance. What do $\mbf{I}^{1}$, $\mbf{I}^{0}$, and $\mbf{I}^{1/2}$ denote? <br></latex>	pg 11453<br>
What does it mean for a 3-valued database instance to be <i>total</i>?<br>	Every fact is either true or false: none are unknown.<br>pg 11453
<latex>~\\<br>For any $datalog^{\neg}$ program $P$, there is a natural ordering $\prec$ among three-valued instances over $sch(P)$. Give the definition of $\prec$.<br></latex>	pg 11453<br>
<latex>~\\<br>Given a three-valued instance $\mbf{I}$, what does $\hat{\mbf{I}}$ denote? Give its definition.<br></latex>	pg 11453<br>
<latex>~\\<br>Let $P$ be $datalog^{\neg}$ program. What does it mean for a 3-valued instance $\mbf{I}$ over $sch(P)$ to \emph{satisfy} a formula $\alpha$? <br></latex>	pg 11453, bottom paragraph above example 15.3.2<br><br><br>
<latex>~\\<br>Given a $datalog^{\neg}$ program $P$, what is a \emph{3-valued model} of $\Sigma_P$?<br></latex>	pg 11453, bottom paragraph above example 15.3.2<br>
<latex>~\\<br>Read example 15.3.1 on pg 11452. Consider the following two ground sentences:<br>$$win(a) \leftarrow moves(a,d), \neg win(d)$$<br>$$win(a) \leftarrow moves(a, b), \neg win(b)$$<br>Which of these sentences are true? false? unknown?<br></latex>	pg 11453, example 15.3.2<br>
<latex>~\\<br>What is a \emph{3-extended datalog program}? How do we define the \emph{3-valued immediate consequence operator} $3$-$T_P$?<br></latex>	pg 11454<br>
<latex>~\\<br>Consider the 3-extended datalog program $$P = \{ p \leftarrow 1/2 ; p \leftarrow q, 1/2 ; q \leftarrow p , r; q \leftarrow p, s ; s \leftarrow q ; r \leftarrow 1 \}$$<br>Compute the following:\\~\\<br>$3$-$T_P(\{ \neg p , \neg q , \neg r , \neg s \})$\\<br>$3$-$T_P(\{ \neg q , r , \neg s\})$\\<br>$3$-$T_P(\{ r , \neg s \})$\\<br>$3$-$T_P(\{ r \})$<br></latex>	pg 11454, example 15.3.3<br><br>
<latex>~\\<br>Let $P$ be a 3-extended datalog program. Consider the following statement:\\~\\<br>$3$-$T_P$ is monotonic and the sequence $\{ 3$-$T^{i}_P(\bot) \}_{i > 0}$ is increasing and converges to the least fixpoint of $3$-$T_P$.\\~\\<br>Prove or disprove.<br></latex>	pg 11454, lemma 15.3.4 (1) at bottom<br><br>
<latex>~\\<br>Let $P$ be a 3-extended datalog program. Consider the following statement:\\~\\<br>$P$ has a unique minimal 3-valued model that equals the least fixpoint of $3$-$T_P$\\~\\<br>Prove or disprove.<br></latex>	true. pg 11454/11455, lemma 15.3.4 (2)<br>TODO: add impostor?<br>
<latex><br>If $P$ is an extended datalog program, then what does $P(\bot)$ denote?<br></latex>	The least fixpoint of 3-T_P.<br>pg 11455 top<br>
<latex>~\\<br>Let $P$ be a $datalog^{\neg}$ program. What is the \emph{positivized ground version} of $P$, given database instance $\mbf{I}$?<br></latex>	<latex>~\\<br>pg 11455 "3-stable models of $datalog^{\neg}$"<br>(Note that ground(P) is simply the set of rules of P containing no free variables.)<br></latex>
<latex>~\\<br>Let $P$ be a $datalog^{\neg}$ program. What does $conseq_P(\mbf{I})$ denote?<br></latex>	pg 11455, bottom of the "3-stable models..." section<br>
<latex>~\\<br>Let $P$ be a $datalog^{\neg}$ program. What is a \emph{3-stable model} of $P$?<br></latex>	pg 11455, definition 15.3.5<br>
<latex>~\\<br>Consider the following $datalog^{\neg}$ program $P$. \\~\\<br>$p \leftarrow \neg r$\\<br>$q \leftarrow \neg r , p$\\<br>$s \leftarrow \neg t$\\<br>$t \leftarrow q , \neg s$\\<br>$u \leftarrow \neg t, p , s$\\~\\<br>Consider the following statement:\\~\\<br>$P$ has a unique 3-stable model.\\~\\<br>Prove or disprove.<br></latex><br>	IMPOSTOR. pg 11455, example 15.3.6<br><br>
<latex>~\\<br>Let $P$ be a datalog program. What does $P^{wf}$ denote? If $\mbf{I}$ is an input instance for $P$, what does $P^{wf}(\mbf{I})$ denote?<br></latex>	pg 11456, def 15.3.7<br><br>
What is the intuitive advantage of semi-naive evaluation over naive evaluation.<br>	semi-naive focuses on new information, avoiding redundant computations<br>read pg 11378<br>
Consider the "rsg" datalog program on pg 11378. Rewrite this to a slightly different "program" (which unlike a real program, may have an unbounded number of rules) which demonstrates its "semi-naive structure".<br>	pg 11379, top<br><br>
Read pg 11379<br>	<br>
<latex>~\\<br>Give psuedocode for the "Basic Seminaive Algorithm" for Datalog evaluation.\\<br>Input : Datalog program $P$ and input instance $\mbf{I}$\\<br>Output: $P(\mbf{I})$<br></latex><br><br>	pg 11381<br>
Give psuedocode for the "Improved Seminaive Algorithm" for Datalog evaluation.<br>	pg 11382, algorithm 13.1.2. note that the equivalence classes referenced are described in the paragraph above.<br>
What is the difference between <i>linear</i> and <i>non-linear</i> datalog rules?<br>	linear rules contain at most one recursive recursive literal in their bodies.<br>pg 11843, paragraph above section 2.1<br><br>
How does NDlog deal with the fact that relations may be distributed across sites in a network?	pg 11183, bottom right<br>pg 11184, top left<br>
What is a <i>location specifier</i> in NDlog? In what field of a fact might one expect to find the location that contains said fact?	the first field<br>pg 11844, top left near definition 1<br><br>
Consider the following statement:<br><br>NDlog assumes a network graph that is fully connected (i.e. complete)<br><br>True or false?	False. NDlog assumes a graph that is not complete to reflect the way the internet is actually structured.<br>pg 11844, left column below def 1<br><br>
What is a <i>link relation</i> in NDlog?	pg 11844, def 2, left column<br>
True or false: In NDlog, links (edges) between nodes are undirected.	this is in fact true, as pointed out below def 2 on pg 11844<br>
What is a <i>local rule</i> in NDlog?	pg 11844, def 3 near bottom left<br><br>
What is a <i>link literal</i> in NDlog, and why does NDlog include such a concept?	pg 11844, bottom left, definition 4, top right<br>
In NDlog, what is a <i>link-restricted</i> rule?	pg 11844, top right, definition 5<br>
Give the definition of a Network Datalog (NDlog) program. Hint: it is defined as a Datalog program which satisifies four constraints: what are they?<br>	pg 11844, right column, definition 6<br><br>
<latex>~\\<br>Consider the NDlog program on figure 1 of page 11844. <br>Execute this program intuitively on the following network.<br>\usetikzlibrary{automata, positioning, arrows}<br>\tikzset{node distance = 3cm}<br>\begin{small}<br>\begin{tikzpicture}<br>\node[state, above of = b] (a) {a};<br>\node[state, below of = a] (b) {b};<br>\node[state, below right of = a] (c) {c};<br>\node[state, above of = a] (e) {e};<br>\node[state, below of = b] (d) {d}; <br>\draw <br>  (a) edge[left] node{5} (b)<br>  (a) edge[right] node{1} (c)<br>  (c) edge[above] node{1} (b)<br>  (e) edge[left] node{1} (a)<br>  (b) edge[left] node{1} (d);<br>\end{tikzpicture}<br>\end{small}<br></latex><br>	pg 11844, bottom right<br>pg 11845, top left<br>
Explainthe semi-naive (SN) evalutation algorithm, which is used as a basis for NDlog's buffered and pipelined semi-naive evaluation algorithms.<br>	pg 11845<br>
Examine figure 1 in the top-left corner of pg 11844. The rule SP2 must be rewritten for distributed execution. Explain why and how this is done.<br>	pg 11846, left column<br>
Give Loo's "Rule Localization Rewrite" algorithm for NDlog.<br>	pg 11846<br>
What does Loo's "Rule Localization Rewrite" achieve? I.e. what desired properties hold of the resulting NDlog program?	pg 11846, claim 1<br>
Why is standard semi-naive datalog evaluation insufficient in Loo's declarative networking setting?	pg 11846, section 3.3 intro
Explain Loo's "Buffered Semi-naive" evaluation strategy for NDlog.	pg 11846, section 3.3.1<br>
Give psuedo-code for Loo's "Pipelined Semi-naive Evaluation" algorithm for the evaluation of NDlog programs.<br>	pg 11847, "Algorithm 3"
Explain the purpose of "timestamping" facts in Loo's pipelined semi-naive evaluation strategy.	pg 11847, left column<br><br>
Discuss the differences between the "Continuous Update Model" and the "Bursty Update Model". Which model does Loo focus on for declarative networking?	bursty update. pg 11847, right column<br>
What are the three basic types of changes that can happen to a declarative network state, and how are they handled by Loo?	pg 11847<br>
What is a <i>naive table</i>, and how are naive tables different than tables?	pg 11558<br>
Consider the following statement:<br><br>Naive tables form a weak representation system for positive relational algebra.<br><br>Prove or disprove (intuitively).<br>	pg 11558, thm 19.2.2<br>
Why aren't Codd tables and naive tables rich enough to provide a strong representation system? What can be done to rectify this?	pg 11559, section 19.3 "Conditional Tables"<br>
In the terminology of conditional tables, what is a <i>condition</i>?	pg 11559, section 19.3, second paragraph<br><br>
How can the boolean values <i>true</i> and <i>false</i> be encoded as conditions (in the conditional tables sense of the word <i>condition</i>)?<br> 	pg 11559<br>
<latex>~\\<br>If $\Phi$ is a condition, what does it mean for a valuation $\nu$ to \emph{satisfy} $\Phi$?<br></latex>	pg 11559<br>
<latex>~\\<br>A condition may be associated with a table $T$ in two ways. Describe these two ways.<br></latex>	pg 11559<br>
<latex>~\\<br>Provide the definition of \emph{conditional table} (c-table for short).<br></latex>	pg 11559<br>
<latex>~\\<br>Consider the following program<br>\begin{lstlisting}<br>ClassA o1 = new ClassA(); //object A<br>ClassB o2 = new ClassB(); // object B<br>ClassB o3 = o2;<br>o2.f = o1;<br>Object r = 03.f;<br>\end{lstlisting}<br>What sorts of questions can a \emph{points-to} analysis help us answer about this program? What set of \emph{facts} would be generated from this program to feed to a datalog solver?<br></latex>	pg 11901, section 2.1<br><br>
Give a four-rule datalog program which performs points-to analysis.<br>	pg 11902, figure 1<br><br>
What two key characteristics make a Flix rule distinct from a standard datalog rule?	pg 11903<br>
How do Ross and Sagiv define the notion of a <i>program component</i>?	pg 11916, top right
What do Ross and Sagiv mean when they say that for a particular component P, predicate p is a "CDB predicate" of P? What does it mean to say that p is an "LDB predicate" of P?	pg 11916, top right
How do Ross and Sagiv define the term "cost predicate"? How do they define "cost-argument"? "cost-domain"? "cost-atom"?	pg 11916, def 2.3<br>
Explain how Ross and Sagiv often leave boolean cost arguments implicit.	pg 11916, bottom right corner. "In the case of boolean cost-domain..."<br>
In Ross and Sagiv's system, if the second argument of p is its cost argument, is it possible for a relation to contain both p(a, 3), p(a, 4)?<br>	nope... these relations are just like our dictionaries!<br>pg 11916, bottom right corner<br>
<latex>~\\<br>Consider a domain $D$ and a range $R$. Let $M(D)$ denote the class of multisets over $D$, and suppose that<br>$\mathcal F$ is a map from $M(D)$ to $R$. What does it mean for $\mathcal F$ to be an \emph{aggregate function}? What is an \emph{aggregate subgoal}? Define the related terminology: \emph{grouping variables}, \emph{local variables}, \emph{multiset variable}.<br></latex>	pg 11917, def 2.4<br>
<latex>~\\<br>Consider a ground instance for an aggregate subgoal, which has the form:<br>$$c = \mathcal F E : p(x_1, \ldots, x_n, Y_1, \ldots, Y_m, E)$$<br>where $c,x_1,\ldots,x_n$ are constants. What does it mean for the above ground instance to be \emph{satisfied}?<br></latex>	pg 11917, bottom left<br>
<latex><br>What is the difference between Ross and Sagiv's aggregate subgoals of the form<br>$$C =  \mathcal F E : p(X_1, \ldots, X_n, Y_1, \ldots, Y_m, E)$$<br>and their aggregate subgoals of the form<br>$$C \overset{r}{=} \mathcal F E : p(X_1, \ldots, X_n, Y_1, \ldots, Y_m, E)$$<br></latex>	pg 11917, right column<br>
<latex>~\\<br>Suppose we have an EDB relation \emph{record} such that $record(S, C, G)$ is true when student $S$ scored a grade $G$ (assume the grade is expressed as a percentage) for course C. Give a  rule for expressing the students' individual averages over all courses.<br></latex>	pg 11918<br>
<latex>~\\<br>Suppose we have an EDB relation \emph{record} such that $record(S, C, G)$ is true when student $S$ scored a grade $G$ (assume the grade is expressed as a percentage) for course C. Give a  rule for expressing the class average for a given course.<br></latex>	pg 11918, top-left<br><br>
<latex>~\\<br>Suppose we have an EDB relation \emph{record} such that $record(S, C, G)$ is true when student $S$ scored a grade $G$ (assume the grade is expressed as a percentage) for course C. The class average for a given course can be written as <br>$$ c\text{-}avg(C, G) \leftarrow G \overset{r}{=} average~G' : record(S, C, G')$$<br>Given this rule, how can we write an additional rule for computing the average grade of all classes?<br></latex>	pg 11918, left column "all-avg"<br><br>
How do Ross and Sagiv's notion of <i>default values</i> interact with their <i>cost orderings</i>?<br>	A default value must be minimal with respect to the cost ordering: yet another parallel with our semilattice-valued dictionaries.<br><br>pg 11918, top-right corner<br>
A cost domain in Ross and Sagiv's presentation is associated with a specific kind of relational structure. Which kind?	A complete lattice. A much stronger constraint than our bounded join-semilattices.<br><br>pg 11918, top right corner.<br> 
Give the motivation for including a notion of <i>range restriction</i> in Ross and Sagiv's system.<br>	pg 11918, section 2.3.3 "Safety"<br>
What is a <i>limited argument</i>? A <i>limited variable</i>?	pg 11918, bottom right<br>
Define the set of <i>quasi-limited variables</i> of a rule of Ross and Sagiv's datalog variant.	pg 11919, top-left corner<br><br>
What does it mean for a rule r of Ross and Sagiv's datalog variant to be <i>range-restricted</i>?	pg 11919<br>
What is the intuition behind the definition of quasi-limited variables?	The intuition behind a quasi-limited variable<br>is that its value is uniquely determined by the values of other<br>limited (or quasi-limited) variables in the rule.<br><br>pg 11919, left column<br>
<latex>~\\<br>Suppose we have an EDB relation $record$ such that $record(S,C,G)$ is true when student $S$ scored a grade $G$ (assume the grade is expressed as a percentage) for course $C$.Suppose that $t$ is a default-value cost-predicate. Which of these rules are range-restricted?\\~\\<br>$$ alt\text{-}class\text{-}count(C,N) \leftarrow record(X,C,Y) $$<br>$$ N = count : record(S, C, G)$$<br>$$ all\text{-}class\text{-}count(C, N) \leftarrow N = count : record(S, C, G)$$<br>$$t(G, C) \leftarrow gate(G, and)$$<br></latex>	1.) yes<br>2.) yes<br>3.) no<br>4.) yes<br><br>pg 11919<br>
<latex>~\\<br>Suppose that $t$ is a default-value cost-predicate. Which of these rules are range-restricted?\\~\\<br>$$C = AND~D : [connect(G, W) \wedge t(W,D)]$$<br>$$t(G, and, C) \leftarrow gate(G, and)$$<br>$$C = AND~D : [connect(G,W) \wedge t(W, X, D)]$$<br>$$s(X, Y, C) \leftarrow C = min~D : path(X, Y, Z, D)$$<br>$$s(X, Y, C) \leftarrow C \overset{r}{=} min~D : path(X,Z,Y,D)$$<br></latex>	yes<br>no<br>no<br>no<br>yes<br><br>pg 11919<br>
How do Ross and Sagiv define an <i>extension</i>? What is the <i>core</i> of an extension?	pg 11919. Right column, near top<br><br>
<latex>~\\<br>Consider a program $P$ in which all rules are range-restricted. Let $D$ be an extension that satisfies the following two conditions. First, the core of $D$ is finite. Second, no two atoms in $D$ differ only on the cost argument. Let $G$ be the set of all ground instances of rules of $P$ whose bodies are satisfied according to $D$. <br>Consider the following statement:\\~\\<br>The following is true for $G$:<br>\begin{itemize}<br>\item G is finite<br>\item For each ground aggregate subgoal in $G$, the multiset for this ground instance is finite<br>\item If $h$ is the head of some rule in $G$, then the constants in the non-const arguments of $h$ are from the active domain.<br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 11919<br>todo: add impostor?
Explain the problem of <i>cost-consistency</i>.	pg 11919, bottom right<br>pg 11920, top left<br>
What does it mean for a program to be <i>cost consistent</i>?	pg 11920, top-left corner, def 2.6
Let r be a rule whose head has a cost argument. What does it mean for r to be <i>cost-respecting</i>?	pg 11920, def 2.7<br>
Express the single-source shortest path problem using Ross and Sagiv's datalog variant.	pg 11921, Right column<br><br>
Suppose a relation<br>s is given, where s(X, Y, N) means that company X owns a<br>fraction N of all the shares in Y. We say a company X con-<br>trols another company Y if the sum of the shares it owns in<br>Y together with the sum of the shares owned in Y by com-<br>panies controlled by X is greater than half the total number<br>of shares in Y. (Note that this definition is recursive.)<br><br>Give a program in Ross and Sagiv's datalog variant for computing s.<br>	pg 11921, bottom right column<br>
<latex>~\\<br>What is the \emph{Herbrand universe} of a program $P$?<br></latex>	pg 11922, def 3.2<br>
<latex>~\\<br>What is the \emph{aggregate Herbrand base} of a program $P$?<br></latex>	pg 11922, def 3.1
<latex>~\\<br>Let $p(x_1, \ldots, x_n, c)$ and $p(y_1, \ldots, y_n, c')$ be ground cost atoms. What does the following mean?<br>$$p(x_1, \ldots, x_n, c) \sqsubseteq p(y_1, \ldots, y_n, c')$$<br></latex>	pg 11922<br>unsurprisingly, this is consistent with dictionary semantics.<br>
<latex>~\\<br>What is an \emph{aggregate Herbrand interpretation} $I$ for a program $P$ containing aggregates?<br></latex>	pg 11922<br>
<latex><br>Let $I$ and $I'$ be aggregate Herbrand interpretations. What does $I \sqsubseteq I'$ mean?<br></latex>	pg 11922, top right corner<br><br>
<latex>~\\<br>What aggregate Herbrand interpreation does $J_{\emptyset}$ denote?<br></latex>	pg 11922, right column<br>
<latex>~\\<br>Let $p$ be a ground atom. What does it mean for $p$ to be \emph{satisfied} in an aggregate Herbrand interpretation $I$? What does it mean for $\neg p$ to be satisfied in $I$?<br></latex>	pg 11922<br>
<latex>~\\<br>What does it mean for the body of a ground rule $r$ to be \emph{satisfied} in an aggregate Herbrand interpretation $I$? What does it mean for $r$ to be satisfied in $I$?<br></latex>	pg 11922, def 3.4<br>
<latex>~\\<br>When is an aggregate Herbrand interpretation $I$ considered an \emph{aggregate Herbrand model} of a program $P$?<br></latex>	pg 11922, def 3.5<br><br>
<latex>~\\<br>When is an aggregate Herbrand interpretation $I$ considered an aggregate Herbrand pre-model of program $P$?<br></latex>	pg 11922, def 3.5<br><br>
Consider the following statement:<br><br>All aggregate Herbrand pre-models of a program P are aggregate Herbrand models of P.<br><br>True or false?<br>	IMPOSTOR! pg 11922, below def 3.5<br><br>
<latex>~\\<br>For interpretations $I$ and $I'$, we define $I \sqsubseteq I'$ if for every atom $p$ in $I$ there exists an atom $p'$ in $I'$ such that $p \sqsubseteq p'$.<br>Let $H$ be the domain of interpretations for a program component $P$. Consider the following statement:\\~\\<br>If the cost arguments of $P$ belong to a complete lattice $(D, \sqsubseteq)$, then $(H, \sqsubseteq)$ is also a complete lattice.\\~\\<br>Prove or disprove.<br></latex>	pg 11922, thm 3.1<br>todo: add an imposotr?<br><br>
<latex><br>Let $P$ be a program component with cost arguments having values from a complete lattice $(R, \sqsubseteq)$. Let $I$ be an interpretation for predicates defined in all lower components (i.e., the LDB), and let $J$ be an interpretation for the predicates defined in $P$ (i.e., the CDB). What does it mean for $J \cup I$ to be a \emph{minimal model} of $P$ \emph{based on} $I$?<br></latex>	pg 11923, def 3.6<br>
<latex>~\\<br>Consider the program of example 2.6, pg 11921. Let the \emph{arc} relation be given by $I = \{ arc(a, b, 1), arc(b, b, 0) \}$. Suppose the domain and range are the nonnegative integers, and that $\sqsubseteq$ is the $\geq$ relation. Beware! "$\sqsubseteq$" here means "greater or equal to", and so minimal models will have \emph{larger} cost values. Give two models of the program (ommiting the \emph{arc} facts), one of which is minimal and another which is not.<br></latex>	pg 11923, example 3.1<br>
<latex>~\\<br>Let $P$ be a program component, and let $I$ be an interpretation for predicates appearing in the bodies of rules in $P$ but not in their heads (i.e., LDB predicates). Let $J$ be an interpretation for predicates appearing in the heads of tuples in $P$ (i.e., CDB predicates). What does $T_P(J, I)$ denote? What does it mean for $P$ to be \emph{cost consistent}?<br></latex>	pg 11923<br>
<latex>~\\<br>Let $I$ be a fixed interpretation for the LDB predicates of a program component $P$, and let $J$ vary over interpretations on the CDB of $P$. Consider the following statement:\\~\\<br>$J \cup I$ is a pre-model of $P$ if and only if $T_P(J, I) \sqsubseteq J$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11923, prop 3.2, bottom right<br>todo: add impostor?<br>
<latex>~\\<br>Let $P$ be a program component. What does it mean for $P$ to be \emph{monotonic}?<br></latex>	pg 11924, def 3.8<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a monotonic program $P$ and for fixed $I$, the least fixpoint $J$ of $T_P$ (with respect to $\sqsubseteq$ on the first argument) exists, and $J \cup I$ is the least pre-model of $P$ that is based on $I$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11924, prop 3.3<br>todo: add impostor?<br>
<latex>~\\<br>Let $P$ be a program component, and $I$ an interpretation for the LDB predicates of $P$.<br>What does $J_I^P$ denote? What about $M_I^P$?<br></latex>	pg 11924, above prop 3.4<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a monotonic program $P$, $M_I^P$ is the least model (with respect to $\sqsubseteq$) of $P$ based on $I$, and is the greatest lower bound of all models of $P$ based on $I$.\\~\\<br>Prove or disprove.<br></latex>	pg 11924, corollary 3.5<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $D$ be some poset. Let the function $\mathcal F$ be a map from $M(D)$, the multisets over $D$, into $R$. Let $\sqsubseteq_D$ be a partial order on elements of $D$. How do we extend $\sqsubseteq_D$ to $M(D)$? <br></latex>	pg 11924, section 4.1, right column<br>
<latex>~\\<br>Let $\mathcal F : M(D) \to R$ be a map from multisets over a poset $(D , \sqsubseteq_D)$ into a poset $(R , \sqsubseteq_R)$.<br>What does it mean for $\mathcal F$ to be \emph{monotonic} on $\langle D, \sqsubseteq_D , R , \sqsubseteq_R \rangle$?<br></latex>	pg 11924, sec 4.1, right column<br><br>
Take a gander at table 1 at the bottom of pg 11925<br>	<br>
<latex>~\\<br>Let $\mathcal F$ be an operator from $M(D)$ into $R$. What does it mean for $\mathcal F$ to be \emph{pseudo-monotonic} on $\langle D, \sqsubseteq_D, R, \sqsubseteq_R \rangle$?<br></latex>	pg 11925, def 4.1<br>
What is an <i>aggregate variable?</i>.	pg 11925, right column<br>
How do Ross and Sagiv define the word <i>type</i>?	pg 11925, right column
<latex>~\\<br>What does it mean for a rule $r$ to be \emph{well-formed}?<br></latex><br>	pg 11926, top-left<br><br>
<latex>~\\<br>Let $E_r$ denote the conjunction of the built-in subgoals in the body of a well-formed rule $r$. What is an \emph{assignment} for $E_r$? What is a \emph{full assignment} for $E_r$? A \emph{partial assignment}? <br></latex>	pg 11926<br>
<latex>~\\<br>Let $u : I \to J$ be a map in a base category of a fibration. What do the notations $\overline{u}$ and $u^*$ mean? (They have something to do with cloven fibrations.)<br>How do we define the contravariant functor $-^* : \mathbb E \to \mbf{Cat}$?<br></latex>	pg 10026, bottom<br><br>
<latex>~\\<br>The terms \emph{reindexing functor}, \emph{substitution} functor, \emph{relabeling} functor, \emph{inverse image functor}, \emph{change-of-base} functor, and \emph{pull-back} functor are all used to refer to the same thing. What is it?<br></latex> 	pg 10027<br>
<latex>~\\<br>What does the term ``substitution along u'' or ``reindexing along u'' refer to?<br></latex>	pg 10027
Read example 1.4.2, pg 10027, (maybe make a card from it?)<br>	pg 10027
<latex>~\\<br>Consider a cloven fibration $\ddisp{\mathbb E}{p}{\mathbb B}$. Consider the following statement:\\~\\<br>Given two composable morphisms.<br>$$I \overset{u}{\rTo} J \overset{v}{\rTo} K$$<br>in $\mathbb B$, are the two resulting functors $\mathbb E_K \rightrightarrows \mathbb E_I$, namely\\<br>\begin{tikzcd}<br> & \mathbb E_J \ar[dr, "u^*"] & \\<br>\mathbb E_K \ar[ur, "v^*"] \ar[rr, "(v \circ u)^*"] & & \mathbb{E}_{I}<br>\end{tikzcd}\\<br>equal?\\~\\<br>Prove or disprove.<br></latex>	pg 10028, near top
<latex>~\\<br>What does it mean for a fibration to be \emph{cloven}? What does it mean for a fibration to be \emph{split}?<br></latex><br>	pg 10028, bottom<br><br>
How do we express standard intutitionistic implication in linear logic?	pg 11935, top<br><br>
<latex>~\\<br>What is the difference between the $\otimes$ and $\&$ operators in linear logic?<br></latex>	pg 11935<br>
<latex>~\\<br>If we have an action of type $A \multimap B$ and an action of type $A \multimap C$, is it possible to form an action of type $A \multimap B \otimes C$? Is it possible to form $A \multimap B \& C$?<br></latex>	pg 11935, bottom paragraph<br>
<latex>~\\<br>Compare and contrast linear logic's $\upand$ operator against standard logical disjunction.<br></latex>	pg 11935, near the very bottom<br>
<latex>~\\<br>Explain the $\oplus$ and $\upand$ connectives of linear logic.<br></latex>	pg 11936, near top<br>
<latex><br>Give a brief overview of the role of the linear negation connective of linear logic $(\cdot)^{\bot}$.<br></latex>	pg 11936, section 1.1.3<br>
Read section 1.1.4 on pg 11937/11938<br>	<br>
<latex>~\\<br>Give the three rules of comprehensions, according to wadler.<br></latex>	pg 12080
<latex>~\\<br>Consider these laws for lists given by Wadler<br>\begin{itemize}<br>\item map~id = id<br>\item map (g $\cdot$ f) = map g $\cdot$ map~f<br>\item map~f $\cdot$ unit = unit $\cdot$ f<br>\item map~f $\cdot$ join = join $\cdot$ map~(map~f)<br>\item $[ t \mid \Lambda]$ = unit t<br>\item $[t \mid x \leftarrow u] = map~(\lambda x \to t)~u$<br>\item $[t \mid (p,q)] = join~[[t \mid q] \mid p]$<br>\end{itemize}<br>Prove this law<br>$[f~t \mid q] = map~f~[t \mid q]$<br></latex>	pg 12081 (no proof provided)<br>
<latex>~\\<br>Consider these laws for lists given by Wadler<br>\begin{itemize}<br>\item map~id = id<br>\item map (g $\cdot$ f) = map g $\cdot$ map~f<br>\item map~f $\cdot$ unit = unit $\cdot$ f<br>\item map~f $\cdot$ join = join $\cdot$ map~(map~f)<br>\item $[ t \mid \Lambda]$ = unit t<br>\item $[t \mid x \leftarrow u] = map~(\lambda x \to t)~u$<br>\item $[t \mid (p,q)] = join~[[t \mid q] \mid p]$<br>\end{itemize}<br>Prove this law<br>$[x \mid x \leftarrow u] = u$<br></latex>	pg 12081 (no proof provided)<br>
<latex>~\\<br>Consider these laws for lists given by Wadler<br>\begin{itemize}<br>\item map~id = id<br>\item map (g $\cdot$ f) = map g $\cdot$ map~f<br>\item map~f $\cdot$ unit = unit $\cdot$ f<br>\item map~f $\cdot$ join = join $\cdot$ map~(map~f)<br>\item $[ t \mid \Lambda]$ = unit t<br>\item $[t \mid x \leftarrow u] = map~(\lambda x \to t)~u$<br>\item $[t \mid (p,q)] = join~[[t \mid q] \mid p]$<br>\end{itemize}<br>Prove this law<br>$[t \mid p, x \leftarrow [u \mid q], r] = [t^u_x \mid p, q, r^u_{x}]$<br></latex>	pg 12081 (no proof provided)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$[t \mid \Lambda, q] = [t \mid q]$<br>Prove or disprove.<br></latex>	true. pg 12082 (I')<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$[t \mid q, \Lambda] = [t \mid q]$\\~\\<br>Prove or disprove.<br></latex>	pg 12082, (II')<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$[t \mid (p, q), r] = [t \mid p, (q, r)]$\\~\\<br>Prove or disprove.<br></latex>	pg 12082 (III')<br><br>
What is Wadler's definition of "monad" in "comprehending monads". Note that it is the standard definition, but the terminology is a bit different.	pg 12082, bottom of page
What are the three forms of qualifiers in "Comprehending Monads". How do they map onto the three components of a monad?	pg 12083, top<br>
In "Comprehending Monads", Wadler uses a definition of "strong monad" that is a bit different (at least, on the surface) from Moggi's. What is the relation between Wadlers' and Moggi's definitions?	pg 12084, top<br>
Provide the definition of the identity monad. What common programming construct does a comprehension in the identity monad correspond to?	pg 12084<br>
<latex>~\\<br>What is an algebra? What does it mean that the algebra $(\mathbb N, 0, s)$, where $s(x) = x + 1$, is an \emph{initial algebra}?<br></latex>	pg 12118, section 2<br><br>
<latex>~\\<br>How does Buneman define the following collection type constructors?~\\<br>$\{\sigma\} \\$<br>$\{| \sigma |\} \\$<br>$[ \sigma ]$<br></latex>	pg 12119, top
Provide the Empty, Addition, Singleton, and Combination operations for the following collection type constructors:<br>- Empty<br>- Addition<br>- Singleton<br>- Combination<br>	pg 12119
Explain the "initial algebra approach" to summing the elements of a list.<br>	pg 12120<br>
<latex>~\\<br>Give the elimination typing rule for the $(col(\sigma),empty,add)$ collection algebra.<br></latex>	pg 12120
<latex>~\\<br>Give the elimination typing rule for the $(col(\sigma),empty,sng,comb)$ collection algebra.<br></latex>	pg 12120, near bottom<br>
Give a universal algebra explanation for why the following definition is invalid:<br>badcount({x}) = 1<br>badcount(S1 U S2) = badcount S1 + badcount S2	pg 12121 "well-definedness conditions"<br><br>
Give well-definedness conditions for the structural recursion constructs on bags, sets, and lists. Provide conditions for both the (empty, add) algebra and the singleton/combination algebra. Give justifications of these conditions.	pg 12122, near top<br>they do not give justifications, but maybe there is a way to prove that we don't have initial algebras without these conditions.<br><br>
Read "More examples" on pg 12122<br>	<br>
Provide the definition (a combined algebraic/typing definition), of the ext elimination form for the (empty, sng, comb)-algebra view of collections.<br>	pg 12123<br>
Why do we consider "every epi splits" to be the categorical version of the axiom of choice?	pg 2688, example 2.8<br>
Roughly, what is the difference between type-specialized PCC and foundational PCC?	pg 12162, top three paragraphs<br>
Discuss the differences between the syntactic and semantic approaches to type soundness.<br>	pg 12163/12164
According to Appel and McAllester, what does it mean for an expression e to be <i>safe</i> for k steps?	pg 12165
According to Appel and McAllester, what does it mean for a term to be <i>safe</i>?	pg 12165
How do Appel and McAllester define the word <i>type</i>?	pg 12165, definition 1<br>
<latex>~\\<br>If $e$ is a closed expression and $\tau$ a type, what does $e :_k \tau$ mean?<br></latex>	pg 12165, definition 2<br>
<latex>~\\<br>How do Appel and McAllester define the following types and type constructors?\\~\\<br>$\bot$\\<br>$\top$\\<br>$\mbf{int}$\\<br>$\tau_1 \times \tau_2$\\<br>$\sigma \to \tau$\\<br>$\mu F$<br></latex>	pg 12165<br>
<latex>~\\<br>Appel and McAllester define \emph{type environments} $\Gamma$ and \emph{value environments} $\sigma$ in the standard way. What does $\sigma :_k \Gamma$ mean? What does $\Gamma \vDash_k e : \alpha$ mean?<br></latex>	pg 12165
<latex>~\\<br>Appel and McAllester provide two ``type inference lemmas'' related to the $\mu$ type constructor: what are they?<br></latex>	pg 12166<br>
<latex>~\\<br>Give a derivation of $\vDash \Omega : \bot$ in Appel and McAllester's system.<br></latex>	pg 12166<br>
<latex>~\\<br>Consider the following lemma of Appel and McAllester:\\~\\<br>If $\vDash e : \alpha$ then $e$ is safe.\\~\\<br>Explain, informally, why it holds.<br></latex>	Since the hypothesis is vacuous, we can choose any k. Hence, after any number of steps we either have a value, or we are reducible.<br><br>pg 12166<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Appel and McAllester's foundational PCC system needs a primitive fix operator to type recursive statements.\\~\\<br>True or false.<br></latex>	pg 12166<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\alpha$ and $\beta$ are types then $\alpha \to \beta$ is also a type.\\~\\<br>Prove or disprove.<br></latex>	true. pg 12167.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $e_1$ and $e_2$ are closed terms and $\alpha$ and $\beta$ are type sets such that $e_1 :_k \alpha \to \beta$ and $e_2 :_k \alpha$ then $(e_1~e_2) :_k \beta$.\\~\\<br>Prove or disprove.<br></latex>	pg 12167
<latex>~\\<br>Let $\Gamma$ be a type environment and let $e_1$ and $e_2$ be (possibly open) terms, and let $\alpha$ and $\beta$ be types such that $\Gamma \vDash e_1 : \alpha \to \beta$ and $\Gamma \vDash e_2 : \alpha$.<br>Consider the following statement:\\~\\<br>$\Gamma \vDash (e_1~e_2) : \beta$\\~\\<br>Prove or disprove.<br></latex>	pg 12167<br>
<latex>~\\<br>Let $\Gamma$ be a type environment, let $\alpha$ and $\beta$ be types, and let $\Gamma[x := \alpha]$ be the type environment that is identical to $\Gamma$ except that it maps $x$ to $a$. Consider the following statement:\\~\\<br>If $\Gamma[x := a] \vDash e : \beta$ then $\Gamma \vDash \lambda x.e : \alpha \to \beta$.\\~\\<br>Prove or disprove.<br></latex>	pg 12167, theorem 9<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\alpha$ and $\beta$ are types then so is $\alpha \times \beta$.\\~\\<br>Prove or disprove.<br></latex>	pg 12168<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\alpha$ and $\beta$ are types and $e_1$ and $e_2$ are closed terms such that $e_1 :_k \alpha$ and $e_2 :_k \beta$ then $\langle e_1, e_2 \rangle :_k \alpha \times \beta$.\\~\\<br>Prove or disprove<br></latex>	pg 12168, lemma 11<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\alpha$ and $\beta$ are types and $e$ is a closed term such that $e :_k \alpha \times \beta$ then $\pi_1(e) :_k \alpha$.\\~\\<br>Prove or disprove.<br></latex>	pg 12168<br>
<latex>~\\<br>How do Appel and McAllester define the \emph{k-approximation} of a type set?<br></latex>	pg 12168, def 13<br>
<latex>~\\<br>How do Appel and McAllester define the notion of a \emph{well-founded functional}? <br></latex>	pg 12168, def 14<br>
<latex>~\\<br>Consider the following statement\\~\\<br>For $F$ well founded and $j \leq k$, for any $\tau, \tau_1, \tau_2$ \\<br>* $approx(j, F^j(\tau_1)) = approx(j, F^j(\tau_2))$ \\<br>* $approx(j, F^j(\tau)) = approx(j, F^k(\tau))$ \\~\\<br>Prove or disprove.<br></latex>	<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $F$ is well founded, then $\mu F$ is a type.\\~\\<br>Prove or disprove.<br></latex>	true. pg 12169.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$\mu F$ is a type for all functionals $F$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! it must be well-founded.<br>pg 12169, thm 16<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$approx(k, \mu F) = approx(k, F^k \bot)$\\~\\<br>Prove or disprove.<br></latex>	pg 12169, lemma 17 (it's obvious)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $F$ is well founded,\\<br>* $approx(k, \mu F) = approx(k, F^k \bot)$\\<br>* $approx(k+1, F(\mu F)) = approx(k + 1, F^{k+1} \bot)$\\~\\<br>Prove or disprove.<br></latex><br>	true. pg 12169, lemma 18<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $F$ is well founded, $approx(k, \mu F) = approx(k, F(\mu F))$\\~\\<br>Prove or disprove.<br></latex>	pg 12170, lemma 19<br>
Provide the definition of <i>ring</i>.	pg 141<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any ring $R$, there exists a $1 \in R$ such that for all $a \in R$, $1 \cdot a = a \cdot 1 = a$.\\~\\<br>True or false?<br></latex>	pg 141, near bottom<br><br>
What is a <i>ring with unit</i>?	pg 141, near bottom<br>
What does it mean for a ring to be a <i>domain</i>?	a ring for which ab = 0 implies that either a = 0 or b = 0<br>pg 142<br>
Explain the difference between commutative rings and non-commutative rings.	pg 142, second paragraph
What is an <i>integral domain</i>?	it is a commutative ring (i.e. multiplication is commutative) that is a domain (i.e. ab = 0 implies that either a = 0 or b = 0).<br><br>pg 142<br>
What does it mean for a ring R with unit to be a <i>division ring</i>?	pg 142, second definition.<br><br>
What is a <i>field</i>?	pg 142, bottom definition.<br>
<latex>~\\<br>The integers $\mathbb Z$ are a special kind of field. Which kind?<br></latex>	pg 143, example 1
Read the examples 1-5 on pg 143.<br>	<br>
<latex>~\\<br>Let $R = \mathbb Z_6$, the integers mod 6, with the addition and the multiplication defined by<br>[a] + [b] = [a + b] and [a][b] = [ab]. Consider the following statement:\\~\\<br>$\mathbb Z_6$ is an integral domain\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 143, example 5<br><br>
<latex>~\\<br>What does it mean for an element $a \neq 0$ in a ring $R$ to be a \emph{zero-divisor}?<br></latex>	pg 143, definition<br>
Read example 7 at the top of pg 144.<br>	pg 144<br>
<latex>~\\<br>Let $\mathbb Q$ be the rational numbers; if $a \in \mathbb Q$, we can write $a = m/n$, where \emph{m} and \emph{n} are relatively prime integers. This is called the \emph{reduced form} for $a$. Let $R$ be the set of all $a \in \mathbb Q$ in whose reduced form the denominator is odd. Under the usual addition and multiplication in $\mathbb Q$ the set $R$ forms a ring. Is $R$ an integral domain? Is it a field? Why or why not?<br></latex>	pg 144, example 8
Read example 9 on pg 144.<br>	pg 144<br>
<latex>~\\<br>Let $R$ be a ring. What is a \emph{subring} of $R$?<br></latex> 	pg 144.<br>
<latex>~\\<br>How do we define the projection:\\~\\<br>$$\pi : \int_{\mbf{C}}P \to \mbf{C}$$\\~\\<br></latex>	pg 2853, top<br><br>
What is the deifference between an <i>internal reference</i> in a database and an <i>external reference</i>?	pg 9341, bottom / 9342, top<br>
Examine table 3.1 on pg 9341.<br>Draw a "Hasse diagram for databases" for this table.	pg 9342, diagram 3.2<br>
What is Fong and Spivak's idiosyncratic definition of <i>database schema</i>?	pg 9342, near bottom.<br>
Consider the "Hasse diagram for databases" (or <i>database schema</i>) pictured on pg 9342.<br>We would like to augment it with the following constraints:<br>- Every department's secretary must work in that department<br>- Every employee's manager must work in the same department as the employee<br>	pg 9343, top<br>
Give FQL (functorial query language) code to display the database table shown on pg 9341, together with the constraints:<br>- every department's secretary must work in that department<br>- every employee's manager must work in the same department as the employee.<br>	pg 9343<br>
Read pg "communication between databases" section, pg 9343, 9344<br>	<br>
What do Fong and Spivak use the notation "f.g" for?	left-to-right composition of the arrows f and g<br>pg 9345<br>
Explain how we obtain the <i>free category</i> generated by a graph.<br>	pg 9346<br>
Explain how the natural numbers can be represented as a free category.	pg 9347<br>
What is a <i>finite presentation</i> for a category?	pg 9347, second paragraph of "Presenting categories via path equations"<br><br>
What is "the poset reflection of a category"?	pg 9349<br>
Let C be a schema, i.e. a finitely presented category. What is a C-<i>instance</i>?	pg 9356, def 3.36<br>
Read pg 9352-9353<br>	<br>
Read example 3.38, pg 9356<br>(todo: turn this into a question?)<br>	pg 9356
Do exercise 3.39 on pg 9357.<br>	pg 9357<br>
<latex>~\\<br>Let $\mathcal N$ denote the category associated to the poset $(\mathbb N, \leq)$, and recall that we can identify a functor $F : \mathb N \to \mathbb N$ with a non-decreasing sequence $(F_0, F_1, F_2, \ldots)$ of natural numbers, i.e. $F_0 \leq F_1 \leq F_2 \leq \cdots$. If $G$ is another functor, considered as a non-decreasing sequence, then what is a natural transformation $\alpha : F \to G$?<br></latex>	pg 9359, example 3.47<br><br>
Exercise 3.48, pg 9359<br>	<br>
What does C-<b>Inst</b> denote? What is an <i>instance homomorphism</i>?	pg 9359, def 3.50<br><br>
Draw the schema <b>Gr</b>, representing a directed graph. (Hint: there are two nodes in this schema diagram). What is the significance of a morphism of <b>Gr</b> in graph theory? <br><br>	pg 9360, top<br>
Read example 3.52 and then do exercise 3.53 on pg 9361<br>	<br>
read pages 9362 and 9363, down to exercise 3.54<br>	<br>
<latex>~\\<br>Let $\mathcal C$ and $\mathcal D$ be categories and let $F : \mathcal C \to \mathcal D$ be a functor. For any set-valued functor $I : \mathcal D \to Set$, what is the \emph{pullback of I along F}?<br></latex>	pg 9363 (I wonder if this has anything to do with the standard category-theoretic notion of a pullback)<br>
<latex>~\\<br>Let $F : \mathcal C \to \mathcal D$ be a functor. What does $\Delta_F$ denote?<br></latex>	<latex>~\\<br>pg 9363, near bottom<br>Note that $I, J \in \mathcal D$-$\mbf{Inst} = \mbf{Sets}^{\mathcal D}$<br></latex>
<latex>~\\<br>Examine the diagram on pg 9344. (3.4).<br>Let $F$ be the obvious functor from $A$ to $B$. Explain how the functors $\Delta_F$, $\Sigma_F$, and<br>$Pi_F$ operate.<br></latex>	pg 9366
Read section 3.4.3, pg 9365/9366	<br>
<latex>~\\<br>Let $\mathcal C$ be some finitely-presented category (database). Let $! : \mathcal C \to 1$ be the functor-to-terminal category at $\mathcal C$. Characterize $\Sigma_!$ and $\Pi_!$, the adjoints of $\Delta_!$.<br></latex>	pg 9367, section 3.4.4
What is a rose tree? Give two haskell-style functions witnessing the isomorphism between binary trees and forrests of rose trees.	pg 12406
Give a proof that inverse arrows are unique using Hinze's equational style of reasoning.	pg 12407, bottom left<br>
Instead of showing that a pair of arrows are isos by proving two equations, we can prove a single formula. Explain.<br>	pg 12407, right column, second paragraph.<br>
In the category <b>Sets</b>, there is an alternative way of proving two functions are isomorphic. What is it?	pg 12407, right column<br><br>
Give Hinze's proof of the Yoneda principle. Note that it is fairly simple and that he doesn't explicitly invoke the Yoneda lemma.<br>	pg 12407, right column, above section 2.1<br><br>
Give a brief explanation of why the concept of an <i>equivalence of categories</i> is important.	pg 12408, bottom right corner<br>pg 12409, top left corner<br>
<latex>~\\<br>Use Hinze's equational proof style to show that the $\cong$ relation<br>is not only an equivalence relation, but a \emph{congruence} relation.<br></latex>	pg 12408<br>
<latex>~\\<br>How does Hinze justify the statement: $F \cong G \wedge A \cong B \Rightarrow F A \cong F B$?<br></latex>	pg 12408
<latex>~\\<br>What \emph{equivalence formula} does Hinze use to prove that a functor $F$ is full and faithful?<br></latex>	pg 12408 (9) -- see surrounding text for explanation.<br>
Give the definition of the factorial function <i>fac</i> in continuation-passing style. Explain why the type signature of <i>fac</i> can be thought to identify it as a natural transformation. Give a Hinze-style equational proof that the function you've identified is indeed the factorial function.	pg 12408, right column
<latex>~\\<br>How are the types of the \emph{fac} function written in continuation-passing style and the fac function written in the direct fashion related?\\~\\<br>$$\forall x. (Nat \to x) \to (Nat \to x)$$<br>$$Nat \to Nat$$<br></latex><br>	pg 12408, bottom right corner<br>pg 12409, top left corner<br><br>
<latex>~\\<br>Define the isomorphism between the types $A \to B$ and $\forall X. (B \to X) \to (A \to X)$,<br>where the iso pair arrows are named $\bbgamma$ and $\bbgamma^{\circ}$.<br></latex>	pg 12409, top left<br>
Transliterate the CPS isomorphism (for example, think of the factorial example) into the language of category theory. Make the connection to the Yoneda lemma.	pg 12409, right column<br><br>
<latex><br>$$\bbgamma \doteq \Lambda X . \lambda f : B \to X . H~f~s$$ <br>$$\bbgamma^{\circ} \bbalpha \doteq \bbalpha~b~id_B$$<br>Prove that these are isos (as part of the Yoneda lemma) using Hinze's <br>equational proof style.<br></latex>	pg 12409, left column<br>
<latex>~\\<br>What does it mean for a set-valued functor $H : \mathbb C \to \mbf{Set}$ to be \emph{representable}?<br></latex>	pg 12409
<latex><br>Show that the functor $H : \mathbb C(A_1, -) \times \mathbb C(A_2, -)$ is representable.<br></latex>	pg 12410
Breifly sketch the <i>representional</i> approach to defining categorical constructs, in constrast to the constructional approach.	pg 12410, left column near top<br>
Describe the representational approach to reasoning about terminal objects, initial objects, products, and coproducts. Derive some basic laws of high-school algebra.	pg 12410
<latex>~\\<br>What is a \emph{$\mathbb B$-indexed category}? What is a \emph{pseudo-functor}?<br></latex><br>	pg 10029/10030, def 1.4.4 (i)<br>** note: this uses horizontal composition of natural transformations: see pg 9572/9573<br><br>
<latex>~\\<br>What does it mean for an indexed category to be \emph{split}? <br></latex><br>	pg 10030, (ii) near top<br>
<latex>~\\<br>Provide the definition of $UFam(\omega$-$\mbf{Sets})$, the category of ``uniform families'' of $\omega$-$\mbf{Sets}$.<br></latex>	pg 10030 bottom / 10031 top, definition 1.4.6<br>
Formally, what is a <i>many-typed signature</i>?	pg 10043, near bottom<br>
<latex>~\\<br>Consider a signature $\Sigma = (T , \mathcal F)$. What does $|\Sigma|$ denote?<br></latex>	pg 10043, bottom<br>
<latex>~\\<br>Consider a signature $\Sigma = (T , \mathcal F)$. What does $F : \sigma_1, \ldots, \sigma_n \longrightarrow \sigma_{n+1}$ mean?<br></latex>	pg 10043 top, pg 10042 bot<br>
<latex>~\\<br>Give the definition of the category $\mbf{Sign}$.<br></latex>	pg 10044, above def 1.6.1<br>also see def 1.6.1 and conv 1.6.2<br><br>
<latex>~\\<br>Describe the fibred approach to dealing with variables-in-context. Let $\Sigma$ be a signature with $T = |\Sigma|$ as underlying set of types. Define the $T$-indexed collection<br>$$ (Terms_\tau(X))_{\tau \in T} $$<br>where $Terms_\tau(X)$ is the set of terms of type $\tau$.<br></latex>	pg 10045, second paragraph.<br><br>
<latex>~\\<br>Let $\Sigma$ be a signature. What is a $\mbf{model}$ or $\mbf{algerba}$ for $\Sigma?$<br></latex>	pg 10045, near bottom "(Set theoretic) semantics"<br>
<latex>~\\<br>How do we model the following signature, containing one function symbol?<br>$$ if : B, N, N \longrightarrow N $$<br>for an if-conditional on natural numbers<br></latex>	pg 10046, example 1.6.3 near top<br><br>
In Jacobs' presentation of universal algebra, what is a <b>valuation</b>? What is an <b>interpretation</b>?<br>	pg 10046, near middle<br>
Read pg 10046/10047, up to def 1.6.4<br>	<br>
Provide the definition of the category <b>S-Model</b>.<br>	pg 10047, def 1.6.4<br>
<latex>~\\<br>Let $\Sigma$ be a signature. Provide the definition of the \emph{term model} of $\Sigma$. Also provide the definition of the \emph{initial model} of $\Sigma$.<br></latex>	pg 10048, example 1.6.5<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The functor $\vrt{\mbf{SModel}}{\mbf{Sign}}$ sending a model to its underlying signature is a split fibration.\\~\\ The fibre over $\Sigma \in \mbf{Sign}$ is the category of models with signature $\Sigma$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10048, lemma 1.6.6 (i)<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>The functor $\vrt{\mbf{SModel}}{\mbf{Sets}}$ which sends a model to its underlying set of types is a split fibration. The fibre over $T \in \mbf{Sets}$ is the category of models of signatures with $T$ as set of types.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10048, lemma 1.6.6 (ii)<br>NOTE: lemma 1.5.5 is on pg 10040<br>todo: add impostor?<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For every set of types $T$, the fibre category (models of signatures over $T$) is fibred over the category (signatures over $T$).\\~\\<br>Prove or disprove.<br></latex>	true. pg 10048, lemma 1.6.6<br>NOTE: lemma 1.5.5 is on pg 10040<br>todo: add impostor?<br>
<latex>~\\<br>What does it mean for a signature $\Sigma$ to be $\mbf{single}$-$\mbf{typed}$? Define the <br>category $\mbf{Sign_{ST}}$ in terms of a change-of-base.<br>Define the category $\mbf{SModel_{ST}}$ of (set-theoretic) models for single-typed signatures using a change-of-base.<br></latex>	pg 10049, def 1.6.7
Read the paragraph below def 1.6.7 on pg 10049 and 10050: it makes a good point.	pg 10049<br>
<latex>~\\<br>Consider the following statement:~\\<br>For each many-typed signature $\Sigma$, there is an equivalence of categories<br>$$ \mbf{S}\mbf{Model}(\Sigma) \simeq \mbf{FPCat}(\mathcal{C} l(\Sigma), \mbf{Sets}) $$<br>Prove or disprove.<br></latex>	true. pg 10105, thm 2.2.1<br>also relevant: pg 10103<br>also relevant: pg 10046<br>
<latex>~\\<br>Let $\Sigma$ be a many-typed signature and $\mathbb B$ a category with finite products. What is a $\mbf{model}$ of $\Sigma$ in $\mathbb B$? What is a $\mbf{morphism}$ between two such models?<br></latex>	pg 10107, def 2.2.2<br>
<latex>~\\<br>What is a \emph{continuous $\Sigma$-algebra}?<br></latex>	pg 10107<br>
<latex>~\\<br>Let $\Sigma$ be a signature. What is the \emph{generic model} of $\Sigma$?<br></latex>	pg 10107, example 2.2.3<br>
<latex>~\\<br>Recall that $\mbf{FPCat}$ is the 2-category that has categories with finite products as objects,<br>finite-product preserving (up-to-isomorphism) functors as 1-arrows, and natural transformations as 2-arrows.<br>Consider the following statement:\\~\\<br><br>%Provide the definition for the functor $\mbf{Sign}(-)$:<br>%$$\mbf{FPCat} \overset{Sign(-)}{\longrightarrow} \mbf{Sign}$$<br><br>(i) There is a forgetful functor<br>$$\mbf{FPCat} \overset{Sign(-)}{\longrightarrow} \mbf{Sign}$$<br>given as follows. For a category $\mathbb B \in \mbf{FPCat}$ the $\textbf{underlying signature}$<br>Sign($\mathbb B$) of $\mathbb B$ has objects from $\mathbb B$ as types and function symbols given by<br>$$F : X_1, \ldots, X_n \to X_{n+1}\text{ in Sign}(\mathbb B) ~\dot{\Leftrightarrow}~ F\text{ is a morphism }X_1 \times \cdots \times X_n \to X_{n+1}\text{ in }\mathbb B$$<br>How does this functor transform functors in $\mbf{FPCat}$ to signature morphisms?<br>Prove this is actually a functor.<br></latex>	true. pg 10108, lemma 2.2.4 (i)<br>
<latex>~\\<br>Recall that $\mbf{FPCat}$ is the 2-category that has categories with finite products as objects,<br>finite-product preserving (up-to-isomorphism) functors as 1-arrows, and natural transformations as 2-arrows.<br>Consider the following statement:\\~\\<br>Taking classifying categories yields a functor<br>$$\mathcal{C}l(-) : \mbf{Sign} \to \mbf{FPCat}$$<br>For a morphism of signatures $\phi : \Sigma \to \Sigma'$ in $\mbf{Sign}$ one obtains a functor <br>$\mathcal{C}l(\phi) : \mathcal{C}l(\Sigma) \to \mathcal{C}l(\Sigma')$ by replacing every $\Sigma$-type and function symbol by its image under $\phi$.\\~\\<br>Prove or disprove.<br></latex>	pg 10108, lemma 2.2.4 (ii)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a signature $\Sigma$ and a category $\mathbb B$ with finite products,<br>there is a bijective correspondence (up-to-isomorphism) between morphisms of signatures $\varphi$ and models $\mathcal M$ as in<br>$$\bimpl{\Sigma \overset{\phi}{\longrightarrow} Sign(\mathbb B)}{\mathcal{C}l(\Sigma) \underset{\mathcal M}{\longrightarrow} \mathbb B} $$<br>Prove or disprove.<br></latex><br>	pg 10108, theorem 2.2.5<br>todo: add impostor (removing up-to-isomorphism?)<br>
<latex>~\\<br>Give the definition of $\mbf{Sign_{tr}}$, the category of signatures and translations.<br></latex>	pg 10109/10110, def 2.2.6<br>
<latex>~\\<br>Read examples 2.2.7 on pg 10110/10111<br></latex>	todo: make questions from these examples?<br>
How does Jacobs define the notion of a <i>product preserving functor</i>?	<latex>~\\<br>He's not talking about the preservation of products on the nose. What he means is this:<br>$$F(A \times B) \cong F(A) \times F(B)$$<br>Rather than this:<br>$$F(A \times B) = F(A) \times F(B)$$<br></latex><br><br>see pg 10106 (It is almost immediate that A preserves finite products...)<br>
<latex>~\\<br>There is an equivalence of categories<br>$$\mbf{SModel}(\Sigma) \simeq \mbf{FPCat}(\mathcal{C}l(\Sigma), \mbf{Sets})$$<br>Give the functor of type $\mbf{SModel}(\Sigma) \to \mbf{FPCat}(\mathcal{C}l(\Sigma), \mbf{Sets})$<br>involved in this equivalence. Note that this functor must not only map models to functors, but also map model morphisms to natural transformations.<br></latex>	pg 10105, proof at very bottom<br>pg 10106 down to "In the reverse direction..."<br>
<latex>~\\<br>There is an equivalence of categories<br>$$\mbf{SModel}(\Sigma) \simeq \mbf{FPCat}(\mathcal{C}l(\Sigma), \mbf{Sets})$$<br>Give the functor of type $\mbf{FPCat}(\mathcal{C}l(\Sigma), \mbf{Sets}) \to \mbf{SModel}(\Sigma)$<br>involved in this equivalence. Note that this functor must not only map functors to models, but also map natural transformations to model morphisms.<br></latex>	pg 10106, "In the reverse direction..."<br><br>
<latex>~\\<br>%Let $\mathcal Cl(-) : \mbf{Sign} \to \mbf{FPCat}$ be the functor which converts signatures into classifying %categories.<br>Let $\phi : \Sigma \to \Sigma'$ be a morphism of signatures. Let $M$ be a term in the signature $\Sigma$. What does $\phi M$ denote?<br></latex>	<latex>~\\<br>It's short for $\mathcal Cl(\phi)(M)$. Remember that $\mathcal Cl(\phi)$ is a functor from $\mathcal Cl(\Sigma) \to \mathcal Cl(\Sigma')$, and that $M$ can be viewed as an arrow in $\mathcal{C}l(\Sigma)$.<br></latex><br><br>pg 10108, near the end of the statement of lemma 2.2.4 (ii)<br><br>
<latex>~\\<br>Boolean logic can be described by the functionally complete pair of connectives<br>\begin{mathpar}<br>\neg : B \to B<br>\and<br>\text{and}<br>\and<br>\wedge : B,B \to B<br>\end{mathpar}<br>Alternatively, negation and implication can be used<br>\begin{mathpar}<br>\neg : B \to B<br>\and<br>\text{and}<br>\and<br>\supset : B,B \to B<br>\end{mathpar}<br>Explain why the former is an alternative to the latter, and why morphisms in the category $\mbf{Sign}_{tr}$<br>are relevant here.<br></latex>	pg 10111, example (ii) at top<br>the category Sign_{tr} is defined at the bottom of pg 10109, in definition 2.2.6<br>
<latex>~\\<br>Let $\Sigma$ be a many-typed signature with $T = |\Sigma|$ as its underlying set of types.<br>How does Jacobs derive from $\Sigma$, the set $T_1$ of the $\lambda 1$ calculus' types?<br>How does Jacobs define the notion of a \emph{basic} type?<br></latex>	pg 10113, first paragraph of section "Lambda1-calculi"<br>
<latex><br>Define the \emph{simpy typed $\lambda$-calculus} $\lambda 1(\Sigma)$. <br></latex>	pg 10113 bottom paragraph,<br>the term calculus is defined on pgs 10100, 10101<br>
<latex>~\\<br>Provide the definition of $\mathcal Cl1(\Sigma)$, the \emph{$\lambda 1$-classifying category of $\Sigma$}.<br></latex>	pg 10114 bottom / pg 10115 top<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The $\lambda 1$-classifying category $\mathcal Cl1(\Sigma)$ of a signature $\Sigma$ has finite products.<br>If $T = |\Sigma|$ is the underlying set of types of $\Sigma$, then $\mathcal Cl1(\Sigma)$ together with the<br>set of types $T_1$ (obtained by closing the set of basic types $T$ under $\to$) is a $CT$-structure; it is non-trivial if and only if $T$ is non-empty.\\~\\<br>Prove or disprove.<br></latex>	pg 10115, proposition 2.3.1<br>the notion of a CT-structure is defined on pg 10021, def 1.3.2 (i)<br>It's non-trivial because the identity abstraction is an inhabitant of T => T.<br>todo: add impostor?
<latex>~\\<br>How does Jacobs define \emph{minimal intuitionistic logic}?<br></latex>	identity, exchange, weakening, contraction, plus implies introduction and implies elimination<br>seems pretty different from Troelstra's minimal predicate logic.<br>pg 10115, section "propositions as types"<br>
Read the "propositions as types" section, starting near the bottom of pg 10115, down to the proof tree of page<br>10116. There is one mistake in this proof tree: what?	<latex>~\\<br>the top-right assumption should be $\varphi \vdash \psi$<br></latex>
<latex>~\\<br>Let $\mathcal A$ be a set of axioms for minimal intuitionistic logic. Define the signature $\Sigma_{\mathcal A}$.<br></latex>	pg 10116: it's is defined in the proof tree, but while you're at it, read the entire page.<br><br><br>
<latex>~\\<br>Read from ``As a result, provability in logic...'' near the bottom of pg 10116, down to <br>the next section ``$\lambda 1_{\times}$-calculi'' on pg 10117.<br></latex>	pg 10116<br>
<latex>~\\<br>Let $\Sigma$ be a many-typed signature. How is the calculus $\lambda 1_{\times}(\Sigma)$ defined by Jacobs?<br></latex>	pg 10117, bottom<br>pg 10118, top<br><br>
<latex><br>How is the \emph{$\lambda 1_{\times}$-classifying category} $\mathcal Cl1_{\times}(\Sigma)$ of $\Sigma$ defined?<br></latex>	pg 10118, near bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The $\lambda 1_{\times}$-classifying category $\mathcal Cl1_{\times}(\Sigma)$ of a signature $\Sigma$<br>is Cartesian closed.\\~\\<br>Prove or disprove.<br></latex>	pg 10119, prop 2.3.2 near bottom<br><br>
<latex>~\\<br>Given a signature $\Sigma$, provide the definition for $\lambda 1_{(\times,+)}(\Sigma)$.<br></latex>	pg 10119, near bottom<br><br>
<latex>~\\<br>What is \emph{commutation conversion}? Prove that $\lambda 1_{(\times,+)}(\Sigma)$ exhibits commutation conversion.<br></latex>	pg 10120, lemma 2.3.3 near bottom<br><br>
<latex>~\\<br>Consider the following statement:<br>Type theoretic coproducts $+$ are automatically distributive: the canonical term<br>$u : (\sigma \times \tau) + (\sigma \times \rho) \vdash P(u) \overset{def}{=} <br> \mbf{unpack}~u~\mbf{as}~[\kappa x~\mbf{in}~\langle \pi x, \kappa(\pi' x) \rangle, \kappa ' y~\mbf{in}~\langle \pi y, \kappa ' (\pi ' y) \rangle] : \sigma \times (\tau + \rho)$<br>is invertible--without assuming exponent types.\\~\\<br>Prove or disprove.<br></latex>	pg 10121, prop 2.3.4 (i)<br><br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>Type theoretic coprojections $\kappa, \kappa'$ are automatically ``injective'': the rules<br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \vdash \kappa M = \kappa M' : \sigma + \tau}<br>  {\Gamma \vdash M = M' : \sigma}<br>\and<br>and<br>\and<br>\inferrule<br>  {\Gamma \vdash \kappa ' N = \kappa ' N' : \sigma + \tau}<br>  {\Gamma \vdash N = N' : \tau}<br>\end{mathpar}<br>are derivable, where = denotes conversion.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10121, prop 2.3.4 (ii)<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Categories $\mathcal Cl1_{(\times,+)}(\Sigma)$ have finite coproducts.\\~\\<br>Prove or disprove.<br></latex>	pg 10122, prop 2.3.5 near bottom<br><br>
Briefly describe the motivation for distributive signatures.	pg 10123, "Distributive signatures" up to the definition.<br>
<latex>~\\<br>Provide the definition of the category $\mbf{DistrSign}$ of distributive signatures.<br></latex>	pg 10123, def 2.3.6 at bottom<br>The Fam(Sets) fibration is described on pgs 10010/10011 "Set-indexed families"<br><br><latex>~\\<br>The bottom edge maps each set of base types to the set of domain/codomain pairs (all possible function signatures generated from these base types and the product and coproduct constructors) \\~\\<br>Viewing the right edge as a display, each function signature (domain/codomain pairs generated from T, product, and coproduct) serves as an index set for various set-indexed families of sets (the top-right category) each object of the top-right category is a signature ($\overline{T}\times\overline{T}$) indexed family of sets: each member of the family is the set of all function symbols which have that signature.\\~\\<br>So in the category of signatures, the objects are pairs $(T,\mathcal F)$ where<br>$T$ is the set of types and $\mathcal F$ maps each signatures $\tau_1 \in T,\ldots \tau_n \in T, \tau \in T$ to the set of function symbols which have that signature. In contrast an object in $\mbf{DistrSign}$ is a pair $(T,\mathcal F)$, where $T$ is a set of \emph{basic types} and $\mathcal F$ maps each signature of the form $\sigma \in \overline{T},\sigma' \in \overline{T}$ to the set of functions having that signature. Note that a signature in $\mbf{DistrSign}$ is not just a list of basic types: its domain and codmain are formed using the type constructors $\times$ and +.<br></latex>
What is a <i>Hagino signature</i>?<br>	pg 10124/10125, def 2.3.7<br><br>
<latex>~\\<br>Let $\Sigma$ be a signature. What is a \emph{model for the calculus $\lambda 1_{\times}(\Sigma)$ in a Cartesian closed category}? Also, what is a \emph{model of $\lambda 1_{(\times,+)}(\Sigma)$ in a bicartesian closed category}?<br></latex>	pg 10126, def 2.4.1<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a Cartesian closed category $\mathbb C$ with finite coproducts, there is a correspondence (up-to-isomorphism)<br>$$\bimpl{\Sigma \overset{\phi}{\longrightarrow} Sign(\mathbb C)~~~~\text{in } \mbf{Sign}}{\mathcal Cl1_{(\times,+)}(\Sigma) <br>  \underset{\mathcal M}{\longrightarrow} \mathbb C~~~~\text{in } \mathbf{BiCCC}}$$<br>Prove or disprove.<br></latex>	pg 10127<br>
<latex>~\\<br>Let $(\mathbb B, T)$ be a CT-structure and $\vrt{\mathbb E}{\mathbb B}{p}$ a fibration. What does it mean for $p$ to have \emph{simple $T$-products}? What does it mean for $p$ to have \emph{simple $T$-coproducts}?<br></latex>	pg 10128 -- note that CT-structures and the category s(T) are discussed on page 10021.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There exist fixed recursive functions $p$ and $t$ of one and three variables, respectively, such that for all $z$,<br>$$\varphi_z = \lambda x[p(\mu y[t(z,x,y) = 1])]]$$<br>Prove or disprove.<br></latex>	true. pg 10820, bottom right, Theorem X<br>
What is <i>recursive unsolvability</i>? What are the two basic techniques for proving recursive unsolvability?<br>	pg 10822, left column
<latex>~\\<br>Consider the problem of deciding, for any $x$, whether or not $\varphi_x$ is a constant function.<br></latex>	pg 10822, right column, Theorem I<br><br><br>
<latex>~\\<br>Consider the function deciding, for any $x$ and $y$, whether $y$ is in the range of $\varphi_x$. Is this function decidable?<br></latex>	nope. pg 10823, left column, (b) at the very top<br>
<latex>~\\<br>Consider the function deciding, for any $x$, $y$, and $z$, whether $\varphi_x(y) = z$. Is this function decidable?<br></latex>	nope. pg 10823, left column, (c)<br>
<latex>~\\<br>Consider the function deciding, for any $x$ and $y$, whether $\varphi_x = \varphi_y$. Is this function recursive? <br></latex>	nope. pg 10823, left column, (d)<br>
<latex>~\\<br>Consider the function deciding, for any $x$, whether $\varphi_x$ has infinite range. Is this function recursive?<br></latex>	nope. pg 10823, left column, (e)<br>
<latex>~\\<br>Consider a fixed $y_0$. Is the function deciding, for any given $x$, whether $y_0$ is in the range of $\varphi_x$ recursive?<br></latex>	nope. pg 10823 (f)<br>
<latex>~\\<br>Let $x_0$ be fixed. Consider the function deciding, for any given $y$, whether $y$ is in the range of $\varphi_{x_0}$. Is this function recursive?<br></latex>	pg 10823, left column, (g)<br><br>
Read pg 10823, right column, down to "The theory of groups"...<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every partial recursive function can be extended to a total recursive function.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR<br>pg 10824, right column, theorem II<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There exists a partial recursive function $\psi$ such that for no recursive $f$ is it true that $\psi = \lambda x[\mu y[f(x,y) = 1]]$.\\~\\<br>Prove or disprove.<br></latex>	pg 10824, right column, Theorem III
<latex>~\\<br>Explain Felix Klein's attempt to define each ``branch'' of mathematics in terms of a space.<br></latex>	pg 10831, left column<br>
<latex>~\\<br>In Felix Klein's sense, what is a \emph{space}? What is a \emph{group}?<br></latex>	pg 10831, left column
<latex>~\\<br>Let $\chi$ be a space and $\varsigma$ a group. What does it mean for a property of subsets of $\chi$ to be $\varsigma$-invariant?<br></latex>	pg 10831, left column<br>
<latex>~\\<br>Let the space $\chi$ and the group $\varsigma$ on $\chi$ be given. Let $A$ and $B$ be subsets of $\chi$. What does $A \equiv_{\varsigma} B$ mean?<br></latex>	pg 10831, right column near top<br>
<latex>~\\<br>Let the space $\chi$ and the group $\varsigma$ on $\chi$ be given. Let $A$ and $B$ be subsets of $\chi$. What does it mean for $A$ and $B$ to be $\varsigma$-isomorphic? What is a $\varsigma$-isomorphism type?<br></latex>	pg 10831, right column near top<br>
<latex>~\\<br>Let $\Omega$ be a collection of $\varsigma$-invariant properties. Let $\frak J$ be a $\varsigma$-isomorphism type. What does it mean for $\Omega$ to be a \emph{set of invariants} for $\frak J$?<br>What does it mean for $\Omega$ to be a \emph{complete set of invariants} for $\frak J$? <br></latex>	pg 10831, right column, above "recursive permutations"
<latex>~\\<br>How does Rogers define $\varsigma^*$? Consider the following statement:\\~\\<br>$\varsigma^*$ is a transformation group on $\mathbb N$.\\~\\<br>Prove or disprove.<br></latex>	pg 10831, right column, Theorem I<br>
<latex>~\\<br>What is a \emph{recursive permutation}? What is the \emph{group of recursive permutations}?<br></latex>	pg 10831, bottom right definition<br>
<latex>~\\<br>What does it mean for $A$ to be recursively isomorphic to $B$?<br></latex>	pg 10832, top left definition<br><br>
<latex>~\\<br>What is a \emph{recursive-isomorphism type}? <br></latex>	pg 10832, second definition top left<br>
<latex>~\\<br>What does it mean for a property of subsets of $\mathbb N$ to be \emph{recursively invariant}?<br></latex>	pg 10832, third definition top-left<br><br>
<latex>~\\<br>How do we extend the notion of recursive invariance to relations (subsets of $\mathbb N^k$)?<br>Let $R \subset \mathbb N^k$ and $Q \subset \mathbb N^k$ for some $k$. What does it mean for $R$ to be \emph{recursively isomorphic} to $Q$?<br></latex>	pg 10832, left column, "the notion of recursive invariance is extended..." and following definition.<br>
<latex>~\\<br>What does it mean for a property of $k$-ary relations on $\mathbb N$ to be \emph{recursively invariant}?<br></latex>	pg 10832, left column, bottom definition.<br><br>
<latex>~\\<br>Consider the following statement:<br>$$\varphi \equiv \psi \Leftrightarrow (\exists f)[f \in \varsigma^* \wedge \varphi = f^{-1}\psi f]$$<br>Prove or disprove.<br></latex>	pg 10832, right column, Theorem II<br>
<latex>~\\<br>What does it mean for $\varphi$ to \emph{resemble} $\psi$?<br></latex>	pg 10832, right column, section 4.4 "resemblance"<br>
Read section 4.5, starting on the right column of pg 10832, ending at theorem III on the left column of pg 10832.	<br>
<latex>~\\<br>What does it mean for a partial recursive function $\psi$ to be \emph{universal}?<br></latex>	pg 10833, left column, definition<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\psi$ is universal and $g$ and $h$ are recursive permutations, then $\eta = g^{-1} \psi h$ is universal; i.e., the property of being universal is invariant under resemblance.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10833, left col, theorem III<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\psi$ is universal and $g$ is a recursive permutation, then $g^{-1} \psi g$ is universal; i.e., the property of being universal is recursively invariant.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10833, left column, corollary III at bottom<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\psi$ is universal and $g$ is a recursive permutation, then $g \psi$ is universal.\\~\\<br>Prove or disprove.<br></latex>	pg 10833, right column, corollary III (b)<br>todo: add impostor?<br><br>
Explain the basic change of viewpoint required when going from usual finitary logics to linear logic. What does the notation "p /= A", "q /= A", ... mean?	pg 11992<br>
<latex>~\\<br>Explain the semantics of linear logic operators ``\&'' and ``$\otimes$'' using phases.  <br></latex>	pg 11992, near bottom<br><br>
<latex>~\\<br>Provide the definition of a phase space.<br></latex>	pg 11993, def 1.1<br>
<latex>~\\<br>Assume that $G$ is a subset of a phase space $P$. How is $G^{\bot}$ defined?<br></latex>	pg 11993, def 1.2<br><br>
<latex>~\\<br>Let $G$ be a phase space. What is a \emph{fact} of $G$? What does it mean for a fact of $G$ to be \emph{valid}?<br></latex>	pg 11993, def 1.3<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any $G \subset P$, $G \subset G^{\bot \bot}.$\\~\\<br>Prove or disprove.<br></latex>	pg 11993 (i)<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any $G$, $H \subset P$, we have $G \subset H \to H^{\bot} \subset G^{\bot}$.\\~\\<br>Prove or disprove.<br></latex>	pg 11993, 1.4 (ii)<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$G$ is a fact iff $G$ is of the form $H^{\bot}$ for some subset $H$ of $P$.\\~\\<br>Prove or disprove.<br></latex>	pg 11993, 1.4 (iii)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In Girard's phase semantics for linear logic, $\bot$ is a fact.\\~\\<br>Prove or disprove.<br></latex>	pg 11993, examples 1.5 (i)<br>
<latex>~\\<br>Define a fact $\mbf{1}$ by $\mbf{1} = \bot^{\bot}$. Consider the following statement:\\~\\<br>$\mbf{1}$ is a submonoid of $P$.\\~\\<br>Prove or disprove.<br></latex>	pg 11993. Example 1.5 (ii)<br>
<latex>~\\<br>Here are some interesting facts about phase spaces (this card isn't a question).\\~\\<br>Define a fact $\top$ by $\top = \emptyset^{\bot}$. Clearly, $\top = P$.\\~\\<br>Define a fact $\mbf{0}$ by $\mbf{0} = \top^{\bot}$; then $\mbf{0}$ is the smallest fact (w.r.t. inclusion).<br>Most of the time $\mbf{0}$ will be void.<br></latex>	pg 11993, examples 1.5 (iii) and (iv)<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Facts are closed under arbitrary intersections.\\~\\<br>Prove or disprove.<br></latex>	pg 11993. Prop 1.6 at bottom.<br>
<latex>~\\<br>Provide the phase semantics for the linear connective \emph{nil} (linear negation).<br></latex>	pg 11994, def 1.7<br>
<latex>~\\<br>Give the phase semantics for the \emph{times} ($\upand$), \emph{par} ($\otimes$), and \emph{entails} ($\multimap$) connectives of linear logic.<br></latex>	pg 11994, def 1.8<br>
<latex>~\\<br>Define $\otimes$ in terms of $\upand$ and nil.<br></latex>	<latex>~\\<br>$G \otimes H = (G^{\bot}~\upand~H^{\bot})^{\bot}$<br></latex>
<latex>~\\<br>Define $\upand$ in terms of $\otimes$ and nil.<br></latex>	<latex>~\\<br>$G~\upand~H = (G^{\bot} \otimes H^{\bot})^{\bot}$\\~\\<br>pg 11994<br></latex>
<latex>~\\<br>Define $\upand$ in terms of $\multimap$ and nil.<br></latex>	<latex>~\\<br>$G~\upand~H = G^{\bot} \multimap H$\\~\\<br>pg 11994, 1.9 (i)<br></latex>
<latex>~\\<br>Define $\multimap$ in terms of $\upand$ and nil.<br></latex>	<latex>~\\<br>$G \multimap H = G^{\bot}~\upand~H$\\~\\<br>pg 11994, 1.9 (i)<br></latex>
<latex>~\\<br>Define $\multimap$ in terms of $\otimes$ and nil.<br></latex>	<latex>~\\<br>$G \multimap H = (G \otimes H^{\bot})^{\bot}$\\~\\<br>pg 11994, 1.9 (i)<br></latex>
<latex>~\\<br>Define $\otimes$ in terms of $\multimap$ and nil.<br></latex>	<latex>~\\<br>$G \otimes H = (G \multimap H^{\bot})^{\bot}$\\~\\<br>pg 11994<br></latex>
<latex>~\\<br>Consider the following statements:\\~\\<br>For all facts $G$, <br>\begin{itemize}<br>\item $\bot~\upand~G = G$<br>\item $\mbf{1} \otimes G = G$<br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 11994 (ii)<br><br>
<latex>~\\<br>Consider the following statements:\\~\\<br>For all facts $G,H,K$, <br>\begin{itemize}<br>\item $(G \upand H) \upand K = G \upand (H \upand K)$<br>\item $(G \otimes H) \otimes K = G \otimes (H \otimes K)$<br>\end{itemize}<br>Prove or disprove. <br></latex>	pg 11994, (ii)<br>
<latex>~\\<br>Consider the following statements:\\~\\<br>For all facts $G,H$, <br>\begin{itemize}<br>\item $G \upand H = H \upand G$<br>\item $G \otimes H = H \otimes G$<br>\end{itemize}<br>Prove or disprove. <br></latex>	pg 11994, prop 1.9 (ii)
<latex>~\\<br>For all facts $G$, consider the following statements:\\~\\<br>\begin{itemize}<br>\item $1 \multimap G = G$<br>\item $G \multimap \bot = G^{\bot}$<br>\item $(G \otimes H) \multimap K = G \multimap (H \multimap K)$ <br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 11994, 1.9 (iii)<br><br>
<latex>~\\<br>For all facts $G$, consider the following statements:<br>\begin{itemize}<br>\item $G \multimap (H \upand K) = (G \multimap H) \upand K$<br>\item $G \multimap H = H^{\bot} \multimap G^{\bot}$<br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 11994, 1.9 (iii)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $F,G$ are two subsets of $P$, then $(F.G)^{\bot \bot} \supset F^{\bot \bot}.G^{\bot \bot}$\\~\\<br>Prove or disprove.<br></latex>	pg 11995, lemma 1.9.1 at top<br><br>
<latex>~\\<br>Consider this alternative definition of $G \multimap H$:\\~\\<br>$p \in G \multimap H$ iff, for all $q \in G$, $pq \in H$.\\~\\<br>Why is this equivalent to definition 1.8 (iii) on pg 11994?<br></latex>	pg 11995, remark 1.10<br>
<latex>~\\<br>If $G$ and $H$ are facts, how do we define their \emph{direct product} (i.e. the connective \emph{with}) using phase semantics?<br></latex>	pg 11995, def 1.11 (i)<br>
<latex>~\\<br>If $G$ and $H$ are facts, provide the definition of the \emph{direct sum} (the connective \emph{plus}) $G \oplus H$.<br></latex>	<latex>~\\<br>$G \oplus H = (G \cup H)^{\bot \bot}$<br></latex><br>pg 11995, def 1.11 (ii)<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$G~\&~H = (G^{\bot} \oplus H^{\bot})^{\bot}$\\~\\<br>Prove or disprove.<br></latex>	pg 11995 (i)<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$G \oplus H = (G^{\bot}~\&~H^{\bot})^{\bot}$\\~\\<br>Prove or disprove.<br></latex>	pg 11995, 1.12 (i)<br>
<latex>~\\<br>Let $G$ be a fact. Consider the following statements:<br>\begin{itemize}<br>\item $\top~\&~G = G$<br>\item $\mbf{0} \oplus G = G$<br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 11995, 1.12 (ii)<br><br>
<latex>~\\<br>Let $G$ be a fact. Consider the following statements:<br>\begin{itemize}<br>\item $G~\&~H = H~\&~G$<br>\item $G \oplus H = H \oplus G$<br>\end{itemize}<br>Prove or disprove.<br></latex>	true. pg 11995, 1.12 (ii)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statements:<br>\begin{itemize}<br>\item $G \with (H \with K) = (G \with H) \with K$<br>\item $G \oplus (H \oplus K) = (G \oplus H) \oplus K$<br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 11995, 1.12 (ii)<br>
<latex>~\\<br>Let $G, H$, and $K$ be facts. Consider the following claim:\\~\\<br>$G \otimes (H \oplus K) = (G \otimes H) \oplus (G \otimes K)$\\~\\<br>Prove or disprove.<br></latex>	pg 11995, 1.13 (i)<br><br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following claim: \\~\\ <br>$G \lpar (H \with K) = (G \lpar H) \with (G \lpar K)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11995, 1.13 (i)<br>
<latex>~\\<br>Let $G$ be a fact. Consider the following statements:<br>\begin{itemize}<br>\item $\mbf{0} \otimes G = \mbf{0}$<br>\item $\top \lpar G = \top$ <br>\end{itemize}<br>Prove or disprove.<br></latex>	true. pg 11995, 1.13 (i)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$(G \oplus H) \multimap K = (G \multimap K) \with (H \multimap K)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 11995<br>todo: add impostor?<br>
<latex>~\\<br>Let $G$ be a fact. Consider the following statement:\\~\\<br>$G \multimap \top = \top$\\~\\<br>Prove or disprove.<br></latex>	true. pg 11995, 1.13 (i)<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$G \otimes (H \with K) \subset (G \otimes H) \with (G \otimes K)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 11995, 1.13 (ii)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$(G \otimes H) \with (G \otimes K)\subset G \otimes (H \with K) $\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 11995, 1.13 (ii)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$G \otimes (H \with K) = (G \otimes H) \with (G \otimes K)$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! pg 11995, 1.13 (ii)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$(G \lpar H) \oplus (G \lpar K) \subset G \lpar (H \oplus K)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 11995, 1.13 (ii)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$(G \lpar H) \oplus (G \lpar K) = G \lpar (H \oplus K)$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! pg 11995, 1.13 (ii)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$G \lpar (H \oplus K) \subset (G \lpar H) \oplus (G \lpar K) $\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! pg 11995, 1.13 (ii)<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>(G \multimap K) \oplus (H \multimap K) \subset (G \with H) \multimap K\\~\\<br>Prove or disprove.<br></latex>	true. pg 11996, top of page<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$(G \with H) \multimap K \subset (G \multimap K) \oplus (H \multimap K)$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! pg 11996, near top of page<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$(G \multimap H) \oplus (G \multimap K) \subset G \multimap (H \oplus K)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 11996, prove or disprove<br>
<latex>~\\<br>Let $G,H$, and $K$ be facts. Consider the following statement:\\~\\<br>$G \multimap (H \oplus K) \subset (G \multimap H) \oplus (G \multimap K)$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! pg 11996, near top
<latex>~\\<br>Consider the following statement:\\~\\<br>If $G$ is any subset of $P$, then $G^{\bot \bot}$ is the smallest fact containing $G$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 11996, lemma 1.13.1<br>todo: add impostor?
Read section 1.15 on pg 11938/11939<br>	<br>
What is affine linear logic, and why is it not a super important logic in the grand scheme of linear logics?	pg 11941, "Affine linear logic" (above contraction)<br>note how this paragraph explains that affine implications can be encoded in standard linear logic using &: This is why affine linear logic is not important.
<latex>~\\<br>Weakening would allow us to ``break" the meaning of the $\otimes$ and $\&$ connectives if we included it in linear sequent calculus. Give a sequent calculus proof tree demonstrating this.<br></latex>	pg 11941, "Weakening"<br><br>
Read the paragraph on "Contraction", which start on pg 11941 and spills over onto pg 11942<br>	<br>
Give a linear sequent calculus proof explaining why including contraction in linear sequent calculus leads to nonsense.<br>	pg 11942<br>
<latex>~\\<br>In linear sequent calculus, sequents are right-sided. That is, they are of the form $\vdash \Delta$, where $\Delta$ is a list of formulas. How are we ``getting away with'' omitting formulas on the left side of the turnstile?<br></latex> 	pg 11943, bottom sentence.<br>
Give the identity and cut rules of the linear sequent calculus.	pg 11944<br>*see also pg 11945 for explanation<br>
Give the linear sequent calculus rules called (one), (false), and (par).<br>	pg 11944<br>*see also pg 11945 for explanation<br>
Give the classical linear sequent calculus rules called (true), (with), (left plus), and (right plus).<br>	pg 11944<br><br>
Give the linear sequent calculus rules called (of course), (weakening), and (derliction).<br>	pg 11944<br>*see also pg 11945 for explanation<br>
Give the (contraction), (for all), and (there is) rules for classical linear sequent calculus.<br> 	pg 11944<br>*see also pg 11945 for explanation<br><br>
<latex>~\\<br>What is a \emph{phase structure}?<br></latex>	pg 11997, 1.14 (i)<br><br>
<latex>~\\<br>Let $S$ be a phase structure and $A$ a proposition. What does $A_S$ denote?<br></latex>	pg 11997 (ii)
<latex>~\\<br>Let $S$ be a phase structure and $A$ a proposition. What does it mean for $A$ to be valid in $S$?<br></latex>	pg 11997 (iii)
<latex>~\\<br>Let $A$ be a linear logic proposition. What does it mean for $A$ to be a \emph{linear tautology}?<br></latex>	pg 11997, 1.14 (iv)<br><br>
What does it mean for a set to be <i>recursive</i>?	pg 10834, definition, right column<br><br>
Consider the following statement:<br><br>The set {0,2,4,...} of even integers is recursive.<br><br>Prove or disprove.	true. pg 10834, right column
Consider the following statement:<br><br>Any finite set is recursive.<br><br>Prove or disprove.	pg 10834, right column
What does it mean for a set A to be <i>recursively enumerable</i>?	pg 10835, top left, definition<br>
<latex>~\\<br>Let $A$ be a recursive set. Consider the following statement:\\~\\<br>$A$ is recursively enumerable. \\~\\<br>Prove or disprove.<br></latex>	pg 10835, left column, Theorem I
<latex>~\\<br>Consider the following statement:\\~\\<br>A set $A$ is recursive iff both $A$ and $\overline{A}$ are recursively enumerable.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10835, left column, theorem II
<latex>~\\<br>Let $A$ be a set of natural numbers. What does it mean for $A$ to be \emph{recursively enumerable in non-decreasing order}?<br></latex>	pg 10835, right column, top definition.<br>
<latex>~\\<br>Let $A$ be a set of natural numbers. What does it mean for $A$ to be \emph{recursively enumerable in increasing order}?<br></latex>	pg 10835, right column, second definition<br>
<latex>~\\<br>Let $A$ be a set of natural numbers. Consider the following statement:\\~\\<br>$A$ is recursive and non-empty $\Leftrightarrow$ $A$ is recursively enumerable in nondecreasing order.\\~\\<br>Prove or disprove.<br></latex>	pg 10835, right column, Theorem III (a)<br>
<latex>~\\<br>Let $A$ be a set of natural numbers. Consider the following statement:\\~\\<br>$A$ is recursive and infinite $\Leftrightarrow$ $A$ is recursively enumerable in nondecreasing order.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 10835, right column, Theorem II
<latex>~\\<br>Let $A$ be a set of natural numbers. Consider the following statement:\\~\\<br>$A$ is recursive and infinite $\Leftrightarrow$ $A$ is recursively enumerable in increasing order.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10835, right column, Theorem III (b)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every recursively enumerable set has an infinite recursive subset.\\~\\<br>Prove or disprove.<br></latex>	pg 10835, right column near bottom, Theorem IV<br><br>
<latex>~\\<br>Let $A$ be a set of natural numbers. Consider the following statement:\\~\\<br>$A\text{ is recursively enumerable }\Leftrightarrow A\text{ is the domain of a partial recursive function }$\\<br>(that is, $\exists x[A = \text{domain } \varphi_x]$)\\~\\<br>Prove or disprove.<br></latex>	true. pg 10836, left column, theorem 5<br>
<latex>~\\<br>Let $x$ be a natural number. What does $W_x$ denote?<br></latex>	pg 10836, right column at top, definition<br>
<latex>~\\<br>What does it mean for a natural number $x$ to be a \emph{recursively enumerable index}?<br></latex>	It means it is used to denote the recursively enumerable set $W_x = domain~\varphi_x$<br>pg 10836, right column, near top<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$A\text{ is recursively enumerable } \Leftrightarrow A\text{ is the range of a partial recursive function.}$\\<br>(that is, $(\Exists x)[A = range~\varphi_x]$)\\~\\<br>Prove or disprove.<br></latex>	pg 10836, right column, corollary V(a)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There exist recursive functions $f$ and $g$ such that for all $x$,<br>$$range~\varphi_{f(x)} = domain~\varphi_x$$<br>$$domain~\varphi_{g(x)} = range~\varphi_x$$<br>Prove or disprove.<br></latex>	pg 10836, right column, Corollary V(b)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There exists a recursive functions $f'$ such that:\\~\\<br>$range~\varphi_{f'(x)} = domain~\varphi_x~\text{ and } [domain~\varphi_x \not = \emptyset \Rightarrow \varphi_{f'(x)} \text{ is total}]$\\~\\<br>Prove or disprove.<br></latex>	pg 10837, top left, Corollary V(c) (i)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There exists a recursive functions $g'$ such that:\\~\\<br>$range~\varphi_{g'(x)} = range~\varphi_x~\text{ and } [range~\varphi_x \not = \emptyset \Rightarrow \varphi_{g'(x)} \text{ is total}]$\\~\\<br>Prove or disprove.<br></latex>	pg 10837, top left, Corollary V(x) (ii)<br>
<latex>~\\<br>What does it mean for a set $A \subseteq \mathbb N$ to be an \emph{initial segment} of $\mathbb N$?<br></latex>	pg 10837, left column, definition.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The projection functor $\vrt{UFam(\omega\text{-Sets})}{\omega\text{-Sets}}$<br>given by the mapping $(X_i, E_i)_{i \in (I,E)} \mapsto (I,E)$, is a split fibration. Moreover, there is the following equivalence of categories in a commuting triangle.\\~\\<br>\begin{tikzcd}<br>\text{UFam}(\omega\text{-}Sets) \arrow[rr, "\simeq"] \arrow[dr] & & \arrow[dl, "dom"] \omega\text{-}Sets^{\to} \\<br> & \omega\text{-}Sets & <br>\end{tikzcd}\\~\\<br></latex>	<latex>~\\<br>pg 10031, prop 1.4.7.\\<br>Note that $E_I(i)$ should just say $E(i)$ in the statement of the proposition<br></latex>
<latex>~\\<br>Give the definition of the category $UFam(\mbf{PER})$.<br></latex>	pg 10032, bottom of page / pg 10033, top of page<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The first projection $\vrt{UFam(\mbf{PER})}{\omega\text{-}Sets}$ mapping $(R_i)_{i \in (I,E)} \mapsto (I,E)$ is a split fibration.\\~\\<br>Prove or disprove.<br></latex>	pg 10033, prop 1.4.9<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration. Consider the following statement:\\~\\<br>For every cleavage one has an isomorphism of sets (or classes)<br>$$\mathbb E(X, Y) \cong \coprod_{u : pX \to pY} \mathbb E_{pX} (X, u^*(Y)) $$<br>where $\coprod$ is the disjoin union. The isomorphism is natural in $X$ and $Y$, between functors<br>$\mathbb E^{op} \times \mathbb E \rightrightarrows \mbf{Sets}$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10033, lemma 1.4.10<br>
Read the last paragraph on pg 10033 "Finally, there is a principle of mathematical purity that deserves attention."<br>	<br>
<latex>~\\<br>Provide the definition of the category $\mbf{Fib}$. What does it mean for a functor to be $\mbf{fibred}$?<br></latex>	pg 10052, def 1.7.1 (i)<br>
<latex>~\\<br>Provide the definition of the category $\mbf{Fib}_{\mbf{split}}$.<br></latex>	pg 10052, def 1.7.1 (ii)<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The functors<br>\begin{mathpar} <br>\vrt{\mbf{Fib}}{\mbf{Cat}}<br>\and<br>and<br>\and<br>\vrt{\mbf{Fib_{split}}}{\mbf{Cat}}<br>\end{mathpar}<br>sending a (split) fibration to its base category are fibrations themselves. Reindexing is done by change-of-base.\\~\\<br>Prove or disprove.<br></latex>	pg 10052<br>
<latex>~\\<br>Let $\mathbb B$ be a fixed category. Define the category $\mbf{Fib}(\mathbb B)$.<br></latex>	pg 10052, def 1.7.3 (i)<br>
<latex>~\\<br>What is a $\textbf{split functor}$?<br></latex>	pg 10053, near top (ii)<br><br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration and $K : \mathbb A \to \mathbb B$ be a functor. <br>Form the pullback in $\mbf{Cat}$.\\<br><br>\begin{center}<br>\begin{tikzcd}<br>\mathbb A \times_{\mathbb B} \mathbb E \ar[d, "K^*(p)" left] \ar[r] \ar[dr, phantom, "\lrcorner", very near start]<br> & \mathbb E \ar[d , "p"] \\<br>\mathbb A \ar[r, "K" below] & \mathbb B<br>\end{tikzcd}<br>\end{center}<br><br>Is the functor $K^*(p)$ a fibration? Under what conditions is it cloven or split? <br><br><br></latex>	pg 10035, lemma 1.5.1<br>
<latex>~\\<br>Explain how a change-of-base may be used to obtain $\vrt{FinFam(\mathbb C)}{\mbf{FinSets}}$, the fibration of finite families of objects and arrows in a category $\mathbb C$.<br></latex>	pg 10036, examples 1.5.2 (i)<br><br>
<latex>~\\<br>What is a \textbf{change-of-base situation}?<br></latex>	pg 10036, examples 1.5.2 (i)<br>
<latex>~\\<br>Let $\mathbb C$ be a locally small category with terminal object $1$. Provide definitions for the categories $Sc(\mathbb C)$ and $iSc(\mathbb C)$.<br></latex>	pg 10036, examples 1.5.2 (ii)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>From the split fibration $\vrt{UFam(\mbf{PER})}{\mbf{PER}}$ of PER-indexed PERs in the following change-of-base situtation.<br>\begin{center}<br>\begin{tikzcd}<br>UFam(\mbf{PER}) \ar[r] \ar[d] \ar[dr, phantom, "\lrcorner", very near start] & UFam(\mbf{PER}) \ar[d] \\<br>\mbf{PER} \ar[r, hook] & \omega\text{-}\mbf{Sets}<br>\end{tikzcd}<br>\end{center}<br>There is then an equivalence of categories in a commuting triangle:<br>\begin{center}<br>\begin{tikzcd}<br>UFam(\mbf{PER}) \ar[rr, "\simeq"] \ar[rd] & & \mbf{PER^{\to}} \ar[ld, "cod"] \\<br> & \mbf{PER} &<br>\end{tikzcd}<br>\end{center}<br>relating pointwise and display indexing of PERs.\\~\\<br>Prove or disprove.<br></latex>	prop 1.5.3<br>pg 10037 bottom / 10038 top 
<latex>~\\<br>In a category $\mathbb C$ with finite limits and finite coproducts $(0,+)$, what does it mean for coproducts to be $\mbf{universal}$?<br></latex>	pg 10037, very bottom<br>pg 10038, very top<br><br>
<latex>~\\<br>In a category $\mathbb C$ with finite limits and finite coproducts $(0,+)$, what does it mean for coproducts to be $\mbf{disjoint}$?<br></latex>	pg 10038
<latex>~\\<br>What does it mean for the initial object of a category to be $\mbf{strict}$?<br></latex>	pg 10038, near center<br><br>
<latex>~\\<br>Let $\mathbb C$ be a category with finite limits and set-indexed coproducts $\coprod_{i \in I} X_i$, which are universal and disjoint. Provide the definition of the copower functor<br>$$ \mbf{Sets} \overset{\coprod}{\longrightarrow} \mathbb C$$<br>Demonstrate an equivalence of categories<br>$$ \mathbb C/\coprod(I) \overset{\simeq}{\longrightarrow} \mathbb C^{I}$$<br>natural in $I \in \mbf{Sets}$\\<br></latex>	pg 10038, prop 1.5.4<br>make sure to read the entire statement of proposition 1.5.4; it contains some actual reasoning.<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ and $\vrt{\mathbb B}{\mathbb A}r$ be fibrations.<br>Consider the following statement:\\~\\<br>The composite $\vrt{\mathbb E}{\mathbb A}rp$ is then also a fibration, in which $f$ in $\mathbb E$ is $rp$-Cartesian $\Leftrightarrow$ f is $p$-Cartesian and $pf$ is $r$-Cartesian. In case both $p$ and $r$ are cloven (or split), then the composite fibration $rp$ is also cloven (or split).\\~\\<br>Prove or disprove.<br></latex>	pg 10040, lemma 1.5.5 (i)<br>todo: add impostor?
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ and $\vrt{\mathbb B}{\mathbb A}r$ be fibrations.<br>Consider the following statement:\\~\\<br>For each object $I \in \mathbb A$ one obtains a functor $p_I$ from $\mathbb E_I = (rp)^{-1}(I)$ to $\mathbb B_I = r^{-1}(I)$ by restriction. All of these $p_I$'s are fibrations.\\~\\<br>Prove or disprove. <br></latex>	pg 10040, lemma 1.5.5 (ii) -- proof is left to the reader<br>I think the trick is that you can express a fibre using a change-of-base, but that trick isn't necessary to understand this: it's pretty straightforward.<br><br>
<latex>~\\<br>Read example 1.5.6 on pg 10041<br></latex>	pg 10041<br>
<latex>~\\<br>Let $\mbf{C}$ be any small category. Consider the following statement:\\~\\<br>The Yoneda embedding<br>$$y : \mbf{C} \to \mbf{Sets^{C^{Op}}}$$<br>has the following UMP: given any cocomplete category $\mathcal E$ and functor $F : \mbf{C} \to \mathcal E$, there is a colimit preserving functor $F_{!} : \mbf{Sets^{C^{Op}}} \to \mathcal E$ such that<br>$$F_! \circ y \cong F$$<br>as indicated in the following diagram:<br>\begin{center}<br>\begin{tikzcd}<br>\mbf{Sets^{C^{Op}}} \ar[r, "F_!", dotted] & \mathcal E \\<br>\mbf{C} \ar[u, "y"] \ar[ur, "F" below] & <br>\end{tikzcd}<br>\end{center}<br>Prove or disprove.<br></latex><br>	pg 2883, prop 9.1.6<br>
<latex>~\\<br>Let $f : \mbf{C} \to \mbf{D}$ be a functor between small categories. Consider the following statement:\\~\\<br>The precomposition functor<br>$$f^{*} : \mbf{Sets^{D^{Op}}}} \to \mbf{Sets^{C^{Op}}}$$<br>given by<br>$$f^{*}(Q)(C) = Q(fC)$$<br>has both left and right adjoints<br>$$f_! \dashv f^{*} \dashv f_{*}$$<br>Moreover, there is a natural isomorphism<br>$$ f_! \circ y_{\mbf{C}} \cong y_{\mbf{D}} \circ f$$<br>as indicated by the following diagram:<br>\begin{center}<br>\begin{tikzcd}<br>\mbf{Sets^{C^{Op}}} \ar[r, shift left = 1.5ex] \ar[r, shift right = 1.5ex, "f_!" below] & \mbf{Sets^{D^{Op}}} \ar[l]\\<br>\mbf{C} \ar[r, "f" below] \ar[u, "y_{\mbf{C}}" left] & \mbf{D} \ar[u, "y_{\mbf{D}}" right]<br>\end{tikzcd}<br>\end{center}<br>Prove or disprove.<br></latex>	pg 2885, corollary 9.17<br>
<latex>~\\<br>Let $I$ be a set. Define the category $\mbf{Sets^I}$.<br></latex>	an arrow is an I-indexed family of arrows between A_i and B_i for each i \in I.<br>pg 2887<br>
Explain the difference between <i>static</i> and <i>dynamic</i> inconsistency policies. Give some examples of each.<br>	pg 12625<br>
Read "The Case for Consistency Safety" on pg 12624. How can consistency types solve this problem?	A solution is proposed on pg 12626<br>
How does one use a value of type Consistent[T]? 	It implicitly gets cast to a value of type T.<br>pg 12626, bottom left corner<br><br>
What does <i>endorsing</i> a value do to it, in the consistency types framework?	pg 12626, right column second paragraph<br><br>
What is the type Rushed[T] for?	If I understand correctly, it's a sum type specific to T where each variant is a weak consistency type (or inconsistent). This type is used as the result of "T-valued" operations with a specified latency bound.<br><br>pg 12626, bottom right corner.<br>
Explain types of the form Interval[T].	pg 12627, left column<br><br>
Explain how a change-of-base can be used to "remove part of" a fibration.	pg 10035, Ex 1.5.2 (i)<br>
What is Facebook's "social graph"?	pg 12653, bottom right corner "Section 2"<br>
The Facebook social graph has many thousands of edge types. Discuss some of the most common edge types.	pg 12654, top left corner.<br>
In the Unicorn data model, what is a DocId? What is a <i>hit</i>?<br> 	pg 12654, bottom left corner<br>
Explain how Facebook Unicorn is <i>sharded</i>. What is the motivation for their particular sharding system?<br>	pg 12654, top right<br><br>
In facebook unicorn, what is a <i>term</i>? What is the conventional form of a term?	pg 12654, right column, near bottom<br>
Explain how Unicorn's weak-and operator works.	pg 12656, bottom right corner<br>
Explain Facebook Unicorn's strong-or command.	pg 12657, top left<br><br>
How does a mobile device GPS API typically provide GPS data to the user? What is the "type" of the interface?	pg 12639, upper right corner<br><br>
A mobile phone phone GPS API provides GPS data to the user in the following format.<br><br>public double Latitude, Longitude; // location<br>public double HorizontalAccuracy; // error estimate<br><br>Horizontal accuracy is a "radius of error". Is this an effective strategy for conveying error to the user? Why or why not?<br><br><br>	pg 12639, bottom right corner<br>
Discuss the problem of "compounding error". 	pg 12639 bottom left / 12640 top right<br>
Why might using a program operating on data derived from a speedometer to issue speeding tickets be problematic?	pg 12640, "conditionals"<br>
Give a brief overview explanation of the generic type Uncertain[T].	pg 12640, bottom right corner<br><br>
Uncertain[T] addresses to sources of error. List and describe them.	pg 12641, right column above sec 3.2<br><br>
How does Uncertain[T] handle arithmetic operations for which some arguments are certain and others are uncertain?	pg 12642<br>
Explain how Uncertain[T] constructs a Bayesian network from the expression "(A/B)-C"	pg 12642, right column
What does it mean for two random variables to be independent? Which pairs of nodes in one of UncertainT's Bayesian networks are considered independent?	pg 12642 (Dependent Random Variables, in bottom right corner)<br>
Draw the Bayes network that UncertainT would generate for the expression "(Y + X) + X"<br>	pg 12643, top left corner<br><br>
In UncertainT, hypothesis tests "introduce a ternary logic". What is meant by this?	pg 12643, bottom right corner<br>
Explain Bayes' theorem, not just the formula, but its intuitive interpretation as "updating based on evidence".	pg 12644, left column<br>
Suppose we want to store a bunch of uncertain values in a sorted list. How do we do this, given that uncertain values are represented by Bayesian networks, which are not totally ordered?	pg 12644<br>
How can we use Unicorn to compute the set of ids of all photos which tag friends of Jon Jones (id 5)?<br>	pg 12658<br>
<latex><br><br>Consider the following Unicorn query:<br><br>\begin{lstlisting}<br>(and (term page-type:restaurant)<br>     (term place-in:102)<br>     (apply likes: (term live-in:100)))<br>\end{lstlisting}<br><br>In what ways could this query cause a problem? How might we solve this problem?<br><br></latex>	pg 12659, bottom right corner<br>pg 12660, full page<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The categories $\mbf{Fib}(\mathbb B)}$ and $\mbf{Fib_{split}}(\mathbb B)$ have finite products;<br>these are preserved by change-of-base.\\~\\<br>Prove or disprove.<br></latex>	pg 10053, lemma 1.7.4<br>todo: add impostor? (all products?)<br><br>
<latex>~\\<br>Let $\mathbb A$ and $\mathbb B$ be categories with pullbacks and let $K : \mathbb A \to \mathbb B$ be a pullback preserving functor. Consider the following statement:\\~\\<br>There are extensions of $K$ to morphisms:\\~\\<br>$\ddisp{Sub(\mathbb A)}{}{\mathbb A} \longrightarrow \ddisp{Sub(\mathbb B)}{}{\mathbb B}$<br>~~~~~~~and~~~~~~~<br>$\ddisp{\mathbb A^{\to}}{}{\mathbb A} \longrightarrow \ddisp{\mathbb B^{\to}}{}{\mathbb B}$\\~\\<br>between the corresponding subobject and codomain fibrations.\\~\\<br>Prove or disprove.<br></latex>	pg 10053, lemma 1.7.5 at bottom<br><br>
<latex>~\\<br>Let $K : (\mathbb A, S) \to (\mathbb B, T)$ be a morphism of $CT$-structures. Consider the following statement:\\~\\<br>One can obtain an extension of $K$ to a morphism between the corresponding simple fibrations $\vrt{s(\mathbb A)}{\mathbb A} \to \vrt{s(\mathbb B)}{\mathbb B}$ which preserves the splitting on-the-nose.\\~\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>pg 10054, lemma 1.7.6. Note that their use of $S$ in place of $\mathbb A$ and $T$ in place of $\mathbb B$ is a mistake.<br></latex><br>
<latex>~\\<br>Assume (K,H) and (L,G) are morphisms $\ddisp{\mathbb E}{p}{\mathbb B} \rightrightarrows \ddisp{\mathbb{D}}{q}{\mathbb A}$ in $\mbf{Fib}$, as below:\\~\\<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb E \ar[r, "H", bend left = 20] \ar[r, "G" below, bend right = 20] \ar[d, "p"] & \mathbb D \ar[d, "q"] \\<br>\mathbb B \ar[r, "K", bend left = 20] \ar[r, "L" below, bend right = 20] & \mathbb A<br>\end{tikzcd}<br>\end{center}<br>What is a $\mbf{2}$-$\mbf{cell}$ $(K,H) \Rightarrow (L,G)$ in $\mbf{Fib}$?<br></latex>	pg 10055, def 1.7.7<br>
<latex>~\\<br>What does it mean for a 2-cell in $\mbf{Fib(\mathbb B)}$ to be \emph{vertical} or \emph{fibred}?<br></latex>	pg 10055
<latex>~\\<br>What does it mean for two fibrations $\vrt{\mathbb E}{\mathbb B}p$ and $\vrt{\mathbb D}{\mathbb B} q$ with the same basis $\mathbb B$ to be \emph{equivalent}?<br></latex>	pg 10055, near bottom<br><br>
Give the "pure" typing rules (ax, sub, abs, and app) of Gaboardi's effect-coeffect calculus. 	pg 9672, top left<br><br>
Give the "effect" rules (unit and letT) for Gaboardi's effect-coeffect calculus.	pg 9672, top left<br><br>
Give the "coeffect" typing rules of Gaboardi's effect-coeffect calculus.<br>	pg 9672, top left<br><br>
Give the <b>dist</b> and <b>op</b> typing rules of Gaboardi's effect-coeffect calculus.<br>	pg 9672, top-left<br><br>
<latex>~\\<br>Let $\Gamma$ and $\Delta$ be typing environments in Gaboardi's effect-coeffect calculus. What does it mean for $\Gamma$ and $\Delta$ to be \emph{summable}?<br></latex>	pg 9671, bottom right corner, definition 4<br>
<latex>~\\<br>Give all seven of Gaboardi's "subeffecting" rules.<br>There are two forms of subeffecting rules. One for contexts, concluding judgments $\Gamma <: \Delta$, <br>and one for types, concluding $A <: B$.<br></latex> 	pg 9672, top right corner.<br>
Draw the table containing the "zoo" of distributive laws for effect-coeffect systems.	pg 9672, right column, figure 4<br>described in section 3.2.1 in the bottom right corner<br><br><br>
<latex>~\\<br>Discuss the basics of an effect-coeffect system for information flow and non-determinism. In particular:\\<br>What is the coeffect preordered semiring $\mathcal R$?\\<br>What is the effect preordered monoid $\mathcal E$?\\<br>What is the distributivity law format?\\<br>What is the $\iota$ function?\\<br>What is the $\kappa$ function?\\<br>What operation (function constant) does the system have?<br></latex>	pg 9677, left column<br>
<latex>~\\<br>Recall the effect-coeffect system for information flow and non-determinism<br>Its distributive law is as follows:<br>$$ \mbf{dist}_{r,e,A}^{(LL,DT)} : D_rT_e A \to T_eD_r A $$<br>Define and justify the semantics for this law.<br></latex>	pg 9677, left column and upper part of right column<br>
Define the category which we use to interpret the effect-coeffect system for information flow and non-determinism.	pg 9677, right column<br><br>
Define the graded exponential comonad used for information flow (from the information flow/nondetermism effect-coeffect system).<br>	pg 9677, right column<br>
<latex>~\\<br>Let $\mathcal C$ be a symmetric monoidal closed category. Let $\mathcal E$ be a preordered monoid. What is an $\mathcal E$-graded monad on $\mathcal C$? What is a \emph{strong} $\mathcal E$-graded monad on $\mathcal E$?<br></latex>	pg 9674, right column<br>
<latex>~\\<br>Let $\mathcal C$ be a symmetric monoidal category. What does $\mbf{SMon}_{l}[\mathcal C, \mathcal C]$ denote? In association with this, what do $\mbf{\dot I}$ and $\dot \otimes$ denote?<br></latex>	pg 9675, left column<br>
<latex>~\\<br>Let $\mathcal R$ be a preordered semiring.<br>What is an \emph{$\mathcal R$-graded exponential comonad}?<br></latex>	pg 9675, left column, fig 7 at top<br>
<latex>~\\<br>Let $\mathcal R = (R, \leq_R, 1_R, \ast)$ and $\mathcal E = (E, \leq_E, 1_E, \bullet)$ be preordered monoids, $D$ be an $\mathcal R$-graded comonad on a category $\mathcal C$, $T$ be an $\mathcal E$-graded monad on $\mathcal C$, and $(\iota, \kappa)$ be an $\mathcal R, \mathcal E$-matched pair for the distributive law format $(LL,DT)$. What is an \emph{$(\iota,\kappa)$-distributive law (for (LL,DT))}?<br></latex>	pg 9675, definition 5, pg 9676 fig 8.<br>
<latex>~\\<br>How does Gaboardi's effect-coeffect system interpret subtyping relations?<br></latex>	pg 9676, left column<br>
<latex>~\\<br>Let $\mathcal R$ and $\mathcal E$ be preordered monoids, $D$ be an $\mathcal R$-graded comonad on a category $\mathcal C$, $T$ be a $\mathcal E$-graded monad on $\mathcal C$, $\phi$ be a distributive law format, and $(\iota, \kappa)$ be an $\mathcal R,\mathcal E$-matched pair for $\phi$. What is an \emph{$(\iota,\kappa)$-distributive law} $(for~\phi)$?\\~\\<br>Hint: the answer should involve providing a table.<br></latex>	pg 9675, def 6<br>
<latex>~\\<br>Define the $\mathcal E$-graded monad used for nondetermism, in Gaboardi's effect-coeffect system with information flow and nondetermism.<br></latex>	pg 9677, bottom right corner, below theorem 2<br>importantly, the monad is T and *not* T' it's important to understand the distinction between these two monads.
<latex>~\\<br>Give the distributive law for Gaboardi's effect-coeffect system for information flow and nondeterminism.<br>Prove that it actually is a distributive law.<br></latex>	pg 9678, definition 7 in the top-left corner.<br>To be a distributive law, it must satisfy the diagrams of pg 9676, figure 8<br>
<latex>~\\<br>Define Gaboardi's effect-coeffect system for bounded reuse and exceptions. In particular:\\~\\<br>What is the preordered semiring $\mathcal R$ for coeffects?\\<br>What is the preordered monoid $\mathcal E$ for effects?\\<br>What is the distributivity law format?\\<br>What are the $\iota$ and $\kappa$ functions?\\<br>What operation (function constant) does it provide?<br></latex>	pg 9678, left column<br>
What is a future? How do futures work in languages such as Oz and Multilisp?	pg 12747, "In Oz..."<br>
Describe and explain the two techniques "concur" and "byneed" for generating futures.	pg 12747. "Similarly, a second kind of 'lazy' future annotation..."<br>
What is the purpose of the <i>prom</i> construct in Alice? How does it work?	pg 12747. "Now, viewing a future as the reading side of a logic variable..."<br><br>
There are three basic ways to introduce a future: what are they?	pg 12747, "In summary..." near bottom of page<br>
What are the (polymorphic) types of <i>concur</i> and <i>byneed</i> in the Alice ML library?<br>	pg 12749, near top<br>
Alice ML provides a few "impure", non-functional operations on futures. What are they?	pg 12749, "The structure Future also contains..."<br><br>
<latex>~\\<br>Give the types and describe the behaviors of the \emph{promise}, \emph{future}, and \emph{fulfill} operations in Alice ML. <br></latex>	pg 12749. "Promises"<br>
Give the equational theory for lambda abstractions and the let forms of Gaboardi's effect coeffect calculus.	pg 9673, top right corner, figure 5<br><br>
State the linear substitution lemma for Gaboardi's coeffect calculus. Also state the coeffectful substitution lemma.<br>	pg 9673, bottom right corner.<br>
<latex>~\\<br>Give both versions of the equational theory for the $\mbf{dist}$ construct in Gaboardi's coeffect calculus.<br>There is one version for DT distributive laws and one version for TD distributive laws.<br></latex>	pg 9674, top left corner<br>
<latex>~\\<br>Give a typing derivation in Gaboardi's effect-coeffect calculus which justifies the equational rule (eff1-dist):<br>$$ [\langle t \rangle ] = dist \langle [t] \rangle $$<br></latex>	pg 9674, left column near top<br>typing rules on pg 9672, upper left<br>
<latex>~\\<br>Explain the (eff$\bullet$-dist) and (coeff$\ast$-dist) equations for the DT distributive laws. <br></latex>	text at pg 9674, bottom left<br>laws at pg 9674, top left<br>
Give the definition of Gaboardi's distributive law for bounded reuse and exceptions. Prove that it is actually a distributive law.<br><br>	pg 9678, right column, right above theorem 5<br>The distributive law diagrams are on pg 9676 top<br>
Explain how lazy futures can be used to implement possibly infinite lists.	pg 12753<br>
Explain how promised futures can be used to implement input streams.	pg 12754, "2.2 Streams"<br>
Read the code in figure 2.3 on pg 12756, and explain how it implements a communication channel.	pg 12755/12756<br>
<latex>~\\<br>If $\to_1 \subseteq A_1 \times A_2$ and $\to_2 \subseteq A_2 \times A_3$, what does Schwinghammer write $\to_1 \to_2$ to mean?<br></latex>	pg 12757
<latex>~\\<br>What does Schwinghammer write $[A \to_{fin} B]$ to mean?<br></latex>	pg 12757, near bottom<br><br>
What does it mean for a binary relation to be <i>confluent</i>? <i>Uniformly confluent</i>? What does it mean for two binary relations on the same set to <i>commute</i>?	pg 12758
<latex>~\\<br>Let $\to \subseteq S \times S$ be a binary relation. What is a \emph{partial execution} of $\to$? What is an \emph{execution} of $\to$?<br></latex>	pg 12758 "Uniform confluence and executions"
How do we handle "multithreading" in the calculus for futures and promises. What is the reduction rule for terms of the form "<b>concur</b> e"?<br>	pg 12758, near bottom<br><br>
<latex>~\\<br>If $x$ is a future, the lambda calculus for futures and promises can evaluate terms of the form<br>"$x~v$". Give the reduction rule.<br></latex>	pg 12758 bottom / 12759 top<br>
Give the reduction rule explaining the interaction between expressions and configurations.	<latex>~\\<br>\inferrule<br>  {e \overset{\alpha}{\to} e'}<br>  {C[x \mapsto e] \overset{\alpha}{\to} C[x \mapsto e']}<br>\\~\\~\\<br>see pg 12759<br></latex>
<latex>~\\<br>Give the inference rule relating the lookup judgment $C \overset{L x v}{\longrightarrow} C'$ <br>to the configuration reduction relation $C \to C'$<br></latex>	pg 12759<br><br><latex>~\\<br>\inferrule<br>  {C \overset{\mbf{L} x v}{\longrightarrow} C' \\ C(x) = v}<br>  {C \to C'}<br></latex><br><br>Note that a "labelled" configuration reduction inherits its label from the expression reduced, as seen below the the text "this interaction between expressions and configurations..."<br><br>Labelled expression reductions are given on pg 12758<br><br>
How do we accomodate the "byneed e" construct into our formal operational semantics?	pg 12759 bottom / pg 12760 top<br><br>remember: the expressions in the C component are the ones that reduce. The expressions in the B component are frozen (evaluated by need)<br><br>
How are promises incorporated into our formal operational semantics?	pg 12760<br>
Give a broad overview of the benefits of Warehouse scale computing (WSC).	pg 13658, second-to-last paragraph.<br><br>- Better user experience (no configuration or backup needed)<br>- Easy for software developers, restrict deployment to a few well-tyested configurations (computer hardware)<br>- Applications run at a lower per-user cost (example: multiplexing a single machine's resources across several users enables better utilization)<br>- Some applications used on mobile, but require massive resources and hence more suitable to datacenters (web search, language translation, machine learning)<br><br>
Why is cost efficiency so important for warehouse scale computing?	pg 13660/13661, section 1.2<br><br>
Consider the following statement:<br><br>Barroso considers a network of geo-distributed data centers to be a single "machine".<br><br>True or false?	False. see pg 13662, 1.4<br>He considers a single data center to be a single machine.<br>
Read sections 1.6.1 and 1.6.2 on pgs 13663-13666<br>	<br>
Read sections 1.6.3 and 1.6.4 on pgs 13667-13669	<br>
Consider the following statement:<br><br>CPUs and memory systems have roughly equal energy consumption in modern WSCs<br><br>True or false?	False. pg 13670, sec 1.6.5<br>
Describe the following different software "layers" in Warehouse Scale Computing:<br>- Platform-level software<br>- Cluster-level infrastructure<br>- Application-level software<br>- Monitoring software<br>	pg 13674<br>
Barroso distinguishes two types of application level software for WSCs: online services and offline computations.<br>Define these.	pg 13674 "application-level software"<br>
Read section 2.2, pgs 13675-13676	<br>
Give a brief overview of the role Kubernetes plays in WSC.	pg 13676, section 2.3.1<br>
There are three types of cluster-level infratructure software<br>- Resource management<br>- Cluster infrastructure<br>- Application framework<br><br>Give a brief discussion of each.<br>	pg 13677-13678
<latex>~\\<br>Provide the definitions of the domains $Loc$, $Val$, $\sem{\Delta}$, $Heap$, and $State(\Delta)$ in Birkedal's semantics for separation logic.<br></latex>	pg 14384<br>
<latex>~\\<br>What is the meaning of the disjointness predicate $h \# h'$ in separation logic? What is the meaning of the heap combination operator $h \cdot h'$?<br></latex><br>	pg 14384<br>
<latex>~\\<br>In Birkedal's separation logic, properties of states are expressed using an assertion language (it's the standard assertion language of separation logic). Give the syntax for this assertion language, which includes two non-terminals E (for expressions) and P (for predicates).<br></latex>	pg 14384<br>
<latex>~\\<br>What do assertions of the form $E \mapsto E'$ mean in separation logic? What does the notation $E \mapsto -$ mean?<br></latex>	pg 14384, second-to-last paragraph
<latex>~\\<br>What do assertions of the form $emp$ mean in separation logic? What do assertions of the form $P \ast Q$ mean?<br></latex>	pg 14384, near bottom<br><br>
<latex>~\\<br>What do the notations $\Delta \vdash P$ and $\Delta \vdash E$ mean in Birkedal's presentation of separation logic?<br></latex><br>	pg 14384, at the very bottom<br>
<latex>~\\<br>In Birkedal's presentation of separation logic, a judgment of the form <br>$\Delta \vdash E$ is interpreted as a function. What are the domain and codomain of this function?<br>Likewise, a judgment of the form $\Delta \vdash P$ is also interpreted as a function. What are the domain<br>and codomain of \emph{this} function?\\~\\<br>Define interpretations of judgments of the following forms:\\<br>$\sem{\Delta \vdash E \mapsto E'}$\\<br>$\sem{\Delta \vdash \mbf{emp}}$\\<br>$\sem{\Delta \vdash P \ast P'}$\\<br>$\sem{\Delta \vdash \forall i. P}$<br></latex>	pg 14385, near top<br><br>
<latex>~\\<br>Give the type well-formedness rule for judgments of the form<br>$$\Delta \vdash \{ P \} - \{ Q \} : Type$$<br></latex>	pg 14385<br>
<latex>~\\<br>Give the type well-formedness rule for judgments of the form<br>$$\Delta \vdash \Pi_i \theta : Type$$<br></latex>	pg 14385<br>
<latex>~\\<br>Give the type well-formedness rule for judgments of the form<br>$$\Delta \vdash \theta \otimes P : Type$$<br></latex>	pg 14385<br>
<latex>~\\<br>What does a type of the form $\theta \otimes P$ mean?<br></latex>	pg 14385, below the four inference rules.<br>
<latex>~\\<br>What does a type of the form $\Pi_i \theta$ mean?<br></latex>	pg 14385, bottom paragraph<br>
Give the syntax of preterms for Birkedal's separation logic calculus.<br>	pg 14386<br>
Explain the special role of integers in Birkedal's separation logic calculus.	pg 14386, top paragraph. <br>tldr: they are "second class"<br><br>
<latex>~\\<br>Explain the form of the typing judgments $\Gamma \vdash_{\Delta} M : \theta$ of Birkedal's separation logic calculus.<br></latex>	Gamma is a standard typing environment (albeit with separation logic refinement types). Theta is and standard (refined) result type. Delta is an environment of integer-valued variables, which may appear in Gamma and Theta.<br><br>pg 14386<br>
There are three basic classes of typing rules for Birkedal's separation logic calculus. List them, and explain the purpose of each class.	pg 14386<br>
<latex>~\\<br>Give the typing rules for variables, command-over-command abstractions, command-to-command applications, <br>integer-over-command abstractions, command-to-integer applications, and fixpoints.<br></latex>	pg 14387, top six typing rules.<br><br>
<latex>~\\<br>Give the $\preceq_{\Delta}$ subtyping rules for:\\~\\<br>- Types of the form $\Pi_i \theta$\\<br>- Types of the form $\theta \otimes P$\\<br>- Types of the form $\{ P \}-\{ Q \}$<br></latex>	pg 14387, fig 2<br><br>
<latex>~\\<br>There is a subtyping axiom that allows us to ``rewrite'' a type of the form $\{ P \}-\{ Q \} \otimes P_0$.<br>What is it?<br></latex>	pg 14387
<latex>~\\<br>There is a subtyping axiom that allows us to ``rewrite'' a type of the form $(\theta \otimes P) \otimes Q$.<br>What is it?<br></latex>	pg 14387, figure 2, bottom left axiom<br><br>
<latex>~\\<br>There is a subtyping axiom that allows us to ``rewrite'' a type of the form $(\Pi_i \theta) \otimes P$.<br>What is it?<br></latex>	pg 14387, fig 2, middle right axiom<br>
Explain the role of pers (partial equivalence relations) in the categorical semantics of Birkedal's separation logic calculus. <br><br>(Hint: Recall the characterization of pers established in Jacbobs' Categorical Type Theory, in the exercises to chpt 1.2, where pers are demonstrated to be equivalent to partial partitions: I find thinking of pers as partial partitions to be intuitive)<br> <br>	pg 14393<br>
List and describe the three intutitive properties that are formalized for Birkedal's type system.	pg 14393, near top<br><br>
<latex>~\\<br>Let $A$ be a pointed cpo. What does it mean for a per $R_0$ on $A$ to be admissible?<br></latex>	<latex>~\\<br>pg 14394, footnote 4. \\<br>question: what is the significance of admissibility?<br></latex><br><br>
What is a pointed cpo?<br>	It's what Reynolds calls a domain. It's a partial order which contains the join of each of its countable chains.<br>It also has a bottom elemented, which is why it's called a "pointed cpo".<br><br>pg 14394 (it's not defined in the paper, I had to do some research in TOPL and Davey&Preistley)<br><br>
<latex>~\\<br>How does Birkedal define the ``extracting'' category $\mathcal C$?<br>Give both its formal definition and an intuitive explanation.<br></latex>	<latex>~\\<br>pg 14394. Note that if $R$ is a partial equivalence relation, then $|R|$ denotes all elements that are reflexively related to themselves by $R$.<br></latex><br>
<latex>~\\<br>Let $c$ be a function from $Heap$ to $\mathcal P(Heap \cup \{ wrong \})$. What does it mean for $c$ to satisfy \emph{safety monotonicity}? What does it mean for $c$ to satisfy the \emph{frame property}? <br></latex>	pg 14394, near bottom<br><br>For safety monotonicity, extending the heap should not yield undefined behavior, because the command c will not actually *access* the heap extension (the reason for this is that wrong \notin c(h)).<br><br>The frame property is similar: since wrong \notin c(h), c cannot mutate h_0<br><br><br><br>
<latex>~\\<br>How does Birkedal define the set $comm$?<br></latex>	pg 14394, near bottom<br>
<latex>~\\<br>For predicates $p,q$ the ``extracting category'' $\mathcal C$ has a ``Hoare triple'' object [p, q] corresponding to the type $\{ p \}-\{ q \}$. Give the definition of this object.<br></latex>	<latex>~\\<br>pg 14394, near bottom\\<br>pg 14395, near top\\~\\<br>read down to ``the category $\mathcal C$ is Cartesian closed'' -- there's some important stuff in there.<br></latex><br>
<latex>~\\<br>What is the terminal object of the ``extraction'' category $\mathcal C$, and why?<br></latex>	pg 14395, near middle of page "the category C is cartesian closed..."<br><br>
<latex>~\\<br>Let $(A,R)$ and $(B,S)$ be objects of the ``extraction'' category $\mathcal C$. Define the categorical product of $(A,R)$ and $(B,S)$ in $\mathcal C$. Show that it actually is a product. <br></latex>	pg 14395, proof is in lemma 4.1<br><br>
<latex>~\\<br>The ``extraction'' category $\mathcal C$ has exponentials. Define the exponential $(A,R) \Rightarrow (B,S)$.<br>Show that it actually is an exponential in $\mathcal C$.<br></latex>	definition on pg 14395 "The category C is carestian closed..."<br>proof on pg 14396 "Next, we prove..."<br>
<latex>~\\<br>Consider the following statement: For every object $(A,R)$ in Birkedal's ``extraction category'' $\mathcal C$, the least fixpoint operator $lfix_A : [A \Rightarrow A] \to A$ on $A$ is a morphism in $\mathcal C$.<br>Prove or disprove.<br></latex>	true. pg 14396, lemma 4.2<br>
<latex>~\\<br>In Alavaro's framework, what is a \emph{component}? What is a \emph{stream}? What is a \emph{component instance}? A \emph{stream instance}?<br></latex>	it's all explained on pg 14465<br>
Two standard schemes exist for fault-tolerant dataflows. What are they? Explain.	They are replication and replay, described on pg 14466, left column<br>
Discuss and provide the definition of <i>cross-run non-determinism</i>.<br>	pg 14466<br>
Discuss and define <i>cross-instance non-determinism</i>.<br>	pg 14466, top right corner<br>
Explain the <i>replica divergence</i> class of anomalies.<br>	pg 14466, top-right corner<br>
What is <i>confluence</i> (note that this is different from PL confluence)? What is <i>convergence</i>? How are the two properties different?	pg 14466, right column<br>
Does confluence (not PL confluence but alvaro's idiosyncratic defn.) imply convergence? What about vice versa?	pg 14466<br>
There are two techniques for acheiving eventual consistency of components which are not confluent. Discuss and define them.	The idea is that the components are not monotone, and so we can enforce a total ordering on the intermediate inputs, or we can refrain from producing any output until all inputs have arrived (sealing). This seems akin to arriving at a fixpoint.<br>pg 14467<br><br>..... do we know of any components which are confluent but not monotone? They act like the latter is a proper subset of the former, but I'm not sure.<br><br>
Read the examples in the right column of pg 14467<br>	<br>
There are two essential properties of distributed systems: "local views" and "evolution of local views". Describe each property.	pg 14487<br>
Read Section 1.1.2 on pg 14487, <br>referring to fig 1.3 on pg 14488 <br>and fig 1.4 on pg 14489<br>	<br>
Why does the topological approach to distributed computing excel at impossibility results?	pg 14489<br>
According to Herlihy, what is a <i>system</i>? What is a <i>process</i>?<br>What is a <i>protocol state</i>? What is an <i>execution</i>?	pg 14491, sec 1.2.1<br>
True or false: In Herlihy's model, a message sent from one process to another may need to traverse several intermediate waypoints on its path.<br>	FALSE. pg 14491, sec 1.2.2 Communication<br>
What is an <i>atomic snapshot memory</i>?	pg 14491, near bottom (second-to-last-paragraph)<br>
What is a <i>wait-free</i> algorithm? What is a <i>t-resilient</i> algorithm?	pg 14492 "failures"<br><br>
What is the difference between a <i>crash failure</i> and a <i>Byzantine failure</i>?	pg 14492, sec 1.2.3 bottom paragraph<br>
Define distributed computing's notion of a <i>task</i>. Is it analogous to some concept from non-distributed computing?	pg 14493, above sec 1.3<br>
Explain "The muddy children problem".<br>	pg 14494, top<br>
Intuitively explain the topological approach to explaining the muddy children problem.<br>	pg 14494 / 14495 / 14496<br><br>
Herlihy uses a somewhat idosyncratic (hint: topological) definition of graphs. Provide this definition.	pg 14503, def 2.1.1<br><br>
What is a <i>simplex</i>?	pg 14503, below def 2.1.1<br>
How do we calculate the <i>dimension</i> of a simplex?	pg 14503<br>
What does it mean for a vertex in a graph to be <i>isolated</i>? What does it mean for a graph to be <i>pure of dimension 0</i>? <i>pure of dimension 1</i>? 	pg 14503, "We say that a vertex is isolated..."<br><br>
What is a <i>coloring</i> of a graph? What does it mean for a graph to be <i>chromatic</i>?	pg 14503<br>
<latex>~\\<br>Let $L$ be some set. What is an \emph{$L$-labelling} of a graph $\mathcal G$?<br></latex>	pg 14503<br>
<latex>~\\<br>If $s$ is a vertex in a labeled chromatic graph, what does $name(s)$ denote? What does $view(s)$ denote?<br></latex>	pg 14503, "For distributed computing..."<br>
<latex>~\\<br>Let $\mathcal G$ and $\mathcal H$ be graphs and $\mu : V(\mathcal G) \to V(\mathcal H)$ a vertex map. What does it mean for $\mu$ to be a \emph{simplical map}?<br></latex>	pg 14504<br>
<latex>~\\<br>What does it mean for a simplical map to be \emph{rigid}?<br></latex>	pg 14504, near top<br><br>
<latex>~\\<br>Consider the following statemet:~\\~\\<br>Chromatic simplical maps are rigid.~\\~\\<br>Prove or disprove.<br></latex>	true. pg 14504, "When G and H are chromatic..."<br>
<latex>~\\<br>Fill in the blank:~\\~\\<br>The image of a connected graph $\mathcal G$ under a simplical map is \underline{~~~~~~~~~~~~~~~~~}.<br></latex>	connected<br><br>pg 14504<br>
<latex>~\\<br>Given two graphs $\mathcal G$ and $\mathcal H$, what is a \emph{carrier map} $\Phi : \mathcal G \to 2^{\mathcal H}$?<br></latex>	pg 14504, def 2.1.3 at bottom 
<latex>~\\<br>What does it mean for a carrier map to be \emph{strict}?<br></latex>	pg 14505<br>
<latex>~\\<br>What does it mean for a carrier map $\Phi$ to be \emph{rigid}? What does it mean for a carrier map to be \emph{connected}?<br></latex>	pg 14505, near top<br>
<latex>~\\<br>Consider the following statement:~\\~\\<br>If $\Phi$ is a connected carrier map from a connected graph $\mathcal G$ to a graph $\mathcal H$, <br>then the image of $\mathcal G$ under $\Phi$ is a connected graph.~\\~\\<br>Prove or disprove.<br></latex>	true. pg 14505, fact 2.1.4<br>
<latex>~\\<br>Assume we are given chromatic graphs $\mathcal G$ and $\mathcal H$ and a carrier map $\Phi : \mathcal G \to 2^{\mathcal H}$. What does it mean for $\Phi$ to be \emph{chromatic}?<br></latex>	pg 14505, def 2.1.5<br>
<latex>~\\<br>Consider the following statement.~\\~\\<br>Let $\Phi$ be a carrier map from $\mathcal G$ to $\mathcal H$, and<br>let $\delta$ be a simplical map from $\mathcal H$ to a graph $\mathcal O$. Consider the carrier map <br>$\delta \circ \Phi$ from $\mathcal G$ to $\mathcal O$. If $\Phi$ is chromatic and $\delta$ is chromatic, then so is $\delta \circ \Phi$. If $\Phi$ is connected, then so is $\delta \circ \Phi$.~\\~\\<br>Prove or disprove.<br></latex>	true. pg 14505, fact 2.1.6<br>
<latex>~\\<br>Let $\Phi_0$ be a chromatic carrier map from $\mathcal G$ to $\mathcal H_0$ and $\Phi_1$ a chromatic carrier map from $\mathcal H_0$ to $\mathcal H_1$. Consider the following statement:~\\~\\<br>The induced chromatic carrier map $\Phi$ from $\mathcal G$ to $\mathcal H_1$ is connected if both $\Phi_0$ and $\Phi_1$ are connected.~\\~\\<br>Prove or disprove.<br></latex>	true. pg 14505, fact 2.1.7<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $A,B$ be process names (sometimes \emph{Alice} and \emph{Bob}), $V^{in}$ a domain of \emph{input values}, and $V^{out}$ a domain of \emph{output values}. What is a \emph{task} for these processes?<br>How does the notion of a \emph{task} map onto the practical problem of 2-process distributed systems?<br></latex>	pg 14506, section 2.2<br><br>
<latex>~\\<br>A carrier map must satisfy a \emph{monotonicity condition}. What is this monotonicity condition, and what is its practical relevance to modelling two-process distributed systems?<br></latex>	pg 14506, paragraph above sec 2.2.1<br>monotonicity condition defined on pg 14504, def 2.1.3<br>
Give an explanation and intuitive overview of the "Coordinated Attack Problem".<br>	pg 14497, described over the course of the entire page.<br>
Explain the combinatorial approach to the "Coordinated Attack Problem", and how it elucidates the impossibility of a solution.	pg 14498 / 14499<br>
Recall the "Coordinated Attack Problem". Formalize this problem as a <i>task</i>.<br>	pg 14506<br>
Recall the "Coordinated Attack Problem". Formulate this problem as a <i>task</i>.	pg 14506/14507, section 2.2.1<br><br>
There are two version of the consensus problem: fixed and binary. Formulate both problems as <i>tasks</i>.<br>	pg 14504, fig 2.1<br>pg 14507, sec 2.2.2<br>"task" is defined on pg 14506<br>
Explain the "Approximate Coordinated Attack" a.k.a. "Approximate Agreement" problem.<br>Define a <i>task</i> capturing this problem.<br>	pg 14508
What is a <i>protocol graph</i>?	pg 14509<br><br>"Now consider a protocol execution in which the processes exchange information through the channels<br>(message passing, read-write memory, or other) provided by the model. At the end of the execution, each<br>process has its own view (final state). The set of all possible final views themselves forms a chromatic<br>graph. Each vertex is a pair (P, p), where P is a process name, and p is P’s view (final state) at the end<br>of some execution. A pair of such vertices {(A, a), (B, b)} is an edge if there is some execution where<br>A halts with view a and B halts with view b. This graph is called the <i>protocol graph</i>."
<latex>~\\<br>Let $\mathcal I$ be an input graph and $\mathcal P$ a protocol graph. What is an \emph{execution carrier map} $\Xi$ from $\mathcal I$ to $\mathcal P$?<br></latex>	pg 14509<br>
<latex>~\\<br>A protocol graph is related to an output graph by a decision map $\delta$. What is a \emph{decision map}?<br></latex>	pg 14509<br>
<latex><br>Let $\mathcal I$ be an input graph, $\mathcal O$ an output graph, and $\mathcal P$ a protocol graph. Let $\delta : \mathcal P \to \mathcal O$ be a decision map, $\Xi : \mathcal I \to \mathcal P$ an execution carrier map, and $\Delta : \mathcal I \to \mathcal O$ a carrier map. What does it mean for $\delta$ to be \emph{carried by} the carrier map $\Delta$?<br></latex>	pg 14509<br>
<latex>~\\<br>Let $\delta : \mathcal P \to \mathcal O$ be a decision map and $\Xi : \mathcal I \to \mathcal P$ be an execution map. What does it mean for $\delta \circ \Xi$ to be \emph{carried by} a carrier map $\Delta : \mathcal I \to \mathcal O$?<br></latex> 	pg 14509, below definition 2.3.1<br>
<latex>~\\<br>What does it mean for a protocol $(\mathcal I, \mathcal P, \Xi)$ to \emph{solve} a task $(\mathcal I, \mathcal O, \Delta)$?<br></latex>	pg 14509, near bottom<br><br>
<latex>~\\<br>Assume that every protocol graph $\mathcal P$ permitted by a particular model has the property that the associated strict carrier map $\Xi : \mathcal I \to 2^{\mathcal P}$ is connected. Consider the following statement:\\~\\<br>The task $(\mathcal I, \mathcal O, \Delta)$ is solvable only if $\Delta$ contains a connected carrier map.\\~\\<br>Prove or disprove.<br></latex>	pg 14510, corollary 2.3.3<br>definition of "connected" is on pg 14505<br>
Explain the alternate message passing model, and the protocol graphs it permits.	pg 14510 (it may help to open two copies of MiscStudy, and compare pg 14510/14511)<br>**NOTE** this section was very confusing to me the first time I tried reading it--maybe it is sloppy and should be ignored.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There is a fibred equivalence as follows\\~\\<br>\begin{tikzcd}<br>Fam(\mbf{Sets_{\bullet}}) \ar[rr,"\cong"] \ar[rd] &  & \ar[ld] \mbf{Sets}_{\bullet}^{\to} \\<br> & \mbf{Sets} &<br>\end{tikzcd}~\\<br>Prove or disprove.<br></latex>	pg 10056<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There is a fibred equivalence as follows\\~\\<br>\begin{tikzcd}<br>UFam(\mbf{PER}) \ar[rr,"\cong"] \ar[rd] &  & \ar[ld] \mbf{PER}^{\to} \\<br> & \mbf{PER} &<br>\end{tikzcd}~\\<br>Prove or disprove.<br></latex>	pg 10056<br>
<latex>~\\<br>Let $K : \mathbb A \to \mathbb B$ be a functor. Consider the following statement:\\~\\<br>Change-of-base along $K$ yields a $2$-functor <br>$K^{\ast} : \mbf{Fib}(\mathbb B) \to \mbf{Fib}(\mathbb A)$.\\~\\<br>Prove or disprove.<br></latex>	pg 10056, it's not proven in the book<br>see "Category Theory in Context", pdf pg 6817 for a definition of 2-functor<br>this lemma seems relevant to exercise 1.6.3 (ii) on pg 10050<br>A full proof is given in DetailedNotes/JacobsExercises.pdf: search for "Lemma 1.7.9"<br>TODO: finish the prrof in DetailedNotes<br><br>
<latex>~\\<br>Assume that two functors $K,L : \mathbb A \rightrightarrows \mathbb B$ are given with natural transformations $\sigma : K \Rightarrow L$ between them. Let $\disp{\mathbb E}{\mathbb B}p$ be a cloven fibration.<br>Consider the following statement:\\~\\<br>There is a lifting $\overline{\sigma} : K' \langle \sigma \rangle \Rightarrow L'$ of $\sigma : K \Rightarrow L$ in a diagram,<br>TODO: write out the latex for this diagram\\~\\<br>Prove or disprove.<br></latex>	pg 10056, lemma 1.7.10<br>
<latex>~\\<br>Let $\diamond$ be some categorical property or structure (for example some limit or colimit or exponent).<br>What does it mean for a fibration to have \emph{fibred $\diamond$'s}? What does it mean for a split fibration to have \emph{split fibred $\diamond$'s}?<br></latex>	pg 10059, def 1.8.1<br>
<latex>~\\<br>Let $\diamond$ be some categorical property or structure (for example some limit or colimit or exponent).<br>What does it mean for a morphism $\ddisp{\mathbb E}{p}{\mathbb B} \overset{(K,L)}{\to} \ddisp{\mathbb D}{q}{\mathbb A}$ of fibrations with $\diamond$'s to preserve (fibred) $\diamond$'s? <br></latex>	pg 10059, def 1.8.1 (ii)<br>
<latex>~\\<br>What is a (split) \emph{fibred CCC}?<br></latex>	pg 10060, def 1.8.2<br>
<latex>~\\<br>Consider the following statement:<br>\begin{center}<br>$\mathbb C$ is a CCC (with chosen structure) $\Leftrightarrow$ $\vrt{Fam(\mathbb C)}{\mbf{Sets}}$ is a split fibred CCC<br>\end{center}<br>Prove or disprove.<br></latex>	pg 10060, example 1.8.3 (i)<br>
<latex>~\\<br>Examine exercise 1.3.1 on pg 10024. Does this exercise imply that the simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ have split finite products? Why or why not?<br></latex>	pg 10060, examples 1.8.3 (ii)<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite limits. Consider the following statement:\\~\\<br>The codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$ on $\mathbb B$ has all fibred finite limits.<br>Furthermore, letting $F : \mathbb A \to \mathbb B$ be a finite limit preserving functor, the induced morphism of fibrations $\vrt{\mathbb A^{\to}}{\mathbb A} \to \vrt{\mathbb{B}^{\to}}{\mathbb B}$ preserves fibred finite limits.\\~\\<br>Prove or disprove.<br></latex>	pg 10060, examples 1.8.3 (iii)<br>todo: add impostor?
<latex>~\\<br>Let $\mathbb B$ be a category with finite limits. Consider the following statement.<br>\begin{center}<br>$\mathbb B$ is locally Cartesian closed $\Leftrightarrow$ the codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$ is a fibred CCC<br>\end{center}<br>Prove or disprove.<br></latex>	pg 10060, example (iv) at bottom<br>todo: add impostor?
Read and understand example (v) at the top of pg 10061<br>	<br>
<latex>~\\<br>Let $\lozenge$ be some categorical property or structure (for example some limit or colimit or exponent).<br>Consider the following statement:\\~\\<br>If a (split) fibration $p$ has (split) fibred $\lozenge$'s, then so has a fibration $K^*(p)$ obtained by change-of-base. Moreover, the associated morphism of fibrations $K^*(p) \to p$ preserves $\lozenge$'s.\\~\\<br>Prove or disprove.<br></latex>	pg 10061, lemma 1.8.4<br>
<latex>~\\<br>Does the fibration $\vrt{\mbf{Sign}}{\mbf{Sets}}$ have fibred limits and colimits? If so, why?<br></latex><br>	pg 10061, Example 1.8.5<br>
<latex>~\\<br>Consider the codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$. Consider the following statement:\\~\\<br>Every fibre $\mathbb B/J$ has a terminal object.\\~\\<br>Prove or disprove<br></latex>	True. pg 10061, "Adjunctions between fibred categories"
<latex>~\\<br>Consider the codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$. Every fibre $\mathbb B/J$ has a terminal object, namely the identity family $1J = \ddisp{J}{id}{J}$. The assignment $J \mapsto 1J$ then extends to a functor $1 : \mathbb B \to \mathbb B^{\to}$.\\~\\~\\<br>Describe the functor $1$ as a fibred functor $1 : id_{\mathbb B} \to cod$.<br></latex>	pg 10062 (i)
<latex>~\\<br>Consider the codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$. Every fibre $\mathbb B/J$ has a terminal object, namely the identity family $1J = \ddisp{J}{id}{J}$. The assignment $J \mapsto 1J$ then extends to a functor $1 : \mathbb B \to \mathbb B^{\to}$.\\~\\~\\<br>The functor $1$ has a left adjoint in $\mbf{Fib}(\mathbb B)$. What is it?<br></latex>	pg 10062 (ii), near top<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ and $\vrt{\mathbb D}{\mathbb B} q$ be fibrations with the same base category $\mathbb B$. What is a \emph{fibred adjunction} between $p$ and $q$?<br></latex>	pg 10062, def 1.8.6 (i)<br>*** see pg 2910 for information on the triangle identities<br><br><br>
<latex>~\\<br>What does it mean for a fibred adjunction to be a \emph{split} fibred adjunction?<br></latex>	pg 10063 (ii) at top<br>
Read Examples 1.8.7 on pg 10063<br>(can we turn this into questions?)<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A fibration $\vrt{\mathbb E}{\mathbb B}p$ has fibred terminal objects if and only if the unique morphism from $p$ to the terminal object in $\mbf{Fib}(\mathbb B)$ has a fibred right adjoint, say 1, in<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb E \ar[rr, "! = p", bend left = 20] \ar[rr, phantom, "\bot"] \ar[dr,"p" below] & & \ar[dl, "id_{\mathbb B}"] \ar[ll, "1" below, bend left = 20] \mathbb B \\<br> & \mathbb B &<br>\end{tikzcd}<br>\end{center}<br>Prove or disprove.<br></latex>	true. pg 10064, lemma 1.8.8<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B} p$ and $\vrt{\mathbb D}{\mathbb B}q$ be fibrations and let $H : \mathbb E \to \mathbb D$ be a fibred functor. Consider the following statement:\\~\\<br>This functor $H$ has a fibred left (resp. right) adjoint if and only if both <br>\begin{itemize}<br>\item For each object $I \in \mathbb B$ the functor $H_{I} : \mathbb E_I \to \mathbb D_I$ restricted to the fibres over I has a left (resp. right) adjoin $K(I)$.<br>\item The \emph{Beck-Chevalley condition} holds, i.e. for every map $u : I \to J$ in $\mathbb B$ and for every pair of reindexing functors.<br>\begin{mathpar}<br>\mathbb E_J \overset{u^*}{\longrightarrow} \mathbb E_I \and \mathbb D_J \overset{u^\#}{\longrightarrow} \mathbb D_I<br>\end{mathpar}<br>The canonical natural transformation<br>\begin{mathpar}<br>K(I)u^\# \Longrightarrow u^*K(J) \and (resp.~u^*K(J) \Longrightarrow K(I)u^\#)<br>\end{mathpar}<br>is an isomorphism.<br>\end{itemize}~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>An important part of this question is knowing what \emph{canonical natural transformation} refers to.<br>For left adjoints, it refers to the transpose of <br>$$u^{\#} \overset{u^*(\eta)}{\longrightarrow} u^{\#}H_J K_J \overset{\cong}{\longrightarrow} H_I u^* K_J $$<br>For right adjoints, it refers to the transpose of...<br>$$H_I u^* K_J \overset{\cong}{\longrightarrow} u^{\#} H_J K_J \overset{u^{\#}(\epsilon_J)}{\longrightarrow} u^{\#}$$<br><br>true. pg 10065, lemma 1.8.9<br></latex>
<latex>~\\<br>What is a \emph{Beck-Chevally condition}?<br></latex>	<latex>~\\<br>An important part of this question is knowing what \emph{canonical natural transformation} refers to.<br>For left adjoints, it refers to the transpose of <br>$$u^{\#} \overset{u^*(\eta)}{\longrightarrow} u^{\#}H_J K_J \overset{\cong}{\longrightarrow} H_I u^* K_J $$<br>For right adjoints, it refers to the transpose of...<br>$$H_I u^* K_J \overset{\cong}{\longrightarrow} u^{\#} H_J K_J \overset{u^{\#}(\epsilon_J)}{\longrightarrow} u^{\#}$$<br><br>pg 10065<br></latex>
<latex>~\\<br>Let $\ddisp{\mathbb E}{p}{\mathbb B} \overset{H}{\longrightarrow} \ddisp{\mathbb D}{q}{\mathbb B}$ be a split functor between split fibrations. Consider the following statement:\\~\\<br>$H$ has a split fibred left (resp. right) adjoint if and only if one has <br>\begin{itemize}<br>\item For each object $I \in \mathbb B$ the functor $H_{I} : \mathbb E_I \to \mathbb D_I$ restricted to the fibres over I has a left (resp. right) adjoint $K_I$.<br>\item The \emph{Beck-Chevalley condition} holds, i.e. for every map $u : I \to J$ in $\mathbb B$ and for every pair of reindexing functors.<br>\begin{mathpar}<br>\mathbb E_J \overset{u^*}{\longrightarrow} \mathbb E_I \and \mathbb D_J \overset{u^\#}{\longrightarrow} \mathbb D_I<br>\end{mathpar}<br>The canonical natural transformation<br>\begin{mathpar}<br>K_Iu^\# \Longrightarrow u^*K_J \and (resp.~u^*K_J \Longrightarrow K_Iu^\#)<br>\end{mathpar}<br>is the identity.<br>\end{itemize}~\\<br>Prove or disprove<br></latex>	<latex>~\\<br>An important part of this question is knowing what \emph{canonical natural transformation} refers to.<br>For left adjoints, it refers to the transpose of <br>$$u^{\#} \overset{u^*(\eta)}{\longrightarrow} u^{\#}H_J K_J \overset{\cong}{\longrightarrow} H_I u^* K_J $$<br>For right adjoints, it refers to the transpose of...<br>$$H_I u^* K_J \overset{\cong}{\longrightarrow} u^{\#} H_J K_J \overset{u^{\#}(\epsilon_J)}{\longrightarrow} u^{\#}$$<br>\\~\\<br>pg 10067, lemma 1.8.10<br>todo: add impostor?<br></latex>
Read the introduction to Exercise 1.8.7 on pg 10070<br>Then read section 1.8.11, pgs 10067/10068, which demonstrates a specific instance of a pseudo-map of adjunctions.<br><br>	<br>
<latex>~\\<br>Let $\ddisp{\mathbb E}{p}{\mathbb B} \overset{H}{\to} \ddisp{\mathbb D}{q}{\mathbb B}$ be a split functor between split fibrations $p$ and $q$. Consider the following statement:\\~\\<br><br>If $H$ has a split fibred left/right adjoin then <br>\begin{itemize}<br>\item For each object $I \in \mathbb B$ the functor $H_I : \mathbb E_I \to \mathbb D_I$ restricted to the fibres over $I$ has a left (resp. right) adjoint $K(I)$.<br>\item For every map $u : I \to J$ in $\mathbb B$, the pair of reindexing functors $u^* : \mathbb E_J \to \mathbb E_I$, $u^{\#} : \mathbb D_J \to \mathbb D_I$ induced by the splitting, forms a map of adjunctions in~\\<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb E_J \ar[rr,"u^*"] \ar[dd, "H_J" left, bend right = 20] & & \ar[dd,"H_I" left, bend right = 20] \mathbb E_I \\<br> & & \\<br>\mathbb D_J \ar[rr,"u^\#"] \ar[uu, "K(J)" right, bend right = 20] & & \ar[uu, "K(I)" right, bend right = 20] \mathbb D_I<br>\end{tikzcd}<br>\end{center}<br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 10068/10069, lemma 1.8.12<br>
<latex>~\\<br>Let $\ddisp{\mathbb E}{p}{\mathbb B} \overset{H}{\to} \ddisp{\mathbb D}{q}{\mathbb B}$ be a split functor between split fibrations $p$ and $q$. Consider the following statement:\\~\\<br>If<br>\begin{itemize}<br>\item For each object $I \in \mathbb B$ the functor $H_I : \mathbb E_I \to \mathbb D_I$ restricted to the fibres over $I$ has a left (resp. right) adjoint $K(I)$.<br>\item For every map $u : I \to J$ in $\mathbb B$, the pair of reindexing functors $u^* : \mathbb E_J \to \mathbb E_I$, $u^{\#} : \mathbb D_J \to \mathbb D_I$ induced by the splitting, forms a map of adjunctions in~\\<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb E_J \ar[rr,"u^*"] \ar[dd, "H_J" left, bend right = 20] & & \ar[dd,"H_I" left, bend right = 20] \mathbb E_I \\<br> & & \\<br>\mathbb D_J \ar[rr,"u^\#"] \ar[uu, "K(J)" right, bend right = 20] & & \ar[uu, "K(I)" right, bend right = 20] \mathbb D_I<br>\end{tikzcd}<br>\end{center}<br>\end{itemize}<br>then $H$ has a split fibred left/right adjoint.\\~\\ <br>Prove or disprove.<br><br></latex>	pg 10068/10069, lemma 1.8.12<br>
What is a <i>cell</i> of dimension d? What is a <i>cell complex</i>?	pg 14522<br>
Give Euler's Polyhedron formula. Read section 3.1, pg 14522, 14523, 14524<br>	<br>
What is a <i>platonic solid</i>?	pg 14523<br>
<latex>~\\<br>Given a set $S$ and a family $\mathcal A$ of finite subsets of $S$, what does it mean for $\mathcal A$ to be an \emph{abstract simplical complex} on $S$?<br></latex>	pg 14524, def 3.2.1<br>
<latex>~\\<br>In combinatorial topology lingo, what is the formal definition of \emph{vertex}? What is the formal definition of \emph{simplex}?<br></latex>	pg 14524<br>
<latex>~\\<br>If $\mathcal A$ is an abstract simplical complex, then what does $V(\mathcal A)$ denote?<br></latex>	pg 14524<br>
<latex>~\\<br>What does it mean for a simplex to have dimension $n$?<br></latex>	pg 14524, below def 3.2.1<br>
<latex>~\\<br>What does it mean for a simplex $\tau$ to be a face of $\sigma$? What does it mean for $\tau$ to be a \emph{proper face} of $\sigma$? What does it mean for $\tau$ to be a $k$-face of $\sigma$?<br></latex>	pg 14524, below def 3.2.1<br><br>
<latex>~\\<br>Let $\sigma$ be an $n$-simplex. What does $Face_i \sigma$ denote?<br></latex>	pg 14524, at bottom<br><br>
<latex>~\\<br>What does it mean for a simplex $\sigma$ in a complex $\mathcal A$ to be a \emph{facet}?<br>What is the \emph{dimension} of a complex?<br></latex>	pg 14525, near top<br>
<latex>~\\<br>What does it mean for a complex to be \emph{pure}? <br></latex>	pg 14525, near top<br>
<latex>~\\<br>What does it mean for a complex $\mathcal B$ to be a \emph{subcomplex} of $\mathcal A$?<br></latex>	pg 14525, near top<br>
<latex>~\\<br>Let $\mathcal A$ be a pure complex. What is the \emph{codimension} $codim(\sigma,\mathcal A)$ of<br>$\sigma \in \mathcal A$?<br></latex>	pg 14525, near top<br>
<latex>~\\<br>Let $\mathcal C$ be an abstract simplical complex and $\ell$ a nonnegative integer. What does $skel^{\ell}(\mathcal C)$ denote? Consider the following statement:\\~\\<br>$skel^{\ell}(\mathcal C)$ is a subcomplex of $\mathcal C$\\~\\<br>Prove or disprove.<br></latex>	pg 14525, second paragraph<br>
<latex>~\\<br>Let $\sigma$ be an $n$-dimensional simplex. What does $2^{\sigma}$ denote? What does $\partial 2^\sigma$ denote?<br></latex>	pg 14525, third paragraph<br>
<latex>~\\<br>Let $\sigma$ be a simplex. What is the \emph{boundary complex} of $\sigma$?<br></latex>	pg 14525, bottom of third paragraph<br><br>
<latex>~\\<br>Given two complexes $\mathcal A$ and $\mathcal B$, what is a \emph{vertex map} $\mu : V(\mathcal A) \to V(\mathcal B)$?<br></latex>	pg 14525, fourth paragraph<br>
<latex>~\\<br>For two simplical complexes $\mathcal A$ and $\mathcal B$, what does it mean for a vertex map $\mu : V(\mathcal A) \to V(\mathcal B)$ to be a \emph{simplical map}?<br></latex>	pg 14525, def 3.2.2<br>
<latex>~\\<br>What does it mean for two simplical complexes $\mathcal A$ and $\mathcal B$ to be \emph{isomorphic}?<br></latex>	pg 14525, def 3.2.3<br><br>
<latex>~\\<br>Given two abstract simplical complexes $\mathcal A$ and $\mathcal B$, what does it mean for a simplical map $\varphi : \mathcal A \to \mathcal B$ to be \emph{rigid}?<br></latex>	pg 14525<br>
Provide the definition of <i>monoidal category</i>.<br>	pg 17226. Note that he neglected to define the tensor product. It is just a binary operator on objects with associativity isos.<br>
In a monoidal category, what is an "element" k of type C? How do we draw elements in string diagrams?	pg 17227, top<br>
<latex>~\\<br>If $\mathcal C$ is a monoidal category and $A$ is a datatype, what does $\mathcal C(A)$ denote?<br></latex>	pg 17227, "Elements" at top<br><br>
<latex>~\\<br>What is a \emph{scalar} of a monoidal category $\mathcal C$?<br></latex>	pg 17227, "Scalars"<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The category $\mbf{Vec}$ of vector spaces and linear operators over a ground field $I$ form a monoidal <br>category.<br>\\~\\<br>Prove or disprove.<br></latex>	true. pg 17227, Examples<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The category $\mbf{Sets}$ is a monoidal category.\\~\\<br>Prove or disprove.<br></latex>	pg 17227, Examples<br><br>
<latex>~\\<br>Define the monoidal category $\mbf{Sets}(1)$. How many scalars does it have?<br></latex>	pg 17227, "Examples"<br>it has one scalar, a function from a singleton set to itself.<br><br>
<latex>~\\<br>The categories $\mbf{Sets}_{fin}$ is equivalent with its \emph{skeletal} subcategory, spanned by the natural numbers, viewed as finite sets. Explain why this is so. Why is this a useful fact?<br></latex>	This is explained by Awodey on pg 2827, example 7.24<br>its usefulness is explained on pg 17227, paragraph above "assumptions"<br>
Pavlovic assumes all monoidal structure to be strict. Why is it okay to do this?	pg 17227, paragraph above assumptions.<br>see 17228 for a precise definition of strictness<br>
Pavlovic assumes all monoidal structure to be <i>symmetric</i>. What is meant by this?	pg 17228<br>
What do intersections in string diagrams represent?<br>	tensor symmetries. see pg 17228 near bottom, also figure 4 on the same page.<br>
<latex>~\\<br>What is a semigroup? What is a monoid? What is a comonoid? Draw diagrams to explain.<br></latex>	pg 17229<br>
What does it mean for a semigroup or a comonoid to be <i>commutative</i>?	pg 17230, top diagram<br>
<latex>~\\<br>At the very bottom of page 10065, Jacobs gives an isomorphism implying that $u^{\#}H_J \cong H_I u^*$.<br>How does one derive this isomorphism?<br></latex>	pg 10065. hint: it has to do with Cartesianness.<br><br>It's explained near the beginning of the proof on pg 10066 (using K instead of H): see the<br>diagram labelled (*).<br><br><br><br>
<latex>~\\<br>What is the difference between the ordinary version og the Beck-Chevalley condition and the ``split Beck-Chevally condition''?<br></latex>	pg 10067, lemma 1.8.10<br>
Read "Excurs on the Beck-Chevalley Condition" pg 10067. Explain the part around "it arises as transpose of the pair...". Explain concretely why this is an instance of the <i>canonical map</i> of the Beck-Chevalley condition.	<latex>~\\<br>Note that applying $-\times-$ to $(g_1,g_2)$ yields $g_1 \times g_2$: that is \textbf{not} the transpose of $(g_1,g_2)$. Rather, it is the precomposition of $(g_1, g_2)$ with the unit $\langle id, id \rangle$ of the adjunction $\Delta \dashv - \times -$.<br>\\~\\<br>How is this an instance of the Beck-Chevalley condition? Note that it is the dual perspective from what is explained in the book. The canonical map arises as the transpose of the composite<br>$H_I u^* K_J \overset{\cong}{\longrightarrow} u^{\#} H_J K_J \overset{u^{\#}(\epsilon_J)}{\longrightarrow} u^{\#}$.<br></latex>
Give a brief description of how the geometric view of complexes differs from the combinatorial view.<br>	In the geometric view, we<br>embed a complex in R^d and forget about how the complex is partitioned into simplices, considering<br>only the underlying space occupied by the complex.<br><br>pg 14525, section 3.2.2<br>
<latex>~\\<br>What does Herlihy use the notation [m : n] where $n \geq m$ for? What about [m]?<br></latex>	pg 14525<br>
<latex>~\\<br>What does it mean for a point $y$ in $\mathbb R^d$ to be an \emph{affine combination} of a finite set of points $X = \{ x_0, \ldots, x_n \}$?<br></latex>	pg 14525 bottom / 14526 top<br>
What are <i>barycentric coordinates</i>?<br>	pg 14526 top<br>
What is a <i>convex combination</i>?	pg 14526, near top<br><br>
<latex>~\\<br>Let $X = \{ x_0, \ldots, x_n \}$ be a finite set of points. What does $conv~X$ denote?<br></latex>	pg 14526, "The convex hull of X...."<br>
What does it mean for a finite set of points X to be <i>affinely independent</i>?	pg 14526
<latex>~\\<br>Define the \emph{standard n-simplex} $\Delta^n$.<br></latex>	pg 14526<br>
What is a <i>geometric n-simplex</i>?<br>	pg 14526
<latex>~\\<br>When do we call $v_0, \ldots, v_n$ \emph{vertices}?<br></latex>	pg 14526, above def 3.2.5<br>
<latex>~\\<br>Let $v_0, \ldots, v_n \in \mathbb R^d$ be affinely independent, and let $\sigma = conv~\{ v_0, \ldots v_n \}$. What is a \emph{face} of $\sigma$? What does $Face_i \sigma$ denote?<br></latex>	pg 14526, right above def 3.2.5<br>
<latex><br>What is a \emph{geometric simplical complex} $\mathcal K$ in $\mathbb R^d$?<br></latex>	pg 14526, def 3.2.5<br>
<latex>~\\<br>Let $\sigma = conv(v_0, \ldots, v_n)$ be a geometric $n$-simplex. What is the \emph{characteristic map} of $\sigma$?.<br></latex>	pg 14526, below def 3.2.5<br><br>
<latex>~\\<br>Given a geometric simplical complex $\mathcal K$, how do we define the underlying abstract simplical complex $\mathcal C(\mathcal K)$?<br></latex>	pg 14526, bottom paragraph.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Give an abstract simplicial complex $\mathcal A$, there is a unique geometric simplicial complex $\mathcal K$ with $\mathcal C(\mathcal K) = \mathcal A$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. <br>pg 14526, at bottom<br><br>
<latex>~\\<br>There is a standard way in which a simplicial map $\mu : \mathcal C(\mathcal K) \to \mathcal C(\mathcal J)$ induces a locally affine map between the associated geometric complexes $\mathcal K$ and $\mathcal J$. What is it?<br></latex><br>	pg 14527, near top.<br>
<latex>~\\<br>Let $\mathcal K$ be a geometric simplical complex in $\mathbb R^d$. Then $| \mathcal K |$, the \emph{geometric realization} of $\mathcal K$ denotes a topological space. How is this topological space defined, i.e., what are its carrier set and topology?<br></latex><br>	pg 14527, sec 3.2.3 top<br>
<latex>~\\<br>One might expect the meaning of a variable, when applied to an appropriate environment, to be a reference. Why is this view too simplistic to accommodate arrays in Algol? What is the solution to this dillemma?<br></latex>	pg 9090, right column "One might expect..." down to "The choice between..."<br>
Provide an intuitive, implementation-independent definition of <i>block structure</i>.<br>	"After execution of a command, the values of all variables and arrays declared within the command have no further effect on the program"<br><br>pg 9091, left column<br><br>
Why are Scott-Strachey semantics ill suitied for reasoning about stack discipline (aka block structure)?	pg 9091, left column, "Suppose C is a command..." down to "In contrast..."
<latex>~\\<br>In what particular way is Algol's intrinsic semantics organized that makes the stack discipline (aka block structure) obvious?<br></latex>	pg 9091 left, "In contrast ...."<br>down to<br>pg 9091 right "Before going further"<br>
<latex>~\\<br>How are references represented in Algol's denotational semantics? <br></latex>	pg 9091 "Before going further..."<br><br>
<latex>~\\<br>What can be said about the domains of states in Algol's denotational semantics?<br></latex>	They consist of a contiguous set of natural numbers (we use those to represent references) including 0.<br>For example: {0, 1, 2, 3}<br><br>pg 9091, "Before going further..."<br>
<latex>~\\<br>In Algol's denotational semantics, what is a \emph{state shape}? What is $\mbf{Shp}$?<br> </latex>	pg 9091, right column, "For this reason..."<br>
<latex>~\\<br>Let $\alpha$ be a state shape. What does Reynolds denote with the notation $\Pi \alpha$? <br></latex>	pg 9091, right column, "For this reason..."<br>pg 9103, top left (depends on pg 9102 bottom left)<br><br>
<latex>~\\<br>How does the basic framework of the intrinsic semantics presented by Algol differ from the framework Reynolds defines in his initial presentation of intrinsic semantics in an earlier chapter?<br></latex>	pg 9091, bottom right,<br>pg 9092, top left<br><br><br>
Give the following conversion equations for Algol's denotational semantics:<br>CONV EQ: Reflexivity<br>CONV EQ: Transitivity<br>TY SEM EQ: Subsumption<br>TY SEM EQ: Identifiers<br><br>	pg 9092, bottom left<br>
<latex>~\\<br>In update-evaluate semantics, give the semantics for subsumption from variables to expressions \sem{\delta \mbf{var} \leq \delta \mbf{exp}}.<br></latex>	pg 9093, near top of sec 19.6<br><br>
<latex>~\\<br>For update-evaluate semantics, give the semantics for assignment \sem{\pi \vdash \mbf{p_0} := \mbf{p_1} : \mbf{comm}}.<br></latex>	pg 9093, near top of sec 19.6<br><br>
<latex>~\\<br>Define the semantics for Algol variables declaration $\sem{\pi \vdash \mbf{new}~\delta\mbf{var}~\iota := p_0~\mbf{in}~p_1 : \mbf{comm}}\alpha \eta \sigma$.<br></latex>	pg 9093, left, "Now consider the variable declaration..."<br>down to<br>pg 9094, section 19.7<br><br>If the update-evaluate semantics looks strange (because it only applies to the last component of the state), handling variables in the global part of the state will be explained in the right column pg 9093, as part of the T metafunction.<br>
<latex>~\\<br>For an Algol style language, we might expect that the set $\mathcal D(\theta \to \theta') \alpha$ of meanings of procedures of type $\theta \to \theta'$ to be $\mathcal D(\theta)\alpha \to \mathcal D(\theta')\alpha$. Why is this not the case?<br></latex>	pg 9094, left column, section 19.7<br>
<latex>~\\<br>Give Algol's typing judgment semantics for lambda abstractions.<br></latex>	<latex>~\\<br>pg 90945, near top, right column, ``$\to$ Introduction''<br></latex>
<latex>~\\<br>Give Algol's typing judgment semantics for procedure application $\sem{\pi \vdash p_0~p_1 : \theta'}$.<br></latex>	<latex>~\\<br>pg 9094, right column, "Elimination"<br></latex>
<latex>~\\<br>Explain the meaning of the family of phrase types $\delta\mbf{acc}$.<br></latex><br>	pg 9095, right column, section 19.8<br>
What are acceptors and why are they useful?	They are useful for sharpening procedure specifications with "write-only arguments"<br>pg 9095, right column, section 19.8<br>pg 9096, left column
<latex>~\\<br>What does Oles use $Mng~\tau$ to denote?<br></latex>	<latex>~\\<br>It's an alternative to $\sem{\tau}$. $\tau$ is a metavariable used for phrase types, i.e. an alternative to $\theta$.<br></latex>
<latex>~\\<br>Oles makes use of implicit casts from sets to predomains. How do these casts work?<br></latex>	<latex>~\\<br>The set is endowed with a discrete order.<br>pg 17354<br></latex>
<latex>~\\<br>Let $S$ be the set of all possible stores. Implicitly cast $S$ to a discretely ordered predomain. Why is the object $S \Rightarrow S_{\bot}$ in the category $PDom$ not adequate for the meaning of commands in Algol style languages?<br></latex>	It doesn't capture block structure. i.e. the idea that the value of the locally declared variables of a command do not affect later commands.<br><br>pg 17354, bottom half.<br>also see pg 9091, top left<br><br><br>
<latex>~\\<br>Let $\Sigma$ be the collection of all store shapes. Let $X \in \Sigma$. What does $St~X$ denote?<br></latex>	pg 17355<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In Oles' semantics for Algol, $Mng~\tau$ (i.e. $\sem{\tau}$) is a predomain.\\~\\<br>True or false?<br></latex>	IMPOSTOR. It is a store-shape-indexed family of predomains.<br>pg 17355<br>Even more precisely, it should be a functor from the category of store shapes to the category of predomains.<br>pg 17356 top<br><br>
Read the entirety of pg 17355<br>	<br>
Why should the store shapes of an Algol semantics be a category rather than a mere collection?	pg 17355, bottom paragraph<br>
<latex>~\\<br>What does Oles mean when he uses the term \emph{expansion}?<br></latex>	<latex>~\\<br>An arrow in the category of store shapes.<br>pg 17356, near top<br></latex>
<latex>~\\<br>How does Oles define $\sem{\tau \Rightarrow \theta}$ for arbitrary phrase types $\tau$ and $\theta$?<br></latex>	<latex>~\\<br>$Mng~(\tau \Rightarrow \theta) \doteq (Mng~\tau) \Rightarrow (Mng~\theta)$, where <br>the $\Rightarrow$ on the right is exponentiation in the functor category $[\Sigma, PDom]$.<br>On the left $\Rightarrow$ is just a procedure type.<br>pg 17356<br></latex>
<latex>~\\<br>Why does Oles interpret types as objects of the category $[\Sigma, \mbf{PDom}]$ rather than $[\Sigma,\mbf{Dom}]$?<br></latex>	the latter is not Cartesian closed.<br>pg 17356.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In Oles' semantics, typing contexts are interpreted as predomains.\\~\\<br>True or false?<br></latex>	IMPOSTOR! They are interpreted as functors from the category of state shapes to the category of predomains.<br>pg 17357<br>
Read pg 17357, from the top down to "Our final topic..."<br>	<br>
<latex>~\\<br>Let $\mathcal A$ be an abstract simplicial complex. Then $| \mathcal A |$ denotes a topology. How is this topology defined?<br></latex>	pg 14527, sec 3.2.3<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A vertex map $\mu : V(\mathcal A) \to V(\mathcal B)$ induces a continuous map between the geometric realizations $|\mathcal A|$ and $| \mathcal B |$.\\~\\<br>Prove or disprove.<br></latex>	pg 14527, sec 3.2.3 second paragraph<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A simplicial map $\mu : V(\mathcal A) \to V(\mathcal B)$ induces a continuous map between the geometric realizations $|\mathcal A|$ and $| \mathcal B |$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 14527, equation 3.2.2<br>
Helihy overloads his use of the term "simplex" with two distinct but related meanings: explain.<br>	pg 14527, last paragraph of section 3.2.3<br><br>
<latex>~\\<br>Let $\mathcal C$ be an abstract simplicial complex and $\sigma$ be a simplex of $\mathcal C$. What does $St(\sigma, \mathcal C)$ denote? <br></latex>	pg 14528, section 3.3.1<br>
<latex>~\\<br>Let $\mathcal C$ be an abstract simplicial complex and $\sigma$ be a simplex of $\mathcal C$. What does $St^{\circ}(\sigma, \mathcal C)$ denote? <br></latex>	pg 14528, section 3.3.1<br>
<latex>~\\<br>How does Oles define the arrow $hom^{\Sigma} : \Sigma^{op} \to (\Sigma \Rightarrow Pdom)$?<br></latex>	pg 172357 "Our final topic..."<br>
<latex>~\\<br>Consider the folowing statement:\\~\\<br>$St^{\circ}(\sigma) = \bigcap_{v \in V(\sigma)} St^{\circ}(v)$\\~\\<br>Prove or disprove.<br></latex>	pg 14528. It's stated, and seems pretty straightforward to prove.<br>
<latex>~\\<br>Let $\mathcal C$ be an abstract simplicial complex, and let $\sigma$ be a simplex of $\mathcal C$. What does $Lk(\sigma,\mathcal C)$ denote?<br></latex>	pg 14528, sec 3.3.2<br><br>
<latex>~\\<br>Given two abstract simplicial complexes $\mathcal A$ and $\mathcal B$ with distinct sets of vertices, what does $\mathcal A \ast \mathcal B$ denote?<br></latex>	pg 14528, "Join" near bottom<br><br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be abstract simplicial complexes with disjoint sets of vertices.Let $\mathcal K$ be a geometric simplicial complex in $\mathbb R^m$ such that $\mathcal C(\mathcal K) = \mathcal A$, and $\mathcal L$ is a geometric simplicial complex in $R^n$, such that $\mathcal C(\mathcal L) = \mathcal B$. Then there is a standard way to construct a geometric simplicial complex in $\mathbb R^{m+n+1}$ whose underlying abstract simplicial complex is $\mathcal A \ast \mathcal B$. Explain.<br></latex>	pg 14529 / 14530<br><br>
<latex>~\\<br>Given two abstract simplicial complexes $\mathcal A$ and $\mathcal B$, what is a \emph{carrier map} from $\mathcal A$ to $\mathcal B$?<br></latex>	pg 14530. Note that *Carrier maps are not vertex maps*.<br>Vertex maps take vertices to vertices, but a carrier map takes a vertex (or any other form of simplex) to a set of sets of vertices S such that (A,S) is a simplicial complex.<br><br>
<latex>~\\<br>Let $\Phi : \mathcal A \to \mathcal B$ be a carrier map. Let $\mathcal K$ be a subcomplex of $\mathcal A$. What does $\Phi(\mathcal K)$ mean?<br></latex>	pg 14530, below equation 3.4.1<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any carrier map $\Phi$, we have $\Phi(\sigma \cap \tau) \subseteq \Phi(\sigma) \cap \Phi(\tau)$.\\~\\<br>Prove or disprove.<br></latex>	pg 14530, this is a straightforward consequence of monotonicity<br>
<latex>~\\<br>Assume that we are given two abstract simplicial complexes $\mathcal A$ and $\mathcal B$ and a carrier map $\Phi : \mathcal A \to 2^{\mathcal B}$. What does it mean for the carrier map $\Phi$ to be \emph{rigid}?<br></latex><br>	pg 14530, def 3.4.2 (1), near bottom<br><br>the definitions of "dimension" and "pure" are at the top of pg 14525<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be simplicial complexes and $\Phi : A \to 2^{\mathcal B}$ a carrier map. What does it mean for $\Phi$ to be \emph{strict}?<br></latex>	pg 14530, def 3.4.2 (2), near bottom<br><br><br>
<latex>~\\<br>Let $\Phi : \mathcal A \to 2^{\mathcal B}$ be a strict carrier map. Let $\tau \in \Phi(\mathcal A)$. <br>What does $Car(\tau, \Phi(\sigma))$ denote?<br></latex>	pg 14531, near top<br><br>
<latex>~\\<br>Let $\Phi : \mathcal A \to 2^{\mathcal B}$ and $\Psi : \mathcal A \to 2^{\mathcal B}$, where $\mathcal A$, $\mathcal B$, are simplicial complexes.<br>What does it mean for $\Phi$ to be \emph{carried} by $\Psi$?<br></latex>	pg 14531, definition 3.4.3<br>
<latex>~\\<br>Let $\Phi : \mathcal A \to 2^{\mathcal B}$ be a carrier map, where $\mathcal A$ and $\mathcal B$ are simplicial complexes. Let $\varphi : \mathcal A \to \mathcal B$ be a simplicial map. What does it mean for $\varphi$ to be \emph{carried by} $\Phi$?<br></latex>	pg 14531, def 3.4.3 (2)<br><br>
<latex>~\\<br>Let $\mathcal A$, $\mathcal B$, and $\mathcal C$ be simplicial complexes and $\Phi$ a carrier map from $\mathcal A$ to $\mathcal B$. Let $\varphi : \mathcal C \to \mathcal A$ be a simplicial map. How is $\Phi \circ \varphi$ defined?<br></latex>	pg 14531, def 3.4.4 (1)<br>
<latex>~\\<br>Let $\mathcal A$, $\mathcal B$, and $\mathcal C$ be simplicial complexes and $\Phi$ a carrier map from $\mathcal A$ to $\mathcal B$. Let $\varphi : \mathcal B \to \mathcal C$ be a simplicial map. How is $\varphi \circ \Phi$ defined?<br></latex>	pg 14531, def 3.4.4 (2)<br>
<latex>~\\<br>Given two carrier maps $\Phi : \mathcal A \to 2^{\mathcal B}$ and $\Psi : \mathcal B \to 2^{\mathcal C}$, where $\mathcal A$, $\mathcal B$, and $\mathcal C$ are simplicial complexes, how is the carrier map $\Psi \circ \Phi$ defined? <br></latex>	pg 14532, def 3.4.5<br>
<latex>~\\<br>Let $\Phi : \mathcal A \to 2^{\mathcal C}$ and $\Psi : \mathcal B \to 2^{\mathcal C}$ be carrier maps, and $\mathcal A$, $\mathcal B$, and $\mathcal C$ simplicial complexes. Consider the following statement:\\~\\<br>If the carrier maps $\Phi$ and $\Psi$ are rigid, then so is their composition $\Psi \circ \Phi$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 14532, prop 3.4.6 (1)<br>Q: do the rigid carrier maps constitute a category?<br>
<latex>~\\<br>Let $\Phi : \mathcal A \to 2^{\mathcal B}$ and $\Psi : \mathcal B \to 2^{\mathcal C}$ be carrier maps, and $\mathcal A$, $\mathcal B$, and $\mathcal C$ simplicial complexes. Consider the following statement:\\~\\<br>If the carrier maps $\Phi$ and $\Psi$ are strict, then so is their composition $\Psi \circ \Phi$.\\~\\<br>Prove or disprove.<br></latex>	pg 14532, prop 3.4.6 (2)<br>Q: do the strict carrier maps (and simplicial complexes) constitute a category?<br>
<latex><br>Let $\mathcal A$ and $\mathcal B$ be geometric complexes. What does it mean for a continuous map $f : |\mathcal A| \to |\mathcal B|$ to be \emph{carried} by a carrier map $\Phi : \mathcal A \to 2^{\mathcal B}$.<br></latex><br>	pg 14532, right above section 3.4.1<br><br>
<latex>~\\<br>What is an \emph{m-labeling}, or simply \emph{labeling}, of a complex $\mathcal A$?<br></latex>	pg 14532, near bottom<br><br>
<latex>~\\<br>What is an \emph{m-coloring}, or simply \emph{coloring}, of an n-dimensional complex $\mathcal A$?<br></latex>	pg 14532, bottom<br>
<latex>~\\<br>What is a \emph{chromatic complex}?<br></latex>	pg 14532<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A coloring $\chi : \mathcal A \to \Delta^{m-1}$ exists if and only if the $1$-skeleton of $\mathcal A$, viewed as a graph, is $m$-colorable in the sense of graph colorings (more precisely, vertex-colorings of graphs).\\~\\<br>Prove or disprove.<br></latex>	pg 14533, mathematical note at top.<br><br>
<latex>~\\<br>Assume we are given chromatic simplicial complexes $\mathcal A$ and $\mathcal B$ and a carrier map $\Phi : \mathcal A \to 2^{\mathcal B}$. What does it mean for $\Phi$ to be \emph{chromatic}?<br></latex>	pg 14533, def 3.4.9<br><br>
<latex>~\\<br>Assume we are given chromatic simplicial complexes $\mathcal A$ and $\mathcal B$ and a carrier map $\Phi : \mathcal A \to 2^{\mathcal B}$. What does it mean for $\Phi$ to be \emph{name preserving}?<br></latex>	it is a synonym for chromatic<br>pg 14533, def 3.4.9, near top<br>
<latex>~\\<br>Let $\mathcal K$ be an arbitrary simplicial complex. What is an \emph{edge path} (or simply \emph{path}) between vertices $u$ and $v$ in $\mathcal K$? What does it mean for a path to be \emph{simple}?<br></latex>	pg 14533, def 3.5.1<br><br>
<latex>~\\<br>What does it mean for a simplicial complex $\mathcal K$ to be \emph{path-connected}? What is a \emph{path-connected component} of $\mathcal K$?<br></latex>	pg 14533, def 3.5.2<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The path connectivity of $\mathcal K$ depends only on the 1-skeleton of $\mathcal K$, $skel^1(\mathcal K)$ \\~\\<br>True or false?<br><br></latex>	true. pg 14533, below def 3.5.2<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>An image of a path-connected complex under a simplicial map is again path-connected. In particular, if $A$ and $B$ are simplicial complexes, $\varphi: A \to B$ is a simplicial map, and $A$ is path-connected, then $\varphi(A)$ is contained in one of the connected components of $B$.\\~\\<br>Prove or disprove.<br></latex>	pg 14533, prop 3.5.3: the explanation is above
<latex>~\\<br>Provide the definitions of:\\<br>- 1-dimensional disk\\<br>- 0-dimensional sphere\\<br>- 2-dimensional disk\\<br>- 1-dimensional sphere\\<br>- 2-dimensional sphere\\<br>- 3-dimensional ball<br></latex>	pg 14533 bottom / pg 14534 top<br><br>
<latex>~\\<br>Complete the sentence:\\~\\<br>An n-sphere $S^n$ is the boundary of a \underline{~~~~~~~~~~~~~~}.<br></latex>	pg 14534, near top<br>
<latex>~\\<br>Let $\mathcal K$ be a simplicial complex and let $|\mathcal K|$ denote its polyhedron. In what way can a path in $|\mathcal K|$ be defined as a continuous map?<br></latex>	pg 14534, second paragraph.<br>
<latex>~\\<br>Let $\mathcal K$ be a simplicial complex and let $|\mathcal K|$ denote its polyhedron. What does it mean for $|\mathcal K|$ to be \emph{path connected}?<br></latex>	<latex>~\\<br>pg 14534, above second paragraph\\<br>I believe that its mention of the edge-path-connectivity of $\mathcal K$ is a reference to the notion of \emph{path connectivity} defined on the previous page, in definition 3.5.2<br></latex>
What does it mean for a path-connected complex to be <i>0-connected</i>? Justify this terminology.	pg 14534, paragraph above mathematical note 3.5.4<br>
<latex>~\\<br>Let $\mathcal K$ be an arbitrary path-connected simplicial complex. What does it mean for the complex $\mathcal K$ to be \emph{1-connected}?<br></latex>	pg 14534, def 3.5.5<br>
Look at the complex in the right part of figure 3.10 on pg 14541. Is it 0-connected? Is it 1-connected?<br>	pg 14534, below definition 3.5.5<br>
<latex>~\\<br>Let $k$ be any positive integer. What does it mean for a complex $\mathcal K$ to be \emph{k-connected}?<br></latex>	pg 14534,def 3.5.6<br><br>
<latex>~\\<br>What does it mean for a complex $\mathcal K$ to be \emph{contractible}?<br></latex>	pg 14535. Definition 3.5.8. See also helpful text below.
<latex>~\\<br>What does it mean for a geometric complex $\mathcal B$ to be a subdivision of a geometric complex $\mathcal A$?<br></latex>	pg 14536. See also figure 3.7 on pg 14535.<br><br>
<latex>~\\<br>Given an $n$-simplex, $\sigma = \{ s_0, \ldots, s_n \}$, what does $stel(\sigma,b)$ denote?<br>What does $Stel~\sigma$ denote?<br></latex>	<latex>~\\<br>pg 14536, def 3.6.1 \\<br>I think that Stel $\sigma$ just means that the barycenter is used as the default value for $b$.<br></latex><br><br>
<latex>~\\<br>Given a geometric complex $\mathcal K$, how is the complex $Bary~\mathcal K$ defined?\\<br>(note: there is a different, purely combinatorial definition for abstract simplicial complexes)<br></latex>	pg 14537, section 3.6.2<br>for visualization, see pg 14536, fig 3.8<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The important questions of distributed computing are not only concerned with the communication and dissemination of knowledge, but also the computational power of individual processes.\\~\\<br>True or false?<br></latex>	IMPOSTOR. it is false. pg 14547<br>this is an interesting claim, and seems relevant to my research. I would be interested to see how it is justified.<br>
What is a <i>snapshot</i>? What is an <i>immediate snapshot</i>?	pg 14547, second-to-last paragraph<br><br>
Why use snapshots in our idealized model, rather than the more realistic approach of atomic single-word reads and writes?	pg 14548, top<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In models where processes execute asynchronously, failures are undetectable.\\~\\<br>True or false?<br></latex>	pg 14548<br>
In distributed computing, what is a <i>task</i>?	defined on pg 14493, above section 1.3<br>pg 14548 asserts that this definition is relevant to chpt 4<br>there is a connection to ameloot's relational transducers here. Both the input and output are distributed across nodes: why is it okay to have a distributed output? How do individual nodes access the output?
<latex>~\\<br>What does it mean for a task to be \emph{colorless}?<br></latex>	pg 14548, fifth paragraph from bottom.<br>example: ameloot's relational transducers perform colorless tasks.<br>
<latex>~\\<br>In distributed computing, what is a \emph{protocol}? What does it mean for a protocol to be \emph{wait-free}?<br></latex>	pg 14548, second-to-last paragraph<br>
What is a "full-information" protocol?<br>	pg 14548, near bottom<br>
<latex>~\\<br>What does the symbol $\Pi$ denote? What is a typical value for $\Pi$?<br></latex>	pg 14549, "Processes" first, two paragraphs.<br><br>
<latex>~\\<br>In Herlihy's operational model for colorless wait-free computation, what do $Q_{i}^{in}$ and $Q_{i}^{fin}$ denote?<br></latex>	pg 14549, "Processes", third paragraph<br>
<latex>~\\<br>In Herlihy's operational model of colorless wait-free computation, does each process "know" its name? Does it know the names of other processes? <br></latex>	pg 14549, "Processes" 4th paragraph
<latex>~\\<br>In Herlihy's operational model of colorless wait-free computation, where is a process's name ``stored''?<br></latex>	pg 14549, "Processes" 5th paragraph
<latex>~\\<br>In Herlihy's operational model for colorless wait-free computation, let $q$ be a process state. What does $view(q)$ denote?<br></latex>	pg 14549, "Processes", second-to-bottom paragraph
<latex>~\\<br>A state $q$ may be written as a pair $(P,v)$. What do $P$ and $v$ denote here?<br></latex>	pg 14549<br>
<latex>~\\<br>In Herlihy's operational model for colorless wait-free computation, what is a \emph{configuration} $C$?<br>What is an \emph{initial configuration} $C_0$? What is a \emph{final configuration}?<br>What do $names(C)$ and $active(C)$ denote?<br></latex>	pg 14549, "Configurations and executions"<br><br>
<latex>~\\<br>Sometimes a configuration includes an \emph{environment}. What is an \emph{environment}?<br></latex>	pg 14549, near bottom<br>
<latex>~\\<br>In Herlihy's operational model of colorless wait-free computation, what is an \emph{execution}? What is a \emph{schedule}? What is a \emph{partial execution}? A \emph{concurrent step}?<br></latex>	pg 14549 bottom / 14550<br><br>
<latex>~\\<br>In Herlihy's operational model of concurrent wait-free computation, what does it mean for a process to \emph{take a step}?<br></latex>	pg 14550, near top<br><br>
<latex>~\\<br>In Herlihy's model of colorless wait-free computation, how are process crashes modelled?<br></latex>	pg 14550, paragraph above "Colorless tasks"<br><br>
<latex>~\\<br>In Herlihy's definition of colorless tasks, what is an \emph{input assignment}? What is a \emph{colorless input assignment}?<br></latex>	pg 14550, "Colorless tasks", third paragraph.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Herlihy's notion of \emph{colorless input assignments} requires that every value in a colorless input assignment is assigned to a process.\\~\\<br>True or false.<br></latex>	FALSE. pg 14550, near bottom<br>
<latex>~\\<br>Provide the definition of \emph{colorless task}.<br></latex>	pg 14551, top, def 4.1.2<br><br>
<latex>~\\<br>Formulate \emph{binary consensus} as a \emph{colorless task}.<br></latex>	pg 14551, above section 4.1.5<br>
<latex>~\\<br>Herlihy considers protocols where computation is split into two parts: a task-independent \emph{full-information protocol} and a task-dependent \emph{decision}. Explain how this works.<br></latex>	pg 14551, section 4.1.5<br>
<latex>~\\<br>Give psuedo-code for the \emph{colorless layered immediate snapshot protocol}.<br></latex>	pg 14551 bottom / pg 14552 top<br>
<latex>~\\<br>What is a \emph{colorless layered execution}? <br></latex>	pg 14552, Near top<br><br>
<latex>~\\<br>What is a \emph{colorless configuration}, and what is the significance of this concept?<br></latex>	pg 14552, second and third paragraphs.<br>
Read the bottom two paragraphs of pg 14552, and compare them to Figures 4.2 and 4.3 on the subsequent pages.<br>	pg 14552
<latex>~\\<br>What does it mean for a final colorless configuration $\tau$ to be \emph{reachable} from a colorless initial configuration $\sigma$?<br></latex>	pg 14553, second paragraph
<latex>~\\<br>Given a set of colorless input assignments $\mathcal I$ for the psuedocode of Figure 4.1 on pg 14552,<br>we represent its behavior as a \emph{protocol-triple} $(\mathcal I, \mathcal P, \Xi)$. How are the components of this triple defined?<br></latex>	pg 14553<br>
<latex>~\\<br>In Herlihy's operational model for colorless wait-free computation, in what way are protocols and tasks linked?<br></latex>	pg 14553, bottom paragraph, spills onto pg 14554<br>
<latex>~\\<br>What does it mean for a process to \emph{choose} or \emph{decide} the output value $u$ with final view $v$?<br></latex>	pg 14553/14554<br>
<latex>~\\<br>What does it mean for a colorless protocol $(\mathcal I, \mathcal P, \Xi)$ with decision map $\delta$ to \emph{solve} a colorless task $(\mathcal I, \mathcal O, \Delta)$?<br></latex>	pg 14554/14555<br><br><br>
Read the top paragraph of pg 14555	pg 14555
<latex>~\\<br>Give the combinatorial definition of \emph{colorless task}. Explain how it relates to the operational definition of \emph{colorless task}.<br></latex><br>	pg 14555, section 4.2.1<br>
<latex>~\\<br>Simplicial complexes are closed under containment. What is the practical argument for the colorless input complex to be closed under containment? (i.e. how does it apply to real distributed systems)<br></latex>	pg 14555
<latex>~\\<br>From a practical perspective, why does it make sense for the carrier map $\Delta$ of a colorless task to be monotonic?<br></latex>	pg 14556, first full paragraph.<br>
<latex>~\\<br>Explain the colorless task \emph{binary consensus}. Explain the colorless task \emph{c-consensus}.<br></latex>	pg 14556, near bottom<br>pg 14557, near top<br><br>
<latex>~\\<br>Explain the colorless task called \emph{k-set agreement}.<br></latex>	pg 14557<br>
<latex>~\\<br>Provide the definition of the \emph{approximate agreement} colorless task.<br></latex>	pg 14558<br>
<latex>~\\<br>Let $\mathcal K$ be a pure geometric simplicial complex. Let $v$ be a vertex. What is the \emph{cone} over $\mathcal K$ with \emph{apex} v?<br></latex>	pg 14530, second paragraph near top<br>
<latex>~\\<br>Consider the following statement:~\\~\\<br>For any vertex $v$ of a pure complex $\mathcal K$ of dimension $d$, we have<br>$$St(v) = v \ast Lk(v)$$<br>Prove or disprove.<br></latex>	pg 14530, second paragraph near top.<br>TODO: add impostor?<br>
<latex>~\\<br>Given an abstract simplicial complex $\mathcal A$, how is the complex $Bary~\mathcal A$ defined?\\<br>(note: there is a different, geometrical definition for geometric simplicial complexes)<br></latex>	pg 14537, def 3.6.2<br>
<latex>~\\<br>Define the colorless task called \emph{Barycentric agreement}.<br></latex>	pg 14558<br>
<latex>~\\<br>Give the ``simplicial complex'' version of the definition of a \emph{colorless protocol}.<br></latex>	pg 14559, def 4.2.2<br>
<latex>~\\<br>Formulated in the language of simplicial complexes, what does it mean for a protocol $(\mathcal I, \mathcal P, \Xi)$ to \emph{solve} a task ($\mathcal I$, $\mathcal O$, $\Delta$)? Explain every aspect of this definition of \emph{solve}.<br></latex>	pg 14559, below def 4.4.2<br>pay attention to the reason that delta must be simplicial<br>
<latex>~\\<br>Assume we have two protocols $(\mathcal I, \mathcal P, \Xi)$ and $(\mathcal I', \mathcal P', \Xi')$, where $\mathcal P \subseteq \mathcal I'$. How do we define the \emph{composition} $(\mathcal I, \mathcal P'', \Xi'')$ of these two protocols?<br></latex>	pg 14559, def 4.2.3 near bottom<br>
<latex>~\\<br>What does it mean to ``compose a protocol with a task''? What about ``compose a task with a protocol''?<br></latex>	pg 14559, bottom paragraph<br>pg 14560, def 4.2.4, 4.2.5<br><br><br>
<latex>~\\<br>Assume that for any input complex $\mathcal I$ and $N > 0$, there is a protocol that solves the barycentric agreement task $(\mathcal I, Bary^N \mathcal I, Bary^N)$. Consider the following statement:\\~\\ <br>A task $(\mathcal I, \mathcal O, \Delta)$ has a protocol if and only if there exists a protocol $(\mathcal I, \mathcal P, \Xi)$ with a continuous map:<br>$$f : |\mathcal P| \to |\mathcal O|$$<br>such that $(f \circ \Xi)$ is carried by $\Delta$.\\~\\<br>Prove or disprove.<br></latex>	pg 14560, lemma 4.2.6,<br>proof spills onto pg 14561<br>
<latex>~\\<br>State the \emph{protocol complex lemma}, and explain its significance. (No need to prove: there's a different card for that.) <br></latex>	pg 14560, near bottom<br>
<latex>~\\<br>For the purposes of combinatorial topology for distributed computing, what is the major flaw in the concept of barycentric subdivision? What is the solution to this?<br></latex>	pg 14537, section 3.6.3, first paragraph<br>
<latex>~\\<br>Given a chromatic complex $(\mathcal K, \chi)$, how is $Ch~\mathcal K$ defined?<br></latex>	pg 14537, section 3.6.3, second paragraph<br>see visualization on pg 14536, figure 3.8 lower right corner<br>
<latex>~\\<br>Let $(\mathcal A, \chi)$ be a chromatic abstract simplicial complex. What is its \emph{standard chromatic subdivision} $Ch~\mathcal A$?<br></latex>	pg 14538, def 3.6.3<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be abstract simplicial complexes. What does it mean for $\mathcal B$ to \emph{subdivide} the complex $\mathcal A$?<br></latex>	pg 14538, def 3.6.4<br>
Read the paragraph above section 3.6.4 on pg 14538<br>	<br>
<latex>~\\<br>What do the notations $Car(\tau, \mathcal A)$ and $Car(\tau)$ mean?<br></latex>	pg 14538, paragraph above section 3.6.4<br>see figure 3.9 on pg 14539<br>
<latex>~\\<br>What is a \emph{boundary-consistent subdivision of simplices}? What is such a subdivision used for?<br></latex>	pg 14538, def 3.6.5<br>
<latex>~\\<br>Let $\mathcal K$ be a geometric simplicial complex with an ordered set of vertices and let $(\mathcal S_i)_{i \geq 1}$ be a boundary-consistent subdivision of simplices. What is $\mathcal S(\mathcal K)$?<br></latex>	pg 14539, def 3.6.6<br>
<latex>~\\<br>Let $\mathcal A$ be an abstract simplicial complex and $(\mathcal S_i)_{i \geq 1}$ be a boundary-consistent subdivision of simplices. What does $\mathcal S(\mathcal A)$ denote?<br></latex>	pg 14539<br>
<latex>~\\<br>Let $\sigma$ be a geometric $n$-simplex. What is the \emph{diameter} of $\sigma$?<br></latex>	the length of its longest edge<br>pg 14539<br>
<latex>~\\<br>Let $\mathcal K$ be a geometric simplicial complex. What does $mesh~\mathcal K$ denote?<br></latex>	pg 14539, definition 3.6.7, near bottom<br><br>
<latex>~\\<br>What does it mean for the subdivision operator $\mathcal S(\cdot)$ corresponding to a boundary-consistent subdivision of simplices $(\mathcal S_i)_{i \geq 1}$ to be \emph{mesh-shrinking}?<br></latex>	pg 14539, definition 3.6.8<br><br>
<latex>~\\<br>Assume $\mathcal K$ is a finite geometric simplicial complex of dimension $n$, and $Div$ is a mesh-shrinking subdivision operator given by $(\mathcal S_i)_{i \geq 1}$. Consider the following statement:<br>$$ lim_{N \to \infty}~\text{mesh}~Div^N \mathcal K = 0 $$<br>Prove or disprove.<br></latex>	true. pg 14540, prop 3.6.9 at top<br><br>todo: add impostor?
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be abstract simplicial complexes, let $f : |\mathcal A| \to |\mathcal B|$ be a continuous map, and let $\varphi : \mathcal A \to \mathcal B$ be a simplicial map. What does it mean for $\varphi$ to be a \emph{simplicial approximation} to $f$?<br></latex>	pg 14540, def 3.7.1<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be abstract simplicial complexes. What does it mean for a continuous map $f : |\mathcal A| \to |\mathcal B|$ to satisfy the \emph{star condition}?<br></latex>	pg 14540, def 3.7.2 at bottom<br>
<latex>~\\<br>Assume that $\mathcal A$ and $\mathcal B$ are abstract simplicial complexes. Consider the following statement: \\~\\<br>A continuous map $f : |\mathcal A| \to |\mathcal B|$ satisfies the star condition if and only if it has a simplicial approximation.\\~\\<br>Prove or disprove.<br></latex>	pg 14541, prop 3.7.3 at top<br>todo: add impostor?<br>
<latex>~\\<br>Assume that $\mathcal A$ and $\mathcal B$ are abstract simplicial complexes, <br>$f : | \mathcal A | \to | \mathcal B |$ is a continuous map, and $\varphi : \mathcal A \to \mathcal B$ is a simplicial approximation of $f$. For an abritrary simplex $\alpha \in \mathcal A$, let $\mathcal C_{\alpha}$ denote the minimal simplicial subcomplex of $\mathcal B$ for which the geometric realization contains $f(|\alpha|)$. Consider the following statement:\\~\\<br>$\varphi(\alpha)$ is a simplex of $\mathcal C_{\alpha}$.\\~\\<br>Prove or disprove.<br></latex>	pg 14541, prop 3.7.4<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be simplicial complexes. Assume that $\mathcal A$ is finite and that $Div$ is a mesh-shrinking subdivision operator. Let $f : |\mathcal A| \to |\mathcal B|$ be a continuous map. Consider the following statement:\\~\\<br>There is an $N > 0$ such that $f$ has a simplicial approximation $\varphi : Div^N \mathcal A \to \mathcal B$.\\~\\<br>Prove or disprove.<br></latex>	pg 14542, theorem 3.7.5<br><br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be simplicial complexes, and $\Phi : \mathcal A \to 2^{\mathcal B}$ be a carrier map. What does it mean for a continuous map $f : |\mathcal A| \to |\mathcal B|$ to be a continuous approximation of $\Phi$?<br></latex>	pg 14543, point (1) at top of page<br><br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be simplicial complexes, and $\Phi : \mathcal A \to 2^{\mathcal B}$ be a carrier map. What does it mean for $\Phi$ to have a \emph{simplicial approximation}?<br></latex>	pg 14543 (2), near top<br>
<latex>~\\<br>Assume $\mathcal A$ and $\mathcalB$ are simplicial complexes such that $\mathcal A$ is finite. Assume furthermore that $\Phi : \mathcal A \to 2^{\mathcal B}$ is a carrier map such that for every simplex $\alpha \in \mathcal A$, the subcomplex $\Phi(\alpha)$ is (dim($\alpha$ - 1))-connected. Consider the following statement:\\~\\<br>The carrier map $\Phi$ has a continuous approximation.\\~\\<br>Prove or disprove.<br></latex>	pg 14543, theorem 3.7.7 (1)<br><br>
<latex>~\\<br>Assume $\mathcal A$ and $\mathcal B$ are simplicial complexes such that $\mathcal A$ is finite. Assume furthermore that $\Phi : \mathcal A \to 2^{\mathcal B}$ is a carrier map such that for every simplex $\alpha \in \mathcal A$, the subcomplex $\Phi(\alpha)$ is (dim($\alpha$ - 1))-connected. Consider the following statement:\\~\\<br>The carrier map $\Phi$ has a simplicial approximation.\\~\\<br>Prove or disprove.<br></latex>	pg 14543, theorem 3.7.7 (2)<br><br>
<latex>~\\<br>Let $\Phi : \mathcal A \to 2^{\mathcal B}$ be a carrier map, and $f : |\mathcal A| \to |\mathcal B|$ a continuous map carried by $\Phi$. Consider the following statement:\\~\\<br>Any simplicial approximation $\phi : Bary^N \mathcal A \to \mathcal B$ of $f$ is also carried by $\Phi$.\\~\\<br>Prove or disprove.<br></latex>	pg 14544, lemma 3.7.8 at top<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every continuous map has a simplicial approximation.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR<br>pg 14541, figure 3.10<br><br>
<latex>~\\<br>Assume that for any input complex $\mathcal I$ and any $N > 0$, there is a protocol that solves the barycentric agreement task $(\mathcal I, Bary^N \mathcal I, Bary^N)$. Consider the following statement:~\\~\\<br>A task $(\mathcal I, \mathcal O, \Delta)$ has a protocol if and only if there exists a protocol $(\mathcal I, \mathcal P, \Xi)$, subdivision $Div~\mathcal P$ of $\mathcal P$, and a simplicial map <br>$$\phi : Div~\mathcal P \to \mathcal O$$<br>carried by $\Delta$.<br></latex>	pg 14561, lemma 4.2.7<br><br>
<latex>~\\<br>Explain how the output complex of the single-layer colorless protocol is the barycentric subdivision of its input complex. Hint: pictures help<br></latex>	pg 14562, entire page
<latex>~\\<br>Examine pg 14562, figure 4.5. It's the output complex for the single-layer colorless immediate snapshot protocol for three or more processes and input values p, q, r. How does the carrier map for single-layer colorless immediate snapshot protocol manifest in this diagram?<br></latex>	pg 14562, second paragraph from bottom<br>
<latex>~\\<br>Figure 4.5 on pg 14562 shows the single-layer colorless immediate snapshot protocol complex for three or more processes and input values p,q,r. What happens if we add one more possible input value s, with the restriction that if some process has input r, no process can have input s, and vice versa? <br></latex>	pg 14563, figure 4.6<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any colorless single-layer (n + 1)-process immediate snapshot protocol $(\mathcal I, \mathcal P, \Xi)$, the protocol complex $\mathcal P$ is the barycentric subdivision of the $n$-skeleton of $\mathcal I$, and the execution map $\Xi$ is the composition of the barycentric subdivision and $n$-skeleton operators.\\~\\<br>Prove or disprove.<br></latex>	pg 14563, theorem 4.2.8<br><br>
<latex>~\\<br>What does it mean for a category $\mathbb C$ to have \emph{set-indexed products}? <br></latex>	pg 10073, top<br>
<latex>~\\<br>Justify the following claim in detail:\\~\\<br>Set-indexed products in a category $\mathbb C$ can be described in terms of right adjoints to certain reindexing functors of the family fibration.<br></latex>	<latex>~\\<br>pg 10073, from top to right above the definition at bottom \\<br>note that the arrow composition just describes $\Delta_I$, and that there is a generalization of the standard $\Delta \vdash \times$ adjunction to I-indexed products.<br></latex>
<latex>~\\<br>Let $\mathbb B$ be a category with Cartesian products $\times$ and $\vrt{\mathbb E}{\mathbb B}p$<br>a fibration. What does it mean for $p$ to have \emph{simple products}?<br></latex>	pg 10073, def 1.9.1 near bottom<br><br>
<latex>~\\<br>Why are the functors $\pi_{I,J}^*$ called \emph{weakening functors}?<br></latex>	pg 10003, example 1.1.1 (iii) (yes, it's a previous chapter, but relevant to 1.9)<br>
What does it mean for a preorder to be <i>directed</i>?<br>	pg 13538, section 1<br>
What do the terms "directed set" and "filtered set" refer to?	pg 13538<br>
What does it mean for a category J to be <i>filtered</i>?	pg 13538<br>
<latex>~\\<br>What is a \emph{filtered colimit}?<br></latex>	pg 13539<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A category $\mathbb C$ with finite coproducts and colimits over all (small) directed preorders has all (small) coproducts.\\~\\<br>Prove or disprove.<br></latex>	true. pg 13539, Theorem 1<br>todo: add impostor!<br>
<latex>~\\<br>Given categories $C,B$ and functors $S,T : C^{op} \times C \to B$, what is a \emph{dinatural transformation} $\alpha : S \overset{. .}{\to} T$?<br></latex>	pg 13545, "Diagonal Naturality"<br>
<latex>~\\<br>What does it mean for a functor to be ``dummy'' in one of its arguments?<br></latex>	pg 13546, near top<br><br>
<latex>~\\<br>If $S$ is dummy in its second variable and $T$ is dummy in its first variable, what can be said of a dinatural transformation $\alpha : S \overset{..}{\to} T$?<br></latex>	pg 13546, second paragraph<br>
<latex>~\\<br>What do you think of the following statement? There is a notion of natural transformations between covariant functors and a notion of natural transformations between contravariant functors, but nothing in category theory allows us to speak of a ``natural transformation'' from a contravariant functor to a covariant one.<br></latex>	"wrong" is probably the correct answer. dinatural transformations allow us to do this.<br>pg 13546, "The following types..."<br><br>
<latex>~\\<br>Define the category-theoretic notion of a \emph{wedge}. <br></latex>	pg 13546. ** Important: Note that this is not oriented in one direction: the dual notion is also called wedge<br>
<latex>~\\<br>A Euclidean vector space $E$ is a vector space over the field $\mathbb{R}$ of real numbers equipped with an inner product function $(~,~) : E \times E \to \mathbb{R}$ which is bilinear, symmetric, and positive definite. These spaces are the objects of a category $\mbf{Euclid}$, with arrows those linear maps which preserve inner product.<br>There are two functors <br>$$U : \mbf{Euclid} \to \mbf{Vct}_{\mathbb R}$$<br>$$-^{\ast} : (\mbf{Euclid})^{op} \to \mbf{Vct}_{\mathbb R}$$<br>Where $U$ is the forget ful functor which ``forgets inner products'', and $-^{\ast}$ takes the dual vector space of its argument.\\~\\<br>Provide a dinatural transformation from $U$ to $-^{\ast}$<br></latex>	<latex>~\\<br>The first step is to view $U$ is a bifunctor that forgets its first argument and $-^{\ast}$ as a bifunctor which forgets its second. \\~\\<br>Let $E$ be a euclidiean vector space. Letting $e \in E_0$, the component <br>$\kappa_E : UE \to E^\ast$ of our natural transformation is <br>defined such that $e \mapsto (e, _)$. Note that, while $UE$ has no inner product, there is nothing<br>preventing us from using the inner product $(~,~)$ of $E$ in the definition. Furthermore, observe<br>that $\kappa_E$ is a \emph{linear transformation} from $UE$ to $E^{\ast}$.\\~\\<br>$\kappa$ is natural because it makes the following diagram commute\\~\\<br>\begin{tikzcd}<br>UD \ar[r, "\kappa"] & D^{\ast} \ar[d, "f^{\ast}"] \\<br>UE \ar[u, "Uf"] \ar[r, "\kappa"] & E^{\ast}<br>\end{tikzcd}\\~\\<br>Note that for Euclidean morphisms $f : E \to D$, we define $f^{\ast}(g : D \to \mathbb R) \doteq g \circ f$.<br>The commutativity relies on $f$ preserving inner products.\\~\\<br>pg 13547<br></latex><br>
<latex>~\\<br>$V_X$, for $X$ a (small) set, takes the value of each function $h : X \to A$ at each argument $x \in X$. If the (small) set $A$ is fixed, $V_X$ may be regarded as a function<br>\begin{mathpar}<br>V_X : hom(X,A) \times X \to A<br>\and<br>\langle h, x \rangle \mapsto h~x<br>\end{mathpar}<br>defined for each object $X \in \mbf{Set}$. In what way are the functions $V_X$ components of a dinatural transformation?<br></latex>	pg 13547. Note that this is a special kind of dinatural transformation called an extranatural transformation (or wedge), defined on pg 13546.<br>
<latex>~\\<br>Let $S : C^{op} \times C \to X$ be a functor. What is an \emph{end} of $S$?<br></latex>	pg 13549, definition at bottom.<br>
<latex>~\\<br>Explain the following subtlety of terminology regarding ends:\\~\\<br>What is the difference between an \emph{end}, and an \emph{ending wedge}?<br></latex>	pg 13550, first full paragraph<br>
<latex>~\\<br>Let $S : C^{op} \times C \to X$ be a functor. What does the notation <br>$$ \int_{c} S(c,c) $$<br>mean?<br></latex>	pg 13550<br>
Give the (problematic) "join-based" typing rule for let expressions. What is wrong with this approach?	pg 17209, right column, (1)<br>
<latex>~\\<br>Give the let typing rule that Katsumata chooses as ``correct'' for his paper.<br></latex>	pg 17210, bottom left corner<br><br>
<latex>~\\<br>What are the axioms for Katsumata's graded monad T? (hint: commutative diagrams may be a good way to communicate these axioms).<br></latex>	pg 17210, top right corner. Note that Katsumata calls graded monads "parametric effect monads" in this paper.<br><br>
<latex>~\\<br>How does Katsumata define the categories $\mbf{LaxMonCAT}$ and $\mbf{StrictMonCAT}$?<br></latex>	pg 17211, right column, "Monoidal category".<br><br>
<latex>~\\<br>What is a \emph{preordered monoid}?<br></latex>	pg 17211, right column near bottom, below "postulate 2.1"<br><br><br>
<latex>~\\<br>Let $\mathbb E$ be a preordered monoid. What is a parametric $\mathbb E$-monad?<br></latex>	pg 17212, top-left, Definition 2.2-bis.<br>see pg 17211 bottom-right for definition of "preordered monoid"<br>
<latex>~\\<br>Let $\mathbb E = (E, \lesssim, 1, \cdot)$ be a preordered monoid. What is a \emph{parametric $\mathbb E$-Kleisli triple} on a category $\mathbb C$?<br></latex><br>	pg 17212, left column, def 2.3<br><br>
<latex>~\\<br>Describe how \emph{tensorial strengths} for parametric effect monads work.<br></latex>	pg 17212, bottom left corner<br><br>
<latex>~\\<br>Let $\mathbb C$ be a category with finite products and $\mathbb E$ a preordered monoid. What is a \emph{strong parametric $\mathbb E$-monad}?<br></latex>	pg 17212, top-right, definition 2.5<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Monads are a specific subclass of the parametric effect monads.\\~\\<br>Prove or disprove.<br></latex>	true. pg 17212, right column, example 2.7<br>
Provide the definition of the parametric writer monad.	pg 17212, right column, example 2.8<br>note that the definition of the unit should use { \epsilon } in the left component rather than simply \epsilon<br>
Define the parametric state monad.<br>	<latex>~\\<br>pg 17213, left column, Example 2.10 \\~\\<br>Let $F_e : \mathbb E^{op} \times \mathbb E \to \mathbb C$ be a bifunctor defined as<br>$$F_e(c,d) \doteq (S~c) \Rightarrow (I \times S~(de))$$<br>If $c \leq c'$, then $S(c' \leq c) : Sc' \to Sc$. Then<br>$F_e(c \leq c', d)$ is defined as the precomposition $S(c \leq c') \Rightarrow (I \times S~(de))$.<br>On the other hand, the monoid action of $\mathbb E$ is monotone (see pg 17211, bottom left corner), <br>and by that monotonicity, we have $d \leq d'$ implies $de \leq d'e$. Thus, $F_e(c,d \leq d')$ is defined<br>as the postcomposition $(S~c) \Rightarrow (1_I \times S(de \leq d'e))$.\\~\\<br>The end $T_e I$ is the terminal object making this diagram commute for $c,d \in \mathbb E$ with $c \leq d$:\\~\\<br>\begin{tikzcd}<br> & (S~d) \Rightarrow (I \times S~(de)) \ar[dr, "F(c \leq d \text{,} 1_d)"] & \\<br>T_e I<br> \ar[ur, "\omega_d"] \ar[dr, "\omega_c" below]<br> & & (S~c) \Rightarrow (I \times (S~de)) \\<br>  & (S~c) \Rightarrow (I \times S~(ce)) \ar[ur, "F(1_c \text{,} c \leq d)" below right] & <br>\end{tikzcd}\\~\\<br>Intuitively, it converts the ``type'' I into a type which allows us to perform a stateful I-producing computation no matter what state (denoted using $d$, the variable of integration) we are in. We transition from state $d$ to $de$. The elements of $\mathbb E$ can be viewed as actions which cause state transitions or, alternatively, states, where $d$ denotes both a state-transforming action and the state resulting from performing $d$ in the initial state $1$ (where $1$ is the unit of the monoid $\mathbb E$). The preorder on $\mathbb E$ is a state subsumption/subtyping relation. Intuitively, the end diagram means that it does not matter whether we perform state subsumption before or after a stateful computation.<br></latex>
<latex>~\\<br>What is a \emph{preordered monad} on the category $\mbf{Sets}$? <br></latex>	pg 17213, bottom left, top right<br><br><latex>~\\<br>Note that $f^{\sharp}$ here denotes the transpose (aka adjoint complement) of $f$. The forgetful functor from preorders to sets is left implicit. $f$ is in $\mbf{Sets}$, $f^{\sharp}$ is in $\mbf{Pre}$.<br></latex>
Give Street's 2-categorical definition of <i>monad</i>.	pg 12509<br>
What is a <i>monad functor</i> (also called <i>monad morphism</i>)?<br> 	pg 12509, near bottom<br>
<latex>~\\<br>What is a \emph{monad functor transformation}? How do we compose two monad functor transformations <br>$(U,\phi) : (X,S) \to (Y,T)$ and $(V,\psi) : (Y,T) \to (Z,W)$?<br></latex>	pg 12510.<br>A careful examination shows that Street gives vertical composition of monad functors. But he also mentions horizontal composition. How would that work?<br><br>
<latex>~\\<br>How does Street define the 2-functors $Inc_{\mathbb C}$ and $Und_{\mathbb C}$?<br></latex>	pg 12510, above theorem 1.<br>todo: show that these are indeed 2-functors (in book/DetailedNotes), perhaps.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The underlying 2-functor $Und_{\mathbb C}$ is the left 2-adjoint of the inclusion 2-functor $Inc_{\mathbb C}$<br>of $\mathbb C$ in $\mbf{Mnd}(\mathbb C)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 12510, theorem 1<br>todo: add impostor?<br>
<latex>~\\<br>What does it mean for a 2-category $\mathbb C$ to \emph{admit the construction of algebras}?<br></latex><br>	pg 12510, bottom<br>
<latex>~\\<br>For $F,G : \mathbf{W} \to \mathbf{D}$, $(F \to G)$ denotes a functor from $\mbf{W}$ to $\mbf{D}$.<br>Briefly, how is this functor defined on objects? And formally in detail, how is it defined on arrows?<br></latex>	pg 8847, below diagram<br>(F -> G) f p g = p(f ;g)<br>
<latex>~\\<br>In O'Hearn and Tennant's denotational semantics for Algol, how do we interpret abstraction typing judgments<br>$\sem{\pi \vdash \lambda \iota : \theta. P : (\theta \to \theta')}$?<br></latex>	<latex>~\\<br>pg 8847, near middle of page\\<br>They use the notation $\sem{\lambda \iota : \theta. P}_{\pi(\theta \to \theta')}$<br></latex><br>
<latex>~\\<br>In O'Hearn and Tennant's denotational semantics for Algol, how do we interpret application typing judgments<br>$\sem{\pi \vdash P~Q : \theta'}$?<br></latex>	<latex>~\\<br>pg 8847, middle of page\\<br>Note that they use the notation $\sem{P~Q}_{\pi \theta'}$<br></latex>
<latex>~\\<br>Functor interpretations of commands and expressions are defined pointwise by O'Hearn and Tennant. But procedures are interpreted using exponentiation of functors. Is it not possible to obtain a more systematic treatment by using exponentiation in the definition of base types as well? That is, one might try to define a ``states'' functor $S$ and proceed as follows:<br>$$\sem{\mbf{exp}} = S \to V_{\bot}$$<br>$$\sem{\mbf{comm}} = S \to S_{\bot}$$ <br>Now we must ask: what is the states functor $S : \mbf{W} \to \mbf{D}$?<br>Suppose that we define it as an exponentiation of the form $S = \sem{var} \to V$. Does this work? What, if any, are the problems with this choice for $S$?<br></latex>	pg 8848,<br>"We can of course"...<br>down to<br>..."An alternative"<br>
<latex>~\\<br>Functor interpretations of commands and expressions are defined pointwise by O'Hearn and Tennant. But procedures are interpreted using exponentiation of functors. Is it not possible to obtain a more systematic treatment by using exponentiation in the definition of base types as well? That is, one might try to define a ``states'' functor $S$ and proceed as follows:<br>$$\sem{\mbf{exp}} = S \to V_{\bot}$$<br>$$\sem{\mbf{comm}} = S \to S_{\bot}$$ <br>Now we must ask: what is the states functor $S : \mbf{W} \to \mbf{D}$?<br>Suppose that we define it as $S(w) \doteq \sem{var}w \to V$, and for any $f : w \to x$ in $\mbf{W}$ and $s \in S(w)$,<br>\[<br>S(f)~s~i \doteq \left \{<br>\begin{array}{ll}<br>s(j), & \text{if }f(j) = i \\<br>v_0, & otherwise<br>\end{array}<br>\]<br>for some fixed storable value $v_0$.\\~\\<br>Does this approach work? What, if any, are its problems?<br></latex>	pg 8848, "An alternative is to use..."<br>down to<br>"... In fact,"
Read the last paragraph of pg 8841, spilling onto pg 8842. We may want to make the defined function S into a functor (where arrows in W are injective maps), to allow it to be resued across multiple worlds. Should this functor be covariant or contravariant, and how should we define it?<br>	see pg 8849, third paragraph from bottom<br>
<latex>~\\<br>For the semantics of the phrase type $\mbf{exp}$, we would like to form the exponential $S \to V_{\bot}$. The problem is that $S$ is a \emph{contravariant} functor. What is O'Hearn and Tennant's solution to this?<br></latex>	pg 8849 bottom paragraph / pg 8850 top paragraph<br>is this a form of dinatural transformation?
<latex>~\\<br>From a contravariant state functor $S$, we can obtain a covariant contra-exponential<br>$(S \to V_{\bot})$. Define both $S$ and $(S \to V_{\bot})$ as O'Hearn and Tennant do.<br></latex>	pg 8849, bottom three paragraphs<br>pg 8850, top paragraph<br>
<latex>~\\<br>We can use contra-exponentiation to define a covariant functor $S \to S_{\bot}$ serving as the interpretation of the phrase type $\mbf{comm}$. If $c(\cdot) \in (S \to S_{\bot})w$ then:\\~\\<br>\begin{tikzcd}<br>S(x) \ar[r,"c(f)"]   & S(x)_{\bot} \\<br>S(y) \ar[u, "S(g)"] \ar[r, "c(f;g)" below] & S(y)_{\bot} \ar[u, "S(g)_{\bot}" right] \\<br>\end{tikzcd}\\~\\<br>Are there any problems with this approach? If so, what are they?<br></latex>	pg 8850. There is guarantee that a local command will leave non-local data unaltered.<br><br>
<latex>~\\<br>Reynolds and Oles argue that it is preferrable to treat variables in Algol-like languages without assuming that states are structured by locations. This can be achieved by defining a category $\mbf{X}$ of possible worlds with \emph{sets} (of allowed states) $W$, $X$, $\ldots$, as objects. Elaborate on this: what are the arrows of this category? What are the identity arrows, and how does arrow composition work?<br></latex><br><br>	pg 8850, "Generalized variables",<br>spills over full page 8851<br><br><br><br>
<latex>~\\<br>How do we define the state functor $S : \mbf{X}^{op} \to \mbf{D}$, where $\mbf{X}$ is the category of ``generalized variables'' described by O'Hearn and Tennant?<br></latex>	pg 8851 bottom pagraph / pg 8852<br>
<latex>~\\<br>What, according to O'Hearn and Tennant, is the fundamental differentce between the location-based semantics for mutable state and the state-set semantics?<br></latex>	pg 8852, "All of this seems very similar..." <br>down to bottom of page<br>
On page 9087, right column, code for an algol procedure for evaluating the nth fibonacci numbers is given. What can go wrong when applying this procedure, and what are the solutions?	aliasing. See top right corner of pg 9087<br>
<latex>~\\<br>Consider the Algol program:<br>\begin{lstlisting}<br>let fordo $\equiv$ $\lambda a_{intexp}. \lambda b_{intexp}. \lambda p_{intexp \to comm}.$ new intvar $k := a$ in<br>  while $k \leq b$ do $(p~k; k := k + 1)$ <br>\end{lstlisting}<br>Explain the phenomenon of \emph{interference} using this example.<br></latex>	pg 9088, right column
<latex>~\\<br>In Algol, we can introduce arrays without adding any new types. Why is this? Give the array declaration typing rule.<br></latex>	pg 9089, left column, Section 19.4 "Arrays and Declarators"<br><br>
<latex>~\\<br>Why doesn't the $\mbf{mkref}$ construct work in an Algol-like language?<br></latex>	It has to do with normal-order evaluation. We would pass the entire mkref construct through an abstraction, making multiple duplicates of the mkref. Each one would allocate a distinct reference cell, which is not the intended behavior.<br><br>pg 9089 right column<br>see also pg 9022 (section 13.10)<br>
<latex>~\\<br>What is a \emph{declarator}?<br></latex>	pg 9089, right column, "On the other hand..."<br>
<latex>~\\<br>Give the term syntax for $\lambda_C$.<br></latex>	pg 9610, top of page<br>
<latex>~\\<br>Give the operational semantics for the operators \emph{abort}, \emph{callcc}, and $\mathcal C$.<br></latex>	pg 9610, "Operational semantics"<br>
<latex>~\\<br>Define the operators abort ($\mathcal A$) and callcc ($\mathcal K$) in terms of the operator $\mathcal C$.<br></latex>	pg 9610, near bottom, abbrev 1 and abbrev 2<br>
<latex>~\\<br>Trace through the small-step evaluation of the $\lambda_{\mathcal C}$ term <br>$\mathcal C~(\lambda c.~1 + (c~2))$.<br></latex>	pg 9611<br>
<latex>~\\<br>Give the local reduction rules for call-by-value $\lambda_{\mathcal C}$.<br></latex>	pg 9611, figure 2<br>
<latex>~\\<br>Give Griffin's type system and typing rules for $\lambda_{\mathcal C}$.<br></latex>	pg 9612, figure 3 at top<br>
Give the core syntax for ISWIM.<br>	it's just lambda calculus<br>pg 19206, left column "call-by-value"<br>
<latex>~\\<br>What does the notation $M \propto E[R]$ mean? <br></latex>	pg 19206, top-right corner.<br>
Read lemma 2, in the bottom right corner of pg 19206.<br>	pg 19206<br>
According to Griffin, what is a <i>continuation</i>?	pg 19207, top-left corner<br><br>
What is the difference between ISWIM and Idealized Scheme (IS)?	<latex>~\\<br>IS adds the $\mathcal A$ and $\mathcal C$ control operators to ISWIM.<br></latex>
<latex>~\\<br>Give the operational semantics for the $\mathcal A$ and $\mathcal C$ operators.<br></latex>	pg 19207, left column<br>
<latex>~\\<br>With the operator $\mathcal C$, we can implement the operator $\mathcal A$ as a derived form. How does this work?<br></latex>	pg 19207<br>
<latex>~\\<br>What relation does Griffin denote by $\mapsto_{u}$?<br></latex>	pg 19207, top right corner<br>
<latex>~\\<br>Explain how we can implement exceptions using the $\mathcal C$ operator.<br></latex>	pg 19207, right column<br>
Read the paragraph in the top right corner of pg 19208. It makes an interesting point.<br>	pg 19208<br>
<latex>~\\<br>Explain how call-by-name ISWIM ($ISWIM_n$) and call-by-name Idealized Scheme ($IS_n$) differ from their call-by-value counterparts.<br></latex>	pg 19208, Section 2.2<br><br>
<latex>~\\<br>Explain how we obtain typed ISWIM ($ISWIM_t$) from call-by-value ISWM ($ISWIM_v$).<br></latex>	pg 19208, right column, down to "First, the Curry-Howard"...<br>
Read "Natural deduction derivations (proofs)..." on pg 19208, down to the end of the page.	pg 19208<br>
<latex>~\\<br>Give the Curry-Howard correspondence for typed ISWIM ($ISWIM_t$).<br></latex>	pg 19209, left column<br><br>
<latex>~\\<br>Describe how Griffin stumbles upon the connection between continuations and classical logic.<br></latex>	pg 19209, "We will now extend" in bottom left corner, down to<br>"From a logical perspective" in right column<br><br>
<latex>~\\<br>What is the type $\neg \alpha$ syntactic sugar for, as used by Griffin?<br></latex>	pg 19209, right column<br>
<latex>~\\<br>Explain the relations between the systems $\mbf{C}$, $\mbf{M}$, and $\mbf{J}$.<br></latex>	pg 19209, right column<br>
<latex>~\\<br>There is a problem with Griffin's first attempt to type ISWIM: The rule $\mapsto_C$ applies only when the entire expression $E[\mathcal C(M)]$ is of type $\bot$. What is the solution to this dillemma?<br></latex>	pg 19209, bottom right corner, "There is one problem..."<br>down to pg 1910, top right corner "Definition 1"<br><br>
<latex>~\\<br>Give the full operational semantics for $IS_t$, in which every lhs is wrapped in the $\mathcal C$ operator for type correctness.<br></latex>	pg 19210, top left corner<br>
Read Definition 1 and Lemma 4 on pg 19210, left column. What is the significance of lemma 4?<br>	pg 19210<br>
<latex>~\\<br>Explain how the $\wedge$-introduction rule can be derived in $\mbf{C}$. (Remember that $\mbf{C}$ is classical logic: minimal logic extended with the law of excluded middle, where $\vee$ and $\wedge$ are derived forms).<br>Use a definition of $\wedge$ suitable for call-by-name reduction. Give an ISWIM term corresponding to $\wedge$-introduction.<br></latex>	pg 19210, right column.<br>
<latex>~\\<br>Explain how the $\wedge$-elimination rule $(\wedge E_1)$ rule can be derived in $\mbf{C}$. (Remember that $\mbf{C}$ is classical logic: minimal logic extended with the law of excluded middle, where $\vee$ and $\wedge$ are derived forms).<br>Use a definition of $\wedge$ suitable for call-by-name reduction. Derive an ISWIM term corresponding to $\wedge E_1$.<br></latex>	pg 19211, top left corner.<br>
<latex>~\\<br>Give $IS_t$ terms corresponding to the $\vee I_1$ and $\vee I_2$ rules, suitable for call-by-name.<br></latex>	pg 19211, bottom left, top right<br>
<latex>~\\<br>Give the $IS_t$ term corresponding to the $\vee E$ rule.<br></latex>	pg 19211, right column<br>recall the derived definition of disjunction, given on pg 19210 right column<br>
<latex>~\\<br>Why does encoding conjunction into $ISWIM_t$ as a derived form require special care when using call-by-value? What is the solution to this dilemma?<br></latex>	pg 19212, left column<br>it may be helpful to look at the call-by-name version in the bottom right corner of pg 19210<br>
<latex>~\\<br>The classicality of $IS_t$ stems from its double negation elimination. The law of excluded middle can then be implemented as a derived form. Give an $IS_t$ term for the law of excluded middle.<br></latex>	pg 19213, left column<br><br>
Give Griffin's cps transform for ISWIM.	pg 19214, top-left corner<br><br>
<latex>~\\<br>Give expression and value syntax for Plotkin's $\lambda_v$.<br></latex>	pg 19222<br>
<latex>~\\<br>What do $\Lambda^0$ and $Values^0$ denote, regarding Plotkin's $\lambda_v$ calculus.<br></latex>	closed expressions and closed values<br>pg 19222<br>
<latex>~\\<br>From a programmer's perspective, what is the SECD-machine?<br></latex>	pg 19223, top paragraph<br><br>
<latex>~\\<br>What are the two basic \emph{notions of reduction} in the $\lambda_v$ calculus?<br></latex>	pg 19223<br>
<latex>~\\<br>Let $\mbf{v} = \delta \cup \beta_v$ be the basic notion of reduction for $\lambda_C$. What does $\to_{v}$ denote? What about $=_{v}$? $\twoheadrightarrow_{v}$?<br></latex>	pg 19223, bottom<br>
<latex>~\\<br>What does $\mbf{\lambda_v} \vdash e_1 = e_2$ mean?<br></latex>	pg 19223<br>
<latex>~\\<br>Why is the concept of \emph{evaluation contexts} important for relating $\lambda_{v}$ reduction to SECD machine evaluation?<br></latex>	pg 19224. "Second, for every..."<br><br>
<latex>~\\<br>Let $\mbf{v}$ be $\lambda_v$'s notion of reduction. What does $e \mapsto_v e'$ stand for?<br></latex>	pg 19224<br>
<latex>~\\<br>How is the set of \emph{standard reduction sequences} defined? (Hint: it is defined inductively using four rules).<br></latex>	pg 19224, def 2.4 at bottom<br><br>
Read definition 2.4 at the bottom of pg 19224. Then read the entirety of pg 19225.<br>	pg 19224/19225<br>
<latex>~\\<br>Let $e$ and $e'$ be $\lambda_v$ terms. What does $e \simeq_v e'$ mean?<br></latex>	pg 19225<br>
<latex>~\\<br>Plotkin showed that the $\lambda_v$-calculus is sound with respect to operational equivalence. Write the formal version of this statement.<br></latex>	pg 19226
<latex>~\\<br>Give the syntax for $\Lambda_c$.<br></latex>	<latex>~\\<br>pg 19226. note that it extends the syntax of $\Lambda$ given on pg 19222.<br></latex>
<latex>~\\<br>What is a \emph{continuation}? What is the \emph{halt} continuation? What are the operational semantics of terms of the form $\mathcal C$?<br></latex>	pg 19226, section 3 "Theories of control"<br><br>
<latex>~\\<br>In $\lambda_c$, how can we define the $\mathcal A$ operator as a derived form in terms of $\mathcal C$?<br></latex>	pg 19226, near bottom <br>see pg 19207, left column, for a more detailed explanation by Griffin<br>
<latex>~\\<br>For complete simulation of an abstract machine, the notion of reduction $\mbf{c}$ is insufficient. Why is this? What is the solution to this? <br></latex>	<latex><br>pg 19228, see $C_T$ and $\triangleright_c$<br></latex>
<latex>~\\<br>What does Felleisen use the notation $\mbf{\lambda}_v$-$\mbf{C}^{\triangleright} \vdash e = e'$ to mean?<br></latex>	pg 19228, above def 3.1<br>
<latex>~\\<br>What does $e \overset{\triangleright}{\mapsto}_c e'$ mean? What is the purpose of this relation?<br></latex>	pg 19228, def 3.1, also paragraph below definition.<br><br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In System $D_{<:}$, substitution is fairly standard.\\~\\<br>True or false?<br></latex>	false. It only allows variable/variable renamings.<br>pg 20117, third paragraph<br>
<latex>~\\<br>With substitutions not present, what mechanism does Amin use to go from a type designator like $k.Key$ to the underlying type it represents?<br></latex>	subtyping<br>pg 20117, third paragraph<br>
<latex>~\\<br>Give the term language of System $D_{<:}$.<br></latex>	pg 20118, first paragraph below "System DSub"<br>pg 20119, top left corner<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In System $D_{<:}$, we allow the let binding of a variable to an arbitrary complex expression.\\~\\<br>True or false?<br></latex>	False. All terms are in ANF.<br>pg 20118, second paragraph of section 2.<br>
<latex>~\\<br>Explain the meaning of types of the form $\forall (x : S) T$.<br></latex>	pg 20118, bottom paragraph.<br>
<latex>~\\<br>What is the meaning of types of the form $\{ A : S..U \}$?<br></latex>	pg 20118, bottom paragraph<br><br>
<latex>~\\<br>Give the type syntax for System $D_{<:}$.<br></latex>	pg 20119, top right corner<br>
<latex>~\\<br>Give the evaluation rules for System $D_{<:}$.<br></latex><br>	pg 20119<br>
<latex>~\\<br>Give the (Var), (All-I), and (Let) typing rules for System $D_{<:}$.<br></latex>	pg 20119<br>
<latex>~\\<br>Give the $(Sub)$, $(All$-$E)$, and $(Typ$-$I)$ typing rules for System-$D_{<:}$.<br></latex>	pg 20119<br>
<latex>~\\<br>Give the $(Top)$, $(Refl)$, $(<:$-$Sel)$, and $(All$-$<:$-$All)$ subtyping rules for System $D_{<:}$.<br></latex>	pg 20119<br>
<latex>~\\<br>Give the $(Bot)$, $(Trans)$, $(Sel$-$<:)$, and $(Typ$-$<:$-$Typ)$ (for tags) subtyping rules for System $D_{<:}$.<br></latex>	pg 20119
<latex>~\\<br>Consider the polymorphic identity function of System $F_{<:}$:<br>$$\Lambda(\alpha <: \top). \lambda(x : \alpha). x$$<br>Write an ``equivalent'' (equivalent for practical purposes, that is) function in System $D_{<:}$.<br></latex>	pg 20120, above section 2.1<br><br>
<latex>~\\<br>Show how existentials can be sugared into System $D_{<:}$. In particular, show how to sugar the:<br>\begin{itemize}<br>\item Type constructor `$\Sigma(x : S) T$''<br>\item Introduction form ``$\mbf{pack}~[x,y]~\mbf{as}~\Sigma(x : S)T$''<br>\item Elimination form ``$\mbf{unpack}~x:S,y:T = t~\mbf{in}~u$''<br>\end{itemize}<br></latex>	pg 20120, example 2.1<br><br>
<latex>~\\<br>How do records work in DOT?<br></latex>	pg 20122<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In DOT, records map labels to values.\\~\\<br>True or false?<br></latex>	FALSE! In DOT, records are call-by-name: see pg 20122, section 4.1<br>
<latex>~\\<br>What is DOT's evaluation rule for field selection?<br></latex>	pg 20122, section 4.1<br><br>
<latex>~\\<br>Give DOT's $(Fld$-$I)$, $(Fld$-$E)$, $(And$-$I)$, and $(AndDef$-$I)$ typing rules.<br></latex>	pg 20123<br>
<latex>~\\<br>Give DOT's subtyping rules associated with intersection types.<br></latex>	pg 20123<br>
Give DOT's evaluation rule for object field selection.	pg 20123, "Evaluation ..."<br>
<latex>~\\<br>Give DOT's $\{\}$-$I$, $Rec$-$I$, and $Rec$-$E$ typing rules.<br></latex>	pg 20123<br>
<latex>~\\<br>What does a judgment of the form $\Gamma \vdash_! t : T$ mean? What is the motivation for having such judgments in DOT?<br></latex>	pg 20125<br>
<latex>~\\<br>How does the DOT calculus define the notion of a \emph{store}? DOT uses $s \mid t$ to denote a store $s$ combined with a term $t$. But $s \mid t$ is treated as syntactic sugar; explain how $s \mid t$ is desugared.<br></latex>	pg 20125, bottom, def 3, 4<br><br>
<latex>~\\<br>Let $\Gamma = \overline{x_i : T_i}$ be an environment and $s = \overline{x_i = v_i}$ be a store. What does $\Gamma \sim s$ mean? <br></latex>	pg 20126, top, definition 5 
<latex>~\\<br>What does it mean for a typing or subtyping derivation to be \emph{tight} in environment $\Gamma$?<br></latex>	pg 20126, def 6<br><br>
<latex>~\\<br>In the DOT calculus, what does $\Gamma \vdash_{\#} t : T$ mean? What does $\Gamma \vdash_{\#} S <: U$ mean?<br></latex>	pg 20126<br>
<latex>~\\<br>Amin proves the following lemma (in coq):\\~\\<br>If $\Gamma \sim s$ and $s(x) = \nu(x : T) d$ and $\Gamma \vdash_{\#} x : \{ A : S..U \}$. then $\Gamma \vdash_{\#} x.A <: U$ and $\Gamma \vdash_{\#} S <: x.A$.\\~\\<br>How would you go about proving this? You don't need to prove the whole thing, but what would the basic structure of the proof be?<br></latex>	pg 20126, lemma 1.<br>
<latex>~\\<br>What does $\mbf{Ts}(\Gamma, x, v)$ denote? (Hint: there are 8 cases in its definition. Because there are so many of them, don't feel obligated to list *all* of them, but list as many as you can).<br></latex>	pg 20126<br>
<latex>~\\<br>Amin proves the following lemma (in coq):\\~\\<br>If $\Gamma \sim s$, $s(x) = v$, $T \in \mbf{Ts}(\Gamma,x,v)$ and $\Gamma \vdash T <: U$, then $U \in \mbf{Ts}(\Gamma, x, v)$.\\~\\<br>What do you think is the intuition and motivation for this lemma? How would you go about proving it? (No need to provide a full proof; what is the basic structure?)<br></latex>	pg 20126, lemma 2<br><br>
<latex>~\\<br>Amin proves the following lemma (in coq):\\~\\<br>If $\Gamma \sim s$ and $\Gamma \vdash x : T$ then $T \in \mbf{Ts}(\Gamma, x, s(x))$\\~\\<br>What do you think is the intuition and motivation for this lemma? How would you go about proving it? (No need to provide a full proof; what is the basic structure?)<br></latex>	pg 20126, bottom, lemma 3 
<latex>~\\<br>Show how booleans can be encoded into DOT. This will involve three definitions:<br>\begin{itemize}<br>\item IFT, the type of true and false<br>\item boolImpl, an object whose fields are Boolean (a type tag), true (a term), and false (also a term)<br>\item bool, a wrapper that converts boolImpl.Boolean into a nominal type<br>\end{itemize}<br></latex>	pg 20127 bottom / 20128 top<br>
Read section 1, pg 20128<br>	<br>
Read the introductory example, starting on pg 20199 section 2, and spanning the rest of the next page, pg 20200.<br>	pg 20199 / 20200<br>
<latex>~\\<br>What does Rapoport use the following syntactic sugar for, for talking about DOT?\\~\\<br>$\{ A \}$\\<br>$\{ A : T \}$\\<br>$\{ A <: T \}$\\<br>$\{ D_1;D_2 \}$<br></latex>	pg 20201<br>
<latex>~\\<br>What does Rapoport use the following syntactic sugar for, for talking about DOT?\\~\\<br>$t~u$\\<br>$t.L$\\<br>$\nu(x)d : T$<br></latex>	pg 20201<br>
Give the forms of the syntactic constructs for allocating, reading, and assigning reference cells.	IMPORTANT: they operate on *variables* rather than arbitrary expressions since we are working in ANF.<br>pg 20202<br>
In what way does DOT's type system allow the user to define a custom subtyping lattice?	pg 20178, top of "Bad Bounds" section<br><br>
<latex>~\\<br>Let $S$ be the object type $\{ a : \top \}$ and $U$ be the function type $\forall(z : \top) \top$. Then the following is a valid and well-typed DOT term:<br>\begin{lstlisting}<br>$\lambda (x : \{ A : S..U \}). \mbf{let}~y = \nu(y : S) \{ a = y.a \}~\mbf{in}~y~y$<br>\end{lstlisting}<br>How is this possible? This term gets stuck, so how can DOT be sound!?<br></latex>	pg 20178, "Bad bounds"<br>pg 20179<br><br>
<latex>~\\<br>Since DOT allows the user to define their own subtyping lattice; this allows some pretty crazy terms to typecheck. What is the payoff of this power?<br></latex>	pg 20180, "Why should DOT have such a strange feature?"...<br><br>
<latex>~\\<br>What does it mean for a typing context $\Gamma$ to be inert, and what is the purpose of the concept of inertness?<br></latex>	pg 20181. below proof tree: "Inertness ensures that customized subtyping in the program does not introduce unexpected subtyping relationships. If the context were not inert, any type could have been customized to have arbitrary subtypes and be inhabited by arbitrary terms, so it would be impossible to draw any conclusions about a term from its type."<br><br>
Explain the connection between linear logic's nil operator and linear algebra's concept of "duality".	pg 11936, see the sticky note.<br>
<latex>~\\<br>Do we have<br>$$ \exists x A = (\forall x A^{\bot})^{\bot}$$<br>in linear logic? Why is this surprising?<br></latex>	pg 11936, near bottom<br>
<latex>~\\<br>There is an important equivalence in linear logic involving $!$, $\otimes$, and $\&$. What is this equivalence, and why does it suggest that linear logic should be have a commutative $\otimes$ operator?<br></latex>	pg 11939<br>
<latex>~\\<br>Give the grammar for classical logic formulas.<br></latex>	pg 12555
<latex>~\\<br>Give all (left and right) classical logic sequent calculus rules for weakening and contraction.<br></latex><br>	pg 12594<br>
<latex>~\\<br>Give all (left and right) classical logic sequent calculus rules for conjunction and implication.<br></latex>	pg 12594<br>
<latex>~\\<br>Give all (left and right) classical logic sequent calculus rules for disjunction, 1, and 0.<br></latex>	pg 12594<br>
<latex>~\\<br>Give all classical logic sequent calculus rules for axiom (aka identity) and cut.<br></latex>	pg 12594<br>
<latex>~\\<br>In an alternative development of classical logic, we could include a negation connective rather than implication. What would the sequent calculus rules for negation be?<br></latex>	pg 12556
<latex>~\\<br>Briefly, how does the cut-elimination proof work? Concretely demonstrate the inductive case where the cut rule is applied when one premise is derived with $\wedge_R$ and the other is derived with $\wedge_{L1}$.<br></latex>	pg 12556, bottom paragraph, bottom diagram<br><br>
<latex>~\\<br>Briefly, how does the cut-elimination proof work? Concretely demonstrate the inductive case where the cut rule is applied when one premise is derived with $\wedge_R$ and the other is derived with $\wedge_{L2}$.<br></latex>	pg 12556, bottom paragraph<br>pg 12557, top diagram
<latex>~\\<br>Briefly, how does the cut-elimination proof work? Concretely demonstrate the inductive case where the cut rule is applied when one premise is derived with $1_R$ and the other is derived with $1_L$.<br></latex>	pg 12556, bottom paragraph<br>pg 12557, second diagram<br>
<latex>~\\<br>Briefly, how does the cut-elimination proof work? Concretely demonstrate the inductive case where the cut rule is applied when one premise is derived with $\Rightarrow_R$ and the other is derived with $\Rightarrow_{L}$.<br></latex>	pg 12556, bottom paragraph<br>pg 12557, third diagram<br><br>
What is the <i>subformula property</i> of classical sequent calculus?	pg 12558, top paragraph<br><br>
<latex>~\\<br>The fundamental idea in the proofs-as-programs paradigm is to consider<br>a proof as a program and reduction of the proof (cut-elimination) as evaluation of the program. This makes it desirable that the same reduced proof is<br>obtained independent of the choices of reductions. However, this is not pos-<br>sible with Classical Logic where cut-elimination is highly non-deterministic. Provide a classical sequent calculus proof tree which demonstrates this issue.~\\~\\<br>There are two basic solutions to this problem: what are they?<br></latex>	pg 12558<br>
<latex>~\\<br>What is the difference between classical sequent calculus and intuitionistic sequent calculus?<br></latex>	pg 12559, section 1.2<br>open up a second copy of MiscStudy to pg 12595 to compare<br><br>
<latex>~\\<br>Give the following natural deduction rules for intuitionistic logic:\\~\\<br>- Axiom\\<br>- 1_I \\<br>- \wedge_I \\<br>- \Rightarrow_I \\<br></latex>	pg 12596<br>
<latex>~\\<br>Give the following natural deduction rules for intuitionistic logic:\\~\\<br>- \wedge_{E1} \\<br>- \wedge_{E2} \\<br>- \Rightarrow_E \\<br>- 0_E<br></latex>	pg 12596<br>
<latex>~\\<br>Give the following natural deduction rules for intuitionistic logic:\\~\\<br>- \vee_{I1} \\<br>- \vee_{I2} \\<br>- \vee_{E}<br></latex>	pg 12596
<latex>~\<br>Let $p : \mathbb E \to \mathbb B$ be a functor. In \emph{comprehension categories}, what does Jacobs say that it means for a morphism $f : D \to E$ in $\mathbb E$ to be \emph{cartesian} over $u : A \to B$ in $\mathbb B$. Note that this definition is a special case of the definition that Jacobs gives in his book.<br></latex>	pg 18552, def 2.1 (i)<br>also, see the diagram on the left at the top of pg 18553<br><br>
<latex>~\<br>Let $p : \mathbb E \to \mathbb B$ be a functor. In \emph{comprehension categories}, what does Jacobs say that it means for a morphism $f : D \to E$ in $\mathbb E$ to be \emph{cocartesian} over $u : A \to B$ in $\mathbb B$?<br></latex>	<latex>~\\<br>$g$ in $\mathbb E^{op}$ is cartesian over $u$ in $\mathbb B^{op}$\\<br>pg 18552, def 2.1 (ii)\\<br>also, see the diagram on the right at the top of pg 18553.<br></latex><br>
<latex>~\\<br>What does it mean for a functor $p : \mathbb E \to \mathbb B$ to be a \emph{fibration}? What does it mean for $p$ to be a \emph{cofibration}? What about a \emph{bifibration}?<br></latex>	pg 18553 (iii), (a) and (b)<br>note that (b) does not need to be built in to the definition, but instead can be derived, as explained in <br>the first few chapters of Jacobs' text book on categorical logic and type theory.<br><br>
<latex>~\\<br>In \emph{comprehension categories}, what does Jacobs' say that it means for a morphism $f : D \to E$ to be \emph{strong cartesian}, or \emph{hypercartesian}?<br></latex>	this is what Jacobs' calls <i>Cartesian</i> in his textbook.<br>pg 18553, paragraph above def 2.2<br>
<latex>~\\<br>Let $p : \mathbb E \to \mathbb B$ be a functor. For $B \in \mathbb B$, what does $\mathbb E_B$ denote?<br></latex>	pg 18553, def 2.2 at bottom<br>
<latex>~\\<br>Let $E,D \in \mathbb E$ and $u : pE \to pD$ in $\mathbb B$. What does $\mathbb E_u(D,E)$ denote?<br></latex>	pg 18554, top paragraph.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Let $p : \mathbb E \to \mathbb B$ be a fibration. Then p is a bifibration iff every inverse image functor $u^*$ has a left adjoint $\Sigma_u$.\\~\\<br>Prove or disprove.<br></latex>	pg 18555, proof at top of pg, pt (i)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $r : \mathbb B \to \mathbb A$ and $p : \mathbb E \to \mathbb B$ are fibrations then $rp : \mathbb E \to \mathbb A$ is also a fibration.\\~\\<br>Prove or disprove.<br></latex>	pg 18554<br>
<latex>~\\<br>Let $\mathbb E \to \mathbb B$ and $q : \mathbb D \to \mathbb B$ be fibrations with the same basis $\mathbb B$. What does it mean for a functor $H : \mathbb E \to \mathbb D$ to be \emph{cartesian}?<br></latex>	pg 18555, def 2.4 (i)<br>
<latex>~\\<br>Let $\mathbb B$ be a category. Describe the 2-category Fib($\mathbb B$). What are its 0-cells? Its 1-cells? Its 2-cells?<br></latex>	pg 18555, def 2.4 (ii)<br><br>
<latex>~\\<br>What is the Brouwer-Heyting-Kolmogorov interpretation of intuitionistic logic? Give the specific cases for the connectives $\wedge$, $\Rightarrow$, and $\vee$.<br></latex>	pg 12560<br>
<latex>~\\<br>Give the natural deduction reduction rules for the $\wedge$ connective.<br></latex>	pg 12561, top two diagrams<br>
<latex>~\\<br>Give the natural deduction reduction rule for the $\Rightarrow$ connective.<br></latex>	pg 12561, third diagram<br><br>
<latex>~\\<br>Explain intuitionistic natural deduction's reduction rule for the $(\vee_{I1},\vee_E)$ case.<br></latex>	pg 12561, bottom<br>
<latex>~\\<br>The natural deduction presentation of intuitionistic logic satisfies the \emph{Church-Rosser} property. What does this mean?<br></latex>	pg 12562, paragraph above section 1.3<br>
<latex>~\\<br>Give Brauner's syntax for the types of the lambda calculus.<br></latex>	pg 12562, bottom of page.<br>
Brauner lists several important properties of his typed lambda calculus. State as many of them as you can.<br>	pg 12564, lemma 1.3.1<br>pg 12565,<br>prop 1.3.2<br>lemma 1.3.3<br>lemma 1.3.4<br>
Briefly explain the idea behind the Curry-Howard isomorphism.<br>	pg 12566, 12567<br>
Intuitively, what are the purposes of the ! and ? modalities in a sequent calculus setting?	! allows contraction and weakening on the left-hand side<br>? allows contraction and weakening on the right-hand side<br>pg 12568, section 2.1<br>
<latex>~\\<br>Give the grammar for linear logic formulae.<br></latex>	<latex>~\\<br>pg 12569 BUT NOTE THAT BRAUNER ACCIDENTALLY OMITS THE OPERAND POSITIONS FOR $\&$ and $\oplus$.<br></latex>
Brauner uses a somewhat different turnstile symbol for classical linear logic sequent calculus than for classical logic sequent calculus. Explain the visual distinction.	classical linear logic uses a bold turnstile.<br>pg 12569
Which of the connectives of classical linear logic are <i>additive</i>?	<latex>~\\<br>$\&$, $1$, $\oplus$, and $0$\\<br>pg 12569<br></latex><br>
<latex>~\\<br>How does Brauner define $A^{\bot}$?<br></latex>	pg 12569<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In linear logic sequent calculi, contexts can be considered as sets of formulae.\\~\\<br>True or false?<br></latex>	FALSE! Without contraction and weakening, they must be considered as multisets!<br>
Give the Axiom and Cut rules for classical linear logic sequent calculus.<br>	pg 12597<br>
<latex>~\\<br>Give the $\otimes_L$, $\otimes_R$, $I_L$ and $I_R$ rules of classical linear logic sequent calculus.<br></latex>	pg 12597<br>
<latex>~\\<br>Give Brauner's classical linear logic sequent calculus rules for $\upand_{\! L}$, $\upand_{\! R}$, $\bot_L$, and $\bot_R$.<br></latex>	pg 12597<br>
<latex>~\\<br>Give Brauner's classical linear logic sequent calculus rules for $\multimap_L$, $\multimap_R$, $!_L$,$!_R$,$?_L$, and $?_R$.<br></latex>	pg 12597<br>
<latex>~\\<br>Give Brauner's classical linear logic sequent calculus rules for $Weakening_L$, $Weakening_R$, $Contraction_L$, and $Contraction_R$.<br></latex>	pg 12597<br>
<latex>~\\<br>Give Brauner's classical linear logic sequent calculus rules for $\&_{L1}$, $\&_{L2}$, $\&_R$, and $1_R$.<br></latex>	pg 12598
<latex>~\\<br>Give Brauner's classical linear logic sequent calculus rules for $\oplus_L$, $\oplus_{R1}$, $\oplus_{R2}$, and $0_L$.<br></latex>	pg 12598<br>
<latex>~\\<br>Conceptually explain all rules involving ! and ? in classical linear logic sequent calculus.<br></latex>	pg 11945, point 2: "exponentials"<br>open another copy of MiscStudy and juxtapose with pg 11944, which contains the actual rules.<br><br>
<latex>~\\<br>Girard says ``it is important to remark that $\forall x$ is very close to $\&$ (and that $\exists x$ is very close to $\oplus$''. Open up the classical linear logic sequent calculus rules on pg 11944, and try to figure out what he means by this.<br></latex>	pg 11944/11945<br><br>
There is a certain theorem for linear logic sequent calculus (and other sequent calculi as well) known as the Hauptsatz. State this theorem.<br>	pg 11945 bottom / pg 11946 top<br>
Read pg 11946, below the proof of theorem 1 ("We have now to keep in mind...") down to the bottom of the page.<br>	pg 11046<br>
<latex>~\\<br>Initially, the structure of cut-elimination for classical linear logic sequent calculus seems quite problematic, because of proofs of the form<br><br>\begin{prooftree}<br>\AxiomC{$\vdash \Gamma,A$}<br>\RightLabel{(r)}<br>\UnaryInfC{$\vdash \Gamma',A$}<br>\AxiomC{$\vdash A^{\bot}, \Delta$}<br>\RightLabel{(s)}<br>\UnaryInfC{$\vdash A^{\bot},\Delta'$}<br>\RightLabel{(cut)}<br>\BinaryInfC{$\vdash \Gamma',\Delta'$}<br>\end{prooftree}<br><br>Here (r) and (s) are unspecified rules. What is the problem here? Why is it difficult to eliminate this application of the cut rule?<br><br></latex>	pg 19946 bottom / 19947 full page<br>
<latex>~\\<br>Why is natural deduction a poor choice for classical linear logic. Does intuitionistic linear logic have the same incompatibility with natural deduction?<br></latex>	pg 11948, point (1), but also see (2), (3), (4)<br><br><br>
<latex>~\\<br>What notation does Girard use for cut links and axiom links. Use an electronics analogy to explain the meanings of cut links and axiom links.<br></latex>	pg 11949<br>
Examine the four linear logic natural deduction rules on page 11948. Draw <i>proof structures</i> for each of these rules.	a formal definition of proof structures is given (in a different document) on pg 12004<br>proof structures are explained on pg 11950 (axiom and cut are explained on pg 11949)<br>answers given on pg 11951<br><br>
Read pg 20222-20224. The last sentence asks us to think about why some paths do not correspond to a unique proof. Why do you think this is the case?	pg 20222-20224<br>
Read pgs 20222-20224. Since we ruled out reflexivity, under which circumstances can we still <i>prove</i> path(x,x)?	when x has at least one neighbor. pg 20225<br>
<latex>~\\<br>What does it mean for a proof to be \emph{schematic} in a set of variables?<br></latex>	It does not depend on what those variables are. "There are several interesting aspects..."<br>pg 20225<br>
<latex>~\\<br>What is a \emph{derived} rule of inference?<br></latex>	pg 20225, right above section 2<br><br>
<latex>~\\<br>Let us represent the natural numbers as $0,s(0),s(s(0)),s(s(s(0))),\ldots$. Give deductive rules to identify even and odd numbers. Create a derived rule which expresses that for each even number x, the double-successor of x is even.<br></latex>	pg 20226, near top<br>
Read section 3. Pg 20226-20227<br>	pg 20226-20227<br>
Read section 4. pg 20228-20229<br>	pg 20228-20229<br>
Explain the difference between ephemeral and persistent propositions.<br>	pg 20230<br>
<latex>~\\<br>Pfenning underlines certain propositions, e.g. $\underline{even}(x)$. What does this notation mean?<br></latex>	It means that the proposition even(x) is persistent: using it as a premise does not destroy it.<br>pg 20231, top<br><br>
The classic <i>blocks worlds</i> scenario from the history of artificial intelligence involves multiple blocks sitting on a table, which can be stacked on top of each other, and a hand which may pick them up. Try coming up with some linear deduction rules to capture this scenario.<br>	pg 20231, section 6<br>pg 20232,<br>pg 20233<br><br>
The classic <i>blocks worlds</i> scenario from the history of artificial intelligence involves multiple blocks sitting on a table, which can be stacked on top of each other, and a hand which may pick them up. See the depiction of this scenario on pg 20231, section 6. We have the following predicates:<br><br>- empty, meaning the hand is empty<br>- holds(x), meaning the hand holds block x<br>- on(x,y), meanining that block x is on block y<br><br>What are some invariants that we expect to hold, expressed using these predicates?<br>	pg 20234, top paragraph<br>
In the Shakespeare play <i>Richard III</i>, richard says "My kingdom for a horse!" (he's speaking of a trade).<br>How would we model this using a linear deduction?	pg 20234, read the full section.<br><br>
Read pg 20235<br>	<br>
What is the motivation for defining the notion of an <i>inert typing context</i>?	pg 20181, section 3.2 near bottom<br><br>
<latex>~\\<br>What does it mean for a type $U$ to be inert? What does it mean for a typing context $\Gamma$ to be inert?<br></latex>	pg 20181<br>
What is the "inert context guarantee"? What is the significance of this property?	pg 20182, property 1.<br>Its significance is discussed below the property statement.<br><br>
Does every value have an inert type? Is every inert type inhabited by a value? Explain.	pg 20182, "Every value has an inert type..."<br><br>
<latex>~\\<br>Consider the following well-typed program<br>$$\mbf{let}~y = v~\mbf{in}~(\lambda (x : \{ A : S..U\}).t)~y$$<br>When $t$ begins executing, will it have an inert context? If so, why? If not, why not?<br></latex>	pg 20182, last paragraph (above "Tight typing")<br>
What is the difference between <i>tight typing</i> and general DOT typing?	Type selection subtyping rules are only allowed when we are selecting a tight type binding.<br>pg 20179, fig 2 (the shaded part is the different part)<br>pg 20183, second paragraph<br><br>
<latex>~\\<br>What is \emph{precise typing}? Hint: there are two basic classes of precise typing rules.<br>Give as many of the rules as you can (there are 6 total). <br></latex>	pg 20182<br>
State the "Tight typing guarantee".	pg 20183, property 2<br>
<latex>~\\<br>Tight typing is given on pg 20179. It replaces the normal Sel subtyping rules (see shaded rules) with special ones. What is the intuition and motivation behind doing this?<br></latex>	The general typing rules that enable DOT programs to define new user-defined subtyping relationships, <:-Sel and Sel-<:, are restricted in tight typing to <:-Sel-# and Sel-<:-#, which allow only to give an alias to an existing type, but not to introduce new subtyping between existing types.<br><br>Property 2 makes reasoning in tight typing easy: we never have to worry about unexpected custom subtyping<br>relationships being introduced by the program, and we do not need to reason about whether we are in an inert<br>typing context, because tight typing gives the guarantee in all contexts.<br><br>pg 20183<br>
<latex>~\\<br>State the ($\vdash$ to $\vdash_{\#}$) theorem. How would we go about proving this theorem? (Give a sketch.) <br></latex>	stated on pg 20183<br>proof sketch is on pg 20184, below proof of lemma 3.4<br>
Read the bottom two paragraphs of pg 20183.<br>	<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\Gamma$ is an inert context, then if $\Gamma \vdash_{\#} x : \{ A : S .. U \}$, then $\Gamma \vdash_{\#} S <: x.A$ and $\Gamma \vdash_{\#} x.A <: U$.\\~\\<br>How would we go about proving this? Give a broad outline.<br></latex>	pg 20184, lemma 3.4<br>todo: add impostor?<br><br>
<latex>~\\<br>What are \emph{precise typing} judgments used for?<br></latex>	They are used in the premises of <:-Sel-# and Sel-<:-#, see figure 2 og 20179<br>
<latex>~\\<br>Rapoport proves the following lemma:~\\~\\<br>If $\Gamma$ is an inert context, then if $\Gamma \vdash_{\#} x : \{ A : S..U \}$, then there exists a type $T$ such that $\Gamma \vdash_{!} x : \{ A : T..T \}$, $\Gamma \vdash_{\#} S <: T$, and $\Gamma \vdash_{\#} T <: U$.\\~\\<br>How could this lemma be used to prove the following?\\~\\<br>If $\Gamma$ is an inert context, then if $\Gamma \vdash_{\#} x : \{ A : S..U \}$, then $\Gamma \vdash_{\#} S <: x.A$ and $\Gamma \vdash_{\#} x.A <: U$.<br></latex>	pg 20184<br>
<latex>~\\<br>To reason about spanning tree computations using linear deduction, we must reference two graphs: the originial graph, and the computed spanning tree. What predicates do we use for such reasoning? What deductive rules do we use for performing this algorithm? What invariants do these rules preserve? Why do these rules produce a ``correct'' output?<br></latex>	pg 20239, 20240, 20241<br><br><br>
<latex>~\\<br>Try translating the following English proverb into predicates and linear deductive rules:\\~\\<br>If wishes were horses, beggars would ride.\\~\\<br>Why is this task difficult without the ability to use logical connectives?<br></latex>	pg 20231, section 2<br>pg 20232<br>
<latex>~\\<br>What doe the binary \emph{simultaneous conjunction} operator $\otimes$ mean? How does Pfenning motivate this operator? What are its (problematic) introduction and elimination forms in linear deduction, and why are they problematic?<br></latex>	pg 20242, section 3<br>pg 20243 top<br>
<latex>~\\<br>How does Pfenning define the notion of a linear sequent? <br></latex>	pg 20243, section 4<br>pg 20244, top<br>
<latex>~\\<br>Give and explain the sequent calculus rules $\otimes R$ and $\otimes L$ for simultaneous conjunction.<br></latex>	pg 20244, top<br><br>
<latex>~\\<br>Explain the $id_{A}$ and $cut_{A}$ rules of linear sequent calculus.<br></latex>	pg 20244, section 5<br>pg 20245, top<br>
<latex>~\\<br>What is ``identity expansion''? Give the concrete example of identity expansion for the simultaneous conjunction operator.<br></latex>	pg 20245<br>
<latex>~\\<br>What is ``cut reduction''? Give the concrete example of cut reduction for simultaneous conjunction.<br></latex>	pg 20246, section 7<br><br>
<latex>~\\<br>Give the $\multimap \! L$ and $\multimap \! R$ rules.<br></latex>	pg 20246, section 8<br>pg 20247<br><br>
<latex>~\\<br>Demonstrate identity expansion for the $\multimap \! L$ and $\multimap \! R$ operators.<br></latex>	pg 20247<br>
<latex>~\\<br>Demonstrate cut reduction for the $\multimap \! R$ and $\multimap \! L$ rules.<br></latex>	pg 20247<br>
<latex>~\\<br>Give a broad overview of the Curry-Howard-Lambek correspondence.<br></latex>	pg 19333, section 1.1<br><br>
<latex>~\\<br>Give the syntax and operational semantics of the $(I,K,S)$-combinatoric system.<br></latex>	pg 19333, section 1.1.1 at bottom<br>pg 19334<br><br>
<latex>~\\<br>\emph{Simple types} have the syntax:\\<br>$A,B,\ldots ::= a \mid A \to B$\\<br>where $a$ ranges over base types. \\~\\Give simple type ascriptions to the combinators of the $(I,K,S)$-combinatoric system. Prove subject reduction for this system.<br></latex>	pg 19334, defs 2,3<br><br>
Provide the definition of propositional minimal logic.	pg 19335, definition 4<br>note that the axioms are the types of the I,K,S combinators (see previous page)<br>
<latex>~\\<br>Is the \emph{canonical transformation} (Beck-chevalley) used in the definition of \emph{simpled products} an instance of the \emph{canonical transformation} described in lemma 1.8.9, which relates a global adjunction $H \dashv K$ to fibred adjunctions at the restrictions of $H$ and $K$ to fibres $H_I \dashv K_I$?<br></latex>	<latex>~\\<br>not quite. for simple products, the reindexing functors on the left and right sides are over \emph{distinct} arrows<br>$u$ and $u \times id$, whereas for global/local adjunctions we use the same arrow $u$ on both sides.<br>\\~\\<br>see page 10074, and compare to pg 10065<br></latex><br>
<latex>~\\<br>Let $\mathbb B$ be a category with Cartesian products $\times$ and $\vrt{\mathbb E}{\mathbb B}p$ be a fibration. We say that $p$ has \mbf{simple products} if both<br>\begin{itemize}<br>\item For every pair of objects $I,J \in \mathbb B$, every ``weakening functor'' <br>$$ \mathbb E_I \overset{\pi^*_{I,J}}{\longrightarrow} \mathbb E_{I \times J}$$<br>induced by the Cartesian projection $\pi_{I,J} : I \times J \to I$, has a right adjoin $\Pi_{(I,J)}$;<br>\item the Beck-Chevalley condition holds: for every $u : K \to I$ in $\mathbb B$ and $J \in \mathbb B$, in<br>the diagram \\<br>\begin{tikzcd}[sep = 60]<br>\mathbb E_I   \ar[r, "u^*"] \ar[d, "\pi^*_{I\text{,}J}" left, bend right = 20]   <br>  &  \mathbb E_K \ar[d, "\pi^*_{K\text{,}J}", bend left = 20] \\<br>\mathbb E_{I \times J} \ar[u, "\Pi_{(I\text{,}J)}" right, bend right = 20]  \ar[r, "(u \times id)^*" below]<br>  & \mathbb E_{K \times J} \ar[u, "\Pi_{(K\text{,}J)}", bend left = 20]<br>\end{tikzcd}~\\~\\<br>the canonical transformation $$u^* \Pi_{(I,J)} \Rightarrow \Pi_{(K,J)} (u \times id)^*$$<br>is an isomorphism. <br>\end{itemize}<br>What \emph{is} the natural transformation $u^* \Pi_{(I,J)} \Rightarrow \Pi_{(K,J)} (u \times id)^*$?<br></latex>	<latex><br>It's the transpose of this composite<br>$$\pi^*_{K,J}u^*\Pi_{(I,J)} \overset{\cong}{\longrightarrow} (u \times id)^* \pi^*_{I, J} \Pi_{(I,J)} \overset{(u \times id)^* \epsilon}{\longrightarrow} (u \times id)^*$$<br>Note that transposition can be read off of the above square diagram, showing that it is ``type correct''.<br>pg 10074<br></latex>
<latex>~\\<br>Consider the following statement:\\~\\<br>For an arbitrary category $\mathbb C$, one has:\\~\\<br>the family fibration $\vrt{Fam(\mathbb C)}{\mbf{Sets}}$ has (split) simple products/coproducts $\Leftrightarrow$ $\mathbb C$ has set-indexed products/coproducts.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10074, lemma 1.9.2<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. Consider the following statement:\\~\\<br>The simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ on $\mathbb B$ always has simple coproducts.\\~\\<br>Prove or disprove.<br></latex>	pg 10075, prop 1.9.3 (i)<br>todo: add impostor.
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. Consider the following statement:\\~\\<br>The simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ on $\mathbb B$ has simple products if and only if $\mathbb B$ is Cartesian closed.\\~\\<br>Prove or disprove.<br></latex>	true. <br>pg 10075, prop 1.9.3 (ii)<br><br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. Consider the following statement:\\~\\<br>The simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ on $\mathbb B$ always has simple products.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! should be possible to find a counterexample<br>pg 10075, prop 1.9.3<br>
<latex>~\\<br>Let $\mathbb B$ be a category with pullbacks and $\vrt{\mathbb E}{\mathbb B}p$ a fibration on $\mathbb B$. What does it mean for $p$ to have \emph{products}?<br></latex>	pg 10076, def 1.9.4<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Simple products are products.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10076, below def 1.9.4<br>
<latex>~\\<br>Let $\mathbb B$ be a category with pullbacks and $\vrt{\mathbb E}{\mathbb B}p$ a fibration on $\mathbb B$. What does it mean for $p$ to have \emph{coproducts}?<br></latex>	<latex>~\\<br>\begin{itemize}<br>\item for every morphism $u : I \to J$ in $\mathbb B$, every substitution functor $u^* : \mathbb E_J \to \mathbb E_I$ has a left adjoint $\coprod_{u}$.<br>\item the Beck-Chevalley condition holds: for every pullback $\mathbb B$ of the form\\<br>\begin{tikzcd}<br>K \ar[d,"r" left] \ar[r,"v"] & L \ar[d,"s"] \\<br>I \ar[r,"u" below] & J<br>\end{tikzcd}\\~\\<br>the canonical natural transformation\\~\\<br>$\coprod_v r^* \Longrightarrow s^* \coprod_u $\\~\\<br>is an isomorphism.<br>\end{itemize}<br>pg 10076<br><br></latex>
<latex>~\\<br>Let $\mathbb C$ be an arbitrary category. Consider the following statement:\\~\\<br>the family fibration $\vrt{Fam(\mathbb C)}{\mbf{Sets}}$ has (split) products/coproducts $\Leftrightarrow$<br>\mathbb C has set-indexed products/coproducts.\\~\\<br>Prove or disprove.<br></latex>	pg 10077<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The fibration $\vrt{UFam(\mbf{PER})}{\omega\text{-}\mbf{Sets}}$ of PERs over $\omega$-sets has both products and coproducts (along all maps in $\omega$-\mbf{Sets}).<br></latex>	pg 10077, lemma 1.9.6<br><br>
<latex>~\\<br>Consider the following statement.\\~\\<br>Consider a fibration for which each reindexing functor has both a left $\coprod$ and right $\prod$ adjoint. Then Beck-Chevalley holds for coproducts $\coprod$ if and only if it holds for products $\prod$.\\~\\<br>Prove or disprove.<br></latex>	pg 10077, lemma 1.9.7 at bottom.<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite limits. Consider the following statement:\\~\\<br>The codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$ on $\mathbb B$ has coproducts $\coprod_u$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10078, prop 1.9.8<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite limits. Consider the following statement:\\~\\<br>The codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$ on $\mathbb B$ has simple products $\Pi_{(I,J)}$ if and only if $\mathbb B$ is Cartesian closed.\\~\\<br>Prove or disprove.<br></latex>	pg 10078, prop 1.9.8 (ii)
<latex>~\\<br>Let $\mathbb B$ be a category with finite limits. Consider the following statement:\\~\\<br>The codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$ on $\mathbb B$ has products $\Pi_u$ if and only if $\mathbb B$ is locally Cartesian closed.\\~\\<br>Prove or disprove.<br></latex>	pg 10078, prop 1.9.8 (iii)
<latex>~\\<br>Let $\mathbb B$ be a category with finite limits. Consider the following statement:\\~\\<br>The codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$ on $\mathbb B$ has products $\prod_u$ if and only if $\mathbb B$ is Cartesian closed.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! Cartesian closed guarantees simple products, but not general products.<br>pg 10078, prop 1.9.8<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite limits. Consider the following statement:\\~\\<br>The codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$ on $\mathbb B$ has simple products.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR!<br>Cartesian closedness is required for simple products.<br>pg 10078, prop 1.9.8<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If a category $\mathbb B$ with finite limits is Carteisan closed/locally Cartesian closed, then its subobject fibration has simple/ordinary products $\Pi$.\\~\\<br>Prove or disprove.<br></latex>	pg 10079, cor 1.9.9<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration on a base category $\mathbb B$ with pullbacks. For each object $I \in \mathbb B$, write $I^*(p)$ for the fibration obtained by change-of-base in:<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb B/I \times_{\mathbb B} \mathbb E \ar[r] \ar[d,"I^*(p) = dom^*_I(p)" left] & \mathbb E \ar[d,"p"] \\<br>\mathbb B / I \ar[r,"dom_I" below] & \mathbb B <br>\end{tikzcd}<br>\end{center}<br>Then consider the following statement:\\~\\<br>$p$ has (ordinary) products $\Pi_{u}$ if and only if each fibration $I^*(p)$ has simple products $\Pi_{(v,w)}$.\\~\\<br>Prove or disprove.<br></latex>	pg 10079, theorem 1.9.10 at bottom<br>
<latex>~\\<br>What does it mean for a fibration to be \emph{complete}? What does it mean for a fibration to be \emph{cocomplete}?<br></latex>	pg 10080, def 1.9.11<br><br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibred $CCC$ with simple coproducts. Consider the following statement:\\~\\<br>For each pair of objects $I,J \in \mathbb B$ in the basis and each pair of objects $Y \in \mathbb E_I$, $Z \in \mathbb E_{I \times J}$ in appropriate fibres, the canonical morphism<br>\begin{center}<br>$\coprod_{(I,J)}(\pi^*_{I,J}(Y) \times Z) \longrightarrow Y \times \coprod_{(I,J)}(Z)$<br>\end{center}<br>is an isomorphism.\\~\\<br>Prove or disprove.<br></latex>	pg 10081, lemma 1.9.12 (i)<br>todo: add impostor?<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibred $CCC$ with coproducts. Consider the following statement:\\~\\<br>For each $u : I \to J$ in $\mathbb B$, $Y \in \mathbb E_J$, $Z \in \mathbb E_I$, the canonical morphism<br>\begin{center}<br>$\coprod_{u}(u^*(Y) \times Z) \longrightarrow Y \times \coprod_{u}(Z)$<br>\end{center}<br>is an isomorphism.\\~\\<br>Prove or disprove.<br></latex>	pg 10081, lemma 1.9.12 (ii)<br>todo: add impostor?<br>
<br><latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibred $CCC$ with simple coproducts. <br>For each pair of objects $I,J \in \mathbb B$ in the basis and each pair of objects $Y \in \mathbb E_I$, $Z \in \mathbb E_{I \times J}$ in appropriate fibres, there exists something called a \emph{Frobenius map}.<br>What is a Frobenius map?<br></latex><br>	pg 10081, in the proof of lemma 1.9.12 at bottom<br><br>Think of Y as the typing context of a case expression; it doesn't depend on the scrutinee J, but we can view that as a sort of dependence: trivial non-dependence. The two views are isomorphic; this is what the Frobenius condition is all about.
<latex>~\\<br>Let $\disp{\mathbb E}{p}{\mathbb B} \overset{(K,L)}{\longrightarrow} \disp{\mathbb D}{q}{\mathbb A}$ be a morphism of fibrations. Assume that $p$ and $q$ have simple products. Then what does it mean for $(K,L) : p \to Q$ to \emph{preserve simple products}?<br></latex>	pg 10082, def 1.9.13<br><br>
<latex>~\\<br>Let $\disp{\mathbb E}{p}{\mathbb B} \overset{(K,L)}{\longrightarrow} \disp{\mathbb D}{q}{\mathbb A}$ be a morphism of fibrations. Assume that $p$ and $q$ have simple products. Then what does it mean for $(K,L) : p \to Q$ to \emph{preserve simple coproducts}?<br></latex>	pg 10082, def 1.9.13<br>
<latex>~\\<br>Let $\disp{\mathbb E}{p}{\mathbb B} \overset{(K,L)}{\longrightarrow} \disp{\mathbb D}{q}{\mathbb A}$ be a morphism of fibrations. Assume that $p$ and $q$ have products. Then what does it mean for $(K,L) : p \to q$ to \emph{preserve products}?<br></latex>	pg 10083, (ii) at top<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration and $K : A \to B$ a finite limit (product) preserving functor. Consider the following statement:<br>\begin{center}<br>$p$ has (simple) products/coproducts $\Rightarrow$ $K^*(p)$ has (simple) products/coproducts<br>\end{center}<br>Moreover, the morphism of fibrations $K^*(p) \to q$ preserves these.\\~\\<br>Prove or disprove.<br></latex>	pg 10083, lemma 1.9.14<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration and $K : A \to B$ a finite limit (product) preserving functor. Consider the following statement:<br>\begin{center}<br>$p$ has (simple) products/coproducts $\Leftrightarrow$ $K^*(p)$ has (simple) products/coproducts<br>\end{center}<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 10083, lemma 1.9.14<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The fibration $\vrt{\mbf{Sign}}{\mbf{Sets}}$ of many-typed signatures has products and coproducts.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10083, example 1.9.15<br>
What is a <i>phase space</i>?	pg 11956<br>
<latex>~\\<br>How is the formula $X \multimap Y$ interpreted under phase semantics? <br></latex>	pg 11956, section 2.1.1<br><br>
<latex>~\\<br>How is $X^{\bot}$ interpreted under phase semantics?<br></latex>	pg 11956
<latex>~\\<br>What is a \emph{fact}? Under what conditions is $X \multimap Y$ a fact? <br></latex>	pg 11956<br>
<latex>~\\<br>Give the phase semantic interpretations for times ($\otimes$), par ($\upand$), and $\mbf{1}$.<br></latex>	<latex>~\\<br>For the semantics of times, note that some tasks can be accomplished using the combination of resources $n$ and $m$ that cannot be decomposed into two separate tasks, one accomplished with $n$ and the other accomplished with $m$; the inner negation produces a set that *includes these tasks*. The outer negation then computes the set of all resources that can be used to compute both tasks which requiring m and n \emph{separately} and tasks which require m and n \emph{together}.<br>\\~\\<br>For par, if $X$ is a task and $Y$ is a task, then $X^{\bot}$ is the set of resources which can be used to compute $X$ and likewise for $Y^{\bot}$. $X \upand Y$ is then the set of all tasks which can be computed using the resources required to perform the combination of tasks X and Y. <br>\\~\\<br>The monoidal element $1$ can be considered an empty set of resources due to its monoidal unitality.<br>The tasks it can accomplish are all in $\bot$, which represents ``finished'' states in which there are no tasks left to perform. Then $\mbf{1}$ contains all resources which can be used to accomplish nothing (could we consider these resources ``affine''?)<br>\\~\\<br>pg 11956<br></latex><br><br><br><br>
<latex>~\\<br>Give the phase semantic interpretations for plus ($\oplus$), with ($\&$), and $\mbf{zero}$ ($\mbf{0}$).<br></latex>	<latex>~\\<br>Let $X$ and $Y$ be sets of resources. Then $(X \cup Y)^{\bot}$ is the set of tasks which may either be accomplished using a resource which may be either in $X$ or $Y$ (we don't know which). $(X \cup Y)^{\bot \bot}$ is the set of all resources which may accomplish those tasks; could this set of resources contain resource which are neither in $X$ nor $Y$? That seems to be the purpose of the double negation.<br>\\~\\<br>Since a resource of $X \& Y$ may be used either as a resource of $X$ or a resource of $Y$, we define it as the intersection.<br>\\~\\<br>$\emptyset^{\top}$ is the set of all possible resources. $\emptyset^{\top \top}$ is the set of tasks which can be accomplished by any resource. <br></latex>
<latex>~\\<br>Give the phase semantics of true $(\top)$, $! X$, $? X$.<br></latex>	<latex>~\\<br>I'm not sure how to interpret $\mbf{true}$. A state about which nothing is known? How does that fit into the resources/tasks dichotomy? The task is to take the current state to an element of $\bot$. I don't know how that squares with true's sequent calculus rule.<br>\\~\\<br>Since $I = \mbf{1}$ consists of all resources which do not require annihilation (since they take elements of $\bot$ to elements of $\bot$), ($X \cap I$) consists of those resources of $X$ which do not require balance.<br>If $x \in I$ then $xx \in I$, etc.<br>($X \cap I$)^$\bot$ consists of the tasks that can be solved by them, and $(X \cap I)^{\bot \bot}$.<br>It's important that $X$ here is a \emph{fact}, because if $x \in X$ and $y \in X^{\bot}$ (i.e. $xy \in \bot$) then $xxy \in \bot$, and so $xx \in X^{\bot \bot} = X$.<br>\\~\\ <br>TODO: talk a bit about $?$<br></latex>
<latex>~\\<br>What are the differences between $\kappa$DOT and Amin's Wadlerfest DOT?<br></latex>	see the bullet point list above section 2.1.1 on pg 22132<br>also, see the highlighted parts of figure 2 on pg 22133<br>
<latex>~\\<br>For a field declaration in $\kappa$DOT, what is the \emph{getter} type of the field? What is its \emph{setter} type?<br></latex>	pg 22132, bottom right corner, section 2.1.1<br><br>
<latex>~\\<br>Give the syntactic form of constructors in $\kappa$DOT.<br></latex>	pg 22132, bottom right corner, section 2.1.1<br><br>
<latex>~\\<br>What is the difference between the type syntax for field declarations between Wadlerfest DOT and $\kappa$DOT?<br></latex>	pg 22133, figure 2 (see shaded parts)<br><br>
<latex>~\\<br>Give the term syntax for $\kappa$DOT.<br></latex>	pg 22133<br>
<latex>~\\<br>Give $\kappa$DOT's syntax for:<br>\begin{itemize}<br>\item Stacks<br>\item Heaps<br>\item Configurations<br>\item Answers<br>\end{itemize}<br></latex>	pg 22133, bottom left corner<br><br>
<latex>~\\<br>Give the $\kappa$DOT reduction rules for <br>\begin{itemize}<br>\item Project <br>\item Assignment<br>\item Application<br>\end{itemize}<br></latex>	pg 22133, fig 3<br><br>
<latex>~\\<br>Give $\kappa$DOT reduction rules for<br>\begin{itemize}<br>\item New<br>\item Return<br>\end{itemize}<br></latex>	pg 22133, figure 3<br>
<latex>~\\<br>Give $\kappa$DOT reduction rules for:<br>\begin{itemize}<br>\item Let-Loc<br>\item Let-Lit<br>\item Let-Push<br>\end{itemize}<br></latex>	pg 22133<br>
<latex>~\\<br>Explain how let frames and return frames work in $\kappa$DOT.<br></latex>	pg 22133 botom right,<br>pg 22134 top left<br>see also fig 3 on pg 22133<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In $\kappa$DOT, field labels map to values, so multiple field reads do not cause redundant reevaluation.\\~\\<br>True or false?<br></latex>	IMPOSTOR<br>pg 22134, section 2.2.2<br><br>
<latex>~\\<br>State the type safety (i.e. soundness) theorem for $\kappa$DOT.<br></latex>	pg 22134, bottom left corner<br>
<latex>~\\<br>For a context $\Gamma$ and an (dynamic) environment $\Sigma$, what does $\Gamma \sim \Sigma$ mean in $\kappa$DOT?<br></latex>	pg 22134, def 3.2, bottom right<br>
<latex>~\\<br>Give the $:=\text{-}I$ and $Lit\text{-}I$ typing rules of $\kappa$DOT.<br></latex>	pg 22134, right column<br><br>
<latex>~\\<br>Give the $K\text{-}E$ and $K\text{-}I$ typing rules of $\kappa$DOT.<br></latex>	pg 22134<br>
Give the definition of standard untyped lambda calculus and its equational theory.	pg 19335, def 5<br><br>
<latex>~\\<br>Give the definition of the natural deduction system for minimal logic $NJ_{\Rightarrow}$.<br></latex>	pg 19336, definition 7, at bottom<br><br>
<latex>~\\<br>Why is it problematic to view the ``Curry-Howard Correspondence'' as a bijection? How instead should we view it?<br></latex>	it's a functor.<br><br>see pg 19337, near top<br>may be useful to open two copies of MiscStudy to compare to fig 1 & 2 on page 19336<br>
<latex>~\\<br>What symbol does Graham-Lagrand for the unique arrow to the terminal object instead of $!_A$?<br></latex>	<latex>~\\<br>$1_A$... that is pretty confusing.<br>pg 19338 top<br></latex>
<latex>~\\<br>State the ``soundness and completeness'' theorem relating the reductions of the simply-typed $\lambda$-calculus to the equality of morphisms in a $CCC$.<br></latex>	pg 19339, theorem 4<br><br>
<latex>~\\<br>How would we go about encoding the $(I,K,S)$-combinatoric system in the simply typed lambda calculus. How can we piggy back off of STLC to derive a categorical semantics for $(I,K,S)$ and what properties of this encoding can we use determine that the categorical semantics is sound?<br></latex> 	pg 19339, theorem 5<br>
Read section 1.1.4, pgs 19339 to 19340<br>	pg 19339<br>
<latex>~\\<br>By identifying one of the atomic types of STLC as $\bot$, intuitionistic negation can be defined as follows:<br>$\neg A \doteq A \Rightarrow \bot$. With this definition, the following rules are instances of those of the simply-typed $\lambda$-calculus:<br><br>\begin{mathpar}<br>\inferrule<br>  {\Gamma,x:A \vdash M : \bot}<br>  {\Gamma \vdash \lambda x. M : \neg A}<br>\and<br>\inferrule<br>  {\Gamma \vdash M : \neg A \\ \Gamma \vdash N : A}<br>  {\Gamma \vdash M~N : \bot}<br>\end{mathpar}<br><br>But intuitionistic logic has another rule which we cannot account for without extending the STLC:<br><br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \vdash \bot}<br>  {\Gamma \vdash A}<br>\end{mathpar}<br><br>Explain the extension that we must make to STLC to obtain this rule. Give syntax, typing, reduction semantics, and a categorical interpretation.<br></latex>	pg 19340, Example 1.<br>
<latex>~\\<br>Assuming EFQ (intuitionistic absurdity), there are three equivalent (under EFQ) axiom schemes we can add to extend intuitionistic logic to classical logic. Give each, and name them.<br></latex>	pg 19341, near top<br><br>
<latex>~\\<br>If we look at categorical interpretations of the rules of classical logic, it suggests that applying the Curry-Howard view to classical logic should not be fruitful from a proof theoretic standpoint. Why is this?<br></latex>	<latex>~\\<br>pg 19341\\~\\<br>``\\<br>A CCC with initial object $\bot$ and such that every object A is naturally isomorphic to $\bot^{\bot^A}$,<br>collapses to a boolean algebra: there is at most 1 morphism between any 2 objects.<br>That means that such a category would not distinguish two proofs of the same theorem,<br>which is rather useless for a theory of proofs, or for the proofs-as-programs paradigm.\\<br>''<br></latex><br><br>
<latex>~\\<br>We could interpret the object type $Point \doteq \{ x,y : Int \}$ semantically as the record type obtained by solving the type equation $Point = \langle x,y : Point \to Int \rangle$ (where $\langle \ldots \rangle$ is a record type constructor). What is the problem with this? Roughly, what is the solution to this problem?<br></latex>	pg 3108, right column, near top<br>
<latex>~\\<br>When interpreting Abadi and Cardelli's calculus in an untyped universe, terms are mapped to \underline{~~~~~~~~~~}.<br>Errors are represented as \underline{~~~~~~~~~~}. and objects are represented as \underline{~~~~~~~~~~}.<br></latex>	pg 3108, section 14.1<br>
<latex>~\\<br>The domain equation for Abadi and Cardelli's semantics is:<br>$$D \cong W + (D \to D) + (L \to D)_{\bot}$$<br>Give definitions for the various components of this equation. Does $+$ mean disjoint union (coproduct)?<br></latex>	pg 3109, top left<br><br>
<latex>~\\<br>Give a step-by-step walkthrough of solving the domain equation:<br>$$D \cong W + (D \to D) + (L \to D)_{\bot}$$<br></latex>	pg 3109, "It is important for our purposes to..."<br>
<latex>~\\<br>What is a \emph{complete partial order}?<br></latex>	pg 3109, first bullet<br>
<latex>~\\<br>Abadi and Cardelli's domain-theoretic semantics requires a few embedding/retraction pairs in the DCPO category. What are they?<br></latex>	pg 3109, second bullet point<br><br>
<latex>~\\<br>What is the purpose of domain theory? Give a brief informal explanation.<br></latex>	pg 19630, full page.<br>pg 19631, top of page<br>
<latex>~\\<br>We have two distinct classes of data values: those with canonical representations, and those without canonical representations. Give some examples of data values from each class.<br></latex>	pg 19630, bottom paragraph<br>
Roughly and informally, how do we describe an infinite data value in domain theory?	pg 19630 bottom / 19631 top<br>
<latex>~\\<br>There are two separate kinds of finite values in higher order data domains. What are they?<br></latex>	pg 19631, bullet points<br>
<latex>~\\<br>Let $(B, \sqsubseteq)$ be a poset.<br>What does it mean for a subset $S$ of $B$ to be \emph{consistent}?<br></latex>	It has some upper bound in B.<br>pg 19632<br>
<latex>~\\<br>Let $(B,\sqsubseteq)$ be a poset.<br>What does it mean for a subset $S$ of $B$ to be \emph{progressive}?<br></latex>	S contains no maximal element.<br>pg 19632, def 1.4<br>
<latex>~\\<br>What is a \emph{complete partial order}, according to Cartwright?<br></latex>	pg 19632, def 1.6 near bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every $cpo$ has a least element.\\~\\<br>Prove or disprove.<br></latex>	true. bottom is the least upper bound of the empty set, which is directed.<br>pg 19632, claim 1.7 at bottom<br>
<latex>~\\<br>What is a \emph{finitary basis}?<br></latex>	pg 19633, def 1.8<br>
<latex>~\\<br>Why are the elements of finitary bases called \emph{propositions}?<br></latex>	pg 19633, below def 1.8<br><br>
<latex>~\\<br>Why does every finitary basis have a $\bot$ element? What does this $\bot$ element represent intuitively?<br></latex>	pg 19633, below def 1.8<br><br>
<latex>~\\<br>Let $B = \{ \bot, 0\bot, 1\bot, 00, 01, 10, 11 \}$ where $0 \bot$ describes strings that start with $0$ and are indeterminate past that point; 00 describes the string consisting of two consecutive 0's, etc. Let $\sqsubseteq$ be the  prefix (or ``approximates'') partial order on $B$. Consider the following statement:\\~\\<br>$B$ is a finitary basis.\\~\\<br>Prove or disprove.<br></latex>	true. pg 19633, example 1.9<br><br>
<latex>~\\<br>Let $B = \{ (n,m) \mid n,m \in \mathbb N \cup \{ \infty \}, n \leq m \}$ where the proposition $(n,m)$ represents an integer $x$ such that $n \leq x \leq m$. Let $\sleq$ be defined as<br>$$ (n,m) \sqsubseteq (j,k) \Leftrightarrow n \leq j \text{ and } k \leq m $$<br>Consider the following statement:\\~\\<br>$\langle B, \sqsubseteq \rangle$ is a finitary basis.\\~\\<br>Prove or disprove.<br></latex>	true. pg 19633, example 1.10<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $\langle B, \sqsubseteq \rangle$ be a finitary basis. Let $p \in B$. What does $\mathcal I_p$ denote?<br></latex>	<latex>~\\<br>It's $\downarrow p$\\<br>pg 19634<br></latex>
<latex>~\\<br>For a finitary basis $\mbf{B}$, what does it mean for $\mathcal I \subseteq \mbf{B}$ to be an \emph{ideal}?<br></latex>	pg 19634, def 1.11<br><br>
<latex>~\\<br>Let $\mbf{B}$ be a finitary basis. How do we define the domain $\mathcal D_{\mbf{B}}$ determined by $\mbf{B}$?<br></latex>	pg 19635, def 1.12<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The domain $\mathcal D_{\mbf{B}}$ determined by a finitary basis $\mbf{B}$ is a complete partial order.\\~\\<br>Prove or disprove.<br></latex>	pg 19635, claim 1.14<br><br>
<latex>~\\<br>What does it mean for an element $e$ of a $cpo$ $\mathcal D = \langle D, \sqsubseteq \rangle$ to be \emph{finite}?<br></latex>	pg 19636, definition 1.17 at top<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>An element of the domain $\mathcal D_{\mbf{B}}$ of ideals determined by a finitary basis $\mbf{B}$ is finite iff<br>it is principal. (Recall: we're using an idiosyncratic definition of finite, which does not mean ``finite as a set''.)\\~\\<br>Prove or disprove.<br></latex>	pg 19636, theorem 1.18<br><br>
<latex>~\\<br>Let $\mathcal D$ be the domain determined by a finitary basis $\mbf{B}$. <br>Consider the following statement:\\~\\<br>For any $\mathcal I \in \mathcal D$, $\mathcal I = \bigsqcup \{ \mathcal I' \in \mathcal D^{0} \mid \mathcal I' \sqsubseteq \mathcal I \}$.\\~\\<br>Prove or disprove.<br></latex>	pg 19636, theorem 1.19<br><br>
<latex>~\\<br>Let $\mbf{B} = \langle B, \sqsubseteq \rangle$ be a partial order. What does it mean for an element $b \in B$ to be \emph{partial}? What does it mean for an element $b \in B$ to be \emph{total}?<br></latex>	Partial and total are just synonyms for non-maximal and maximal, respectively.<br>pg 19636, def 1.20<br>
<latex>~\\<br>Read example 1.21 on page 19636. (may want to open another copy of the pdf to page 19633, where the referenced basis is defined)<br></latex>	pg 19636
<latex>~\\<br>Read example 1.22 on pg 19636, referring to the finitary basis defined in example 1.10 on page 19633.<br></latex>	pg 19636<br>
<latex>~\\<br>Let $\Sigma = \{ 0, 1 \}$, and let $\Sigma^{*}$ be the set of all finite strings over $\Sigma$, including the empty string. $\Sigma^*$ forms a finitary basis under the prefix ordering on strings. Consider the domain generated by this finitary basis. What are its principal ideals? What are its non-principal ideals?<br></latex>	pg 19637, example 1.23<br><br>
<latex>~\\<br>What does Cartwright write $A \approx B$ to denote? <br></latex>	<latex>~\\<br>It means that A is isomorphic to B, see pg 19637, def 1.24; a rather idiosyncratic notation. The typical notation is $\cong$.<br></latex><br><br>
<latex>~\\<br>Let $\mathcal D$ be the domain determined by a finitary basis $\mbf{B}$. Consider the following statement:\\~\\<br>$\mathcal D^{0}$ forms a finitary basis $\mbf{B}'$ under the approximation ordering $\subseteq$ (restricted to $\mathcal D^{0}$). Moreover, the domain $\mathcal E$ determined by the finitary basis $\mbf{B'}$ is isomorphic to $\mathcal D$.\\~\\<br>Prove or disprove.<br></latex>	pg 19637<br>definition of D^0 is on page 19636, below def 1.17<br>
<latex>~\\<br>Let $\mathcal D$ be the domain determined by a finitary basis $\mbf{B}$. Let $S$ be a subset of $\mathcal D$. Consider the following statement:\\~\\<br>$\bigcap S \in \mathcal D$ and $\bigcap S = \bigsqcap S$\\~\\<br>Prove or disprove.<br></latex>	pg 19638, theorem 1.27<br><br>
<latex>~\\<br>Let $\mathcal D$ be the domain determined by a finitary basis $\mbf{B}$. Let $S$ be a directed subset of $\mathcal D$. Consider the following statement:\\~\\<br>$\bigcup S \in \mathcal D$ and $\bigcup S = \bigsqcup S$\\~\\<br>Prove or disprove.<br></latex>	true. pg 19638, thm 1.27<br>
<latex>~\\<br>Let $\mathcal D$ be the domain determined by a finitary basis $\mbf{B}$. Let $S$ be a subset of $\mathcal D$. Consider the following statement:\\~\\<br>$\bigcup S \in \mathcal D$ and $\bigcup S = \bigsqcup S$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! This is guaranteed to be true if S is directed, but it is not true in general.<br>pg 19638, theorem 1.27<br>
<latex>~\\<br>Intuitively, why are program operations considered monotone by domain theorists?<br></latex>	pg 19640, top paragraph.<br>
<latex>~\\<br>When an operation $f$ is applied to the input value $x$, $f$ gathers information about $x$ by asking the program computing $x$ to generate \underline{~~~~~~~~~~~~~~~~~~~~}.<br></latex>	pg 19641, top paragraph. read the whole paragraph.<br><br><br>
<latex>~\\<br>A computable operation $f$ mapping domain $\mathcal A$, with basis $\mbf{A}$, into domain $\mathcal B$, with basis $\mbf{B}$, can be formalized as a relation $F \subseteq \mbf{A} \times \mbf{B}$ satisfying which two properties?<br></latex>	pg 19641, second paragraph. 
<latex>~\\<br>What is an \emph{approximable mapping}?<br></latex>	pg 19641, def 2.1<br><br>"<br>Conditions 1, 2, and 3 force the image of an input ideal to be an ideal. Con-<br>dition 4 states that the function on ideals associated with F is monotonic.<br>"<br>
<latex>~\\<br>What does Cartwright use the notation $Map(\mbf{A},\mbf{B})$ for?<br></latex>	It's a essentially a homset. The finitary bases form objects of a category whose arrows are approximable mappings.<br>pg 19641<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be the domains determined by finitary bases $\mbf{A}$ and $\mbf{B}$, respectively. What does it mean for a function $f : \mathcal A \to \mathcal B$ to be \emph{continuous}?<br></latex>	pg 19642<br>
<latex>~\\<br>What does Cartwright use the notation $Fun(\mathcal A, \mathcal B)$ for?<br></latex>	<latex><br>the homset of continuous functions between \mathcal A and \mathcal B\\<br>pg 19642<br></latex>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be domains determined by finitary bases, and let $f : \mathcal A \to \mathcal B$ be continuous. Consider the following statement:\\~\\<br>For every directed subset $S$ of $\mathcal A$, $f(\bigsqcup S) = \bigsqcup \{ f(\mathcal I) \mid \mathcal I \in S \}$.~\\~\\<br>Prove or disprove.<br></latex>	pg 19642, thm 2.3<br>todo: add impostor?<br><br>
<latex>~\\<br>How, intuitively, should we think of the connective $1$?<br>Give and explain the rule $1R$. Give an explain the rule $1L$. Show that these rules are in harmony.<br></latex>	we should think of it as the unit of simultaneous conjunction. <br>pg 20251, 20252 section 1<br>
<latex>~\\<br>As a rule of thumb, what makes the multiplicative unit 1 of linear logic useful?<br></latex>	<latex>~\\<br>It can be used to express the elimination of resources via the idiom $A \multimap 1$.<br></latex>
<latex>~\\<br>Assume that we replace the \emph{standard} left rule for simultaneous conjunction with the following two rules<br>\begin{mathpar}<br>\inferrule<br>  {\Delta,A \vdash C}<br>  {\Delta,A \otimes B \vdash C}<br>\and<br>\inferrule<br>  {\Delta,B \vdash C}<br>  {\Delta,A \otimes B \vdash C}<br>\end{mathpar}<br>Are these rules in harmony, why or why not?<br></latex>	pg 20252, section 2<br>spills over to pg 20253<br>
<latex>~\\<br>Assume that we replace the \emph{standard} left rule for simultaneous conjunction with the following two rules<br>\begin{mathpar}<br>\inferrule<br>  {\Delta,A \vdash C}<br>  {\Delta,A \otimes B \vdash C}<br>\and<br>\inferrule<br>  {\Delta,B \vdash C}<br>  {\Delta,A \otimes B \vdash C}<br>\end{mathpar}<br>Prove that these rules allow \emph{weakening} as a derived rule of inference.<br></latex>	pg 20254, top<br><br>
<latex>~\\<br>What is the meaning of the $\&$ connective? Give the $\& R$, $\& L_1$, and $\& L_2$ rules. Prove they are in harmony.<br></latex>	pg 20254 / 20255<br>
<latex>~\\<br>How, intuitively, should we think of the nullary connective $\top$ in linear logic? What are its rules? <br></latex>	We should think of it as the unit of additive conjunction &. <br>pg 20255<br>
<latex>~\\<br>Explain the binary connective $\otimes$ of linear logic. What are its rules? Show that they are in harmony.<br></latex>	pg 20255, "5 Disjunction"<br>
<latex>~\\<br>How, intuitively, should we think of the connective $\mbf{0}$ of linear logic? What are its rules? Are they in harmony?<br></latex>	we can think of it as the unit of disjunction, or as a contradiction.<br>pg 20256<br>
<latex>~\\<br>When we add the notion of persistent truth to intuitionistic linear logic, we introduce two new rules called $copy$ and $cut^!$. Give and explain these rules.<br></latex>	pg 20256, 20257, Section 7 "Persistent Truth"<br>
<latex>~\\<br>What is the meaning of the unary $!$ operator of linear logic? Give its $!L$ and $!R$ rules and show that they are in harmony.<br></latex>	pg 20257/20258, Section 8 "Of course"<br>
<latex>~\\<br>For an approximable mapping<br>$$ F \subseteq \mbf{A} \times \mbf{B}$$<br>If $d \in \mathcal A$, what does $\mbf{apply}(F,d)$ denote? What is the \emph{function determined by} F? <br></latex>	pg 19642, def 2.4<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any approximable mapping $F \subseteq \mbf{A} \times \mbf{B}$, the function determined by $F$ is continuous.\\~\\<br>Prove or disprove.<br></latex>	pg 19642<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any approximable mapping $F \subseteq \mbf{A} \times \mbf{B}$, and any $d \in \mathcal A$,<br>$apply(F,d)$ is an element of $\mathcal B$.\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>remember: by convention, $\mathcal A$ is the domain generated by the finitary basis $\mbf{A}$.\\<br>pg 19642, remark 2.5 at bottom, spills onto pg 19643<br></latex>
<latex>~\\<br>Let $\mbf{A}$ and $\mbf{B}$ be finitary bases. Consider the following statement:\\~\\<br>The partial order $Map(\mbf{A},\mbf{B})$ consisting of the set of approximable mappings over $\mbf{A}$ and $\mbf{B}$ is isomorphic to the partial order $\mathcal A \to_c \mathcal B$ of continuous functions mapping $\mathcal A$ into $\mathcal B$. \\~\\<br>Prove or disprove.<br></latex>	true. pg 19643, theorem 2.6.<br>
<latex>~\\<br>Define the function $\mathbb F : Map(\mbf{A},\mbf{B}) \to (\mathcal A \to_c \mathcal B)$ by<br>$$\mathbb F(F) = f$$<br>where $f$ is the function defined by the equation<br>$$f(d) = apply(F,d)$$<br>for all $d \in \mathcal A$. Consider the following statement:~\\<br><br>For any approximable mappings $F,G \subseteq \mbf{A} \times \mbf{B}$<br>\begin{itemize}<br>\item $\forall a \in \mbf{A}, b \in \mbf{B}$.~a~F~b \Longleftrightarrow \mathcal I_b \sqsubseteq \mathbb F(F)(\mathcal I_a)$<br>\item $F \subseteq G \Longleftrightarrow \forall a \in \mbf{A}.~\mathbb{F}(F)(a) \sqsubseteq \mathbb F(G)(a)$<br>\end{itemize} <br>Prove or disprove.<br></latex>	pg 19643, lemma 2.7 (i)<br>todo: add impostor?<br>
<latex>~\\<br>Define the function $\mathbb F : Map(\mbf{A},\mbf{B}) \to (\mathcal A \to_c \mathcal B)$ by<br>$$\mathbb F(F) = f$$<br>where $f$ is the function defined by the equation<br>$$f(d) = apply(F,d)$$<br>for all $d \in \mathcal A$. Consider the following statement:~\\~\\<br>The function $\mathbb F$ is one-to-one and onto.<br>\\~\\<br>Prove or disprove.<br></latex>	pg 19643, lemma 2.7 (ii)<br>
<latex>~\\<br>Recursive function calls can be implemented using continuations. How does this work?<br></latex>	pg 19341, section 1.2 <br>pg 19342, full page<br>
<latex>~\\<br>Explain the \emph{call-with-current-continuation} construct $cc$. What logical axiom does its typing rule correspond to?<br></latex>	pierce's law<br>pg 19343<br>
Read the bottom of pg 19343, starting with "these types..." down to section 1.3 on pg 19344<br>	pg 19343<br>
<latex>~\\<br>Give the syntax of terms and commands for Parigot's $\lambda\mu$-calculus. Also, give their typing rules.<br></latex>	pg 19344, section 1.3,<br>spills to pg 19345: make sure to read the helpful paragraph directly below the figure<br><br><br>
<latex>~\\<br>Present the classical logic natural deduction system underlying the type system for the $\lambda \mu$-calculus.<br>This system has two forms of sequent; what are they, and how do we interpret each one?<br></latex>	pg 19345 bottom paragraph / spills to 19346<br>
<latex>~\\<br>State the subject reduction theorem for the $\lambda \mu$ calculus. Prove the cases for $\lambda$ application, $\mu$ application, and ``continuation renaming''.<br></latex>	pg 19346, theorem 6<br>
<latex>~\\<br>In the $\lambda \mu$-calculus, we can define a term implementing $cc$. Give this term, and give its typing derivation, which shows that $cc$ is essentially Peirce's law.<br></latex>	pg 19346, remark 7<br><br>
Read example 2.8 on pg 19644. Verify that P is an approximable mapping and that p is the continuous function determined by P.<br>	pg 19644<br>
<latex>~\\<br>Given the domain $\mathcal B$ described in example 2.8 of pg 19644, let $g : \mathcal B \to \mathcal B$ be the function defined by the equation.<br><br>\[<br>g(x) = \left\{ \begin{array}{ll}<br>  0^{n+1}y & \text{if } x = 0^n1^k0y \\<br>  \bot_D    & otherwise \end{array} \right <br>\]<br><br>Confirm that $g$ is continuous and determine the approximable mapping $G$ corresponding to $g$.<br></latex>	pg 19645, example 2.9 at top<br><br>
<latex>~\\<br>Read theorem 2.10 on pg 19645. Prove this theorem without looking at the next page.<br></latex>	pg 19645, bottom<br><br>
Take a gander at corollary 2.11 on pg 19647. Does the proof make any sense to you? Because it didn't make sense to me on first reading. What is the "partial order of finitary bases"?<br><br>	pg 19647<br>
<latex>~\\<br>What do $\mbf{FB}$ and $\mbf{Dom}$ denote?<br></latex>	pg 19647, paragraph above section 2.4<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every isomorphism between domains is characterized by an approximable mapping between finitary bases. Additionally, finite elements are always mapped to finite elements.\\~\\<br>Prove or disprove<br></latex>	pg 19648, full page<br>
<latex>~\\<br>The difficulties met in trying to use $\neg \neg A \to A$ (or the classical absurdity rule) as a type for control operators is not really due to classical logic: what is it due to?<br></latex>	the restriction of one conclusion<br>pg 23548, first full paragraph<br><br>
<latex>~\\<br>Give the identity, $\to_i$, and $\to_e$ rules of classical natural deduction.<br></latex>	pg 23549<br>
<latex>~\\<br>Give the $\neg_i$ and  $\neg_e$ rules of classical natural deduction.<br></latex>	pg 23549<br>
<latex>~\\<br>There are two $\forall_i$ and two $\forall_e$ rules of classical natural deduction. Give all four rules.<br></latex>	the top two are for quantifying over terms, and the bottom two are for quantifying over formulas.<br>pg 23549<br>
<latex>~\\<br>When examining a classical natural deduction rule, what are the \emph{active} formulas? Which is the \emph{main} formula? <br></latex>	pg 23549, below the figure containing all rules.<br><br>
<latex>~\\<br>Write the $\to$ rules of classical natural deduction using the ``no-sequent'' presentation.<br></latex>	pg 23549, point (ii) near bottom<br>
Cuts are understood as "obstacles" to ____________.	the subformula property: the formulas occuring in the proof are all subformulas of the formulas in the conclusion.<br>pg 23550, section 2.3<br>
<latex>~\\<br>What is the difference between a \emph{logical cut} and a \emph{structural cut}? Which of these two is specific to \emph{classical} natural deduction?<br></latex>	pg 23550, 23551 (open up two pdf viewers: one on each page)<br>
<latex>~\\<br>Explain the difference between $\lambda$ variables and $\mu$ variables. What role do they play in the algorithmic interpretation of classical natural deduction?<br></latex>	pg 23552, section 2.4<br>
<latex>~\\<br>We can extend the basic classical natural deduction system so that sequents identify a \emph{current formula}. What is the \emph{current formula}, and what is its purpose?<br></latex>	pg 23552, section 2.4, second paragraph<br><br><br>
<latex>~\\<br>One way of understanding the $\lambda \mu$-calculus is to consider it as an extension of the $\lambda$-calculus where one has the possibility to \underline{~~~~~~~~~~~~~~~~~}.<br></latex>	pg 23553, top of section 3.1<br><br>
<latex>~\\<br>Provide the mutually inductive definitions of $\mbf{named}$ and $\mbf{unnamed}$ terms in the $\lambda \mu$-calculus.<br></latex>	pg 23553, section 3.1<br>
<latex>~\\<br>Give the three basic reduction rules of the $\lambda \mu$-calculus. What is their proof-theoretic significance?<br></latex>	pg 23553, near bottom<br>open a separate pdf viewer to pg 23551 to see the corresponding proof normalization rules<br><br>
<latex>~\\<br>Contrary to the $\lambda$-calculus, in the $\lambda \mu$-calculus there are terms which give always the same result, regardless of the number of arguments they are applied to. Give a term $\tau$ such that for each $n \in \mathbb N$, $(((\tau~x)~y)~z_1 \ldots z_n) \triangleright ((\tau~x)~y)$<br></latex>	pg 23554, example near top<br>
<latex>~\\<br>There is a reduction for the operator $\mu$ which is similar to the $\lambda$-calculus' $\eta$-reduction. Give this reduction.<br></latex>	pg 23554, remark above section 3.2<br>
<latex>~\\<br>Give the Var, Abs, and App rules for Parigot's typed $\lambda \mu$-calculus.<br></latex>	pg 23555
<latex>~\\<br>Give the two forall elimination rules for Parigot's typed $\lambda \mu$-calculus.<br></latex>	pg 23555<br>
<latex>~\\<br>Give the two forall introduction rules for Parigot's typed $\lambda \mu$-calculus.<br></latex>	pg 23555<br>
<latex>~\\<br>Give the two ``naming'' typing rules of Parigot's $\lambda \mu$-calculus.<br></latex>	pg 23555<br>
<latex>~\\<br>How do we interpret the unary logical connective $\neg$ in Parigot's typed $\lambda \mu$-calculus?<br></latex>	pg 23555, near bottom<br>
<latex>~\\<br>Give a term of Parigot's typed $\lambda \mu$-calculus of type $\neg A \to (A \to \forall X~X)$.<br>Also give its typing derivation.<br></latex>	pg 23556, top example.<br>
<latex>~\\<br>Give a term of type $\neg \neg A \to A$ in Parigot's typed $\lambda \mu$-calculus. Give its typing derivation.<br></latex>	pg 23556 bottom / 23557 top<br>
<latex>~\\<br>Give a term of type $((A \to B) \to A) \to A$ in Parigot's $\lambda \mu$-calculus. Give its typing derivation.<br></latex>	pg 23557, lower example<br><br>
<latex>~\\<br>In the proof of prop 1.9.3 (i) on pg 10075, Jacobs demonstrates an adjunction, but does not demonstrate Beck-Chevalley. Demonstrate that the adjunction satisfies Beck-Chevalley.<br></latex>	pg 10075
<latex>~\\<br>Let $\mbf{D}$ and $\mbf{E}$ be the finitary bases generating domains $\mathcal D$ and $\mathcal E$. What is the \emph{product basis} $\mbf{D} \times \mbf{E}$. Prove that it is, in fact, a finitary basis.<br></latex>	pg 19651,def 3.1, theorem 3.2<br><br>
<latex>~\\<br>For a finitary basis $\mbf{D} \times \mbf{E}$, what are the \emph{projection mappings} $P_0$ and $P_1$?<br>Prove that they are, in fact, approximable mappings.<br></latex>	pg 19652, def 3.3, part of thm 3.4<br><br><br><br>
<latex>~\\<br>For finitary bases $\mbf{D}, \mbf{E},$ and $\mbf{A}$, and approximable mappings <br>$F \subseteq \mbf{A} \times \mbf{D}$ and $G \subseteq \mbf{A} \times \mbf{E}$,<br>what is the \emph{paired mapping} $\langle F, G \rangle$. Prove that it is, in fact, an approximable mapping.<br></latex>	pg 19652, definition 3.3, part of thm 3.4<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>P_0 \circ \langle F,G \rangle = F\\~\\<br>Prove or disprove.<br></latex>	It's true. pg 19652, thm 3.4.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For $[d,e] \in \mbf{D} \times \mbf{E}$ and $d' \in \mbf{D}$, $[d,e]~P_0~d' \Longleftrightarrow d' \sqsubseteq d$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 19652. <br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For approximable mapping $H \subseteq \mbf{A} \times (\mbf{D} \times \mbf{E})$, $H = \langle (P_0 \circ H), (P_1 \circ H)\rangle$.\\~\\<br>Prove or disprove.<br></latex>	pg 19652, theorem 3.4<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A relation $F \subseteq (\mbf{A} \times \mbf{B}) \times \mbf{C}$ is an approximable mapping iff<br>for every $a \in \mbf{A}$ and every $b \in \mbf{B}$, the derived relations<br>$$F_{a,\ast} = \{ [y,z] \mid [[a,y],z] \in F \}$$<br>$$F_{\ast,b} = \{ [x,z] \mid [[x,b],z] \in F \}$$<br>are approximable mappings.\\~\\<br>Prove or disprove.<br></latex>	pg 19653, theorem 3.5<br><br>
<latex>~\\<br>What is a \emph{$\lambda$1-category}? What is a \emph{morphism of} $\lambda1$-categories?<br></latex>	<latex>~\\<br>pg 10128, def 2.4.4\\<br>Lemma 1.7.6 is on pg 10054\\<br>"Morphisms of CT structures" is defined on pg 10021\\<br>I used to think that finite product-preserving functors $K$ only guaranteed the existence <br>of an arbitrary iso $KA \times KB \cong K(A \times B)$. Nope, they provide the stronger guarantee that $\langle K\pi, K\pi' \rangle$<br>has an inverse: Categories for Types talks about this.<br></latex>
<latex>~\\<br>Let $\Sigma$ be a signature with non-empty underlying set $T = |\Sigma|$ of atomic types. (This guarantees non-triviality of the associated CT-structure. Why?). Show that $(C \ell 1(\Sigma),T_1)$, where $T_1$ is the closure of $T$ under the $\to$ connective, is a $\lambda 1$-category.<br></latex>	pg 10128/10129 example 2.4.5<br><br>
<latex>~\\<br>Let $\Sigma$ be a signature with $S = |\Sigma|$ as set of atomic types. What is a \emph{$\lambda 1$-model}?<br></latex>	pg 10129, def 2.4.6<br>
<latex>~\\<br>Let $(\mathbb B, T)$ be a non-trivial $CT$-structure. Consider the following statement:\\~\\~\\<br>The following two statements are equivalent:\\~\\<br>(i) The pair $(\mathbb B, T)$ forms a $\lambda 1$-category.\\~\\<br>(ii) The collection $T \subseteq Obj~\mathbb B$ is closed under exponents. That is,<br>for types $X,Y \in T$ there is an exponent type $X \Rightarrow Y \in T$ together with an evaluation<br>morphism $ev : (X \Rightarrow Y) \times X \to Y$ such that for each object $I \in \mathbb B$ and map <br>$f : I \times X \to Y$ in $\mathbb B$ there is a unique abstraction map $\Lambda(f) : I \to X \Rightarrow Y$ with $ev \circ \Lambda(f) \times id = f$.\\~\\~\\<br>Prove or disprove.<br></latex>	true. pg 10129, lemma 2.4.7<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A category $\mathbb B$ with finite products is Cartesian closed if and only if the simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ on $\mathbb B$ has simple products (i.e. forms a $\lambda1$-category).\\~\\<br>Prove or disprove.<br></latex>	pg 10131, corollary 2.4.8<br>
<latex>~\\<br>What is a \emph{$\lambda$-category}?<br></latex>	pg 10134, def 2.5.1<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products and let $\Omega \in \mathbb B$ be a non-empty object (i.e. with non-empty hom-set $\mathbb B(1, \Omega)$). Consider the following statement:\\~\\<br>The pair $(\mathbb B, \Omega)$ is then a $\lambda$-category if and only if there is a map $app : \Omega \times \Omega \to \Omega$ such that for each $f : I \times \Omega \to \Omega$ there is precisely one $\lambda(f) : I \to \Omega$ with $app \circ \lambda(f) \times id = f$.\\~\\<br>Prove or disprove.<br></latex>	pg 10134, lemma 2.5.2<br>todo: add impostor?<br>
<latex><br>Consider a signature with one atomic type $\Omega$ and no function symbols. Identify the exponent type $\Omega \to \Omega$ with $\Omega$. In the resulting $\lambda 1$-calculus on this signature we can provide every untyped term $M(\vec{v})$ with a typing $v_1 : \Omega,\ldots, v_n:\Omega \vdash M : \Omega$. How, then, can the classifying $\lambda 1$-cateogry be described?<br></latex>	pg 10134, examples 2.5.3 (i)<br>
Read example 2.5.3 on pg 10134, parts (i) (ii) and (iii). Note that Jacobs uses "reflexive object" to mean something *slightly* different than Barendregt. See page 5388 for Barendregt's definition of reflexive object.	pg 10134/10135
<latex>~\\<br>Give the context rules ``axiom'', ``identity'', and ``cut''.<br></latex>	pg 10151<br>
<latex>~\\<br>Give the context rules ``weakening for propositions'', ``contraction for propositions'', and ``exchange for propositions''.<br></latex>	pg 10151, fig 3.1<br><br>
<latex>~\\<br>Give the context rules ``weakening for types'', ``contraction for types'', ``exchange for types'', and ``substitution''.<br></latex>	pg 10151, fig 3.1<br><br>
<latex>~\\<br>Why is the following rule not, in general, valid?\\<br>\begin{center}<br>\inferrule<br>  {\Gamma,x:\sigma \mid \Theta \vdash \psi}<br>  {\Gamma \mid \Theta \vdash \psi}<br>\end{center}<br>(when $x$ is not free in $\Theta,\psi$)<br></latex>	pg 10152, above "Fibrations of contexts in logic"<br>
<latex>~\\<br>Let $(\Sigma,\square)$ be a specification for some system of logic, where $\Sigma$ is a many-typed signature and $\square$ is something extra, determined by the specific logic; it may consist of collections of additional atomic symbols and/or axioms. For example, for equational logic, $\square$ will be a set of equations which serve as axioms.<br>The specific logic of this chapter gives rise to a fibration of contexts<br>$$ \vrt{\mathcal L(\Sigma, \square)}{C \ell(\Sigma)}$$<br>Describe the total category $\mathcal L(\Sigma, \square)$ in detail. In particular, how is arrow composition defined? Prove that your definition actually produces arrows in the total category. (Hint: You may have to apply some rules from figure 3.1 on pg 10151) Does this category have fibred finite products?<br></latex>	pg 10153<br>
Read example 3.1.1 on pg 10154	pg 10154<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A function of two arguments, $f : \mathcal A \times \mathcal B \to \mathcal C$ is continuous iff for every $a \in \mathcal A$ and every $b \in \mathcal B$, the unary functions<br>$$x \mapsto f[a,x] \text{ and } y \mapsto f[y,b]$$<br>are continuous.\\~\\<br>Prove or disprove.<br></latex>	pg 19654, theorem 3.7<br><br>
<latex>~\\<br>Let $S$ be a set of symbols used to denote primitive types. What does $S^*$ denote?<br></latex>	pg 19654, def 3.8
<latex>~\\<br>What, according to Cartwright, is a \emph{signature} $\Sigma$?<br></latex>	pg 19654<br>
<latex>~\\<br>Let $\Sigma$ be a signature.<br>What does Cartwright use the notation $\mathcal E$§($\Sigma$) to mean?<br></latex>	the set of typed expressions belonging to that signature.<br>pg 19655<br>
<latex>~\\<br>What is a \emph{finitary algebra} with signature $\Sigma$?<br></latex>	pg 19655, def 3.9<br><br>
<latex>~\\<br>Let $M$ be a term in $\mathcal E$§($\Sigma$) and let $l = x_1^{\tau_1},\ldots,x_n^{\tau_n}$ be a list of distinct variables in $V$ containing all the free variables of $M$. Let $\mbf{A}$ be a finitary algebra with <br>signature $\Sigma$ and for each tuple $[d_1, \ldots, d_n] \in \mbf{A}\sem{\tau_1} \times \ldots \times \mbf{A}\sem{\tau_n}$, let $\mbf{A}_{x_1 := d_1, \ldots, x_n := d_n}$ denote the algebra $\mbf{A}$ extended by defining<br>$\mbf{A}\sem{x_i} \doteq d_i$<br>for $1 \leq i \leq n$.\\~\\What does $\mbf{A}\sem{x_1^{\tau_1},\ldots,x_n^{\tau_n} \mapsto M}$ mean?<br></latex>	pg 19656, def 3.11<br>
<latex>~\\<br>Let $M$ be a term in $\mathcal E$§($\Sigma$) and let $l = x_1^{\tau_1}, \ldots, x_n^{\tau_n}$ be a list of distinct variables of in $V$ containing all the free variables of $M$. Let $\mbf{A}$ be a finitary algebra with signature $\Sigma$. Prove that $\mbf{A}\sem{x_1^{\tau_1},\ldots,x_n^{\tau_n} \mapsto M}$ is approximable.<br></latex>	pg 19656, theorem 3.12<br><br>
<latex>~\\<br>Let $\mbf{A}$ and $\mbf{B}$ be finitary bases. What does it mean for an approximable mapping $F \subseteq \mbf{A} \times \mbf{B}$  to be a \emph{finite step mapping}?<br></latex>	pg 19657, def 3.13<br><br>
<latex>~\\<br>What is the least approximable mapping respecting the empty set?<br></latex>	pg 19657, the paragraph below def 3.13<br>
<latex>~\\<br>For finitary bases $\mbf{A}$ and $\mbf{B}$, what is the \emph{mapping basis} $\mbf{A} \Rightarrow \mbf{B}$? Prove that $\mbf{A} \Rightarrow \mbf{B}$ is a finitary basis.<br></latex>	pg 19657, def 3.14<br>
<latex>~\\<br>If $\mbf{A}$ and $\mbf{B}$ are finitary bases, what does $\mathcal A \Rightarrow \mathcal B$ denote?<br>(yes, I used both boldface and mathcal on purpose.)<br></latex>	pg 19658, def 3.16<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be the domains determined by the finitary bases $\mbf{A}$ and $\mbf{B}$,<br>respectively. What does it mean for a continuous function $f$ in $\mathcal A \to_{c} \mathcal B$ to be \emph{finite}?<br></latex>	pg 19658, def 3.18<br><br>
<latex>~\\<br>For domains $\mathcal A$ and $\mathcal B$, what is the \emph{function basis} $(\mathcal A \to_{c} \mathcal B)^0$? Prove that it is a finitary basis.<br></latex>	pg 19658, def 3.18 <br>(note that *finite step function* is defined in def 3.17)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The domain of ideals determined by $\mbf{A} \Rightarrow \mbf{B}$ is isomorphic to the partial order of the approximable mappings $Map(\mbf{A},\mbf{B})$. Hence, $Map(\mbf{A},\mbf{B})$ is a domain.\\~\\<br>Prove or disprove.<br></latex>	pg 19659, theorem 3.20<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The domain of ideals determined by the finitary basis $(\mathcal A \to_{c} \mathcal B)^0$ is isomorphic to <br>the partial order of continuous functions $\mathcal A \to_{c} \mathcal B$. Hence, $\mathcal A \to_{c} \mathcal B$ is a domain.\\~\\<br>Prove or disprove.<br></latex>	pg 19659, corollary 3.21<br>
<latex>~\\<br>Let $\mbf{A}$ and $\mbf{B}$ be finitary bases. Consider the following statement:\\~\\<br>There is an approximable mapping<br>$$Apply : ((\mbf{A} \Rightarrow \mbf{B}) \times \mbf{A}) \times \mbf{B}$$<br>such that for all $F : \mbf{A} \Rightarrow \mbf{B}$ and $a \in \mbf{A}$,<br>$$Apply[F,a] = F(a)$$<br>Prove or disprove.<br></latex>	true. pg 19659, theorem 3.22<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be domains. Consider the following statement:\\~\\<br>There exists a continuous function<br>$$apply : ((\mathcal A \to_{c} \mathcal B) \times \mathcal A) \to_{c} \mathcal B$$<br>such that for all $f : \mathcal A \to_{c} \mathcal B$ and $a \in \mathcal A$,<br>$$apply[f,a] = f(a)$$<br>Prove or disprove.<br></latex>	pg 19660, corollary 3.23<br><br>
<latex>~\\<br>Let $\mbf{A}$, $\mbf{B}$, and $\mbf{C}$ be finitary bases. Given an approximable mapping $G$ in the basis $\mbf{A} \times \mbf{B} \Rightarrow \mbf{C}$, what is the relation $Curry_G : \mbf{A} \Rightarrow (\mbf{B} \Rightarrow \mbf{C})$? Given any continuous function $g : (\mathcal A \times \mathcal B) \to_{c} \mathcal C$, what is the function $curry_g : \mathcal A \to_{c} (\mathcal B \to_{c} \mathcal C)$?<br></latex>	pg 19661, def 3.24<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In Parigot's $\lambda \mu$-calculus, the types $\bot$ and $\forall X. X$ have exactly the same behavior.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. see discussion below the first example on pg 23556<br>
<latex>~\\<br>In a Cartesian-closed category, what does Selinger use the notations $\diamond_A$ and $f^*$ for?<br>What does $x : A \triangleright M : B$ denote?<br></latex>	pg 19742 bottom / 19743 top<br>
<latex>~\\<br>What is a \emph{binoidal} functor?<br></latex>	pg 19743, note that |A| denotes the underlying set (in the categorical sense of having only identity arrows) of category A.<br><br>
<latex>~\\<br>What is the difference between a \emph{bifunctor} and a \emph{binoidal functor}?<br></latex>	pg 19743, "A binfunctor is just a binoidal functor where the latter to compositions are equal" below def 2.1<br><br><br>
<latex>~\\<br>What do we mean when we speak of \emph{natural transformations between binoidal functors}? <br></latex>	pg 19743, above def 2.2<br>
<latex>~\\<br>What is a \emph{binoidal category}? What does it mean for a morphism in a binoidal category to be \emph{central}?<br></latex>	pg 19743<br>
<latex>~\\<br>Let $f : A \to A'$ and $g : B \to B'$ be morphisms in a binoidal category. What does $f \upand g$ denote?<br></latex>	pg 19743, end of def 2.2<br><br>
<latex>~\\<br>What is a \emph{premonoidal category}?<br></latex>	pg 19743<br>**important** make sure you stated that the natural isos are <i>central</i><br><br>
<latex>~\\<br>What does it mean for a premonoidal category to be \emph{symmetric}?<br></latex>	pg 19744<br>**important** these natural isomorphisms must be <i>central</i>.<br>
<latex>~\\<br>What is a \emph{pretensor}?<br></latex>	<latex>~\\<br>it's the $\upand$ operator of a premonoidal category.<br></latex>
<latex>~\\<br>Let $\mbf{P}$ be a premonoidal category. What is $\mbf{P^{\bullet}}$?<br></latex>	pg 19744, below diagrams<br><br>
<latex>~\\<br>Let $f : A \to A'$ be an arrow in a premonoidal category. Consider the following statement:\\~\\<br>The induced family of arrows $A \upand B \to A' \upand B$ is natural in $B$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. should be possible to give a counterexample. <br>pg 19744, second paragraph below diagrams.<br>
<latex>~\\<br>Let $\mbf{P}$ be a symmetric premonoidal category. What is a \emph{symmetric monoid} in $\mbf{P}$?<br></latex>	pg 19744 / 19745<br>
<latex>~\\<br>What does it mean for a symmetric premonoidal category to have \emph{codiagonals}?<br></latex>	pg 19745<br>
<latex>~\\<br>When the $\mathcal C$-expression $\mathcal C e$ occurs as the function part of an application $(\mathcal C e)~e'$, its immediate continuation is the application of a yet-unknown function $f$ to the expression $e'$. Composing the two pieces, $k~(f~e')$, yields the functional part of the continuation of $\mathcal C e$, which in turn is the argument for $e$. Since this continuation must abort its context upon invocation, we wrap this expression in an $\mathcal A$-application.\\~\\<br>This discussion inspires a local reduction rule for $(\mathcal C e)~e'$. Give this rule.<br></latex>	<latex>~\\<br>pg 19227. Remember: $\mathcal C e$ applies $e$ to an abstraction that places its argument into the evaluation context of $\mathcal C e$. <br></latex><br>
<latex>~\\<br>``When a control expression occurs as the argument part of an application, the abstraction of the control context applies the known function to a unknown argument, passing the result to the continuation of the entire application.''\\~\\<br>The above discussion inspires a local reduction rule to reduce expressions of the form $v~(\mathcal C e)$. Give this rule.<br></latex>	pg 19227, second reduction rule.<br>
<latex>~\\<br>Give the BNF syntax of \emph{singular evaluation contexts} $E^s$. What is the motivation for defining the notion of singular evaluation contexts?<br></latex>	pg 19227. motivation starts at. "When the C-expression", and goes to the bottom of the page.<br>
<latex>~\\<br>Give Felleisen and Hieb's $C_{lift}$ reduction rule.<br></latex>	pg 19227<br>
<latex>~\\<br>Define Felleisen and Hieb's notion of reduction $\mbf{c}$.<br></latex>	pg 19228<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any continuous function $f : \mathcal D \to \mathcal D$ determined by an approximable mapping $F : \mbf{D} \to \mbf{D}$, there exists a least element $x \in \mathcal D$ such that<br>$$f(x) = x$$<br>Prove or disprove.<br></latex>	true. pg 19666, theorem 4.1<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any domain $\mathcal D$, there is an approximable mapping<br>$$fix : (\mbf{D} \to \mbf{D}) \to \mbf{D}$$<br>such that if $f : \mbf{D} \to \mbf{D}$ is an approximable mapping,<br>$$fix(f) = f(fix(f))$$<br>and for $x \in \mathcal D$,<br>$$f(x) \sqsubseteq x \Rightarrow fix(f) \sqsubseteq x$$<br>Prove or disprove.<br></latex>	true. pg 19667, theorem 4.2<br>
Read Example 4.3, on pg 19668 - pg 19670	pg 19668. TODO: make some cards from this?<br><br>
Read Example 4.4, pg 19670 - pg 19671<br>	pg 19670.<br>
<latex>~\\<br>In Hoffman and Streicher's calculus, a typing judgment has the form $\Gamma;\Delta \vdash t : A$. Explain this judgment form.<br></latex>	pg 23108 bottom right<br>pg 23109 top left<br>
<latex>~\\<br>Give the typing rules of Hoffman and Streicher's calculus: Axiom, Const, $\Rightarrow$-intro, $\Rightarrow$-elim, $\bot$-elim, and $\bot$-intro.<br></latex>	pg 23109, top left<br>also, read the entire left column<br><br><br>
<latex>~\\<br>How do Hoffman and Streicher define the notion of a $\lambda_\mu$-theory over a signature $(\mathcal B, \mathcal C)$?<br></latex>	pg 23109, right column, def 2.1<br><br>
<latex>~\\<br>Give and explain the $\mu-\beta$ schema of equality laws for Hoffman and Streicher's $\lambda_{\mu}$ calculus.<br></latex>	pg 23109
<latex>~\\<br>Give and explain the $\mu$-$\eta$ schema of equality laws for Hoffman and Streicher's $\lambda_{\mu}$-calculus.<br></latex>	pg 23109, right column. Note that there are *two* eta rules, and the second one is pretty fundamental, since it is about distributing applications to their continuation variables.<br>
<latex>~\\<br>Give and explain the $\mu$-$\zeta$ schema of equality laws for Hoffman and Streicher's $\lambda_{\mu}$ calculus.<br></latex>	pg 23109, right column
<latex>~\\<br>Give and explain Hoffman and Streicher's concept of \emph{mixed substitution}.<br></latex>	pg 23109, bottom right<br>pg 23110, top left<br>
<latex>~\\<br>Complete the following cases for the definition of mixed substitution:\\~\\<br>$([\gamma]t)[s :: \beta / \alpha] \doteq \underline{~~~~~~~~~~~~~~~}$\\<br>$([\gamma]t)[s :: \star / \alpha] \doteq \underline{~~~~~~~~~~~~~~~}$\\<br></latex>	pg 23110
<latex>~\\<br>What is the intuitive idea behind \emph{mixed substitution}?<br></latex>	pg 23110, top left corner.<br>
<latex>~\\<br>Give the definition for Hoffman and Streicher's notion of a \emph{category of continuations}.<br></latex>	pg 23110<br>
<latex>~\\<br>Briefly give two standard concrete examples of continuation categories. In each continuation category, what is the response object R?<br></latex>	pg 23110<br>
<latex>~\\<br>How do we interpret the type syntax of the simply typed lambda calculus (i.e., minimal logic w/ $\bot$) using a continuation category?  <br></latex>	<latex>~\\<br>pg 23110, right column\\<br>there are two type constructors $\bot$ and $A \Rightarrow B$<br></latex>
<latex>~\\<br>Let $\Gamma \equiv x_1 : A_1, \ldots, x_n : A_n$ be an object context and $\Delta \equiv \alpha_1 : B_1, \ldots, \alpha_m : B_m$ be a continuation context. What does $R^{\sem{\Gamma}} \times \sem{\Delta}$ denote?<br></latex>	pg 23110, bottom right corner
<latex>~\\<br>Let $A,B$ be type objects and $X$ any object of a continuation category $\mbf{C}$. Consider the following statement:\\~\\<br>We have the following isomorphisms natural in $X$<br>$$\mbf{C}(X \cdot R^A, R^B) \cong \mbf{C}(X, R^{R^A \times B}})$$<br>$$\mbf{C}(X \cdot A, R^1) \cong \mbf{C}(X, R^A)$$<br>Prove or disprove.<br></latex>	true. this follows from basic facts about Cartesian products and exponentials.<br>pg 23111, top-right corner.
<latex>~\\<br>How dow we interpret constants in Hoffman and Streicher's $\lambda_{\mu}$-calculus with constants?<br></latex>	pg 23111, top-left corner<br>
<latex>~\\<br>In Hoffman and Streicher's $\lambda_{\mu}$ semantics, what is the ``signature'' (domain and codomain) of the interpretation of a typing judgment $\Gamma;\Delta \vdash t : A$? <br></latex>	<latex>~\\<br>$\sem{\Gamma;\Delta \vdash t : A} : R^{\sem{\Gamma}} \cdot \sem{\Delta} \to R^{\sem{A}}$\\<br>pg 23111, top-left corner.<br></latex>
<latex>~\\<br>Give Hoffman and Streicher's interpretations of the various typing rules of the $\lambda_{\mu}$ calculus using a category of continuations. Use the ``internal language'' of the category, i.e., pretend the category is $\mbf{Sets}$, and define judgment interpretations as functions ala TOPL.\\~\\<br>Bonus points: Instead of using the internal language, give a direct interpretation.<br></latex>	pg 23112, top<br>
<latex>~\\<br>State the soundness theorem for Hoffman and Streicher's categorical semantics for the $\lambda_{\mu}$ calculus. (don't prove it)<br></latex>	pg 23111, theorem 3.3<br><br>
<latex>~\\<br>Give the ``equational proposition formation'' rule.<br></latex>	pg 10156<br>
<latex>~\\<br>Let $\sigma$ be a type. Explain the difference between the $=_{\sigma}$ and $=$ symbols, as used by Jacobs.<br></latex>	pg 10156<br>
<latex>~\\<br>Give the rule titled ``From external to internal equality''.<br></latex>	pg 10156<br>
<latex>~\\<br>What is a \emph{$\Sigma$-equation}? What does it mean for a $\Sigma$-equation to be \emph{algebraic}?<br></latex>	pg 10157, def 3.2.1 (i)<br>
<latex>~\\<br>What is an \emph{equational specification}? What does it mean for an equational specification to be \emph{algebraic}?<br></latex>	pg 10157, def 3.2.1 (ii)<br>
<latex>~\\<br>What is a \emph{torsion free group}? What is the key idea behind giving an equational specification for the notion of torsion free groups?<br></latex>	pg 10157, examples 3.2.2 (ii)<br>
Read example 3.2.2 (iii) on pg 10157<br>	<br>
<latex>~\\<br>Give the substitution rule for equational logic.<br></latex>	pg 10158 top
<latex>~\\<br>What are the four \emph{basic rules of equational logic}? Give each one.<br></latex>	pg 10158<br>
<latex>~\\<br>Give the ``Lawvere equality'' rule. Why is this rule so useful?<br></latex>	pg 10158, lemma 3.2.3<br><br>For symmetry, we implicitly uses the cut rule given on page 10151 to transition from sequent to inference.<br>
<latex>~\\<br>Derive reflexivity, symmetry, and transitivity from Lawvere's rule.<br></latex>	pg 10159, near top<br>
<latex>~\\<br>Derive the replacement rule from Lawvere's rule.<br></latex>	pg 10159, "Finally, in order to derive replacement..."<br>
<latex>~\\<br>Give the rule titled ``Lawvere equality with Frobenius''. How does this rule relate to the standard Lawvere equality rule?<br></latex>	pg 10160, lemma 3.2.4<br><br>
<latex>~\\<br>When do we call an equational specification $(\Sigma, \mathcal H)$ an \emph{equational theory}?<br>When do we call an algebraic specification a theory?<br></latex>	pg 10160, def 3.2.5 (i)<br>
<latex>~\\<br>Let $(\Sigma, \mathcal H)$ be an equational specification. What does $\mathcal Th(\Sigma, \mathcal H)$ denote?<br></latex>	pg 10161, (ii) at top<br>
<latex>~\\<br>Define the category $\mbf{EqSpec}$. Also define the category $\mbf{AlgSpec}$.<br></latex>	pg 10161, def 3.2.6 parts (i) and (ii)<br>
<latex>~\\<br>Hoffman and Streicher establish a completeness theorem for their model of $\lambda_{\mu}$. State this theorem.<br></latex>	pg 23111, thm 4.1<br>The notion of a "theory induced by a continuation model" isn't defined, but it isn't hard to figure our what this is: it includes the basic equations of def 2.1 on pg 23109, and additionally equates two terms whenever they have the same denotation.<br><br>
<latex>~\\<br>Every morphism $f : \sem{\Delta} \to \sem{A}$ induces a morphism from $\sem{\Delta}$ to $R^{R^{\sem{A}}}$. How does this work?<br></latex>	<latex>~\\<br>We define a curried evaluation map at $\eta_{\sem{A}} : \sem{A} \to R^{R^{\sem{A}}}$ as follows:<br>$$\eta_{\sem{A}}(a : \sem{A}) \doteq \underline{\lambda} p : R^{\sem{A}}.~p~a$$<br>We can then form the composition $f;\eta_{\sem{A}} : \sem{\Delta} \to R^{R^{\sem{A}}}$.\\<br>pg 23111, top right corner<br></latex>
<latex>~\\<br>Hoffman and Streicher's completeness theorem states the following:\\~\\<br>For every $\lambda_{\mu}$-theory $\mathcal E$ over a signature ($\mathcal B$, $\mathcal C$) there exists a continuation category $(\mbf{C},R)$ with the following two properties.<br>\begin{enumerate}<br>\item $\mathcal E$ is the theory induced by this continuation model $(\mbf{C},R)$<br>\item Let $\Gamma$ be an object context $\Delta$ be a continuation context and $A$ be a type.<br>Every $\mbf{C}$-morphism $f : R^{\sem{\Gamma}} \cdot \sem{\Delta} \to R^{\sem{A}}$ arises as the interpretation of some $\lambda_{\mu}$-term $\Gamma;\Delta \vdash t : A$.<br>\end{enumerate}<br>Describe a broad strategy for generating such a continuation category $(\mbf{C},R)$ from a $\lambda_{\mu}$-theory $\mathcal E$. What are the objects of $\mbf{C}$?<br></latex>	pg 23111, top-right corner.<br>
<latex>~\\<br>What do Hoffman and Streicher use $\mu \bot. M$ and $[\bot] M$ to denote?<br></latex><br>	pg 23112, convention 4.2, top-left corner.<br>
<latex>~\\<br>Let $\Delta$ be a continuation context and $A$ be a type. What is a \emph{continuation term} (or \emph{C-term} for short)? What is an \emph{observer}? What is a \emph{continuation map}?<br></latex>	pg 23112, def 4.3<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\alpha : A$ is a continuation variable (declared in $\Delta$) then the term $v_{\alpha} := \lambda x : A. [\alpha] x$ is a $C$-term of type $A$.\\~\\<br>Prove or disprove. <br></latex>	pg 23112, prop 4.4<br>todo: add impostor?<br><br>
Read the entire right column of pg 23111	pg 23111
<latex>~\\<br>Read the statement of theorem 4.1 on pg 19666, and the proof up to ``Closure under lubs is direct since $F$ must include lubs to be approximable''. Closure under lubs isn't as direct as this sentence leads on, is it? Give your own proof of closure under lubs.<br></latex><br><br><br><br>	<latex>~\\<br>Hint:\\<br>We need this lemma: $\bot~F^n d~\Rightarrow \bot~F^{n+1}~d$.\\<br>The proof is simple. Suppose $\bot~F^n~d$. Since $\bot \sqsubseteq d$, monotonicity of $F^n$ gives us $d~F^{n}~d$.<br>Then $\bot~F~d~F^{n}~d$, i.e. $\bot~F^{n+1}~d$.\\<br>pg 19666 (the proof isn't given, you have to figure it out yourself)<br></latex><br>
<latex>~\\<br>For any domain $\mathcal D$ there is an approximable mapping <br>$$ fix : (\mbf{D} \to \mbf{D}) \to \mbf{D}$$<br>which plays a special role in domain theory. This mapping satisfies two important properties: what are these properties and what motivates them?<br></latex>	the first property just states that it generates a fixpoint<br>the second property guarantees that it is the least fixpoint (and therefore unique)<br>pg 19667, theorem 4.2<br>
<latex>~\\<br>Give the definition for a finite basis that generates the domain of partial functions over the natural numbers.<br></latex>	pg 19668, example 4.3 (no need to follow this example to the next page)<br><br>
<latex>~\\<br>What is a \emph{structured domain}? Give the definition of the \emph{structured domain} that Cartwright et al. refer to as ``The Domain of Integers'' (note that this seems like a misnomer, since the domain involves the natural numbers rather than the integers).<br></latex>	pg 19670, near top<br>
<latex>~\\<br>Quickly skim over section 5.1 starting at pg 19676 and ending at pg 19678. It covers mostly standard notations.<br></latex>	pg 19676<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every typed $\lambda$-term defines an approximable function of its free variables.\\~\\<br>Prove or disprove.<br></latex>	true.<br>pg 19678, theorem 5.1<br>
<latex>~\\<br>Given two lambda calculus terms $\tau$ and $\sigma$, what does $\tau = \sigma$ mean?<br></latex>	It is not syntactic equality: instead, it means that the two terms are interpreted as the same approximable mapping of their free variables.<br><br>pg 19679, above theorem 5.2<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For appropriately typed terms, the following equation is $true$:\\<br>$(\lambda x_0,\ldots,x_{n-1}.\tau)(\sigma_0, \ldots, \sigma_{n-1}) = \tau[\sigma_0/x_0,\ldots,\sigma_{n-1}/x_{n-1}]$.\\~\\<br>Prove or disprove.<br></latex>	pg 19679, theorem 5.2 at bottom<br>TODO: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The least fixed point of $$\lambda x,y. \langle \tau(x,y), \sigma(x,y) \rangle$$ <br>is the pair with coordinates $$\mathit{fix} (\lambda x.\tau(x,fix(\lambda y. \sigma(x,y))))$$<br>and $$\mathit{fix}(\lambda y. \sigma (\mathit{fix}(\lambda x. \tau(x,y)), y))$$<br>Prove or disprove.<br></latex>	pg 19681, theorem 5.3<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $x,y$ and $\tau(x,y)$ be of type $\mathcal D$ and let $g : \mathcal D \to \mathcal D$ be a function. Consider the following statement:\\~\\<br>The equation <br>$$\lambda x. \mathit{fix}(\lambda y.\tau(x,y)) = \mathit{fix}(\lambda g. \lambda x. \tau (x, g(x)))$$<br>holds.\\~\\<br>Prove or disprove.<br></latex>	pg 19682, theorem 5.4<br>todo: add impostor?<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For every partial recursive function $h : \mathbb N \to \mathbb N$, there is a $\lambda$-term $\tau$ of type $\mathcal N \to \mathcal N$ such that the only constants occurring in $\tau$ are \emph{cond}, \emph{succ},<br>\emph{pred}, \emph{zero}, and \emph{0}, and if $h(n) = m$ then $\tau(n) = m$. If $h(n)$ is undefined, then $\tau(n) = \bot$ holds. $\tau(\bot) = \bot$ is also true.\\~\\<br>Prove or disprove.<br></latex>	pg 19684, theorem 5.5.<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following domain equation <br>$$\mathcal T = \mathcal A + (\mathcal T \times \mathcal T)$$<br>What do the elements of this domain look like? In particular, what are the finite elements of this domain?<br></latex>	pg 19689, "The domain equation tells us..." down to "Now that some intuition..."<br><br>
<latex>~\\<br>Consider the following domain equation <br>$$\mathcal T = \mathcal A + (\mathcal T \times \mathcal T)$$<br>How do we formally construct the finitary basis which generates the domain $\mathcal T$? <br></latex>	pg 19689, "Now that some intuition..."<br>down to pg 19690 "Now that the basis elements..."
<latex>~\\<br>What does it mean for a domain $\langle \mathcal R, \sqsubseteq_R \rangle$ to be a \emph{sub-domain} of a domain $\langle \mathcal D, \sqsubseteq_D \rangle$?<br></latex>	pg 19692<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mathcal D \triangleleft \mathcal E$, then there exists a projection pair of approximable mappings $i : \mathcal D \to \mathcal E$ and $j : \mathcal E \to \mathcal D$ where $j \circ i = I_{\mathcal D}$ and $i \circ j \sqsubseteq I_{\mathcal E}$ where $i$ and $j$ are determined by the following equations:<br>\begin{center}<br>\begin{tabular}{lll}<br>$i(x)$ & $=$ & $\{ y \in \mbf{E} \mid \exists z \in x. z \sqsubseteq y \}$ \\<br>$j(y)$ & $=$ & $\{ x \in \mbf{D} \mid x \in y \}$<br>\end{tabular}<br>\end{center}<br>for all $x \in \mathcal D$, $y \in \mathcal E$.\\~\\<br>Prove or disprove.<br></latex>	true. Theorem 6.3, pg 19693.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$\mathcal D_0 \triangleleft \mathcal E \wedge \mathcal D_1 \triangleleft \mathcal E \Rightarrow (\mathcal D_0 \triangleleft \mathcal D_1 \Longleftrightarrow \mathcal D_0 \subseteq \mathcal D_1)$\\~\\<br>Prove or disprove.<br></latex>	pg 19693, below theorem 6.3<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a given domain $\mathcal D$, the set of sub-domains $\{ \mathcal D_0 \mid \mathcal D_0 \triangleleft \mathcal D \}$ form a domain. \\~\\<br>Prove or disprove.<br></latex>	pg 19693, theorem 6.4<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For two domains $\mathcal D$ and $\mathcal E$, if there exists a projection pair $i : \mathcal D \to \mathcal E$ and $j : \mathcal E \to \mathcal D$ with $j \circ i = I_{\mathcal D}$ and $i \circ j \sqsubseteq I_{\mathcal E}$, then $\exists \mathcal D' \triangleleft \mathcal E$ where $\mathcal D \cong \mathcal D'$.\\~\\<br>Prove or disprove.<br></latex>	pg 19693, theorem 6.5<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>Given a top-level continuation variable $top : \bot$, the $\lambda \mu$-calculus can express \emph{Ex falso quodlibet} and also double negation elimination.\\~\\<br>Prove or disprove.<br></latex>	true. pg 19346, remark 8, spills to pg 19347<br><br>
<latex>~\\<br>Give the mutually inductive syntax for \emph{terms}, \emph{continuations}, and \emph{commands} in System L. Also, give (brief, shallow) descriptions of each of these three syntactic classes.<br></latex> 	pg 19349, definition 11 and the text below it<br>
<latex>~\\<br>Give the grammar for \emph{types} in System L. Give the forms of the three kinds of typing judgments.<br></latex>	pg 19349, definition 12.<br>
<latex>~\\<br>In the Curry-Howard interpretation of System L, term constructs offer basic ways in which types can be \underline{~~~~~~~~~~~} and continuation constructs offer basic ways in which inhabitants of types can be \underline{~~~~~~~~~~~}.<br></latex>	pg 19349 bottom / pg 19350 top<br>
<latex>~\\<br>Give the identity typing rules and the $(\to)$ typing rules for System L.<br></latex>	pg 19350, figure 6<br>
<latex>~\\<br>Give the $(\wedge)$ typing rules and the $(\vee)$ typing rules of System L.<br></latex>	pg 19350, figure 6.<br><br>
<latex>~\\<br>Give the $\mu$ typing rules of System L.<br></latex>	pg 19350, <br>
<latex>~\\<br>Give the command (i.e., $\langle t \mid e \rangle$) typing rule for System L. What rule off classical sequent calculus does this rule correspond to?<br></latex>	pg 19350, figure 6, very bottom.<br>it corresponds to the cut rule.<br><br>
<latex>~\\<br>System L does not have a syntactic construct for application. But it doesn't need one. Why is this?<br></latex>	pg 19350, third bullet point.<br><br>
Recount the story "The Devil, The Fool, and the $1,000,000". Why does this story correspond to the computational contents of classical logic?	pg 19351, example 2 at top. also, read the text below the example.<br>
<latex>~\\<br>Give the five small-step reduction rules of System L.<br></latex>	pg 19352, definition 13<br>
<latex>~\\<br>Give an encoding of $\lambda$ terms into System L. What two lemmas must we prove to show this encoding is sound?<br></latex>	pg 19352, def 14. Also see lemma 9 and 10.<br>
<latex>~\\<br>What does MacQueen use the notation $\mu s. s \to \tau$ for?<br></latex>	pg 23644, near top<br>
<latex>~\\<br>How do we express the type of pure lambda terms, using MacQueen's type expression syntax?<br></latex>	<latex>~\\<br>$\mu t. t \to t$ \\<br>page 23644<br></latex>
<latex>~\\<br>Why must the set of terms used to model a type be non-empty under MacQueen's interpretation?<br></latex>	pg 23644, paragraph above section 1.3<br>
<latex>~\\<br>Let $I$ and $J$ be sets of values. What does $I \boxarrow J$ denote?<br></latex>	pg 23645, "Intuition about the role of..."<br>
<latex>~\\<br>Let the type $s = s \to \tau$. Show how the set $I$ modeling $s$ can be estimated through iterated use of the $\boxarrow$ operator.<br></latex>	pg 23645, near bottom<br><br>
<latex>~\\<br>Here is an attempt to model the type $s = s \to \tau$. Let $J$ be the set of values denoted by the type $\tau$. Starting with the set $\mbf{V}$ of all values, we estimate the set $I$ modeling $s$ by writing the sequence:<br>\begin{center}<br>\begin{tabular}{l}<br>$I_0 = \mbf{V}$ \\<br>$I_1 = I_0 \boxarrow J = \mbf{V} \boxarrow J$ \\<br>$I_2 = I_1 \boxarrow J = (\mbf{V} \boxarrow J) \boxarrow J$<br>\end{tabular}<br>\end{center}<br>Prove that\\~\\<br>$I_0 \supseteq I_2 \supseteq I_4 \supseteq \cdots$\\<br>$I_1 \subseteq I_3 \subseteq I_5 \subseteq \cdots$\\<br>$I_1 \subseteq I_0, I_3 \subseteq I_2, I_5 \subseteq I_4, \cdots$\\<br></latex><br><br>	pg 23646, 23647<br><br>
<latex>~\\<br>What is a \emph{complete partial order}, according to Mac Queen?<br></latex>	pg 23647, section 2.1<br>
<latex>~\\<br>What does it mean for a function between cpos to be \emph{continuous}?<br></latex>	pg 23647, near bottom<br><br>
<latex>~\\<br>What does it mean for a function between cpos to be \emph{strict}?<br></latex>	pg 23647, near bottom.<br>
<latex>~\\<br>In what way can a function on sets be ``casted'' to a continuous function on cpos?<br></latex>	pg 23648, near top<br><br>
<latex>~\\<br>What does it mean for a function between posets to \emph{reflect} lubs?<br></latex>	pg 23648<br>
<latex>~\\<br>What are the domains, codomains, and definitions of the families of continuous functions \emph{isl}, \emph{inl}, and \emph{outl}?<br></latex>	pg 23649, near bottom "functions"<br>
<latex>~\\<br>What is the \emph{coalesced sum} operator on domains?<br></latex>	pg 23649<br>
<latex>~\\<br>Give the definition of the continuous function $cond : \mbf{T} \to (D \to (D \to D))$?<br></latex>	pg 23650, near top.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The coalesced sum operator is functorial in each of its arguments in the category of continuous functions.\\~\\<br>Prove or disprove.<br></latex>	I think I mistakenly labeled this as an impostor even though it's true. The referenced page shows how the functor is defined.<br><br>IMPOSTOR! It's only functorial on the subcategory of <i>strict</i> continuous functors.<br>The problem with non-strict functions is that the if-then-else construct preserves bottom no matter what; even if f and g don't. So functorality isn't really the problem: it's that the "coalesced sum functor" doesn't actually do what we expect it to when its arguments are not strict.<br>pg 23650<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The coalesced sum operator is functorial in each of its arguments in the category of strict continuous functions.\\~\\<br>Prove or disprove.<br></latex>	true. pg 23650<br>
<latex>~\\<br>What does it mean for a continuous map to be an \emph{embedding}? If $\phi$ is a continuous map, then what does $\phi^R$ denote? <br></latex>	pg 23650, section 2.3<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\langle \phi, \psi \rangle$ is a projection pair then $\phi$ and $\psi$ form a Galois connection.\\~\\<br>Prove or disprove.<br></latex>	pg 23650, section 2.3 near bottom<br><br>
<latex>~\\<br>Let $\phi_0 : D_0 \to E_0$ and $\phi_1 : D_1 \to E_1$ be embeddings. Consider the following statement:\\~\\<br>$\phi_0^R \to \phi_1$ is an embedding\\~\\<br>Prove or disprove.<br></latex>	true. pg 23651<br>
<latex>~\\<br>Let $\phi_0 : D_0 \to E_0$ and $\phi_1 : D_1 \to E_1$ be embeddings. Consider the following statement:\\~\\<br>$\phi_0 \to \phi_1^R$ is an embedding\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! it is not an embedding, but it is a projection.<br>pg 23651<br> 
<latex>~\\<br>Let $\phi_0 : D_0 \to E_0$ and $\phi_1 : D_1 \to E_1$ be embeddings. Consider the following statement:\\~\\<br>$\phi_0 \to \phi_1$ is an embedding\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! because we did not take contravariance of the argument position into account. pg 23651<br>
<latex>~\\<br>Let $\phi_0 : D_0 \to E_0$ and $\phi_1 : D_1 \to E_1$ be embeddings. Consider the following statement:\\~\\<br>$\phi_0 \times \phi_1$ is an embedding\\~\\<br>Prove or disprove.<br></latex>	true. pg 23651, near top<br><br>
<latex>~\\<br>Show how the cpo $\mbf{V} \cong \mbf{T} + \mbf{N} + (\mbf{V} \to \mbf{V}) + (\mbf{V} \times \mbf{V}) + (\mbf{V} + \mbf{V}) + \mbf{W}$ can be constructed via a limiting process.<br></latex>	pg 23651<br>
<latex>~\\<br>In the categorical approach to recursive domain specifications we try to regard all equations as<br>having what form?<br><br></latex>	pg 26431 bottom, which refers to some equations on the previous page 26430.<br>also, read the first paragraph of the next page 26432.<br><br>
<latex>~\\<br>Many domain equations are defined through simultaneous recursion. However, we want all domain equations to have the form $X \cong F(X)$, which is essentially a single equation. How do we handle this?<br></latex>	use product categories. see page 26432, middle of page, "Simultaneous equations are handled..."<br>
<latex>~\\<br>Let $\mbf{K}$ be a category and $F : \mbf{K} \to \mbf{K}$ be an endofunctor. What is a \emph{fixed point} of $F$? What is a \emph{prefixed point} of $F$? What is an $F$-algebra?<br></latex>	pg 26432, definition 1 near bottom<br>
<latex>~\\<br>Let $(A, \alpha)$ and $(A', \alpha')$ be $F$-algebras. What is a \emph{morphism} $f : (A, \alpha) \to (A', \alpha')$?<br></latex>	pg 26432, definition 2 near bottom, spills to pg 26433<br><br>
<latex>~\\<br>Let $\mbf{K}$ be a category and $F : \mbf{K} \to \mbf{K}$ an endofunctor. What is a \emph{fixed point} of $F$? What is an $F$-algebra? Do the $F$-algebras form a category? Consider the following statement:\\~\\<br>The initial $F$-algebra, if it exists, is also the initial fixed point.\\~\\<br>Prove or disprove.<br></latex>	pg 26433, lemma 1 near top<br><br>
<latex>~\\<br>What is an $\omega$-chain in a category $\mbf{K}$? With some fixed $\omega$-chain, and with $m \leq n$, what does Smyth use the notation $f_{mn}$ for? What is an $\omega^{\mbf{op}}$ chain?<br></latex>	pg 26433, second-to-last paragraph<br>
<latex>~\\<br>Let $\mu$ be a limit over a diagram $\Delta$, and let $\nu$ be another cone over $\Delta$. What is the \emph{mediating morphism} between $\nu$ and $\mu$?<br></latex>	pg 26433, latter part of second-to-last paragraph<br>
<latex>~\\<br>Let $\mbf{K}$ be a category and $A$ an object of $\mbf{K}$. What does Smyth use the notation $\bot_{\mbf{K}}$ for? What about $\bot_{A}$?<br></latex>	pg 26433, bottom paragraph<br>
<latex>~\\<br>Let $\Delta = D_0 \overset{f_0}{\to} D_1 \overset{f_1}{\to} \cdots$ be an $\omega$-chain in a category $\mbf{K}$ and $\mu : \Delta \to A$ a cone over $\Delta$. What does $\Delta^{-}$ denote? Let $F : \mbf{K} \to \mbf{L}$ be a functor. What does $F\Delta$ denote?<br></latex>	pg 26433, bottom paragraph<br><br>
<latex>~\\<br>Let $\mbf{K}$ be a category with initial object $\bot_{\mbf{K}}$ and let $F : \mbf{K} \to \mbf{K}$ be a functor. Define the $\omega$-chain $\Delta$ to be $\langle F^{n}(\bot_{\mbf{K}}), F^n(\bot_{F \bot})\rangle$. Suppose that both $\mu : \Delta \to A$ and $F \mu : F \Delta \to F A$ are colimiting cones. Consider the following statement:\\~\\<br>The initial F-algebra exists and is $(A, \alpha)$, where $\alpha : FA \to A$ is the mediating morphism from $F\mu$ to $\mu^-$.\\~\\<br>Prove or disprove.<br></latex>	pg 26434, lemma 2<br>
<latex>~\\<br>What is an \emph{$\omega$-complete partial order}? What does it mean for a function $F : K \to L$ of partial orders to be \emph{$\omega$-continuous}, a.k.a \emph{continuous}?<br></latex>	pg 26434, above definition 3<br><br>
<latex>~\\<br>What does it mean for a category to be an \emph{$\omega$-complete pointed category}? (Smyth uses $\omega$-category as shorthand for this term.)<br></latex>	pg 26434, definition 3 near bottom<br><br>
<latex>~\\<br>Let $F : \mbf{K} \to \mbf{L}$ be a functor. What does it mean for $F$ to be \emph{$\omega$-continuous}, according to Smyth?<br></latex>	pg 26434, definition 4 near bottom. WARNING: They chose to use the order-theoretic convention for the term "continuous", which in category theory is actually called "cocontinuous"!!!<br><br><br>
State Smyth and Plotkin's "Basic Lemma"<br>	pg 26434, lemma 2<br>
<latex>~\\<br>Page 26435 says ``Clearly, when $\mbf{K}$ is an $\omega$-category and $F : \mbf{K} \to \mbf{K}$ is $\omega$-continuous, the conditions of the basic lemma are satisfied.''\\~\\<br>Verify that this is the case. It will be helpful to open a second copy of MiscStudy.pdf to pg 26434, where the basic lemma is stated.<br></latex>	pg 26435
<latex>~\\<br>What does it mean for a category $\mbf{K}$ to be an $\mbf{O}$-category? (Hint: it must satisfy two conditions.)<br></latex>	pg 26436, definition 5<br>
<latex>~\\<br>Provide the definition of the category $\mbf{O}$.<br></latex>	pg 26436, above definition 6<br><br>
<latex>~\\<br>Let $\mbf{K}$ be an $\mbf{O}$-category and let $f : A \to B$ and $g : B \to A$ be arrows. What does it mean for $\langle f, g \rangle$ to be a \emph{projection pair from A to B}?<br></latex>	pg 26436, definition 6<br>
<latex>~\\<br>Let $\langle f,g \rangle$ and $\langle f', g' \rangle$ both be projection pairs from $A$ to $B$, in an $\mbf{O}$-category $K$. Consider the following statement:\\~\\<br>$f \sqsubseteq f'$ if and only if $g \sqsupseteq g'$\\~\\<br>Prove or disprove.<br></latex>	true. pg 26436, lemma 3 near bottom.<br>todo: add impostor?
<latex>~\\<br>Smyth and Plotkin use the term ``adjoint'' in an idiosyncratic way. Explain.<br></latex>	pg 26437, top paragraph.<br>
<latex>~\\<br>Given an $\mbf{O}$-category $\mbf{K}$, what do $\mbf{K}^E$ and $\mbf{K}^P$ denote? Are $\mbf{K}^E$ and $\mbf{K}^P$ $\mbf{O}$-categories?<br></latex>	pg 26437, above section 3.1<br><br>
<latex>~\\<br>Let $\mbf{K}$ be an $\mbf{O}$-category.<br>Consider the following statement:\\~\\<br>$\mbf{K}^E \cong (\mbf{K}^P)^{op}$\\~\\<br>Prove or disprove.<br></latex>	true. pg 26437, beginning of section 3.1. The information necessary to construct the proof should be shortly before section 3.1<br>
<latex>~\\<br>Let $\mbf{K}$ be an $\mbf{O}$-category which has a terminal object, $\bot$, and in which every $hom(A,B)$ has a least element, $\bot_{A,B}$. Suppose too that composition is left-strict in the sense that for any $f : A \to B$ we have $\bot_{B,C} \circ f = \bot_{A,C}$. Consider the following statement:\\~\\<br>$\bot$ is the initial object of $\mbf{K}^E$\\~\\<br>Prove or disprove.<br></latex>	true. pg 26437, theorem 1.<br>todo: add impostor?<br>
<latex>~\\<br>Let $\mbf{K}$ be an $\mbf{O}$-category and $\mu : \Delta \to A$ a cone in $\mbf{K}^E$, where $\Delta$ is the $\omega$-chain $\langle A_n, f_n \rangle$. What does it mean for $\mu$ to be an $\mbf{O}$-colimit of $\Delta$? What does it mean for a cone $\nu : B \to \Gamma$ to be an \emph{$\mbf{O}$-limit} of an   $\mbf{\omega}^{op}$-chain $\Gamma$ in $\mbf{K}^P$?<br></latex>	pg 26437, definition 7<br><br>
<latex>~\\<br>Let $\mbf{K}$ be an $\mbf{O}$-category and $\Delta$ be an $\omega$-chain in $\mbf{K}^E$. Consider the following statement:\\~\\<br>The following properties are equivalent:\\<br>\begin{itemize}<br>\item (a) $\Delta$ has a colimit in $\mbf{K}$<br>\item (b) $\Delta^R$ has a limit in $\mbf{K}$<br>\item (c) $\Delta$ has an $\mbf{O}$-colimit<br>\item (d) $\Delta^R$ has an $\mbf{O}$-limit<br>\item (e) $\Delta$ has a colimit in $\mbf{K}^E$<br>\item (f) $\Delta^R$ has a limit in $\mbf{K}^P$<br>\end{itemize}\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 26437, theorem 2 at bottom of page<br>some are equivalent: discuss<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mu : \Delta \to A$ is an $\mbf{O}$-colimit, then $\mu$ is colimiting in both $\mbf{K}$ and $\mbf{K}^E$.\\~\\<br>Prove or disprove.<br></latex>	pg 26438, proposition A<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\nu : A \to \Delta^R$ is limiting in $\mbf{K}$, then each $\nu_n$ is a projection and $\nu$ is an $\mbf{O}$-limit of $\Delta^R$.\\~\\<br>Prove or disprove.<br></latex>	pg 26438, Proposition C, near bottom<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$\mu : \Delta \to A$ is colimiting in $\mbf{K}^E$ if and only if $\mu^R : A \to \Delta^R$ is limiting in $\mbf{K}^P$.\\~\\<br>Prove or disprove.<br></latex>	true. should be obvious. pg 26439, proposition E.<br>
<latex>~\\<br>What does it mean for an $\mbf{O}$-category $\mbf{K}$ to have \emph{locally determined $\omega$-colimits of embeddings}?<br></latex>	pg 26439, definition 8 near bottom<br><br>
<latex>~\\<br>Suppose that the $\mbf{O}$-category $\mbf{K}$ has all $\mbf{\omega}^{op}$-limits (i.e., every $\mbf{\omega}^{op}$-chain in $\mbf{K}$ has a limit). Consider the following statement:\\~\\<br>$\mbf{K}$ has locally determined $\omega$-colimits of embeddings.\\~\\<br>Prove or disprove.<br></latex>	pg 26439, corollary near bottom<br>
<latex>~\\<br>Let $\mbf{K}$, $\mbf{L}$, and $\mbf{M}$ be $\mbf{O}$-categories and $T : \mbf{K}^{op} \times \mbf{L} \to \mbf{M}$ a bifunctor. What does it mean for $T$ to be \emph{locally monotonic}?<br></latex>	pg 26440, def 9<br>
<latex>~\\<br>Let $\mbf{K}$, $\mbf{L}$, and $\mbf{M}$ be $\mbf{O}$-categories and $T : \mbf{K}^{op} \times \mbf{L} \to \mbf{M}$ a bifunctor. Consider the following statement:\\~\\<br>If $T$ is locally monotonic then a covariant functor $T^E : \mbf{K}^E \times \mbf{L}^E \to \mbf{M}^E$ can be defined by putting, for objects $A, B : T^E(A,B) \doteq T(A,B)$ and for morphisms $f,g : T^E(f,g) \doteq T((f^R)^{op},g)$.\\~\\<br>Prove or disprove.<br></latex>	pg 26440, lemma 4<br><br>
<latex>~\\<br>Let $\mbf{K}$, $\mbf{L}$, and $\mbf{M}$ be $\mbf{O}$-categories and $T : \mbf{K}^{op} \times \mbf{L} \to \mbf{M}$ a bifunctor. What does it mean for $T$ to be \emph{locally continuous}?<br></latex>	pg 26440, definition 10<br><br>
<latex>~\\<br>Read pg 26595.<br></latex>	pg 26595<br>
<latex>~\\<br>The projection of a 1-dimensional subspace onto another results in a \underline{~~~~~~~~~~}.<br></latex>	0-dimensional subspace. (projection here refers to the standard dot product, which produces a scalar)<br>pg 26596, above section 2.1. **Also see the diagram on the previous page.<br><br>
<latex>~\\<br>What, intuitively, is a bivector? Also, what is the \emph{outer product} operation?<br></latex>	pg 26596, read the whole page<br><br>
<latex>~\\<br>The outer product operator is \emph{anti-commutative}. What does this mean, formally?<br></latex>	pg 26596<br>
<latex>~\\<br>From what property of the outer product operator can we easily derive $\forall a.~a \wedge a = 0$?<br></latex>	anti-commutativity<br>pg 26597, near top<br><br>
<latex>~\\<br>Draw pictures convincing yourself of the following three algebraic properties of the outer product, where $\lambda$ is a scalar and $a$ and $b$ are vectors:\\<br>\begin{itemize}<br>\item $(\lambda a) \wedge b = \lambda (a \wedge b)$<br>\item $a \wedge (b + c) = (a \wedge b) + (a \wedge c)$<br>\end{itemize}<br></latex>	pg 26597<br>
<latex>~\\<br>Let $a = \alpha_1 e_1 + \alpha_2 e_2$ and $b = \beta_1 e_1 + \beta_2 e_2$ be two-dimensional vectors. Show that $a \wedge b = (\alpha_1 \beta_2 e_1 \wedge e_2) + (\alpha_2 \beta_1 e_2 \wedge e_1)$.<br></latex>	pg 26597 sec 2.1.1 <br>down to <br>pg 26598<br><br>
A nice thing about Parser type constructor is that it is a Functor, an Applicative, a Monad, and an Alternative. Explain what each of these means.	pg 26778, section 2.3<br>
In Haskell, how would we define parser combinators some and many for non-empty and potentially empty lists, respectively.<br><br>	pg 26779<br>
Explain why the naive method for parsing the following grammar yields an infinite loop:<br><br>Expr ::= Int | Expr `+` Expr<br> <br>What is the standard solution?	pg 26779, section 3<br>
<latex>~\\<br>Give types and definitions of the combinators\\~\\<br>$\_ \! \longrightarrow \! \_$,\\<br>$\kappa$,\\ <br>$\_ \! \otimes \! \_$,\\ <br>and $[\_]$\\~\\on indexed sets. How are they used in implementing parser combinators?<br></latex>	pg 26780<br>
<latex>~\\<br>Provide the definition of the $\square$ record definition. How is it used for implementing total parser combinators?<br></latex>	pg 26781<br>
<latex>~\\<br>Provide the definition of the $\mathit{map}$ function, of type $[ A \longrightarrow B ] \to [ \square A \longrightarrow \square B ]$. What is its purpose?\\~\\<br>note: may involve copatterns.<br></latex>	pg 26781<br>
<latex>~\\<br>Give the meanings of the following judgments in Abel's system:\\~\\<br>$\kappa \leq \kappa'$\\<br>$\Gamma \vdash F : \kappa$\\<br>$\Gamma \vdash F = F' : \kappa$\\<br>$\Gamma \vdash F \leq F' : \kappa$\\<br>$F \drto W$\\<br>$\Gamma \vdash N \leq^q N' \rightrightarrows \kappa$\\<br>$\Gamma \vdash W \leq^q W' \leftleftarrows \kappa$<br></latex>	pg 12450, bottom<br>
<latex>~\\<br>Given two derivations $\mathcal D_1$ and $\mathcal D_2$, what does Abel mean by $\mathcal D_1 \leq \mathcal D_2$, i.e. how does he define the default ordering on derivations?<br></latex>	<latex>~\\<br>It means the height $|\mathcal D_1|$ of $\mathcal D_1$ is less than the height $|\mathcal D_2|$ of $\mathcal D_2$.\\~\\<br>pg 12450<br></latex>
<latex>~\\<br>Give the meanings of Abel's four polarities $\circ$,$+$,$-$, and $\top$. Draw a Hasse diagram for their default ordering. How does their ``composition'' operator work?<br></latex>	pg 12451, figure 1<br>also read text below figure 1.<br><br>
<latex>~\\<br>Each polarity $p$ yields a composition function $f_p : \mathit{Pol}\to\mathit{Pol}$, defined as $f(x) \doteq px$.$f_p$ is part of a Galois connection. Give the left adjoints of $f_+$ and $f_-$, and prove that they are actually left adjoints.<br></latex>	pg 12452, near top<br>
<latex>~\\<br>Each polarity $p$ yields a composition function $f_p : \mathit{Pol}\to\mathit{Pol}$, defined as $f(x) \doteq px$.$f_p$ is part of a Galois connection. Give the left adjoints of $f_\circ$ and $f_\top$, and prove that they are actually left adjoints.<br></latex>	pg 12452<br>
<latex>~\\<br>Give Abel's grammar for kinds ($\kappa$)<br></latex><br> 	pg 12452, near middle of page<br>
<latex>~\\<br>What does it mean for a type-to-kind context $\Gamma'$ to be more \emph{liberal} than another type-to-kind context $\Gamma$?<br></latex>	pg 12453<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\Gamma_1 \leq \Gamma_2$ and $q_1 \leq q_2$ then $q_1 \Gamma_1 \leq q_2 \Gamma_2$<br>and $q_1^{-1}\Gamma_1 \leq q_2^{-1}\Gamma_2$.\\~\\<br>Prove or disprove.<br></latex>	pg 12453, lemma 2.2 near bottom.<br><br>
<latex>~\\<br>Give and explain the kinding application rule KIND-APP.<br></latex>	pg 12454<br>
<latex>~\\<br>Give and explain the kinding rule KIND-$\lambda$.<br></latex>	pg 12454<br>
<latex>~\\<br>Give and explain the kinding rule KIND-SUB.<br></latex>	pg 12454<br>
<latex>~\\<br>Give and explain the kinding rules KIND-C and KIND-VAR.<br></latex>	pg 12454<br>
Give the three subkinding rules.	pg 12452<br>
<latex>~\\<br>Let $\vec{p} \vec{\kappa} \to \ast$ be an arbitrary kind. What is the \emph{rank} of $\vec{p} \vec{\kappa} \to \ast$?<br></latex>	pg 12452, above "subkinding"<br><br>
<latex>~\\<br>Let $\vec{p} \vec{\kappa} \to \kappa_0 \leq \kappa'$. Consider the following statement:\\~\\<br>There are $\vec{p}'$, $\vec{\kappa}'$, $\kappa'_0$ with $\kappa' = \vec{p}'\vec{\kappa}' \to \kappa'_0$ and $|\vec{p}'| = |\vec{\kappa}'| = |\vec{p}| = |\vec{\kappa}| = n$ such that $\kappa_0 \leq \kappa_0'$ and both $p_i' \leq p_i$ and $\kappa'_i \leq \kappa_i$ for all $1 \leq i \leq n$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 12452, lemma 2.1<br>todo: add impostor?
<latex>~\\<br>Give the kind signatures of the following type constructor constants (the second one being a member of a kind-indexed family):\\~\\<br>$\to$\\~\\<br>$\forall_\kappa$<br></latex>	pg 12453 top<br>
<latex>~\\<br>How does Allais define the function $\mathit{extract}$ of type $[~\square A~] \to [~A~]$? Hint: it makes use of the $\box \_$ type constructor (defined using a record type definition), so you'll have to recall that first.<br></latex>	pg 26781, near bottom<br><br>
<latex>~\\<br>What is the type of the \emph{duplicate} function that Allais defines?<br></latex>	pg 26781<br>
<latex>~\\<br>How does Allais define the \emph{app} function of type $[~\square~(A \longrightarrow B) \to (\square~A \longrightarrow \square~B)~]$?<br></latex>	pg 26782<br>
<latex>~\\<br>Give the type of Allais's \emph{fix} function. Explain its purpose.<br></latex>	pg 26782<br>
<latex>~\\<br>Give the definition and motivation for Allais's \emph{Success} record datatype. Also, give the Parser record type definition.<br></latex>	pg 26782, "Parsing, Totally" near bottom,<br>pg 26783, near top<br><br>
<latex>~\\<br>Give the definition of the $\_ \langle \& \rangle \_$ combinator, which takes two parsers, runs them sequentially, and returns a pair of their results.<br></latex>	the interesting part is the box on the second argument.<br>pg 26784<br>
<latex>~\\<br>Give the Agda definition of the \emph{some} combinator, which takes a parser for $A$ and returns a parser for $\mathit{List}^+~A$, the type of non-empty lists of $A$s. Hint: the definition should use Allais's \emph{fix} combinator, of type $\forall A \to [~\square~A \longrightarrow A~] \to [~A~]$.<br></latex>	pg 26784<br>
<latex>~\\<br>What are the $\_\langle\&?\rangle\_$ and $\_\langle ?\& \rangle\_$ combinators defined by Allais? Give their types.<br></latex>	pg 26784, near bottom<br><br>
<latex>~\\<br>Explain, intuitively, what Allais's $\_ \& ? \gg =\_$ combinator does. Give its type signature.<br></latex>	pg 26785<br>
<latex>~\\<br>Suppose we have a model $\mathcal M : C \ell(\Sigma) \to \mathbb B$ of $\Sigma$ in a category $\mathbb B$ and two terms $\Gamma \vdash N, N' : \sigma$ in the term calculus of $\Sigma$. What does it mean for an algebraic $\Sigma$-equation $\Gamma \vdash N =_\sigma N'$ to be \emph{valid} (or to \emph{hold})?<br></latex>	pg 10162<br>
<latex>~\\<br>Let $\mathcal M : C \ell(\Sigma) \to \mathbb B$ be a model of $\Sigma$ in a category $\mathbb B$. Let $\mathcal A$ be a set of algebraic equations over $\Sigma$. What does $\mathcal M \vDash \mathcal A$ mean?<br></latex>	pg 10162<br>
<latex>~\\<br>Consider the specification of groups, whose signature has one type $G$ and three function symbols $m : G,G \to G$, $e : 1 \to G$, and $i : G \to G$, and also the equations:\\~\\<br>$v_1 : G \vdash m(e, v_1) =_G v_1$\\<br>$v_1 : G \vdash m(v_1, e) =_G v_1$\\<br>$v_1 : G \vdash m(i(v_1),v_1) =_G e)$\\<br>$v_1 : G \vdash m(v_1,i(v_1)) =_G e)$\\<br>$v_1 : G, v_2 : G, v_3 : G \vdash m(v_1, m(v_2, v_3)) =_G m(m(v_1,v_2),v_3)$\\~\\<br>What, concretely, is a \emph{model} of this specification?<br></latex>	pg 10162, example 3.3.1<br>spills over to pg 10163 top<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a category $\mathbb B$ with finite limits, the posets $Sub(I)$ of subobjects of an object $I \in B$ have finite products.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10163<br>
<latex>~\\<br>Let $E$ be a conditional $\Sigma$-equation<br>$$ \Gamma \mid M_1 =_{\sigma_1} M'_1,\ldots,M_n =_{\sigma_n} M'_n \vdash N =_\tau N'$$<br>What does it mean for $E$ to \emph{hold} in a model $\mathcal M : C\ell(\Sigma) \to \mathbb B$?<br></latex>	pg 10163<br>
<latex>~\\<br>What does it mean for an inference rule<br>\begin{mathpar}<br>\inferrule<br>  {S_1}<br>  {S_2}<br>\end{mathpar}<br>to be \emph{sound}?<br></latex>	pg 10164<br>
<latex>~\\<br>Let $(\Sigma,\mathcal A)$ be an algebraic specification and let $\mathcal M : C \ell(\Sigma) \to \mathbb B$ be a model of $\mathcal A$. Consider the following statement:\\~\\<br>Every (algebraic) equation derivable from $\mathcal A$ holds in $\mathcal M$. Thus $\mathcal M$ is a model of the theory of $(\Sigma, \mathcal A)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10164, lemma 3.3.2<br>todo: add impostor?<br>todo: obviously this is by induction on the structure of derivations; but there are a lot of rules, so maybe we should break this card up into smaller cards asking to prove individual cases.<br><br>
<latex>~\\<br>Let $(\Sigma, \mathcal A)$ be an algebraic specification. What does it mean for $\Sigma$-terms $\Gamma \vdash N, N' : \sigma$ to be \emph{equivalent modulo} $\mathcal A$?<br></latex>	pg 10164, def 3.3.3<br><br>
<latex>~\\<br>Let $(\Sigma, \mathcal A)$ be an algebraic specification. How do we define the \emph{classifying category} $C \ell(\Sigma,\mathcal A)$?<br></latex>	pg 10164, def 3.3.3<br>
<latex>~\\<br>Sometimes Jacobs uses the notation $| M |$ for equivalence classes and other times $[ M ]$. What is the distinction between these two notations for?<br></latex>	pg 10164, parenthetical remark at very bottom of page<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A classifying category $C \ell(\Sigma, \mathcal A)$ has finite products. Moreover, there is a bijective correspondence between.<br>\begin{prooftree}<br>\AxiomC{$C \ell(\Sigma,\mathcal A) \overset{\mathcal M}{\longrightarrow} \mathbb B \text{ in } \textbf{FPCat}$}<br>\doubleLine<br>\UnaryInfC{$C \ell(\Sigma) \underset{\mathcal N}{\longrightarrow} \mathbb B \text{ in } \textbf{FPCat} \text{ with } \mathcal N \vDash \mathcal A$}<br>\end{prooftree}<br>Prove or disprove.<br></latex>	true. pg 10165, theorem 3.3.4<br>todo: add impostor.<br>
<latex>~\\<br>Let $(\Sigma, \mathcal A)$ be an algebraic specification. Consider the following statement:\\~\\<br>An (algebraic) equation is derivable from $\mathcal A$ if and only if it holds in all models of $(\Sigma, \mathcal A)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10165, corollary 3.3.5<br>todo: add impostor?<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. What does $\mathcal A(\mathbb B)$ denote? What does $\varepsilon$ (implicitly parameterized by $\mathbb B$) denote?<br></latex>	pg 10166, def 3.3.6 & example 3.3.7<br>the theorems on pg 10108 may be helpful to look at<br>
<latex>~\\<br>We have the following theorem due to Lawvere:\\~\\<br>A category $\mathbb B$ with finite products is equivalent to the classifying category $\mathcal C \ell(\text{Sign}(\mathbb B), \mathcal A(\mathbb B))$ of its own theory of algebraic equations.\\~\\<br>Prove this theorem, and explain why it is useful.<br></latex>	pg 10167<br>
<latex>~\\<br>What does Jacobs use the symbol $\delta$ for?<br></latex>	pg 10169<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$\delta$ is a mono\\~\\<br>Prove or disprove.<br></latex>	It is a mono because it is a split mono, see pg 10169<br>todo: add impostor?
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration on a base category $\mathbb B$ with Cartesian products. What does it mean for $p$ to have \emph{simple equality}?<br></latex>	pg 10169 bottom<br>spills to pg 10170 top<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration on a base category $\mathbb B$ with Cartesian products, and further suppose that $p$ has fibred finite products. What does it mean for $p$ to have \emph{equality with the Frobenius property}?<br></latex>	<latex>~\\<br>The transpose of <br>$$\delta^*(X) \times Y \overset{\mathit{id} \times \eta_Y}{\longrightarrow} \delta^*(X) \times \delta^*(Eq_{I,J}(Y)) \overset{\mathit{rapl}}{\longrightarrow} \delta^*(X \times Eq_{I,J}(Y))$$<br>has an inverse.\\~\\<br>pg 10170, (ii) near top<br></latex>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration with simple equality. Assume $p$ has a terminal object functor $1 : \mathbb B \to \mathbb E$, as described in lemma 1.8.8 on page 10064. For parallel maps $u,v : I \rightrightarrows J$ in $\mathbb B$, what does $Eq(u,v)$ denote?<br></latex>	pg 10170, notation 3.4.2 near bottom,<br>spills onto pg 10171<br><br><br>
<latex>~\\<br>How, mathematically, do we describe a plane in a 3D space? What is an equation that all points $\vh p$ on this plane must satisfy?<br></latex>	<latex>~\\<br>pg 28648, near bottom. To derive the equation, we start with the intuitive formula $$(\vec{p} - \vec{p}_{\beta}) \cdot \vec{n}_{\beta} = 0$$ From this, we can derive the formula shown in the book.<br></latex>
<latex>~\\<br>Go to page 28648, and then scroll down just until fig 6.1 is visible.\\~\\<br>How do we compute the projection $\vec q$ of a point $\vec{p}$ onto a line passing through points $\vec{p_1}$ and $\vec p_2$?<br></latex>	pg 28649, section 6.2<br><br>
<latex>~\\<br>Show how to project a point $\vec p$ onto a plane $\beta$. Drawing a picture may be a good first step.<br></latex><br>	<latex>~\\<br>Remember that a plane $\beta$ is represented by a normal $\vec{n}_{\beta}$ and a point on the plane $\vec{p}_{\beta}$. See page 28649, section 6.3, which spills onto page 28650.<br></latex><br>
Give a block diagram representing the main loop  of a dynamic simulation engine. Describe each block.	pg 28376, figure 1.1, Section 1.3, spills to next page<br><br><br><br><br>
<latex>~\\<br>What is a \emph{psuedo-map of adjunctions}?<br></latex>	pg 10070, exercise 1.8.7 introduction<br>
<latex>~\\<br>Read definition 1.9.4 on pg 10076. Show that the mentioned Beck-Chevalley condition actually is a Beck-Chevalley condition, as described in exercise 1.8.7 on page 10070.<br></latex>	<latex>~\\<br>\begin{tikzcd}<br>\mathbb E_J \ar[r,"s^*"] \ar[d, "u^*" left, bend right = 20] & \mathbb E_L \ar[d,"v^*" left, bend right = 20] \\<br>\mathbb E_I \ar[r,"r^*" below] \ar[u, "\prod_u" right, bend right = 20] & \mathbb E_K \ar[u, "\prod_v" right, bend right = 20] <br>\end{tikzcd}~~~~~~~~~<br>\begin{tikzcd}<br>K \ar[d,"r" left] \ar[r, "v"] & L \ar[d,"s" right]  \\<br>I \ar[r,"u" below] & J<br>\end{tikzcd}\\~\\<br>To show this actually is a Beck-Chevalley condition, we must have $r^*u^* \cong v^*s^*s$, which we get from:<br>$$ r^*u^* \cong (ur)^* = (sv)^* \cong v^*s^*$$<br><br></latex>
<latex>~\\<br>Consider definition 1.9.1 on page 10073, and in particular its Beck-Chevalley condition (top of pg 10074). <br>Demonstrate that this actually is a Beck-Chevalley condition, as described in the introduction to Exercise 1.8.7 pg 10070. <br></latex>	<latex>~\\<br>We must show that $(u \times id)^*\pi^*_{I,J} \cong \pi^*_{K,J}u^*$. This comes from:<br>$$ (u \times id)^*\pi^*_{I,J} \cong (\pi_{I,J} \circ (u \times id))^* = (u \circ \pi_{K,J})^* \cong \pi_{K,J}^*u^*$$<br></latex>
<latex>~\\<br>Assume that the pair $(\mathbb B, T)$ forms a $CT$-structure. Consider the following statement:\\~\\~\\<br>The collection $T \subseteq Obj~\mathbb B$ is closed under exponents. That is,<br>for types $X,Y \in T$ there is an exponent type $X \Rightarrow Y \in T$ together with an evaluation<br>morphism $ev : (X \Rightarrow Y) \times X \to Y$ such that for each object $I \in \mathbb B$ and map <br>$f : I \times X \to Y$ in $\mathbb B$ there is a unique abstraction map $\Lambda(f) : I \to X \Rightarrow Y$ with $ev \circ \Lambda(f) \times id = f$.\\~\\~\\<br>Prove or disprove.<br></latex>	true. pg 10130/10131, (i) => (ii)<br>
<latex>~\\<br>Let $(\mathbb B, T)$ be a non-trivial $CT$-structure. Assume the collection $T \subseteq Obj~\mathbb B$ is closed under exponents. That is,<br>for types $X,Y \in T$ there is an exponent type $X \Rightarrow Y \in T$ together with an evaluation<br>morphism $ev : (X \Rightarrow Y) \times X \to Y$ such that for each object $I \in \mathbb B$ and map <br>$f : I \times X \to Y$ in $\mathbb B$ there is a unique abstraction map $\Lambda(f) : I \to X \Rightarrow Y$ with $ev \circ \Lambda(f) \times id = f$.\\~\\<br>Consider the following statement:\\~\\<br>The pair $(\mathbb B, T)$ forms a $\lambda1$-category.\\~\\<br>Prove or disprove.<br></latex>	pg 10130, (ii) => (i)<br><br>
<latex>~\\<br>What is a \emph{monoidal category}?<br></latex>	pg 18601<br>
<latex>~\\<br>There is a class of monoidal categories called the \emph{cartesian monoidal categories}. Define this class.<br></latex>	pg 18601, bottom paragraph<br><br>
<latex>~\\<br>Kelly defines a functor $V$ with respect to the background monoidal category $\mathcal V$. How is $V$ defined?<br></latex>	<latex>~\\<br>It's defined as the representable functor $\mathcal V_0(I, -)$. Intuitevly, it produces the underlying set of whichever object it is applied to.<br>pg 18602, second paragraph above section 1.2<br><br></latex>
<latex>~\\<br>Let $X \in \mathcal V_0$ be an element of the monoidal category $\mathcal V$. What is an \emph{element} of $X$?<br></latex>	pg 18602, right above section 1.2<br>
<latex>~\\<br>Let $\mathcal V$ be a monoidal category. Provide the definition of ``$\mathcal V$-category''.<br></latex>	pg 18602, section 1.2<br>
<latex>~\\<br>What does it mean for a $\mathcal V$-category to be \emph{small}?<br></latex>	pg 18603, near top<br>
<latex>~\\<br>What, intuitively, is a $\mbf{Cat}$-enriched category?<br></latex>	It's a 2-category.<br>pg 18602, near bottom<br>
<latex>~\\<br>What, intuitively, is a $\mbf{2}$-enriched category? (Hint: it's a familiar mathematical structure.)<br></latex>	A pre-ordered set.<br>pg 18602<br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be $\mathcal V$-categories. What is a ``$\mathcal V$-functor''?<br></latex>	pg 18603, near top.<br>
<latex>~\\<br>What, concretely, is a $\mbf{Cat}$-functor?<br></latex>	it's a 2-functor<br>pg 18603, "In the six examples above, we re-find..."
<latex>~\\<br>What, concretely, is a $\mbf{2}$-functor? (Note that we don't mean 2-functor; we mean a $\mathcal V$-functor where $\mathcal V = \mbf{2}$).<br></latex>	It's a monotone function between preordered sets.<br>pg 18603, "In the six examples..."
<latex>~\\<br>Let $T,S : \mathcal A \to \mathcal B$ be $\mathcal V$-functors. What is a $\mathcal V$-natural transformation?<br></latex>	<latex>~\\<br>pg 18603, ``For \mathcal V-functors ...''<br></latex><br>
<latex>~\\<br>Take a look at example 3.4.4 (i) on page 10172. Jacobs gives a rather high-level view of what's going on. Provide an in-depth explanation.<br></latex>	<latex>~\\<br>Recall that the category $\vrt{\mathbb B^\to}{\mathbb B}\mathit{cod}$ is only a fibration when $\mathbb B$ has pullbacks, and so that is an assumption of this example. Then the $\delta_{I,J}^* : \mathbb{B}^{\to}_{(I \times J) \times J }\to \mathbb B^{\to}_{I \times J}$ functor works as follows: \\<br>\begin{center}<br>\begin{tikzcd}<br>\delta_{I,J}^*(X) \ar[dr, phantom, "\lrcorner", very near start] \ar[d,"\delta_{I\text{,}J}^*(f)" left] \ar[r, "\overline{\delta^*_{I \text{,} J}}(X)"] & \ar[d,"f" right] X \\<br>I \times J \ar[r,"\delta_{I\text{,}J}" below] & (I \times J) \times J<br>\end{tikzcd}<br>\end{center}<br>And we have the following adjunction:<br>\begin{center}<br>\begin{prooftree}<br>\AxiomC{$\vrt{Y}{(I \times J) \times J}g;\delta_{I,J} ~~~~~\overset{a;\overline{\delta_{I,J}^*}(X)}\longrightarrow~~~~~ \vrt{X}{(I \times J) \times J}f$}<br>\doubleLine<br>\UnaryInfC{$\vrt{Y}{I \times J}g~~~~~\overset{a}{\longrightarrow}~~~~~\vrt{\delta^*(X)}{I \times J}\delta^*(f)$}<br>\end{prooftree}<br>\end{center}<br>Note that $1$, the terminal object of $\mathbb{B}^{\to}_{I \times J}$, is $id_{I \times J}$. The rest should follow from here.<br>TODO: prove that this is actually an adjunction. What is the unit? What is the counit?\\~\\<br>pg 10172<br></latex>
<latex>~\\<br>Read example (iii) pg 10173 down to ``In case the category...''.<br>Jacobs has given an outline of an argument that $\vrt{\text{Fam}(\mathbb C)}{\mbf{Sets}}$ has equality; complete this argument. In particular, show:<br>\begin{enumerate}<br>\item The given bijection is actually an adjunction.<br>\item The Beck-Chevalley condition for equality is satisfied.<br>\end{enumerate}<br></latex>	<latex>~\\<br>Here is the adjunction diagram.\\~\\<br>\begin{tikzcd}[sep = 70]<br>(Y_{i \text{,} j})_{(i\text{,}j) \in I \times J} \ar[r, "(f_{(i\text{,}j\text{,}j)})_{(i\text{,}j) \in I \times J}"] & (X_{(i\text{,}j\text{,}j)})_{(i\text{,}j) \in I \times J} \\<br>(Y_{i \text{,} j})_{(i\text{,}j) \in I \times J} \ar[u,"id"left ] \ar[ur, "~~~~~~~~~~~~~~~~~~(f_{(i\text{,}j\text{,}j)})_{(i\text{,}j) \in I \times J}" below] \\<br>\left ( \begin{array}{l} Y_{i\text{,}j}~~\text{if}~j=j' \\ 0~~~~\text{otherwise} \end{array} \right )_{(i\text{,}j\text{,}j) \in (I \times J) \times J}<br>  \ar[r, "(f_{i\text{,}j\text{,}j'})_{(i\text{,}j) \in (I \times J) \times J}"] <br>  \ar[dr, "\left \{ \begin{array}{l} f_{(i\text{,}j)}~\text{if}~j = j' \\ ! ~~~~~~\text{otherwise} \end{array}~~~~~\right" below]  & <br>  (X_{(i\text{,}j\text{,}j')})_{(i\text{,}j\text{,}j') \in I \times J \times J} \\<br>  & \left ( \begin{array}{l} X_{(i \text{,} j \text{,} j)}~~\text{if}~j = j' \\ 0~~~~~~~~~\text{otherwise} \end{array}  \right )_{(i\text{,}j\text{,}j') \in I \times J \times J}<br>\ar[u, "\left \{ \begin{array}{l} \text{id if } j = j' \\ !~otherwise \end{array} \right" right]<br>\end{tikzcd}\\~\\<br>To show Beck-Chevalley, we must show that the transpose of the natural transformation<br>\begin{center}<br>\begin{tikzcd}<br>(u \times id)^* \ar[r,"(u \times id)^* \eta"] & (u \times id)^*\delta^*Eq \ar[r,"\cong"] & \delta^* ((u \times id) \times id)^* Eq <br>\end{tikzcd}<br>\end{center}<br>has an inverse. Note that, because the unit of this adjunction is the identity transformation (as described above) and because this fibration is split (easy to work out), we are simply taking the transpose of the identity. <br>That yields the arrow $\left ( \begin{array}{ll} id_{X_{u(k),j}} & \text{if j = j'} \\ ! = id_0 & \text{otherwise} \end{array} \right )$. This is an identity arrow, and so it clearly has an inverse (itself).<br>\\<br>pg 10173<br></latex>
<latex>~\\<br>Let $T,S,R : \mathcal A \to \mathcal B$ be $\mathcal V$-functors and $\alpha : T \to S$ and $\beta : S \to R$ be $\mathcal V$-natural transformations. Provide the definition of the ``vertical composite'' $(\beta \cdot \alpha)_A$.<br></latex>	pg 18603<br>
<latex>~\\<br>Let $T,S : \mathcal A \to \mathcal B$ be $\mathcal V$-functors. Let $\alpha : T \to S$ be a $\mathcal V$-natural transformation. Let $Q : \mathcal B \to \mathcal C$ be a $\mathcal V$-functor. How is the composite $Q \alpha$ defined?\\~\\<br>Let $P : \mathcal D \to \mathcal A$. How is $\alpha P$ defined?<br></latex><br>	pg 18603, near bottom<br>pg 18604, near top<br><br><br>
<latex>~\\<br>For some monoidal category parameter $\mathcal V$, we denote $\mathcal I$ by the \emph{unit} $\mathcal V$-\emph{category}. How is this $\mathcal V$-category defined?<br></latex>	pg 18604, top of section 1.3<br>
<latex>~\\<br>Let $\mathcal I$ be the \emph{unit} $\mathcal V$-category with one object $0$ and with $\mathcal I(0,0) = I$.<br>A $\mathcal V$-functor $A : \mathcal I \to \mathcal A$ may be identified with \underline{~~~~~~~} of the <br>$\mathcal V$-category $\mathcal A$ (why?). What can be said of a $\mathcal V$-natural $f : A \to B : \mathcal I \to \mathcal A$?<br></latex>	pg 18604<br>
The second paragraph of section 1.3, pg 18604, speaks of an axiom being trivially satisfied. Elaborate on this.<br>	<latex>~\\<br>We have $\mathcal A(0,0) = I$ by assumption. And from the definition of $\mathcal V$-functor, we can derive that $F_{0,0} = j_{F_0}$. Instead of functors $A$ and $B$, we'll use $F$ and $G$. The top half of diagram (1.7) becomes<br>\begin{center}<br>\begin{tikzcd}<br> & I \otimes I \ar[r,"\alpha_0 \otimes j_{F0}"] & \mathcal B(F0,G0) \otimes \mathcal B(F0,F0) \ar[dr,"M"] & \\<br>I \ar[ur,"l^{-1}"] & & & \mathcal B(F0,G0)<br>\end{tikzcd}<br>\end{center}<br>Expanding this out and adding the bottom half gives<br>\begin{center}<br>\begin{tikzcd}<br> & I \otimes I \ar[r,"\alpha_0 \otimes 1"] & \mathcal B(F0,G0) \otimes I \ar[r,"1 \otimes j_{F0}"] & <br>  \mathcal B(F0,G0) \otimes \mathcal B(F0,F0) \ar[dr, "M"] & \\<br>I \ar[ur,"l^{-1}"] \ar[dr, "r^{-1}~~" below] & & & & \mathcal B(F0,G0) \\<br> & I \otimes I \ar[r,"1 \otimes \alpha_0" below] & \mathcal B(F0,G0) \otimes I \ar[r,"j_{G0} \otimes 1" below] & <br>  \mathcal B(F0,G0) \otimes \mathcal B(F0,F0) \ar[ur, "M" below] & <br>\end{tikzcd}<br>\end{center}<br>Now we can apply (1.4) to get:<br>\begin{center}<br>\begin{tikzcd}<br> & I \otimes I \ar[r,"\alpha_0 \otimes 1"] & \mathcal B(F0,G0) \otimes I \ar[drr,"r"] \ar[r,"1 \otimes j_{F0}"] & <br>  \mathcal B(F0,G0) \otimes \mathcal B(F0,F0) \ar[dr, "M"] & \\<br>I \ar[ur,"l^{-1}"] \ar[dr, "r^{-1}~~" below] & & & & \mathcal B(F0,G0) \\<br> & I \otimes I \ar[r,"1 \otimes \alpha_0" below] & \mathcal B(F0,G0) \otimes I \ar[r,"j_{G0} \otimes 1" below] \ar[urr,"l" below] & <br>  \mathcal B(F0,G0) \otimes \mathcal B(F0,F0) \ar[ur, "M" below] & <br>\end{tikzcd}<br>\end{center}<br>TODO: I think now we can just apply coherence. But I don't understand coherence enough to claim that this is correct, so I will just make a note to look into the topic in the future.\\~\\<br>pg 18604<br></latex><br><br>
<latex>~\\<br>Let $\mathcal A$ be a $\mathcal V$-category. What does $\mathcal A_0$ denote?<br></latex>	pg 18604<br>
<latex>~\\<br>Suppose that $\mathbb C$ is a category with initial object 0. The family fibration $\vrt{Fam(\mathbb C)}{\mbf{Sets}}$ then has equality: for a family $X = (X_{(i,j)})_{(i,j) \in I \times J}$ of $\mathcal C$-objects over $I \times J$ one defines a family over $(I \times J) \times J$ by<br>$$Eq(X)_{(i,j,j')} = \left \{ \begin{array}{ll} X_{(i,j)} & \text{if } j = j' \\ 0 & \text{else} \end{array} \right $$<br>We get a bijective correspondence.<br>\begin{prooftree}<br>\AxiomC{$(Eq(X)_{(i,j,j')}) \longrightarrow (Y_{(i,j,j')})$}<br>\doubleLine<br>\UnaryInfC{$(X_{(i,j)}) \longrightarrow (Y_{(i,j,j)}) = \delta^*(Y_{(i,j,j')})$}<br>\end{prooftree}<br>Now suppose that $\mathbb C$ has finite products in such a way that functors $Z \times (-) : \mathbb C \to \mathbb C$ preserve the initial object, in the sense that the unique arrow $0 \longrightarrow Z \times 0$ is an isomorphism. Does the family fibration have finite products?<br>As rough evidence that the family fibration satisifies equality with Frobenius, show that there exists an isomorphism with the appropriate signature (domain and codomain).<br></latex>	pg 10173,<br>this refers to example 1.8.3 (i) on page 10060.
<latex>~\\<br>The definition of $Eq(u,v)$ at the bottom of page 10170 may look cryptic at first glance. To understand it better, consider its subexpressions bottom-up from three different perspectives:<br>\begin{enumerate}<br>\item For some $\mathbb B$ with pullbacks and products, the codomain fibration $\vrt{\mathbb B^{\to}}{\mathbb B}$<br>\item For some $\mathbb C$ with an initial object 0, the family fibration $\vrt{Fam(\mathbb C)}{\mbf{Sets}}$<br>\item From a purely abstract perspective, assuming an arbitrary fibration.<br>\end{enumerate}<br>For each of these increasingly large sub-expression, do steps 1-3 in order:<br>\begin{itemize}<br>\item The terminal object $1$ of the fibration $I \times J$<br>\item $Eq_{I,J}(1)$, i.e. the image of $1$ through the functor $Eq_{I,J}$<br>\item $\langle id, \langle u, v \rangle \rangle^*(Eq_{I,J}(1))$<br>\end{itemize}<br></latex>	<latex>~\\<br>\begin{description}<br>\item[1 - The terminal object of the fibre over $I \times J$]~\\<br>\begin{description}<br>\item[Codomain fibration:]~\\<br>The terminal object is $\vrt{I \times J}{I \times J}id$. It represents ``pure dependence'' on $I \times J$.<br>\item[Family fibration:]~\\<br>The terminal object is $(1)_{(i,j) \in I \times J}$, again a from of pure dependence.<br>\item[Arbitrary fibration:]~\\<br>Pure dependence on $I \times J$.<br>\end{description}<br>\item[2 - $Eq_{I,J}(1)$:]~\\<br>\begin{description}<br>\item[Codomain fibration:]~\\<br>$Eq_{I,J}(1)$ is the display map $\vrt{I \times J}{I \times J \times J}\delta$. It represents pure dependence when two $J$ components coincide and degenerate dependence (the empty set) when they do not.<br>\item[Family fibration:]~\\<br>$Eq_{I,J}(1)$ is the family $\left ( \begin{array}{ll} 1 & \text{if } j = j' \\ 0 & \text{otherwise} \end{array} \right )_{(i,j,j')}$. It represents pure dependence ($1$ means ``no information'') when $j = j'$ and degenerate independence ($0$ means ``contradiction'') when $j \neq j'$.<br>\item[Arbitrary fibration:]~\\<br>Pure independence where $j = j'$ and degenerate independence where $j \neq j'$.<br>\end{description}<br>\item[3 - $\langle id, \langle u, v \rangle \rangle^*(Eq_{I,J}(1))$:]~\\<br>\begin{description}<br>\item[Codomain fibration:]~\\<br>TODO.<br>\end{description}<br>\end{description}<br></latex>
<latex>~\\<br>Let $ax^2 + bx + c = 0$. Solve for $x$.<br></latex>	<latex>~\\<br>This is the quadratic formula: $x = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}$<br></latex><br>
<latex>~\\<br>Simplify the following expressions:\\~\\<br>sin(x + y)\\<br>sin(x - y)<br></latex>	<latex>~\\<br>1.) sin~x~cos~y + cos~x~sin~y\\<br>2.) sin~x~cos~y - cos~x~sin~y\\~\\<br>note that the latter can be derived from the former. TODO: Is there a way to derive the former somehow?<br></latex>
<latex>~\\<br>Simplify the following expressions:\\~\\<br>cos(x + y)\\<br>cos(x - y)<br></latex>	<latex>~\\<br>1.) cos~x~cos~y - sin~x~sin~y   \\<br>2.) cos~x~cos~y + sin~x~sin~y  \\~\\<br>Note that the latter can be derived from the former. TODO: Is there some way to derive the former?<br></latex>
<latex>~\\<br>Prove the following isomorphism.<br>$$w^*(Eq(u,v)) \cong Eq(u \circ w, v \circ w)$$<br></latex>	pg 10171<br>
Why does the definition of a fibration having equality (an Eq fibration) require a Beck-Chevalley condition?	<latex>~\\<br>It's used to justify substitution, i.e. to prove the following isomorphism:<br>$$w^*(Eq(u,v)) \cong Eq(u \circ w, v \circ w)$$<br>see page 10171\\~\\<br>It's also used for transitivity. \\~\\ see pg 10175/10176<br></latex>
<latex>~\\<br>How do we prove the isomorphism<br>$$Eq_{I,J}(X) \cong \pi^*(X) \times Eq_{I,J}(1)$$<br>Does this isomorphism hold in every fibration with equality, or just some of them?<br>Why is this isomorphism useful? Intuitively what does it mean?<br></latex>	pg 10171<br>
<latex>~\\<br>Consider the fibration defined on page 10153. Does this fibration have equality? If so, does it satisfy Frobenius? Prove your answer.<br></latex>	pg 10173 (iv) / 10174<br>
Read example (iv), starting at the bottom of page 10173.<br><br>The "proof" of Frobenius near the top of pg 10174 is not actually a proof, since Frobenius speaks of a *specific* iso between these two objects rather than an arbitrary one. Demonstrate that the iso pair provided on this page includes the canonical map as one of its components.<br><br>	all we need to do is note that this is a preorder fibration: there is at most one iso between any two objects in the total category.<br><br>pg 10174, it isn't discussed on the page, but the above explanation should be sufficient.<br><br>
<latex>~\\<br>For any fibration with equality satisfying Frobenius, and any map $u : I \to J$ in the base category, there is a combinator $1 \overset{refl}{\longrightarrow} Eq(u,u)$. Show how this combinator is constructed.<br></latex>	pg 10175
<latex>~\\<br>For any fibration with equality satisfying Frobenius, and any parallel morphisms $u,v : I \rightrightarrows J$ in the base category, there is a combinator $Eq(u,v) \overset{sym}{\longrightarrow} Eq(v,u)$. Show how this combinator is constructed.<br></latex>	<latex>~\\<br>Note that the isomorphism on the second line between $\gamma^*Eq(1)$ and $Eq(1)$ is due to the fact that both $\overline{\gamma^*}(Eq(1))$ and $id_{Eq(1)}$ are Cartesian arrows into $Eq(1)$.\\<br>pg 10175<br></latex><br>
<latex>~\\<br>For any fibration with equality satisfying Frobenius, and any parallel maps $u,v,w : I \rightrightarrows J$ in the base category, there is a combinator $Eq(u,v) \times Eq(v,w) \overset{trans}{\longrightarrow} Eq(u,w)$. Show how this combinator is constructed.<br></latex>	pg 10175
<latex>~\\<br>For any fibration with equality satisfying Frobenius, and all maps $u,v : I \rightrightarrows J$ and $t : I \times J \to K$ in the base category, there is a combinator $Eq(u,v) \overset{repl}{\longrightarrow} Eq(t \circ \langle id, u \rangle,t \circ \langle id,v \rangle)$. Show how this combinator is constructed.<br></latex>	<latex>~\\<br>pg 10176, "For the replacement combinator repl..."\\<br>The isomorphism here is a bit subtle. As a lemma, note that $id_{I \times J} = \pi \circ \delta$. Then we have:\\~\\<br>$Eq(t \circ \pi \circ \delta, t \circ (\pi \times id) \circ \delta)$ \\<br>$= \langle \langle id, t \circ \pi \circ \delta \rangle, t \circ (\pi \times id) \circ \delta \rangle^*Eq(1)$\\<br>$= \langle \langle \pi \circ \delta, t \circ \pi \circ \delta \rangle, t \circ (\pi \times id) \circ \delta \rangle^*Eq(1)$\\<br>$= (\langle \langle \pi, t \circ \pi \rangle, t \circ (\pi \times id) \rangle \circ \delta)^*Eq(1)$\\<br>$\cong \delta^*\langle \langle \pi, t \circ \pi \rangle, t \circ (\pi \times id) \rangle^*Eq(1)$\\<br>$= \delta^*\langle \langle id, t \circ \pi \rangle, t \circ (\pi \times id) \rangle^*((\pi \times id) \times id)^*  Eq(1)$\\<br>$\cong \delta^*\langle \langle id, t \circ \pi \rangle, t \circ (\pi \times id) \rangle^*Eq(\pi \times id)^*(1)$\\<br>$\cong \delta^*\langle \langle id, t \circ \pi \rangle, t \circ (\pi \times id) \rangle^*((\pi \times id) \times id)^*Eq(1)$\\~\\<br>The second-to-last line is Beck-Chevalley of Eq. The last line fibred finite (nullary) products, which requires reindexing to preserve 1.<br></latex><br><br>
<latex>~\\<br>For any fibration with equality satisfying Frobenius, and all parallel maps $u,v : I \rightrightarrows J$ in the base category, there is a combinator $u^*(X) \times Eq(u,v) \overset{subst}{\longrightarrow} v^*(X)$. Show how this combinator is constructed.<br></latex>	pg 10176, "Finally for the substitution combinator subst notice..."<br>
<latex>~\\<br>Consider a fibred preorder with fibred finite products and equality satisfying Frobenius. <br>Let $u_1,v_1: I \to J_1$ and $u_2,v_2 : I \to J_2$. Consider the following statement:\\~\\<br>There is a vertical morphism<br>$$Eq(\langle u_1,u_2 \rangle, \langle v_1, v_2 \rangle) \to Eq(u_1,v_1) \wedge Eq(u_2,v_2)$$<br>Prove or disprove.<br></latex>	true. pg 10177/10178<br>This is part of an iso pair, but I found the description of the other direction to be extremely confusing.<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p \overset{(K,L)}{\longrightarrow} \vrt{\mathbb E'}{\mathbb B'}p'$ be a morphism of fibrations. What does it mean for $(K,L)$ to \emph{preserve equality}?<br></latex>	<latex>~\\<br>We have $\gamma_1 : KI \times KJ \to K(I \times J)$ and $\gamma_2 : K(I \times J) \times KJ \to K((I \times J) \times J)$, and the following Beck-Chevalley diagram.<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb E_{I \times J} \ar[r, "Eq_{I,J}" above, bend left = 20] \ar[d, "L" left]<br>& \mathbb E_{(I \times J) \times J} \ar[d, "L" right] \ar[l, "\delta^*_{I,J}" below, bend left = 20] \\<br>\mathbb D_{K(I \times J)} \ar[d, "\gamma_1^*" left] & \mathbb D_{K((I \times J) \times J)} \ar[d, "((\gamma_1 \times id);\gamma_2)^*"] \\<br>\mathbb D_{KI \times KJ} \ar[r, "Eq_{KI,KJ}" above, bend left = 20] & \ar[l, "\delta^*_{KI,KJ}" below, bend left = 20] \mathbb D_{(KI \times KJ) \times KJ}<br>\end{tikzcd}<br>\end{center}<br>We must demonstrate a natural isomorphism $\gamma_1^*L\delta_{I,J}^* \Rightarrow \delta_{KI,KJ}^*((\gamma_1 \times id);\gamma_2)^*L$. This isomorphism comes from the unique <br>commuting arrows between the following two Cartesian arrows:<br>\begin{center}<br>\begin{tikzcd}<br>\gamma_1^*L\delta_{I,J}^*(A) \ar[r, "\overline{\gamma_1^*}\cdots"] & L\delta_{I,J}^*(A) \ar[rd, " ~~~~ L\overline{\delta^*}(A)" above] & \\<br>                                            &                          & LA \\<br>\delta_{KI,KJ}^*((\gamma_1 \times id);\gamma_2)^*L(A) \ar[r, "\overline{\delta^*}_{KI,KJ}\cdots" below] & ((\gamma_1 \times id);\gamma_2)^*L(A) \ar[ur, "~~~~~~~~~~~~\overline{((\gamma_1 \times id);\gamma_2)^*}\cdots" below] &<br>\end{tikzcd}<br>\end{center}<br>TODO: Now we must show that this family of isos is natural.\\~\\<br>pg 10178, def 3.4.7<br></latex><br>
<latex>~\\<br>What is an \emph{Eq-fibration}?<br></latex>	pg 10180<br>
<latex>~\\<br>Is the fibration $\vrt{\mathcal L(\Sigma, \mathcal H)}{\mathcal C \ell(\Sigma)}$ an Eq-fibration? Why or why not?<br></latex>	true. pg 10180.<br>todo: add impostor<br>
<latex>~\\<br>For a category $\mathbb B$ with finite limits, is the fibration $\vrt{Sub(\mathbb B)}{\mathbb B}$ an Eq-fibration? Why or why not?<br></latex>	true. pg 10180. references example (ii) on pg 10172.<br><br><latex>~\\<br>It claims that Frobenius is easy. I agree. Here is my proof:\\~\\<br>$Eq(\delta^*(\vrt{X}{I \times J \times J}f) \times \vrt{Y}{I \times J}g) = Eq(\vrt{X}{I \times J}f;\pi~\times~ \vrt{Y}{I \times J} g) = Eq(\vrt{X \times Y}{I \times J}\pi;g) = \vrt{X \times Y}{I \times J \times J}\pi;g;\delta}$\\~\\<br>The codomain of Frobenius is exactly the same, so Frobenius is not only an iso in this case, but more specifically an identity.<br></latex><br>
<latex>~\\<br>For a category $\mathcal B$ with finite limits, is the fibration $\vrt{\mathbb B^\to}{\mathbb B}$ an Eq-fibration? Why or why not?<br></latex>	IMPOSTOR! the total category must be a preorder, as in example (ii) on pg 10180<br>pg 10180<br>
<latex>~\\<br>Let $X$ be a poset (or preorder) with finite meets and a bottom element. Is the family fibration $\vrt{Fam(X)}{Sets}$ an Eq-fibration? Why or why not?<br></latex>	Yes. pg 10180, example (iii)<br> 
<latex>~\\<br>Let $X$ be a poset (or preorder) with a bottom element. Is the family fibration $\vrt{Fam(X)}{Sets}$ an Eq-fibration? Why or why not?<br></latex>	IMPOSTOR!<br><br>Not necessarily. the poset must have finite meets so that the fibration has fibred finite products.<br><br>This is a modification of example (iii) on:<br>pg 10180<br>
<latex>~\\<br>Consider a situation:<br>\begin{center}<br>\begin{tikzcd}<br> & \mathbb E \ar[d,"p" right] \\<br>\mathcal C \ell(\Sigma) \ar[r,"\mathcal M" below] & \mathbb B<br>\end{tikzcd}<br>\end{center}<br>where $p$ is an Eq-fibration and $\mathcal M$ is a model of the signature $\Sigma$ in the base category $\mathbb B$. What does it mean for a $\Sigma$-equation<br>$$ \Gamma \mid M_1 =_{\sigma_1} M_1',\ldots,M_n =_{\sigma_n} M_n' \vdash N =_{\tau} N'$$<br>to \emph{hold in} $\mathcal M$ or be \emph{validated by} $\mathcal M$ with respect to $p$?<br></latex>	pg 10181<br>
<latex>~\\<br>Provide the definition of the category ASub($\mbf{Dcpo}$). There is an obvious forgetful functor $\vrt{\text{ASub}(\mbf{Dcpo})}{\mbf{Dcpo}}$, which is a fibration. What are the $\delta^*$ and $Eq$<br>functors for this fibration? What is the equality predicate $Eq(u,v)$?\\~\\Provide the definition of the fibration $\vrt{\text{DSub}(\mbf{Dcpo})}{\mbf{Dcpo}}$ and answer the same questions about it.<br></latex>	IMPORTANT TO REMEMBER: the total categories are preorders: an arrow in a fibre is always over the subset relation. So the 1-to-1 correspondence aspect of adjunctions is trivial here.<br><br>pg 10182-10183, example 3.5.4.<br><br><br>
<latex>~\\<br>What is a \emph{signature with predicates}?<br></latex>	pg 10201<br>
<latex>~\\<br>Let $(\Sigma, \Pi)$ and $(\Sigma', \Pi')$ be signatures with predicates. What is a \emph{morphism of signatures with predicates} $\phi : (\Sigma,\Pi) \to (\Sigma', \Pi')$?<br></latex>	pg 10201<br>
<latex>~\\<br>Define the category $\mbf{SignPred}$ via a change-of-base.<br></latex>	pg 10201<br>
Read example 4.1.2 on pg 10201/10202<br>	pg 10201/10202<br>
<latex>~\\<br>A signature with predicates implies two forms of \emph{atomic propositions}. What are they? Give their \emph{Prop} formation rules.<br></latex>	pg 10202
<latex>~\\<br>Give the \emph{connectives} aka \emph{logical operations} of first order propositional logic.<br></latex>	pg 10202<br>
<latex>~\\<br>Give the $\bot$-elimination rule for many-typed first order predicate logic.<br></latex>	pg 10204<br>
<latex>~\\<br>Give the $\forall$ introduction rule for many-typed first order predicate logic.<br></latex>	pg 10204<br>
<latex>~\\<br>Give the $\forall$ elimination rule for many-typed first order predicate logic.<br></latex>	pg 10204<br>
<latex>~\\<br>Give the $\exists$ elimination rule for many-typed first order predicate logic.<br></latex>	pg 10204<br>
<latex>~\\<br>Give the $\exists$ introduction rule for many-typed first order predicate logic.<br></latex>	pg 10204<br>
<latex>~\\<br>In many-sorted first order predicate logic, does internal equality include external equality? Why or why not?<br></latex>	it does. pg 10205, "The following rule in the list,..."<br>
<latex>~\\<br>In many-sorted first order predicate logic, for convertible terms $M = M' : \sigma$, how are the propositions $\varphi[M/x]$ and $\varphi[M'/x]$ related?<br></latex>	they are equivalence. pg 10205, "Since term variables x..."<br>
<latex>~\\<br>What is \emph{regular} first order predicate logic? What is \emph{coherent} first order predicate logic?<br></latex>	pg 10206<br>
<latex>~\\<br>What is a \emph{first order specification}? A \emph{regular} first order specification? A \emph{coherent} first order specification?<br></latex>	pg 10206<br>
<latex>~\\<br>What does it mean for a first order specification $(\Sigma,\Pi,\mathcal A)$ to be a \emph{first order theory}?<br></latex>	pg 10206, definition 4.1.4 (i)<br><br>
<latex>~\\<br>What is a \emph{morphism of first order specifications}?<br></latex>	pg 10206<br>
<latex>~\\<br>Provide the definition of the category $\mbf{FoSpec}$.<br></latex>	pg 10206, def 4.1.4<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The replacement rule from equational logic<br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \mid \Theta \vdash M =_\sigma M' \\ \Gamma, x:\sigma \vdash N : \tau}<br>  {\Gamma \mid \Theta \vdash N[M/x] =_\tau N[M'/x]}<br>\end{mathpar}<br>is a consequence of the replacement rule from predicate logic<br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \mid \Theta \vdash M =_\sigma M' \\ \Gamma \mid \Theta \vdash \varphi[M/x]}<br>  {\Gamma \mid \Theta \vdash \varphi[M'/x]}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	true. pg 10207, lemma 4.1.6<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The replacement rule from predicate logic<br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \mid \Theta \vdash M =_\sigma M' \\ \Gamma \mid \Theta \vdash \varphi[M/x]}<br>  {\Gamma \mid \Theta \vdash \varphi[M'/x]}<br>\end{mathpar}<br>is a consequence of the replacement rule from equational logic<br>\begin{mathpar}<br>\inferrule<br>  {\Gamma \mid \Theta \vdash M =_\sigma M' \\ \Gamma, x:\sigma \vdash N : \tau}<br>  {\Gamma \mid \Theta \vdash N[M/x] =_\tau N[M'/x]}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	IMPOSTOR. this is only true when restricted to equations.<br>pg 10207, lemma 4.1.6<br>
<latex>~\\<br>Examine the last four rules of many-sorted first order predicate logic on page 10204. Consider the following statement:\\~\\<br>The aforementioned rules are of the same strength as the (double) rule Eq-mate:<br>\begin{prooftree}<br>\AxiomC{$\Gamma, x:\sigma \mid \Theta \vdash \varphi[x/y]$}<br>\doubleLine<br>\UnaryInfC{$\Gamma,x:\sigma,y:\sigma \mid \Theta, x =_\sigma y \vdash \varphi$}<br>\end{prooftree}<br>Prove or disprove.<br></latex>	true. pg 10208.<br>
<latex>~\\<br>Examine the $\exists$ and $\forall$ rules on page 10204. Consider the following statement:\\~\\<br>The aforementioned rules have the same strength as the following two (double) rules.<br>\begin{prooftree}<br>\AxiomC{$\Gamma \mid \Theta, \exists x:\sigma. \psi \vdash \varphi$}<br>\doubleLine<br>\UnaryInfC{$\Gamma,x:\sigma \mid \Theta,\psi \vdash \varphi$}<br>\end{prooftree}<br>\begin{prooftree}<br>\AxiomC{$\Gamma \mid \Theta,\varphi \vdash \forall x:\sigma. \psi$}<br>\doubleLine<br>\UnaryInfC{$\Gamma,x:\sigma \mid \Theta, \varphi \vdash \psi$}<br>\end{prooftree}<br>Prove or disprove.<br></latex>	true. pg 10209.<br>
Read the passage below the heading "Understanding Motivation" on page 32626<br>	pg 32626<br>
Consider the following introductory paragraph:<br><br>When college students go out to relax on the weekend, many now "binge", downing several alcoholic drinks quickly until they are drunk or even pass out. It is a behavior that has been spreading through colleges and universities across the country, especially at large state universities. It once was done mostly by men, but now even women binge. It has drawn the attention of parents, college administrators, and researchers.<br><br>Is there anything wrong with this paragraph (not on a grammatical level, but a conceptual level: is it good *as an introductory paragraph*)? How should it be changed.<br><br>	pg 32626 / 32627<br>
What are the three basic parts that should appear in the introductory paragraph to an article?	Shared context,<br>Problem statement,<br>Solution/Main point/claim<br><br>The point of these parts is to help the reader understand why they should care.<br><br>pg 32627, left column gives an example<br>
Give a few stereotypical forms of "shared context" that a writer could put in the introductory (motivating) paragraph of an article.	Two are given at the top of pg 32627's left column: Recent well-known events and common beliefs.<br><br>pg 32627 right column top<br>
Explain the "challenging a belief" strategy for the opening (motivational) paragraph of an article.<br>	pg 32627, right column, "These forms of shared context play a special role..."<br><br>
What should come first in an introductory paragraph: the shared context or problem statement? Why?	pg 32627, bottom right corner. The shared context should come first because it can be used to set up the problem statement.<br><br>
A motivating problem can be decomposed into two part. Give and explain these parts.	pg 32628 left "The two parts of a problem"<br>
There are two basic types of problems: practical and conceptual. Describe each approach, and discuss strategies that could be used to write about each.	pg 32628, right column<br>spills to pg 32629<br>
You, a researcher, may not have the time and resources to answer big questions that conference reviewers care about. What is to be done?	Answer a small question that may help answer larger questions: and be explicit about the connection between the two!<br><br>pg 32629 "Here's the point" top left
Read "Part 3: Stating the solution" on page 32629<br>	<br>
What is a "prelude"? List some sterotypical kinds of preludes.<br>	pg 32629 bottom right / 32630<br>
Read "How to Revise: Introductions" on pg 32630 bottom right / 32631	pg 32630<br>
Read the "Conclusions" section on page 32631	pg 32631<br>
<latex>~\\<br>The syntax for $\pi$-calculus prefixes is <br>$$ \pi ::= \overline{x}y \mid x(z) \mid \tau \mid [x=y]\pi$$<br>Explain the meaning of each syntactic form.<br></latex>	pg 29629 left column, item (2)<br><br>
<latex>~\\<br>Explain the meaning of the process syntactic from $P \mid P'$.<br></latex>	pg 29629 left (4)<br>
<latex>~\\<br>Explain the meaning of the process syntactic form $\nu z~P$.<br></latex><br>	pg 29629 left column (5)<br>
<latex>~\\<br>Explain the meaning of the process syntactic form $! P$.<br></latex>	pg 29629, right column, point (6) at top<br><br>
<latex>~\\<br>What is the meaning of the summand form $P + P'$?<br></latex>	pg 29629, left column, point (3)<br>
<latex>~\\<br>What is the meaning of the summand form $\pi. P$?<br></latex>	pg 29629, left column, point (2)<br>
<latex>~\\<br>What is the meaning of the summand form $\mbf{0}$?<br></latex>	pg 29629, point (1) left<br>
<latex>~\\<br>Give the $\pi$ calculus's mutually recursive syntaxes for processes and summations.<br></latex>	pg 29628, right column<br>
<latex>~\\<br>What are the two forms of name binding in the $\pi$ calculus?<br></latex>	pg 29629, right column, def 1.1.2 near bottom<br>
<latex>~\\<br>In the $\pi$ calculus, what does the notation $fn(P)$ mean?<br></latex>	pg 29629, right column, near bottom.<br>
<latex>~\\<br>For two processes to communicate via a name, that name must occur \underline{~~~~~~~~~}.<br></latex>	"free in both processes"<br>pg 29629, right column, bottom paragraph.<br><br>
<latex>~\\<br>In the $\pi$ calculus, we substitute \underline{~~~~~~~~~} for names.<br></latex>	names.<br>pg 29630, top left<br><br>
<latex>~\\<br>Read pg 29630, left column ``To illustrate some of the points made above'' down to the bottom.<br></latex>	pg 29630<br>
<latex>~\\<br>The notion of a \emph{substitution} (a.k.a valuation) is slightly different in the $\pi$ calculus than in the $\lambda$ calculus. How is it defined?<br></latex>	pg 29630, left column, def 1.1.3 at bottom<br><br>
<latex>~\\<br>Given a $\pi$ calculus substitution $\sigma$, what does $\mathit{cosupp}(\sigma)$ denote?<br>What does $\mbf{n}(\sigma)$ denote? Let $X$ be a set of names. What does $X \sigma$ denote?<br></latex>	pg 29630, right column, notation 1.1.4 at top<br>
<latex>~\\<br>In $\pi$-calculus, the entities of interest are the equivalence classes of processes modulo \underline{~~~~~}.<br></latex>	alpha convertability<br>pg 29630, right column near bottom<br>
<latex>~\\<br>Parenthesize the following $\pi$-calculus terms according to syntactic precedence conventions:\\~\\<br>$\pi.P \mid Q$\\<br>$\nu z P \mid Q$\\<br>$!P \mid Q$\\<br>$\pi.P + Q$<br></latex>	pg 29631, bottom left/top right<br>
<latex>~\\<br>Give the $\pi$-calculus's sole top-level reduction rule, i.e. its analogy to the $\lambda$-calculus's $\beta$ reduction.<br></latex>	pg 29631, right column, axiom 1.1<br>
<latex>~\\<br>Give the four reduction rules (which make conclusions of the form $P \longrightarrow P'$) of the $\pi$-calculus. <br></latex>	pg 29635, left column, table 1.3<br>
<latex>~\\<br>When is an occurrence of $\mbf{0}$ in a process considered \emph{degenerate}?<br></latex>	pg 29632, top right<br>
<latex>~\\<br>What is a \emph{context}?<br></latex>	pg 29632, right column, definition 1.2.1<br>note that non-degenerate occurences of 0 do not appear as the operands to sums, as described above<br><br>
<latex>~\\<br>Let $C$ be a context and $P$ a process. Consider the following statement:\\~\\<br>Names free in $P$ may be bound in $C[P]$.\\~\\<br>True or false?<br></latex>	true. pg 29632, right column.<br>
<latex>~\\<br>When is an equivalence relation $\mathcal S$ on processes considered a \emph{congruence}?<br></latex>	pg 29632, right column, definition 1.2.2<br><br>
<latex>~\\<br>Roughly, how is the \emph{structural congruence} relation $\equiv$ defined? (No need to give a full definition; instead, just give an outline.)<br></latex><br>	<latex>~\\<br>pg 29633, left column, table 1.1\\<br>also includes table 1.2, confusingly read $=$ as $\equiv$<br></latex><br><br>
<latex>~\\<br>Let $M \doteq \overline{x}z.\mbf{0}$, $N \doteq \overline{y}w. \mbf{0}$, and $N' \doteq x(v). \mbf{0}$.\\~\\<br><br>Via structural congruence $\equiv$, any restriction $\nu z$ can be brought to the top of a term. Demonstrate this by showing that $\nu x~((N + N') \mid !\nu z M)$ is structurally congruent to a term of the form $\nu z~\nu x \cdots$.<br></latex>	pg 29633, right column, near top
Provide the definition of <i>monoidal category</i>.<br>	<latex>~\\<br>pg 13490 / 13491<br>**WARNING: It's tempting to leave off the last part of the defintion: $\lambda_e = \varrho_e$. Did you do this? If so, you were wrong!<br></latex>
<latex>~\\<br>Does the following diagram necessarily commute in a monoidal category?\\<br>\begin{center}<br>\begin{tikzcd}<br>e \square (b \square c) \ar[r, "\alpha"] \ar[dr, "\lambda" below] & (e \square b) \square c \ar[d,"\lambda \square 1"] \\<br>                                                    & b \square c<br>\end{tikzcd}<br>\end{center}<br></latex>	yes. pg 13491 (a hint is given in exercise 1 on pg 13493)<br> <br>
<latex>~\\<br>What is a \emph{strict morphism of monoidal categories}?<br></latex>	pg 13492<br>
<latex>~\\<br>Provide the definition of the category $\mbf{Moncat}$. Does it have any notable subcategories?<br></latex>	pg 13492<br>
<latex>~\\<br>How is the category W of \emph{binary words}, used to prove coherence, defined? What is the key property of the category?<br></latex>	pg 13493, "The precise definition is by recursion"<br>key property: every diagram commutes<br><br>
<latex>~\\<br>Let $W$ be the category of words described on page 13493 in the second-to-last paragraph. Consider the following statement:\\~\\<br>For any monoidal category $B$ and any object $b \in B$, there is a unique morphism $W \to B$ of monoidal categories with $(-) \mapsto b$.\\~\\<br>Prove or disprove.<br></latex>	pg 19494<br>
<latex>~\\<br>The coherence theorem says that every diagram of a certain class commutes. Describe this class.<br></latex>	it involves only associativity and unital multiplications.<br>pg 13493
<latex>~\\<br>Let $\mathcal A$ be a $\mathcal V$-category. Let $f : A \to B$ and $g : B \to C$ be arrows of $\mathcal A_0$. How do we obtain the composite $g \circ f$?<br></latex>	pg 18604, (1.10)<br>
<latex>~\\<br>Let $T : \mathcal A \to \mathcal B$ be a $\mathcal V$-functor. How is the ordinary functor $T_0 : \mathcal A_0 \to \mathcal B_0$ defined?<br></latex>	<latex>~\\<br>pg 18604, (1.11), (1.12)\\~\\<br>Also consider $1.13$:~\\<br>In $(1.13)$ note that $T_{0AB}$ simply means $T_0$ restricted to the $\mathcal A_0(A,B)$\\<br>$T_{AB}$ is defined as part of the definition of a $\mathcal V$-functor: it is an arrow in $\mathcal V_0$<br>from $\mathcal A(A,B)$ to $\mathcal B(TA,TB)$.<br></latex><br>
<latex>~\\<br>Let $\alpha : T \to S : \mathcal A \to \mathcal B$ be a $\mathcal V$-natural transformation. How is the ordinary natural transformation $\alpha_0 : T_0 \to S_0$ defined?<br></latex>	pg 18604 bottom / 18605 top<br>
<latex>~\\<br>What is a \emph{regular fibration}?<br></latex>	pg 10212<br>Frobenius for equality is defined on pg 10170<br>Frobenius for coproducts is defined on pg 10081<br>
<latex>~\\<br>What is a \emph{coherent fibration}?<br></latex>	pg 10212, def 4.2.1 (ii)<br>
<latex>~\\<br>What is a \emph{first order fibration}?<br></latex>	pg 10212, def 4.2.1 (iii)<br>
<latex>~\\<br>Consider $(\Sigma,\Pi)$ with regular logic and assume a collection $\mathcal A$ of (regular) axioms. How do we construct the classifying fibration $\vrt{\mathcal L(\Sigma,\Pi,\mathcal A)}{\mathcal C \ell(\Sigma)}$?<br>Show that this fibration is regular.<br></latex>	pg 10213, example (i)<br>Note that in the \Exists-mate bi-rule, weakening applied to the codomain on the bottom is left implicit: it is just an assumption that x does not occur free in \varphi.<br>
Read example (ii) on page 10213 and example (iii) on pg 10214	pg 10213<br>
Give and discuss the three principles of document coherence.	pg 32634, points 1-3<br>
List the three principles of coherence for sections.	pg 32634, points 4-6<br><br>
Consider the following passage:<br><br>Thirty sixth-grade students wrote essays that were analyzed to determine the effectiveness of eight weeks of training to distinguish fact from opinion. That ability is an important aspect of making sound arguments of any kind. In an essay written before instruction begain, the writers failed almost completely to distinguish fact from opinion. In an essay written after four weeks of instruction, the sutdents visibly attempted to distinguish fact from opinion, but did so inconsistently. In three more essays, they distinguished fact from opinion more consistently, but never achieved the predicted level of performance. In a final essay written six months after instruction ended, they did no better than they did in their pre-instruction essays. Their training had some effect on their writing during the instruction period, but it was inconsistent, and six months after instruction it had no measurable effect.<br><br>Does this passage have strong coherence? If not, what would you change to improve coherence?	pg 32634, right column<br>
Consider the following passage:<br><br>In this study, thirty sixth-grade students were taught to distinguish fact from opinion. They did so successfully during the instruction period, but the effect was inconsistent and less than predicted, and six months after instruction ended, the instruction had no measurable effect. In an essay written before instruction began, the writers failed almost completely to distinguish fact from opinion. In an essay written after four weeks of instruction, the students visibly attempted to distinguish fact from opinion, but did so inconsistently. In three more essays, they distinguished fact from opinion more consistently, but never achieved the predicted level of performance. In a final essay written six months after instruction ended, they did no better than they did in their pre-instruction essay. We thus conclude that short-term training to distinguish fact from opinion has no consistent or long-term effect.<br><br>Do you consider this passage coherent? If not, what would you change to improve it.	This was used as a positive example of coherence. Bonus question before checking the answer: what is the point of the passage? What are its key terms. Show that they occur in the introduction to the passage.<br><br>pg 32634, bottom right<br>pg 32635, top left
Should the point of a section/document occur at its beginning, end, or both? If forced to choose one, which should we choose?	pg 32635, left column<br><br>
Roughly how long should the introduction to a paragraph be? How long should the introduction to a section be? A document? Why is this question relevant to the issue of <i>coherence</i>?	pg 32635 / left column
Read "Here's the point" on page 32635, right column<br>	<br>
Read point 1 on page 32635, right column (spills onto page 32636)<br><br>	<br>
List some criteria that can be used to decide if a sentence is relevant to the main point of its paragraph.	pg 32636, top left corner<br>
<latex>~\\<br>What is a \emph{vector space}?<br></latex><br>	pg 27879<br>
<latex>~\\<br>Let $S$ be a nonempty subset of a vector space $V$.<br>What is a \emph{linear combination} of vectors in $S$? What does it mean to a linear combination to be \emph{trivial}?<br></latex>	pg 27880<br>
<latex>~\\<br>Let $F$ be a field. What does $\mathcal M_{m,n}(F)$ denote?<br></latex>	pg 27880, example 1.1 2.)<br>
<latex>~\\<br>Let $F$ be a field and $n$ a natural number. What does $F^n$ denote?<br></latex>	pg 27880, point 3) near bottom
<latex>~\\<br>Let $F$ be a field. What does $\text{Seq}(F)$ denote?<br></latex>	pg 27881, point 4)<br>
<latex>~\\<br>Let $V$ be a vector space and $S$ a subset of $V$. What does $S \leq V$ mean? $S < V$?<br></latex>	pg 27881<br>
<latex>~\\<br>How do we determine if a non-empty subset $S$ of a vector space $V$ is a subspace of $V$?<br></latex>	pg 27881, theorem 1.1 at bottom, spills onto<br>pg 27882 top<br>
<latex>~\\<br>Consider the vector space $V(n,2)$ of all binary $n$-tuples, that is, $n$-tuples of $0$'s and $1$'s. Let the \emph{weight} $\mathcal W(v)$ of a vector $v \in V(n,2)$ be the number of nonzero coordinates in $v$. Let $E_n$ be the set of all vectors of even weight. Consider the following statement:\\~\\<br>$E_n$ is a subspace of $V$.\\~\\<br>Prove or disprove.<br></latex>	true. Example 1.2, pg 27882<br>todo: add impostor?<br>
What is a \emph{linear code}?	pg 27882, example 1.3<br>
<latex>~\\<br>Let $V$ be a vector space. What does $\mathcal S(V)$ denote?<br></latex>	pg 27882<br>
<latex>~\\<br>Let $S$ and $T$ be subspaces of a vector space $V$. Consider the following statement:\\~\\<br>$S \cap T$ is a subspace of $V$\\~\\<br>Prove or disprove.<br></latex>	true. pg 27882<br>
<latex>~\\<br>Let $S$ and $T$ be subspaces of a vector space $V$. Consider the following statement:\\~\\<br>$S \cup T$ is a subspace of $V$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! pg 27882, bottom<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A nontrivial vector space $V$ over an infinite field $F$ is not the union of a finite number of proper subspaces.\\~\\<br>Prove or disprove.<br></latex>	pg 27883, Theorem 1.2 near top<br><br>
<latex>~\\<br>Let $S$ and $T$ be subspaces of a vector space $V$. What is the \emph{sum} $S + T$? More generally,<br>what is the \emph{sum} of a set-indexed collection $\{ S_i \mid i \in K \}$ of subspaces of $V$?<br></latex>	pg 27883
<latex>~\\<br>Consider the following statement:\\~\\<br>The set $\mathcal S(V)$ of all subspaces of a vector space $V$ is a complete lattice under set inclusion.\\~\\<br>Prove or disprove.<br></latex>	pg 27884, theorem 1.3<br>
Read the introduction "Continuity and Computability", on pages 24559-24560<br>	pg 24559<br>
<latex>~\\<br>What does it mean for a subset $\Delta$ of a poset to be \emph{directed}? What does it mean for a poset to be a \emph{directed complete partial order}? What is the difference between a directed complete partial order and a \emph{complete partial order}?<br></latex>	NOTE: according to Amadio's definition, directed sets must be *NON-EMPTY*.<br>pg 24560<br>
<latex>~\\<br>What does it mean for a function between dcpo's to be \emph{continuous}? What is a \emph{prefixpoint} of a function $f : P \to P$ on a poset $P$?<br></latex>	pg 24561, definition 1.1.2<br>
<latex>~\\<br>What does it mean for a partial order $(D, \leq)$ to be an \emph{$\omega$-dcpo}?<br></latex>	pg 24561, def 1.1.3<br>
<latex>~\\<br>What does it mean for a cpo to be \emph{flat}?<br></latex>	pg 24561, example 1.1.6<br><br>
<latex>~\\<br>What cpo does $\mbf{O}$ denote? What cpo does $\mbf{T}$ denote?<br></latex>	pg 24561, example 1.1.6<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>All partial orders without infinite ascending chains are dcpo's.\\~\\<br>Prove or disprove.<br></latex>	Hint: this relies on the following lemma: a poset satisfies ACC if and only if each of its non-empty subsets has a maximal element. (this lemma should not be hard to prove, but if you can't prove it then see pdf pg 27, top left corner)<br> <br>true. pg 24561, example 1.1.6<br>
<latex>~\\<br>Let $X \rightharpoonup Y$ be the set of partial functions between sets $X$ and $Y$ endowed with the following partial order:<br>$$f \leq g~\dot{\Leftrightarrow}~(f(x) \downarrow \Rightarrow (g(x) \downarrow \text{ and } f(x) = g(x)))$$<br>Consider the following statement:\\~\\<br>The above partial order is a cpo.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24561, example 1.1.6 (3)<br>
<latex>~\\<br>Provide the definition of the category $\mbf{REL}$. <br></latex>	pg 10184<br>
<latex>~\\<br>What does the notation $R : I \relto J$ mean?<br></latex>	R is a relation from I to J<br>pg 10184, near top<br>
<latex>~\\<br>The category $\mbf{REL}$ can be viewed as a certain Kleisli category. Explain.<br></latex>	pg 10184, "A relation R : I -> J can be viewed as a multifunction..." near top<br>
<latex>~\\<br>What is the terminal object of the category $\mbf{REL}$? What are Cartesian products in $\mbf{REL}$? Let $R : K \relto I$ and $S : K \relto J$. What, concretely, is $\langle R, S \rangle$?<br></latex>	pg 10184, near middle. seems kind of similar to a category of vector spaces?<br>
<latex>~\\<br>There is more than one notion of equality for arrows in the category $\mbf{REL}$ (i.e. relations/multifunctions). Provide explanations of at least two.<br></latex>	pg 10184, "There may be different notions"...
<latex>~\\<br>Provide the definition of the fibration $\vrt{\mbf{PredREL}}{\mbf{REL}}$. How does substitution work in this fibration?<br></latex>	pg 10185, near top<br>
<latex>~\\<br>Let $D$ be a cpo and $f : D \to D$ a continuous function. Consider the following statement:\\~\\<br>$\bigvee_{n \in \omega} f^n(\bot)$ is a fixpoint of $f$, and is the least prefixpoint of $f$ (hence it is the least fixpoint of $f$).\\~\\ <br>Prove or disprove.<br></latex>	true. pg 24562.<br><br>
<latex>~\\<br>Let $D$ be a complete lattice. Consider the following statement:\\~\\<br>Any monotonic function $f : D \to D$ has a least fixpoint. \\~\\<br>Prove or disprove.<br></latex>	true. exercise 1.1.8, pg 24562<br>see pdf page 26 left for the proof.<br><br>
<latex>~\\<br>Let $D$ be a complete lattice. Let $f : D \to D$ be a monotone function. Consider the following statement:\\~\\<br>The set of fixpoints of $f$ is a complete lattice. \\~\\<br>Prove or disprove.<br></latex>	true. pg 24562, exercise 1.1.9.<br><br>
<latex>~\\<br>Let $D$ be a complete lattice and let $f : D \to D$ be a monotonic function. Set $f^0 = \bot$, <br>$f^{\kappa + 1} = f \circ f^{\kappa}$, and $f^{\lambda}(x) = \bigvee_{\kappa < \lambda} f^{\kappa}(x)$, for all $x$, where $\kappa$ is an ordinal and $\lambda$ is a limit ordinal.\\~\\<br>Show that there is an ordinal $\mu$ such that $f^{\mu} = fix(f)$. Describe a dual construction for the greatest fixpoint.<br></latex>	pg 24562<br>if you need to review ordinals, look at:<br>- pg 3646 (ordinal is defined near the bottom of the page)<br>- more advanced material starts on: pg 3694
<latex>~\\<br>Let $D$ be a dcpo. What does it mean for an element $d \in D$ to be \emph{compact}?<br></latex> 	pg 24562<br>this is what Cartwright et al. call <i>finite</i>, see pg 19636<br><br>
<latex>~\\<br>Let $D$ be a cpo. What do Amadio and Curien mean by the notation $\mathcal K(D)$?<br></latex>	pg 24562
<latex>~\\<br>Consider the following statement:\\~\\<br>The lub of two compact elements, if any, is compact.\\~\\<br>Prove or disprove.<br></latex>	pg 24562, exercise 1.1.11, near bottom<br>
<latex>~\\<br>What does it mean for a cpo $D$ to be \emph{algebraic}? $\omega$-algebraic? If $x \in D$, what are the \emph{approximants} of $x$? What is the \emph{basis} of $D$?<br></latex>	pg 24563, definition 1.1.12<br>
<latex>~\\<br>Provide the definitions of the categories $\mbf{Adcpo}$, $\omega \mbf{Adcpo}$, $\mbf{Acpo}$ and $\omega \mbf{Acpo}$.<br></latex>	pg 24563, def 1.1.12<br>note that the category cpo is the subcategory of acpo containing only those cpos with a bottom element.<br>
<latex>~\\<br>What is the intuitive, computation-and-information based interpretation of the notion of a \emph{compact element} of a cpo? What is the intuitive interpretation of a cpo being \emph{algebraic}?<br></latex>	pg 24563, below definition 1.1.12<br>
<latex>~\\<br>Consider the cpo $X \righthookup Y$ described in example 1.1.6 (3) at the bottom of page page 24561. Is this cpo algebraic?<br></latex>	it is. pg 24563, example 1.1.13 (1)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The powerset of natural numbers, $\mathcal P(\omega)$, ordered by inclusion, is an $\omega$-algebraic cpo.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24563.<br><br>
<latex>~\\<br>Let $\Sigma$ be a signature consisting of symbols $f$ with an assciated arity $\mathit{arity}(f)$. How is the poset of "possibly infinite terms on $\Sigma$" defined? Is it a cpo? An algebraic one?<br></latex>	pg 24563, example 1.1.13 (3)<br>
<latex>~\\<br>Define the cpo $D$ as follows\\~\\<br>$D \doteq \omega \cup \{ a, b \}$\\<br>$x \leq_D y~\dot{\Leftrightarrow} \left \{ \begin{array}{l} y = b~\text{or} \\ x = a \text{ or }\\ x=m,y=n, \text{ and } $m \leq n$ \end{array} \right$\\~\\<br>Consider the following statement:\\~\\<br>$D$ is algebraic.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. Example 1.1.13 (4)<br>
<latex>~\\<br>Let $D$ be a dcpo, and $\mathcal K \subseteq \mathcal K(D)$ be such that for any $x \in D$ the set $\{ d \in \mathcal K \mid d \leq x \}$ is directed and has lub x. Consider the following statement:\\~\\<br>$D$ is algebraic and $\mathcal K = \mathcal K(D)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 24563, exercise 1.1.14<br>todo: add impostor?
<latex>~\\<br>Examine the definition of $\omega$-dcpo on page 24561, def 1.1.3. Create a definition of $\omega$-algebraic $\omega$-dcpo. Show that $\omega$-algebraic $\omega$-dcpo's and $\omega$-algebraic dcpo's are the same.<br></latex>	pg 24563, exercise 1.1.15 <br>involves definition 1.1.12 at top of page<br>
<latex>~\\<br>Let $D$ and $E$ be algebraic dcpo's. Consider the following statement:\\~\\<br>A function $f : D \to E$ is continuous iff it is monotonic, and for each $e \in \mathcal K(E)$ and $x \in D$ such that $e \leq f(x)$, there exists $d \leq x$ such that $d \in \mathcal K(D)$ and $e \leq f(d)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24564, prop 1.1.16 (1)<br>
<latex>~\\<br>Let $D$ and $E$ be algebraic dcpo's. Consider the following statement:\\~\\<br>$\{ (d,e) \in \mathcal K(D) \times \mathcal K(E) \mid e \leq f(d) \}$, denoted by graph($f$), and called the \emph{graph} of $f$ determines $f$ entirely.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24564, prop 1.1.16 (2)<br>
<latex>~\\<br>Let $D$ and $E$ be $\omega$-algebraic dcpo's. Let $\{ d_n \}_{n < \omega}$ and $\{ e_n \}_{n < \omega}$ be surjective enumerations of the compact elements of $D$ and $E$. What does it mean for a function $f : D \to E$ to be \emph{effectively continuous}? <br></latex>	pg 24564, def 1.1.17<br><br>
<latex>~\\<br>Let $D$ and $E$ be algebraic dcpo's. What does it mean for a relation $R \subseteq \mathcal K(D) \times \mathcal K(E)$ to be an \emph{approximable relation}?<br></latex>	<br>pg 24564, def 1.1.18. The up arrow simply means that e_1 and e_2 are consistent: They share a common upper bound.<br><br>AR2 is wrong!!!!! the operands to the comparsion operators should be swapped! Indeed, the following proof assumes the correct version of AR2!<br><br><br><br><br>
<latex>~\\<br>Let $(\Sigma, \mathcal H)$ be an equational specification. Suppose a model $\mathcal M : \mathcal C \ell(\Sigma) \to \mathbb B$ validates all equations in $\mathcal H$ (with respect to some Eq-fibration with base $\mathbb B$). Consider the following statement:\\~\\<br>$\mathcal M$ validates all equations in the theory of $(\Sigma, \mathcal H)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10187, lemma 3.5.6<br>todo: add impostor?
<latex>~\\<br>For an equational specification $(\Sigma, \mathcal H)$, consider the situation:<br>\begin{center}<br>\begin{tikzcd}<br>                                              & \ar[d] \mathcal L(\Sigma, \mathcal H) \\<br>\mathcal C \ell(\Sigma) \ar[r, "id"] & \mathcal C \ell (\Sigma)<br>\end{tikzcd}<br>\end{center}<br>Consider the following statement:\\~\\<br>This generic model of $\Sigma$ validates precisely the eqautions in the theory of $(\Sigma, \mathcal H)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10187, lemma 3.5.7<br>
<latex>~\\<br>Provide the definition of the 2-category $\mbf{EqFib}$.<br></latex>	pg 10189<br>
<latex>~\\<br>If we have a morphism of Eq-fibrations in a situation<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb E \ar[r,"H" above] \ar[d,"p" left] & \ar[d,"q" right] \mathbb D \\<br>\mathbb B \ar[r,"K" below]                   & \mathbb A  <br>\end{tikzcd}<br>\end{center}<br>It is obvious that $K : \mathbb B \to \mathbb A$ preserves external equality. Does $K$ also preserve internal equality?<br></latex>	pg 10189, near top<br>
<latex>~\\<br>Let $(\Sigma, \mathcal H)$ be an equational specification and $\vrt{\mathbb E}{\mathbb B} p$ an Eq-fibration. What is a \emph{model} of $(\Sigma,\mathcal H)$ in $p$?<br></latex>	pg 10189, def 3.6.2<br>
<latex>~\\<br>Let $(\Sigma, \mathcal H)$ be an equational specification and let $\vrt{\mathbb E}{\mathbb B}p$ be an Eq-fibration. Consider the following statement:\\~\\<br>Every model $\mathcal M$ in $\mathbb B$<br>\begin{center}<br>\begin{tikzcd}<br> & \ar[d, "p" right] \mathbb E \\<br>\mathcal C \ell(\Sigma) \ar[r, "\mathcal M" above] & \mathbb B  <br>\end{tikzcd}<br>\end{center}<br>validates the equations in $\mathcal H$ (with respect to $p$) if and only if it extends to a (up-to-isomorphism unique) morphism of Eq-fibrations:<br>\begin{center}<br>\begin{tikzcd}<br>\mathcal L(\Sigma, \mathcal H) \ar[r, "\mathcal M'"] \ar[d] & \mathbb E \ar[d,"p" right] \\<br>\mathcal C \ell(\Sigma) \ar[r, "\mathcal M" below] & \mathbb B <br>\end{tikzcd}<br>\end{center}<br>Prove or disprove.<br></latex>	pg 10189, theorem 3.6.3<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be an Eq-fibration. The underlying signature $Sign(\mathbb B)$ of $\mathbb B$ comes equipped with a set of equations $\mathcal H(p)$. What equations does $\mathcal H(p)$ contain?<br></latex>	pg 10191, def 3.6.4<br>
<latex>~\\<br>Let $(\Sigma, \mathcal H)$ be an equational signature and $\vrt{\mathbb E}{\mathbb B}p$ an Eq-fibration.<br>Consider the following statement:\\~\\<br>There is a bijective correspondence (up-to-isomorphism)<br>\begin{prooftree}<br>\AxiomC{$\ddisp{\mathcal L(\Sigma, \mathcal H)}{~}{\mathcal C \ell(\Sigma)} \overset{(\mathcal M,~ \mathcal N)}{\longrightarrow} \ddisp{\mathbb E}{p}{\mathbb B}$ in $\mbf{EqFib}$}<br>\doubleLine<br>\UnaryInfC{$(\Sigma,\mathcal H) \underset{\phi}{\longrightarrow} (Sign(\mathbb B), \mathcal H(p))$ in $\mbf{EqSpec}$}<br>\end{prooftree}<br>which makes the classifying fibration $\vrt{\mathcal L(\Sigma, \mathcal H)}{\mathcal C \ell(\Sigma)}$ the free Eq-fibration generated by $(\Sigma, \mathcal H)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10191, prop 3.6.5.<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be an Eq-fibration. How is the category $\mathbb B/Eq$ defined? How is the category $\mathbb E/Eq$ defined? What does $p/Eq$ denote?<br></latex>	pg 10193, def 3.6.7<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The functor $\vrt{\mathbb E / Eq}{\mathbb B / Eq} p / Eq$ is an Eq-fibration in which internal and external equality coincide.\\~\\<br>Prove or disprove.<br></latex>	pg 10193, prop 3.6.8 (i)<br><br>
<latex>~\\<br>With respect to a fibration $\vrt{\mathbb E}{\mathbb B}p$, consider the following statement:\\~\\<br>The pair of functors $\eta = (\eta_{\mathbb B}, \eta_{\mathbb E})$ forms a morphism of Eq-fibrations $\eta : p \twoheadrightarrow p / Eq$, which is universal in the following sense: every map of Eq-fibrations $p \to q$ to an Eq-fibration q in which internal and external equality coincide factors via a unique map of Eq-fibrations <br>\begin{tikzcd}p/Eq \ar[r, dashed] & q\end{tikzcd} as:<br>\begin{center}<br>\begin{tikzcd}<br>p \ar[r, "\eta" above] \ar[dr,q] & \ar[d, dashed] p/Eq \\<br>                                        & q<br>\end{tikzcd}<br>\end{center}<br>Prove or disprove.<br></latex>	true. pg 10193, prop 3.6.8 (ii)<br><br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The approximable relations are exactly the graphs (for A \& C's definition of graphs rather than the standard one) of continuous functions.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24564, prop 1.1.19. NOTE THAT WE ARE USING A NON-STANDARD DEFINITION OF "GRAPH" HERE, WHICH IS DEFINED AT THE TOP OF THE PAGE.<br>todo: add impostor?<br><br>
<latex>~\\<br>What is an \emph{ideal} of a preorder, according to $A \& C$. (Note that $A \& C$ seem to use a non-standard definition of ideal, I think.)<br></latex>	pg 24565, def 1.1.20<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $P$ is a preorder, then $\mathit{Ide}(P)$ is an algebraic dcpo whose compact elements are exactly the principal ideals.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24565, prop 1.1.21<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $D$ is an algebraic dcpo then $D$ and $Ide(\mathcal K(D))$ are isomorphic in $\mbf{Dcpo}$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24565, prop 1.1.21 (2)<br><br>
<latex>~\\<br>Let $V_1,\ldots,V_n$ be vector spaces. What does $V_1 \boxplus \cdots \boxplus V_n$ denote?<br></latex><br>	pg 27884<br>
<latex>~\\<br>Let $\mathcal F = \{ V_i \mid i \in K \}$ be any family of vector spaces over a field $F$. What is the <br>\emph{direct  product} of $\mathcal F$?<br></latex>	pg 27885<br>
<latex>~\\<br>Let $\mathcal F = \{ V_i \mid i \in K \}$ be a family of vector spaces over $F$. What is the \emph{support} of a function $f : K \to \bigcup V_i$? What does $\bigoplus_{i \in K}^{ext} V_i$ denote?<br></latex>	pg 27885<br>
<latex>~\\<br>Let $\mathcal F = \{ V_i \mid i \in K \}$ be a family of vector spaces over $F$. Consider the following statement:\\~\\<br>The direct product $\prod_{i \in K} V_i$ is equal to the external direct sum $\bigoplus_{i \in K}^{ext}V_i$.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! This is only true when $\mathcal F$ is a finitely indexed family.<br>pg 27885<br>
<latex>~\\<br>What does it mean for a vector space $V$ to be the \emph{internal direct sum} of a family $\mathcal F = \{ S_i \mid i \in I \}$ of subspaces of $V$?<br></latex>	pg 27885 / 27886<br>
<latex>~\\<br>Let $T$ be a subspace of a vector space $V$. What is a \emph{complement} of $V$?<br></latex>	pg 27886<br>
<latex>~\\<br>Note: In the following text, if $S$ and $T$ are distinct subspaces and if $x,y \in S \cap T$, then $x + y$ should be considered a sum of vectors of distinct subspaces ($S$ and $T$), even though they could be interpreted as coming from the same subspace $S \cap T$.\\~\\<br>Let $\mathcal F = \{ S_i \mid i \in I \}$ be a family of distinct subspaces of $V$. Consider the following statement:\\~\\<br>The following are equivalent:<br>\begin{itemize}<br>\item For each $i \in I$<br>$$S_i \cap (\Sigma_{j \neq i} S_j) = \{ 0 \}$$<br>\item The zero vector $0$ cannot be written as a sum of nonzero vectors from distinct subspaces of $\mathcal F$.<br>\item Every nonzero $v \in V$ has a unique, except for order of terms, expression as a sum<br>$$v = s_1 + \cdots + s_n$$<br>of nonzero vectors from distinct subspaces of $\mathcal F$.<br>\end{itemize}<br>Prove or disprove.<br></latex>	<latex>~\\<br>True. Hence, a sum<br>$$V = \sum_{i \in I} S_i$$<br>is direct if and only if any one of the three points holds.\\<br>pg 27887<br></latex>
<latex>~\\<br>What does it mean for a matrix to be \emph{symmetric}? What does it mean for a matrix to be \emph{skew symmetric}?<br></latex>	pg 27848<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mathcal M_n$ is the vector space of $n \times n$ matrices, $\mathit{Sym}_n$ is the<br>subspace of symmetric $n \times n$ matrices, and $\mathit{SkewSym}_n$ is the subspace of skew symmetric <br>$n \times n$ matrices, then $\mathcal M_n = \mathit{Sym}_n + \mathit{SkewSym}_n$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 27888, example 1.5<br>
<latex>~\\<br>Let $S$ be a subset of vector space $V$. What does $span(S)$ denote? What does it mean for $S$ to \emph{span } $V$?<br></latex>	pg 27888/27889<br>
<latex>~\\<br>Let $V$ be a vector space. What does it mean for a nonempty set $S$ of vectors in $V$ to be \emph{linearly independent}?<br></latex>	pg 27889<br>
<latex>~\\<br>Let $S$ be a nonempty set of vectors in a vector space $V$. What does it mean for a nonzero vector $v \in V$ to be an \emph{essentially unique} linear combination of the vectors in $S$? <br></latex>	pg 27889 / 27890<br>
<latex>~\\<br>Let $S$ be a subset of a vector space $V$. What does $\langle S \rangle$ denote?<br></latex>	the span of S,<br>pg 27888 bottom<br>
<latex>~\\<br>Let $S \neq \{ 0 \}$ be a nonempty set of vectors in $V$. Consider the following statement:\\~\\<br>The following are equivalent:<br>\begin{itemize}<br>\item $S$ is linearly independent<br>\item Every nonzero vector $v \in span(S)$ is an essentially unique linear combination of the vectors in $S$<br>\item No vector in $S$ is a linear combination of other vectors in $S$<br>\end{itemize}<br>Prove or disprove.<br></latex>	true. pg 27890, theorem 1.6<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>The following are equivalent:<br>\begin{itemize}<br>\item $S$ is linearly independent and spans $V$<br>\item Every nonzero vector $v \in V$ is an essentially unique linear combination of vectors in $S$<br>\item $S$ is a minimal spanning set, that is, $S$ spans $V$ but any proper subset of $S$ does not span $V$<br>\item $S$ is a maximal linearly independent set, that is $S$ is linearly independent.<br>\end{itemize}<br>Prove or disprove.<br></latex>	true. pg 27891, them 1.7<br>todo: add impostor?
<latex>~\\<br>Let $V$ be a vector space. What is a \emph{basis} for $V$?<br></latex>	pg 27891<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A finite set $S = \{ v_1, \ldots, v_n \}$ of vectors in $V$ is a basis for $V$ if and only if <br>$$ V = \langle v_1 \rangle \oplus \cdots \oplus \langle v_n \rangle $$<br>Prove or disprove.<br></latex>	pg 27891, theorem 1.8<br><br>
<latex>~\\<br>Let $F$ be a field. What is the \emph{standard basis} for the vector space $F^n$?<br></latex>	pg 27891, example 1.6<br><br>
<latex>~\\<br>Let $V$ be a non-zero vector space. Let $I$ be a linearly independent set in $V$ and let $S$ be a spanning set in $V$ containing $I$. Consider the following statement:\\~\\<br>There is a basis $\mathcal B$ for $V$ for which $I \subseteq \mathcal B \sqsubseteq S$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 27892, theorem 1.9<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every vector space has a basis.\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR! Not the zero vector space. pg 27892.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Any spanning set of a vector space $V$ contains a basis.\\~\\<br>Prove or disprove.<br></latex>	true. it's a consequence of theorem 1.9.<br>pg 27892<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $S$ is a subspace of $V$, then there exists a subspace $T$ for which $V = S \oplus T$.\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>This is a consequence of theorem 1.9 on page 27892. Since $S$ is a subspace, it has a basis $I$. Furthermore, $I \cup (V-S)$ spans $V$, and so there is a basis for $V$ that contains $I$ and potentially some elements of $V-S$ as well. The rest of the argument is pretty straightforward.<br></latex>
<latex>~\\<br>Let $V$ be a vector space and assume that the vectors $v_1, \ldots, v_n$ are linearly independent and the vectors $s_1, \ldots, s_m$ span $V$. Consider the following statement:\\~\\<br>$n \leq m$.\\~\\<br>Prove or disprove.<br></latex>	pg 27892, theorem 1.10.<br><br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $V$ has a finite spanning set, then any two bases of $V$ have the same size.~\\<br>Prove or disprove.\\<br></latex>	true. pg 27893, corollary 1.11<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $V$ is a vector space, then any two bases for $V$ have the same cardinality.\\~\\<br>Prove or disprove.<br></latex>	pg 27893, theorem 1.12<br>
<latex>~\\<br>Let $\kappa$ be a cardinal. What does it mean for a vector space $V$ to be $\kappa$-dimensional?<br></latex>	pg 27894, definition<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $\mathcal B$ is a basis for $V$ and if $\mathcal B = \mathcal B_1 \cup \mathcal B_2$ and $\mathcal B_1 \cap \mathcal B_2 = \emptyset$, then $V = \langle \mathcal B_1 \rangle \oplus \langle \mathcal B_2 \rangle$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 27894, theorem 1.13 (1)<br>todo: add impostor?
<latex>~\\<br>Let $V$ be a vector space and let $V = S \oplus T$. Consider the following statement:\\~\\<br>If $\mathcal B_1$ is a basis for $S$ and $\mathcal B_2$ is a basis for $T$, then $\mathcal B_1 \cap \mathcal B_2 = \emptyset$ and $\mathcal B = \mathcal B_1 \cup \mathcal B_2$ is a basis for $V$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 27894, theorem 1.13.<br>todo: add impostor<br>
<latex>~\\<br>Let $S$ and $T$ be subspaces of a vector space $V$. Consider the following statement:\\~\\<br>$dim(S) + dim(T) = dim(S + T) + dim(S \cap T)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 27894, theorem 1.14<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Ideal completion is left adjoint to the forgetful functor $U : \mbf{Dcpo} \to \mbf{P}$, where $\mbf{P}$ is the category of partial orders and monotone functions, and where $U$ takes a dcpo to the underlying partial order and a continuous function to the underlying monotone function.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24565, prop 1.1.22<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>There is an equivalence of categories between $\mbf{Adcpo}$ and the category of partial orders and approximable relations.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24565, prop 1.1.23<br>todo: add impostor? perhaps by replacing Adcpo with a related category<br>
<latex>~\\<br>What is an \emph{Alexandrov topology}?<br></latex>	a topology derived from a partial order P, where open sets are the upper subsets of P.<br>pg 24566<br>
<latex>~\\<br>From every topologyical space $(X, \Omega X)$ we can derive a \emph{specialization preorder}. How is this preorder defined?<br></latex>	pg 24566<br>
<latex>~\\<br>What does it mean for a topology to be $T_0$?<br></latex>	It's specialization preorder is anti-symmetric (i.e. it is a partial order)<br>pg 24566<br>
<latex>~\\<br>Let $D$ be a dcpo. What is the \emph{Scott topology} of $D$? What motivates this topology?<br></latex>	pg 24567, definition 1.2.1. Motivation starts at the bottom of pg 24566.<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The specialisation order on $(D, \Omega_S(D))$ is $(D, \leq_D)$. In particular $\Omega_S(D)$ is $T_0$.\\~\\<br>Prove or disprove.<br></latex>	true. lemma 1.2.3, pg 24567.<br>
<latex>~\\<br>Show that $U_x = \{ y \in D \mid y \not \leq x \}$ is Scott open.<br></latex>	pg 24567, exercise 1.2.2<br>
<latex>~\\<br>Let $D, E$ be dcpo's. Consider the following statement:\\~\\<br>The continuous functions (in the topological sense) from $(D, \Omega_{D})$ to $(E, \Omega_E)$ are exactly the morphisms in $\mbf{Dcpo}$.\\~\\<br>Prove or disprove.<br></latex>	pg 24567, prop 1.2.4<br><br>
<latex>~\\<br>Let $D$ be an algebraic dcpo. Consider the following statement:\\~\\<br>If $D$ is algebraic, then the sets $\uparrow d$, for $d$ compact, form a basis of $\Omega_{S}(D)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24567, prop 1.2.5.<br>
Read the introduction to exercise 1.2.6 at the bottom of pg 24567. Then do exercise 1.2.6, which is near the top of pg 24568. ** I actually don't feel like enough information is provided here. Probably skip this card.<br><br>	pg 24567.<br>
<latex>~\\<br>Provide the definition of the class of \emph{primitive recursive functions}. If $m$ and $n$ are natural numbers, what does $\phi_{n}^m$ denote in recursion theory? What can be said about the mapping $\lambda. \phi_n^1$? Is it injective? surjective?<br></latex>	pg 25041/25042<br>
<latex>~\\<br>Let $A$ be a subset of $PR$ such that $A' = \{ x \mid \phi_x^1 \in A \}$ is r.e. Consider the following statement:\\~\\<br>For any partial recursive $f$, $f \in A$ iff there exists a finite function $\theta \leq f$ such that $\theta \in A$.<br>\\~\\<br>Prove or disprove. <br></latex>	pg 25046, theorem A.3.1. also see text above theorem A.3.1<br><br><br>
State recursion theory's "s-m-n theorem".<br>	pg 25043<br>
<latex>~\\<br>Recall the definition of \emph{effective continuity}. Let $f$ be a total recursive function that is extensional, i.e., $\phi_{f(m)} = \phi_{f(n)}$ whenever $\phi_m = \phi_n$. Consider the following statement:\\~\\<br>There is a unique continuous function $F : (\omega \rightharpoonup \omega) \to (\omega \rightharpoonup \omega)$ ``extending'' f, i.e., such that $F(\phi_n) = \phi_{f(n)}$ for all n. Moreover, $F$ is effectively continuous.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24568, theorem 1.3.1 (1). effective continuity is defined on page 24564.<br>Theorem A.3.1 is defined on pg 25046.<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Any effectively continuous function $F : (\omega \rightharpoonup \omega) \to (\omega \rightharpoonup \omega)$ maps partial recursive functions to partial recursive functions, and there is a total (extensional) recursive function $f$ such that $F(\phi_n) = \phi_{f(n)}$ for all $n$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24569 (ii)<br>effective continuity defined on pg 24564.<br>todo: add impostor?<br><br>
<latex>~\\<br>Do exercise 1.3.2 on page 24569<br></latex><br>	pg 24569<br>
<latex>~\\<br>What is an \emph{indexed category}?<br></latex><br>	pg 10029/10030<br><br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration with cleavage. Consider the following statement:\\~\\The assignment <br>\begin{center}<br>$I \mapsto \mathbb E_I$~~~~~and~~~~~$u \mapsto \text{(the substitution functor }u^*)$<br>\end{center}<br>determines a $\mathbb B$-indexed category. This indexed category is split whenever the cleavage of $p$ is a splitting.\\~\\<br>Prove or disprove.<br></latex>	pg 10030, prop 1.4.5<br>
<latex>~\\<br>Let $\Psi : \mathbb B^{op} \to \mbf{Cat}$ be an indexed category. What is the \emph{Grothendieck completion} $\int_{\mathbb B}\Psi$?<br></latex>	pg 10086, def 1.10.1<br>def 1.4.4 on pg 10029 may be helpful for understanding this
<latex>~\\<br>Consider the following statement:\\~\\<br>The first projection $\vrt{\int \Psi}{\mathbb B}$ is a cloven fibration. It is split whenever the indexed category $\Psi$ is split.\\~\\<br>Prove or disprove.<br></latex>	pg 10087, prop 1.10.2 (i)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Turning a cloven fibration first into an indexed category (in the obvious manner) and then again into a fibration (via the Grothendieck construction) yields a fibration which is equivalent to the original one.\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>We're looking for an equivalence of fibrations:<br>\begin{center}<br>\begin{tikzcd}<br>\mathbb E \ar[dr, "p~" left] \ar[rr, "F" above, bend left = 20] &  & \ar[dl, "~\pi" right] \ar[ll, "U" below, bend left = 20] \int \Phi \\<br>                                                                             & \mathbb B &  <br>\end{tikzcd}<br>\end{center}<br>Recall that the functors $F$ and $U$ must preserve Cartesian arrows and that the triangle must commute in both directions.\\~\\<br>We define $F(X) \doteq (pX, X)$ and $F(f : X \to Y) \doteq (pf : pX \to pY, ! : X \to (pf)^*(Y))$.<br>In the other direction, we define $U(I,X) \doteq X$ and $U(u,f) \doteq f;\overline{u^*}(Y)$.\\~\\<br>These functors clearly make the triangles commute. We must show that they preserve Cartesian arrows.<br>Recall that the Cartesian arrows in a Grothendieck completion have the form $(u,id)$; from this, it becomes<br>clear that both $F$ and $U$ preserve Cartesian arrows.\\~\\<br>TODO: show that they are naturally isomorphic to identities.\\~\\<br>true. pg 10087, prop 1.10.2 (ii)<br></latex><br>
<latex>~\\<br>How can we obtain the family fibration $\vrt{Fam(\mathbb C)}{\mbf{Sets}}$ via the Grothendieck construction? Explain in detail.<br></latex>	pg 10087, example (i)<br>
<latex>~\\<br>What is the category $\vrt{Fam(\mathbb C)}{\mbf{Cat}}$? How do we obtain it via the Grothendieck construction?<br></latex>	pg 10088<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. How do we obtain the simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ via a Grothendieck construction?<br></latex>	pg 10088 (iii)<br>
<latex>~\\<br>Let $\mathbb B$ be a category with chosen pullbacks. How do we obtain the codomain fibration $\vrt{\mathbb B^\to}{\mathbb B}$ via the Grothendieck construction?<br></latex>	pg 10088 (iv)<br>
<latex>~\\<br>The notion of indexed category involves some explicit structure (namely reindexing functors and mediating isomorphisms $id \overset{\cong}{\to} id^*$ and $u^* \circ v^* \overset{\cong}{\to} (u;v)^*$, which is left implicit in fibrations. So an indexed category has a \emph{structure} where a fibration has a \emph{property}.<br>Discuss two disadvantages of working with explicit reindex functors and mediating morphisms, as opposed to working with fibrations and their Cartesian arrow property.<br></latex>	pg 10088 (a) and (b)<br><br>
Read points (iii),(iv), and (v) discussing the benefits of fibrations over indexed categories, on page 10089<br>	<br>
<latex>~\\<br>What is a \emph{morphism of split indexed categories}?<br></latex>	pg 10089, def 1.10.5<br>
<latex>~\\<br>Provide the definition of the category $\mbf{ICat}$.<br></latex>	important: the objects of this category are not just any indexed categories, but *split* indexed categories.<br>pg 10089, def 1.10.5<br><br>
<latex>~\\<br>Consider the following statements:\\~\\<br>The functor $\vrt{\mbf{ICat}}{\mbf{Cat}}$, which sends a split indexed category to its base, is a split fibration.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10089, prop 1.10.6.<br>
Examine example 1.2.6 on pg 29634, left column, and consider the structural congruence rules which are used to demonstrate that these congruences hold. (Don't give a fully detailed proof; just work it out in your head).<br><br>	pg 29634<br>
Quickly examine example 1.2.7 on page 29634 left column and consider how these strucutral congruences would be proven (no need to write it down; just work it out in your head).	pg 29634, left column
<latex>~\\<br>Consider example 1.2.8 on page 29634, left column. Consider the sequence of structural congruence used in order to prove that these structural congruences hold (no need to write them down; just think through them).<br></latex>	pg 29634<br>
<latex>~\\<br>Notation question: what do sangiori and walker use $\tilde{x}$ to denote?<br></latex>	tilde is used to denote a vector, so this is a vector of variables.<br>pg 29634, right column, top<br>
<latex>~\\<br>Do exercise 1.2.10 on page 29634.<br></latex>	todo: actually do this exercise and write it up in DetailedNotes<br>pg 29634<br>
<latex>~\\<br>What does it mean for an occurrence of a process $Q$ in a process $P$ to be \emph{guarded}?<br></latex>	It occurs beneath some prefix.<br>pg 29634, right column<br>
Do exercise 1.2.11 (1), pg 29634	todo: actually do this exercsie, and write it up in DetailedNotes<br>pg 29634<br>
Do exercise 1.2.11 (2), pg 29634	pg 29634
Do exercise 1.2.11 (3), pg 29634, right column<br>	pg 29634, todo: write this up in DetailedNotes<br><br>
<latex>~\\<br>Exercise 1.2.5, pg 29633 right column, defines two processes called $P$ and $P_1$ and establishes that they are structurally congruent.\\~\\<br>Give a derivation for $P_1 \longrightarrow \nu x (\overline{a} y. \mbf{0} \mid \overline{x}b. \mbf{0})$.\\~\\<br>Then give a derivation for $P \longrightarrow \overline{b}y. \mbf{0} \mid \nu x~\overline{x} a. \mbf{0}$.\\~\\<br>From this, conclude that reduction in the $\pi$-calculus is not confluent.<br></latex>	pg 29635, left column near bottom, example 1.2.13<br><br>
Read example 1.2.14 on page 29635, right column;<br>this refers to example 1.2.6 on page 29634 left column<br>(you may want to open up two pdf windows, okulus and evince, for this)<br>	pg 29634<br>
Read example 1.2.15 on page 29635 right column. This continues example 1.2.7 on pg 29634 left column. (You may want to open up two windows for this.<br>	pg 29635<br><br>
<latex>~\\<br>Let $(\Sigma, \Pi)$ be a signature with predicates. What is a $(\Sigma,\Pi)$\emph{-algebra}?<br>Show how a first order fibration can be obtained from a $(\Sigma,\Pi)$ algebra.<br></latex>	pg 10214 / 10215, section 4.2.3<br>if you need to brush up on Grothendieck constructions, see chapter 1.10<br>
<latex>~\\<br>What is a \emph{kripke model} for a signature with predicates $(\Sigma, \Pi)$?<br></latex>	pg 10215, "A *Kripke model*" down to<br>"In order to construct"...<br><br>
<latex>~\\<br>Let $\mathcal K$ be a Kripke model for a signature with predicates $(\Sigma, \Pi)$. There is a canonical way to construct a first order fibration from such a model $\mathcal K$: explain how this works.<br></latex>	pg 10216 "The main clauses of Kripke's interpretation", down to<br>pg 10217 bottom of page<br><br>
<latex>~\\<br>Let $\mathcal K$ be a Kripke model of a signature with predicates $(\Sigma, \Pi)$. Recall that for each sequence<br>$(\sigma_1, \ldots, \sigma_n)$ of types (from $\Sigma$) there is a functor $\mathcal K(\sigma_1, \ldots, \sigma_n) : \mathbb I \to \mbf{Sets}$. What does it mean for a collection of subsets $X_i \subseteq \mathcal K(\sigma_1, \ldots, \sigma_n)(i)$ to be $\mbf{monotone}$?<br></latex>	pg 10216<br>"In order to construct..." down to<br>"In [182]..."<br>hint: can we construct this fibration as a Grothendieck construction?<br>
<latex>~\\<br>What is a \emph{frame}? For a frame $A$, consider $\vrt{Fam(A)}{\mbf{Sets}}$. Is this fibration regular? coherent? first order?<br></latex>	pg 10218, section 4.2.5<br><br>
<latex>~\\<br>In his \emph{realisability interpretation} of constructive logic, clean introduced a relation $n \mbf{r} \varphi$. What is the intuitive purpose of this relation, and how is this relation defined formally?<br>Jacobs gives a ``first-order fibration'' version of realizability. Can you reproduce the definition of this fibration?\\~\\<br>(Hint: It involves first recalling the notion of a \emph{non-standard predicate} on a set $I$, and what it means for such a predicate to be \emph{valid}.)\\~\\<br>How do simple products work in this fibration? Simple coproducts?<br></latex>	<latex>~\\<br>pg 10219, section 4.2.6, spills to page 10220\\~\\<br>I believe the definition of the ordering $X \leq Y$ should say $(X \supseteq Y)(i)$, since I'm not sure what <br>$X(i) \supseteq Y(i)$ even means.<br></latex><br><br>
Readers want to see not just how everything they read is relevant to a point, but what principle is behind the order of its parts. We look for three kinds of order: chronological, coordinate, and logic. Define each kind of order.	pg 32636, left column
State the "general principle of clarity". Which of these two sentences follows the principle better?<br><br>1a. Resistance in Nevada against its use as a waste disposal site as been heated.<br>1b. Nevada has heatedly resisted its use as a waste disposal site.<br><br>	pg 32637, left page<br><br>
State the "principle of clarity". Which of these two passages better obeys this principle?<br><br>- Historians are reassessing Columbus's role in world history because they know more about pre-Columbiean civilizations and how European colonization destroyed their societies by inflicting on them devastating diseases.<br><br>- Greater knowledge of pre-Columbiean civilizations and the effect of European colonization destroying their societies by inflicting on them the devastating diseases has led to a historical reassesment of Columbus's role in world history.<br><br>	pg 32637, left side<br><br>
State the "principle of clarity". Which of these two paragraphs better illustrates the principle of clarity?<br><br>--<br><br>In this study, thirty sixth-grade students were taught to distinguish fact from opinion. They did so successfully during the instruction period, but the ffect was inconsistent and less than predicted, and six months after instruction ended, the instruction had no measurable effect. In an essay written before instruction began, the writers failed almost completely to distinguish fact from opinion. In an essay written after four weeks of instruction, the students visibly attempted to distinguish fact from opinion, but did so inconsistently. In three more essays, they distinguished fact from opinion more consistently, but never achieved the predicted level. In a final essay written six months after instruction ended, they did no better than they did in their pre-instruction essay. We thus conclude that short-term training to distinguish fact from opinion has no consistent or long-term effect.<br><br>--<br><br>Thirty sixth-grade students wrote essays that were analyzed to determine the effectiveness of eight weeks of training to distinguish fact from opinion. That ability is an important aspect of making sound arguments of any kind. In an essay written before instruction began, the writers failed almost completely to distinguish fact from opinion. In an esssay written after four weeks of instruction, the students visibly attempted to distinguish fact from opinion, but did so inconsistently. In three more essays, they distinguished fact from opinion more consistently, but never achieved the predicted level. In a final essay written six months after instruction ended, they did no better than they did in their pre-instruction essay. Their training had some effect on their writing during the instruction period, but it was inconsistent, and six months after instruction it had no measurable effect.	pg 32637, left and right pages.<br>
Consider this sententce:<br><br>In addition to the continual disagreements between Democrats and Republicans on the issues of the day, an explanation of why they so deeply distrust one another must include the divergent values and principles that give them their motivation, the support that arises from their distinct constituencies, and an acceleration of the history of conflict between them.<br><br>This sentence is not great. How would you improve it?	pg 32648, top left<br>
There are four issues that give readers a sense of "shapeless length" (which is bad). What are they?	pg 32648, left, above "starting with your point"<br>note that the passage on pg 32647's bottom left corner suffers from all of these issues.<br>
Consider the following sentence:<br><br>High-deductible health plans and Health Saving Accounts into which workers and their emplyers make tax-deductible deposists result in workers taking more responsibility for their health care.<br><br>What are the problems with this sentence. How would you revise it?	pg 32648, bottom left corner, spills over to the page on the right<br>
Read pg 32648 right, starting from "Here is a very general principle about how we read:" down to the bottom of the page.<br>	pg 32648<br>
What is wrong with the following sentence?<br><br>Since most undergraduate students change their fields of study at least once during their college careers, many more than once, first-year students who are not certain about their program of studies should not load up their schedules to meet requirements for a particular program.<br><br>What is wrong with this sentence and how would you improve it?	pg 32649 "Rule of Thumb 1: Get to the Subject Quickly"<br>
Consider the following sentence:<br><br>The company's understanding of the drivers of its profitability in the Asian market for small electronics helped it pursue opportunities in Africa.<br><br>What is wrong with this sentence? How would you improve it?	pg 32649 right "Rule of Thumb 2: Get to the Verb and Object Quickly"<br>
Consider the following sentence:<br><br>A company that focuses on hiring the best personnel and then trains them not just for the work they are hired to do but for higher-level jobs is likely to earn the loyalty of its employees.<br><br>What is wrong with this sentence? How would you fix it?	pg 32649 right / pg 32650 top left, "Rule of Thumb 2: Get to the Verb and Object Quickly"<br>"relative clause" appears in the glossary on page 32689<br>
α<sup>β</sup>·α<sup>γ</sup> = α<sup>β + γ</sup>.	true. pg 3879
<latex>~\\<br>Consider the following statement:\\~\\<br>An ordinal $\alpha$ is a limit ordinal iff $\alpha = \omega \cdot \beta$ for some ordinal $\beta$.\\~\\<br>Prove or disprove.<br></latex>	this is mentioned but not proven on page 3699. TODO: Write this up in DetailedNotes?<br>
<latex>~\\<br>What is a \emph{symmetry} for a monoidal category? What is a \emph{symmetric monoidal category}?<br></latex>	symmetry defined on pg 18605, section 1.4<br>symmetric monoidal category on pg 18606 near top<br>
<latex>~\\<br>Given $\mathcal V$-categories $\mathcal A$ and $\mathcal B$, what does $\mathcal A \otimes \mathcal B$ denote?<br></latex>	it is a V-category defined near pg 18606, near figure (1.17)<br>note that m is defined directly below the diagram: it requires a symmetry c<br>make sure to give identity and composition law<br><br>
<latex>~\\<br>Let $\mathcal A$ and $\mathcal B$ be $\mathcal V$-categories.<br>Show that the $\mathcal V$-category $\mathcal A \otimes \mathcal B$ defined on page 18606 near figure (1.17) is actually a $\mathcal V$-category. <br></latex>	<latex>~\\<br>laws given at the bottom of page 18602<br>contrary to what pg 18606 says, I couldn't figure this out. I may need some law such as $(f \otimes g) \otimes h;a=a;f \otimes (g \otimes h)$. Can this be derived somehow? Does this have something to do with coherence?<br></latex>
<latex>~\\<br>Given $\mathcal V$-functors $T : \mathcal A \to \mathcal A'$ and $S : \mathcal B \to \mathcal B'$, how<br>do we define the functor $T \otimes S : \mathcal A \otimes \mathcal B \to \mathcal A' \otimes \mathcal B'$?<br></latex>	It isn't defined, but it says that the definition is evident below figure (1.18) on page 18606.<br>
<latex>~\\<br>Given $\mathcal V$-functors $T,T' : \mathcal A \to \mathcal A'$ and $S,S' : \mathcal B \to \mathcal B'$, and $\mathcal V$-natural transformations $\alpha : T \to T'$ and $\beta : S \to S'$, how do we define the natural transformation $\alpha \otimes \beta : T \otimes S \to T' \otimes S'$?<br></latex>	it isn't defined on page 18606 below figure 1.18, where it is claimed that the definition is evident.<br>
<latex>~\\<br>Let $\mathcal V$ be a symmetric monoidal category and let $\mathcal A$ be a $\mathcal V$-category. How is $\mathcal A^{op}$ defined?<br></latex>	pg 18606, "moreover, to each..." near bottom<br>make sure to define both the composition laws and identities!<br>
<latex>~\\<br>Let $\mathcal V$ be a symmetric monoidal category. Let $\mathcal A$ and $\mathcal B$ be $\mathcal V$-categories. Consider the following statement:\\~\\<br>$$(\mathcal A \otimes \mathcal B)^{op} = \mathcal A^{op} \otimes \mathcal B^{op}$$<br>Prove or disprove.<br></latex>	true. pg 18606, near bottom<br>
<latex>~\\<br>Let $\mathcal V$ be a symmetric monoidal category and let $\mathcal A, \mathcal B$ be $\mathcal V$-categories. For $\alpha : T \to S : \mathcal A \to \mathcal B$, how is $\alpha^{op}$ defined? What is its ``type signature''?<br></latex>	pg 18606, near bottom it is claimed that the definition is evident.<br>
<latex>~\\<br>Explain how, from a functor $T : \mathcal A \otimes \mathcal B \to \mathcal C$, we can obtain the functors $T(A, -) : \mathcal B \to \mathcal C$ for each $A \in \mathcal A$ and $T(-,B) : \mathcal A \to \mathcal C$ for each $B \in \mathcal B$. <br></latex>	pg 18606 bottom / 18605 top<br>
<latex>~\\<br>Let $\mathcal V$ be a symmetric monoidal category, and let $\mathcal A, \mathcal B, \mathcal C$ be $\mathcal V$-categories.\\~\\<br>Suppose that we are given a family of functors $T(A, -) : \mathcal B \to \mathcal C$ indexed by $ob~\mathcal A$ and a family of functors $T(-, B) : \mathcal A \to \mathcal C$ indexed by $ob~\mathcal B$, such that on objects we have $T(A,-)(B) = T(-,B)(A) = T(A,B)$.\\~\\<br>Under what conditions does there exist a functor $T : \mathcal A \otimes \mathcal B \to \mathcal C$ for which these are the partial functors?<br></latex>	pg 18607, figure 1.21<br>
<latex>~\\<br>Verify that, if $T,S : \mathcal A \otimes \mathcal B \to \mathcal C$, a family $\alpha_{AB} : T(A,B) \to S(A,B)$ in $\mathcal C_0$ constitutes a $\mathcal V$-natural transformation $T \to S$ if and only if it constitutes, for each fixed $A$, a $\mathcal V$-natural $T(A,-) \to S(A,-)$, and, for each fixed $B$, a <br>$\mathcal V$-natural $T(-, B) \to S(-,B)$. In other words, $\mathcal V$\emph{-naturality may be verified variable-by-variable}.<br></latex><br>	pg 18607, "It is further easy..."<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $D$ and $E$ are dcpo's then $D \times E$ ordered as above is a dcpo. The statement also holds when we replace ``dcpo'' by ``cpo''.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24570, prop 1.4.1<br><br>
<latex>~\\<br>Do exercise 1.4.2 on page 24570.<br></latex>	pg 24570<br>
<latex>~\\<br>Let $D, D'$, and $E$ be dcpo's. Consider the following statement:\\~\\<br>A function $f : D \times D' \to E$ is continuous iff for all $x \in D$ the functions $f_x : D' \to E$, and<br>for all $y \in D'$ the functions $f_y : D \to E$, defined by $f_x(y) \doteq f(x,y)$ and $f_y(x) \doteq f(x,y)$,<br>respectively, are continuous.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24570.<br>todo: add impostor?
<latex>~\\<br>Let $D,E$ be dcpo's. Consider the following statement:\\~\\<br>The set $D \to E$ of continuous functions from $D$ to $E$, endowed with the pointwise ordering defined by<br>$$f \leq_{ext} f'~~~~~\dot{\Leftrightarrow}~~~~~\forall x~f(x) \leq f'(x)$$<br>is a dcpo. Moreover, if $E$ is a cpo, then $D \to E$ is a cpo.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24570 prop 1.4.4<br>
Do exercise 1.4.5 on page 24571.<br>	pg 24571<br>
Do exercise 1.4.6 on page 24571<br>	<br>
Do exercise 1.4.7 on page 24571<br>	pg 24571<br>
<latex>~\\<br>Let $D$, $E$ be cpo's, $d \in D$ and $e \in \mathcal K(E)$. Consider the following statement:\\~\\<br>The step function $d \to e$, defined as follows, is compact as an element of the cpo of continuous functions $D \to E$:<br>\begin{center}<br>$(d \to e)(x) = \left \{ \begin{array}{ll} e & \text{if }x \geq d \\ \bot & otherwise \end{array} \right$<br>\end{center}<br>Prove or disprove.<br></latex>	note: A&C's proof makes use of the fact that continuous functions are monotone.<br>true. pg 24571, lemma 1.4.8 (1)<br>todo: add impostor?<br>
<latex>~\\<br>Let $D$, $E$ be algebraic cpo's, $d \in D$ and $e \in \mathcal K(E)$. <br>Define the step function $d \to e$ as follows:<br>\begin{center}<br>$(d \to e)(x) \doteq \left \{ \begin{array}{ll} e & \text{if }x \geq d \\ \bot & otherwise \end{array} \right$<br>\end{center}<br>Consider the following statement:\\~\\<br>$f = \bigvee \{ d \to e \mid (d \to e) \leq f \}$, for any $f$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24571, lemma 1.4.8 (2)<br>todo: add impostor?<br><br>
<latex>~\\<br>What is a \emph{Scott domain}? What motivates the definition of Scott domains?<br></latex>	pg 24571, bottom paragraph.<br>pg 24572, def 1.4.9 at top<br>
Do exercise 1.4.14 on page 24572. **Note that this references 1.4.10, which contains a MISTAKE: the third condition is not equivalent to the first two, but only the equivalence between the first two conditions is relevant to this exercise.	pg 24572.<br>
Dp exercise 1.4.11 on page 24572<br>	pg 14572<br>
<latex>~\\<br>Suppose that $D$ is a cpo and $E$ is a bounded complete cpo. Let $d,d' \in D$ and $e,e' \in \mathcal K(e)$, and<br>suppose that $d \to e$ and $d' \to e'$ have a common upper bound (i.e. they are consistent). Does the lub $(d \to e) \vee (d' \to \e')$ necessarily exist? If so, what is it?<br></latex>	it exists. pg 24572, above theorem 1.4.12<br>
<latex>~\\<br>What does it mean for a dcpo to be \emph{bounded complete}?<br></latex>	pg 24572, definition 1.4.9<br><br>
<latex>~\\<br>Let $D$ be an algebraic dcpo and $E$ a Scott domain. Consider the following statement:\\~\\<br>$D \to E$ is a Scott domain.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24572, theorem 1.4.12<br>todo: add impostor?<br>
Read remark 1.4.13 on page 24572	pg 24572<br>
Examine exercise 1.4.10 on page 24572. Is the theorem A&C are asking us to prove even correct?<br> 	here is a counterexample to (ii) => (iii):<br>I think perhaps condition (iii) should have included that the non-empty set is lower bounded.<br><latex>~\\<br>Consider the dcpo $(\mathbb Z^{-}, \leq)$ of the negative integers and the standard ordering on negative integers. Clearly each non-empty upper-bounded set has a lub (its maximum). Yet, one can easily construct a non-empty set without a glb, for example the entire set $\mathbb Z^-$.\\<br>pg 24572\\~\\<br>Todo: add some cards asking us to prove (iii) $\Rightarrow$ (i) and (i) $\Rightarrow$ (ii), which has already been done in DetailedNotes.<br></latex><br>
Do exercise 1.4.15 on page 24573.<br>	pg 24573<br>
<latex>~\\<br>Let $\kappa$ be a cardinal. What does $\kappa^+$ denote? <br></latex>	<latex>~\\<br>The smallest cardinal that is strictly greater than $\kappa$. See pg 3708, top paragraph (which is kind of a follow-up to lemma 3.6.6 at the bottom of the previous page).<br></latex>
<latex>~\\<br>What do $\omega_1, \omega_2, \omega_3, \ldots$ denote?<br></latex>	the first cardinal after omega, the second cardinal after omega, etc.<br><br>pg 3708<br>
<latex>~\\<br>Let $\delta$ be a limit ordinal, and let $\langle \kappa_{\xi} \mid \xi < \delta \rangle$ be a strictly increasing sequence of infinite cardinals. Let $\kappa = \lim_{\xi < \delta} \kappa_\xi$. Consider the following statement:\\~\\<br>$\kappa$ is a cardinal.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3708, lemma 3.6.7.<br>todo: add impostor?
<latex>~\\<br>What does Devlin use $\aleph_\alpha$ to denote?<br></latex>	<latex>~\\<br>It means $\omega_{\alpha}$ (the $\alpha_{th}$ cardinal), but interpreted as a \emph{cardinal} rather than an ordinal. See the top of pg 3709.<br></latex>
<latex>~\\<br>What does it mean (from a cardinality perspective) for a set to be \emph{finite}? \emph{countable}? \emph{uncountable}?<br></latex>	pg 3709, "We are now in a position..."<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The function $\aleph_{(-)} : \text{On} \to \text{On}$ is a normal function.\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>This is a rather straightforward consequence of the definition of $\aleph_{(-)}$. pg 3710.<br></latex>
<latex>~\\<br>Consider the following statement:\\~\\<br>$\omega_\alpha \geq \alpha$ for all $\alpha$\\~\\<br>Prove or disprove.<br></latex>	true. it's because it's a strictly order preserving endofunction on the ordinals. see text below lemma 3.6.8 on pg 3710.<br>
<latex>~\\<br>Let $\langle \kappa_{\alpha} \mid \alpha < \beta \rangle$ be a sequence of cardinal numbers. How is the \emph{cardinal sum} $$\sum_{\alpha < \beta} \kappa_{\alpha}$$ defined?<br></latex>	pg 3710 bottom / 3711 top<br>
<latex>~\\<br>If $\kappa_1$ and $\kappa_2$ are cardinals then what does $\kappa_1 + \kappa_2$ denote?<br></latex>	pg 3711, near top<br>
<latex>~\\<br>Let $\kappa, \lambda, \mu$ be cardinals. Consider the following statement:\\~\\<br>$\kappa + (\lambda + \mu) = (\kappa + \lambda) + \mu$\\~\\<br>Prove or disprove.<br></latex>	true. immediate from the definition of cardinal addition. pg 3711, lemma 3.7.1.<br>
<latex>~\\<br>Let $\kappa, \lambda, \mu$ be cardinals. Consider the following statement:\\~\\<br>$\kappa + \lambda = \lambda + \kappa$\\~\\<br>Prove or disprove.<br></latex>	immediate from the definition of cardinal addition. pg 3711.<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $\langle \kappa_\alpha \mid \alpha < \beta \rangle$ and $\langle \lambda_{\gamma} \mid \gamma < \delta \rangle$ be sequences of cardinals. What does it mean for $\langle \lambda_{\gamma} \mid \gamma < \delta \rangle$ to be a \emph{rearrangement} of $\langle \kappa_\alpha \mid \alpha < \beta \rangle$? <br></latex>	<latex>~\\<br>``rearrangement'' is mentioned without definition on page 3711. I think it means that there is a bijection $f : \beta \leftrightarrow \delta$ such that $\lambda_{f(\alpha)} = \kappa_{\alpha}$ for all $\alpha < \beta$, and <br>$\kappa_{f^{-1}(\gamma)} = \lambda_{\gamma}$ for all $\gamma < \delta$.<br></latex>
<latex>~\\<br>Let $\langle \kappa_{\alpha} \mid \alpha < \beta \rangle$ be any sequence of cardinals, and let $\langle \lambda_{\gamma} \mid \gamma < \delta \rangle$ be a rearrangment of of this sequence. Consider the following statement:\\~\\<br>$$\sum_{\alpha < \beta} \kappa_\alpha = \sum_{\gamma < \delta} \lambda_{\gamma}$$<br>Prove or disprove. <br></latex>	true. pg 3711, lemma 3.7.2.<br>
<latex>~\\<br>Let $\langle \kappa_{\alpha} \mid \alpha < \beta \rangle$ be a sequence of cardinals. What does $\prod_{\alpha < \beta}^\# \kappa_\alpha$ denote?<br></latex>	pg 3711, below lemma 3.7.2<br>
<latex>~\\<br>Let $\kappa_0$ and $\kappa_1$ be cardinals. What does $\kappa_0 \cdot \kappa_1$ denote?<br></latex>	pg 3711, near bottom<br>
<latex>~\\<br>Let $\kappa$ and $\lambda$ be cardinals. Consider the following statement:\\~\\<br>$$\kappa \cdot \lambda = |\kappa \times \lambda|$$<br>Prove or disprove.<br></latex>	true. pg 3711, near bottom.<br>todo: add impostor?<br>
<latex>~\\<br>Let $\kappa$, $\lambda$, $\mu$ be cardinals. Consider the following statement:\\~\\<br>$\kappa \cdot (\lambda \cdot \mu) = (\kappa \cdot \lambda) \cdot \mu$\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>The underlying sets are both isomorphic to $\{ f : 3 \to \kappa \cup \lambda \cup \mu \mid f(0) \in \kappa, f(1) \in \lambda, f(2) \in \mu \}$. The bijections aren't hard to build.\\~\\<br>true. pg 3712, lemma 3.7.3<br></latex>
<latex>~\\<br>Let $\kappa$ and $\lambda$ be cardinals. Consider the following statement:\\~\\<br>$\kappa \cdot \lambda = \lambda \cdot \kappa$\\~\\<br>Prove or disprove.<br></latex>	true. pg 3712, lemma 3.7.3 (ii)<br>todo: add impostor?<br>
<latex>~\\<br>Let $\kappa$, $\lambda$, and $\mu$ be cardinals. Consider the following statement:\\~\\<br>$\kappa \cdot (\lambda + \mu) = \kappa \cdot \lambda + \kappa \cdot \mu$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 3712, lemma 3.7.5<br>todo: add impostor? (what would it even be?)<br><br>
<latex>~\\<br>Let $\kappa$ be a cardinal. Consider the following statement:\\~\\<br>$\kappa + \kappa = 2 \cdot \kappa$\\~\\<br>Prove or disprove.<br></latex>	pg 3712, below lemma 3.7.5<br><br>
<latex>~\\<br>Let $\kappa$ and $\lambda$ be cardinals. What does $\kappa^{\lambda}$ denote?<br></latex>	pg 3712<br>
<latex>~\\<br>Let $\kappa, \lambda, \mu$ be cardinals. Consider the following statement:\\~\\<br>$\kappa^{\lambda} \cdot \kappa^{\mu} = \kappa^{\lambda + \mu}$\\~\\<br>Prove or disprove. <br></latex>	true. pg 3712, lemma 3.7.6 (i)<br>todo: add impostor?<br>
<latex>~\\<br>Let $\kappa, \lambda, \mu$ be cardinals. Consider the following statement:\\~\\<br>$\kappa^{\lambda} \cdot \mu^{\lambda} = (\kappa \cdot \mu)^{\lambda}$\\~\\<br>Prove or disprove. <br></latex>	true. pg 3712, lemma 3.7.6.<br>
<latex>~\\<br>Let $\kappa, \lambda, \mu$ be cardinals. Consider the following statement:\\~\\<br>$(\kappa^\lambda)^\mu = \kappa^{\lambda \cdot \mu}$\\~\\<br>Prove or disprove. <br></latex>	pg 3712, lemma 3.7.6 (iii)<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $\kappa \geq \alpeh_0$. Consider the following statement:\\~\\<br>$\kappa \cdot \kappa = \kappa$\\~\\<br>Prove or disprove.<br></latex>	true. pg 3713, theorem 3.7.7.<br>
<latex>~\\<br>Let $\kappa \geq \aleph_0$. Consider the following statement:\\~\\<br>$\kappa \cdot \kappa > \kappa$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. pg 3713, theorem 3.7.7<br>
<latex>~\\<br>Let $\kappa, \lambda$ be cardinals, $1 \leq \kappa \leq \lambda$, $\lambda \geq \alpeh_0$. Consider the following statement:\\~\\<br>$\kappa + \lambda = \lambda$\\~\\<br>Prove or disprove.<br></latex>	true. pg 3714, corollary 3.7.8 (yes, the other half has a card too).<br>todo: add impostor?<br>
<latex>~\\<br>Let $\kappa, \lambda$ be cardinals, $1 \leq \kappa \leq \lambda$, $\lambda \geq \alpeh_0$. Consider the following statement:\\~\\<br>$\kappa \cdot \lambda = \lambda$\\~\\<br>Prove or disprove.<br></latex>	true. pg 3714, corollary 3.7.8. (yes, the other half of this corollary also has a card)<br>todo: add impostor?<br>
Consider the following sentence:<br><br>Some scientists, because they write in a style that is impersonal and abstract, do not easily communicate with laypeople.<br><br>Is this a good sentence? If not, explain why, and describe how would you revise it.	it is bad<br>pg 32650 left
Consider the following sentence:<br><br>Since some scientists write in a style that is impersonal and abstract, they do not easily commuinicate with laypeople.<br><br>Is this a bad sentence? If so, explain why, and propose a way to improve it.	This is actually used as an example of a good sentence.<br><br>pg 32650 left<br>
Suppose that we want to revise the following sentence:<br><br>Some scientists, because they write in a style that is impersonal and abstract, do not easily communicate with laypeople.<br><br>To either:<br><br>Since some scientists write in a stile that is impersonal and abstract, they do not easily communicate with laypeople.<br><br>Or:<br><br>Some scientists do not easily communicate with laypeople because the write in a style that is impersonal and abstract.<br><br>Why are the latter two sentences preferable to the orinial? How would we decide which one to choose?	pg 32650 left. we decide based on whichever flows better with surrounding context, as demonstrated by the examples.<br><br>
Consider the following sentence:<br><br>We must develop, if we are to become competitive with other companies in our region, a core of knowledge regartding the state of the art in effective industrial organizations.<br><br>Is this sentence good or bad. If it's bad, explain why, and propose a better version.	pg 32650 bottom left / top right<br><br>
Read the point on pg 32650 right that begins with "When a prepositional phrase..."	pg 32650 right<br>
Do exercises 1-3 on page 32650.<br>	<br>
Do exercises 4-6 on page 32651 left.<br>	pg 32651 left<br>
Do exercises 7-9 on page 32651 left.<br>	pg 32651 left<br>
This sentence starts well, but then sprawls through a string of four explanatory subordinate clauses:<br><br>No scientific advance is more exciting than genetic engineering, which is a new way of manipulating the elemental structural units of life itself, what are the genes and chromosomes that tell our cells how to reproduce to become the parts that constitute our bodies.<br><br>One technique for revising text such as this is known as "cutting". What is cutting? Cut the above passage.<br>	pg 32651 right.<br>
Consider the following sentence:<br><br>The day is coming when we will all have numbers that will identify our financial transactions so that the IRS can monitor all activities that involve economic activities. <br><br>What is wrong with this sentence, and how would you revise it?	pg 32651, right<br><br>
Consider the following sentence:<br><br>Of the many areas of science important to our future, few are more promising than genetic engineering, a new way of manipulating the elemental structural units of life itself, the genes and chromosomes that tell our cells how to reproduce to become the parts that constitute our bodies.<br><br>What is wrong with this passage, and how would you fix it?	pg 32651 right, "2. Turn subordinate clauses into independent sentences"<br>
What is a <i>resumptive modifier</i>? Why are they useful?	pg 32652 left. they allow us to replace relative clauses.<br>
Read the idea presented on pg 32652 left, starting with "You can also resume with an adjective or verb..."<br>	pg 32652<br>
Give the type formation rule for subset types.	pg 10251<br>
<latex>~\\<br>Give the introduction rule for subset types.<br></latex>	pg 10251<br>
<latex>~\\<br>Give both the typing rule and the logical rule for the elimination of subset types.<br></latex>	pg 10251 bottom<br>
<latex>~\\<br>Give the two term conversion rules for subset types.<br></latex>	pg 10251 bottom<br>
What does it mean for a system to have <i>full subset types</i>? Why are full subset types useful?	pg 10252<br>
Give a brief, non-technical explanation of the difference between simple predicate logic (SPL) and dependent predicate logic (DPL).	pg 10252, "Notice that in the above type formation rule..."
<latex>~\\<br>Let $Y \in \mathbb E$, i.e. an object of the total category of a fibration. What is the \emph{extent} of $Y$?<br></latex>	pg 10253, top two paragraphs.<br><br>
<latex>~\\<br>Let $J$ be an object of the base category (i.e. a ``type''). Under what conditions can we say that a generalized element $k : I \to J$ is a member of the subset type $\{ Y \}$?<br></latex>	pg 10253, to the left of (*)
<latex>~\\<br>What does it mean for a preorder fibration $\vrt{\mathbb E}{\mathbb B}p$ with terminal object functor $\top : \mathbb B \to \mathbb E$ to have \emph{subsets} (or \emph{subset types})?<br></latex>	pg 10253, def 4.6.1<br>
<latex>~\\<br>A fibration with subset types has a family of maps $\pi_X : \{ X \} \to pX$ for each $X \in \mathbb E$. How is the family $pX$ defined, and intuitively what is its meaning?<br></latex>	pg 10253, def 4.6.1<br>
<latex>~\\<br>What does it mean, categorically, for a fibration to have \emph{full subset types}?<br></latex>	pg 10253, def 4.6.1<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a preorder fibration with subset types. Consider the following statement:\\~\\<br>Each projection morphism $\pi_X : \{ X \} \to pX$ in $\mathbb B$ is monic.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10254, lemma 4.6.2.<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a preorder fibration with subset types. Consider the following statement:\\~\\<br>For each map $u : I \to J$ in $\mathbb B$ and object $Y \in \mathbb E$ over $J$, there is a bijective correspondence<br>\begin{prooftree}<br>\AxiomC{$\top \leq u^*(Y)$~~~~~over $I$}<br>\doubleLine<br>\UnaryInfC{$u \longrightarrow \pi_Y$~~~~in $\mathbb B/J$}<br>\end{prooftree}<br>Prove or disprove.<br></latex>	true. pg 10254, lemma 4.6.2 (ii)<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a preorder fibration with subset types. Consider the following statement:\\~\\<br>The assignment $X \mapsto \pi_X$ extends to a functor $\mathcal P : \mathbb E \to \mathbb B^{\to}$ which maps Cartesian morphisms to pullback squares. This functor restricts to $\mathbb E \to \text{Sub}(\mathbb B)$ by (i).\\~\\<br>Prove or disprove.<br></latex>	true. pg 10254, lemma 4.6.2 (iii)<br>todo: add impostor?
Read the proof of lemma 4.6.2 on page 10254 - 10255<br>	pg 10254<br>
<latex>~\\<br>Let $\vrt{\mathbb E}{\mathbb B}p$ be a fibration. Prove that $p$ is preordered (i.e. all its fibre categories are preorders) if and only if above each map $pX \to pY$ in $\mathbb B$ there is at most one arrow $X \to Y$ in $\mathbb E$ (i.e. if $p$ is faithful). Conclude that in the total category of a preorder fibration, a vertical morphism is monic.<br></latex>	<latex>~\\<br>$(\Leftarrow)$ is dead simple, so we focus on $(\Rightarrow)$.<br>Let $f,f' : X \rightrightarrows Y \in \mathbb E_1$. All arrows in a total category can be decomposed into a vertical arrow and a Cartesian arrow; for some $g,g'$ vertical above $pX$ and $h : X \to Y$, $h' : X' \to Y$ Cartesian, we have $f = g;h$ and $f' = g';h'$.<br>\begin{center}<br>\begin{tikzcd}<br> & Z \ar[dr, "h"] & \\<br>X \ar[ur, "g" above] \ar[dr, "g'" below] & & Y \\<br> & Z' \ar[ur, "h'" below] &<br>\end{tikzcd}<br>\end{center}<br>Since $h'$ is Cartesian and $p(h) = p(g;h) = pf = pf' = p(g';h') = p(h')$ we have a vertical arrow $r : Z \to Z'$ such that $r;h' = h$. <br>\begin{center}<br>\begin{tikzcd}<br> & Z \ar[dr, "h"] \ar[dd,"r" right] & \\<br>X \ar[ur, "g" above] \ar[dr, "g'" below] & & Y \\<br> & Z' \ar[ur, "h'" below] &<br>\end{tikzcd}<br>\end{center} <br>Because the fibration is preordered, there is a unqiue arrow between any pair of objects in the fibration over $pX$.<br>Thus, $g;r = g'$. Hence, $f' = g';h' = g;r;h' = g;h$.\\~\\<br>pg 10026, exercise 1.3.11 at top<br>(yes, I know this is in a different chapter: it's relevant to the current one.)<br></latex>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. Consider the following statement:\\~\\<br>The simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ on $\mathbb B$ has fibred finite products.\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>true. the product of $(I,X)$ and $(I,Y)$ is $(I, X \times Y)$. For $u : I \to J \in \mathbb B$ we have<br>$u^*(J,X) = (I,X)$ and $\overline u (J,X) = (u, \pi')$.\\~\\<br>pg 10137, near top<br></latex>
<latex>~\\<br>What does it mean for a category to have \emph{coproducts with simple parameters}?<br></latex>	pg 10137<br>
<latex>~\\<br>Let $\mathbb B$ be a category with binary products $\times$ and coproducts $+$. Consider the following statement:\\~\\<br>The following statements are equivalent:<br>\begin{itemize}<br>\item $\mathbb B$ has coproducts with simple parameters<br>\item The simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ has fibred coproducts.<br>\item $\mathbb B$ has distributive coproducts: the canonical maps <br>$$(I \times X) + (I \times Y) \longrightarrow I \times (X + Y)$$ are isomorphisms.<br>\end{itemize}<br>Prove or disprove.<br></latex>	true. pg 10137, prop 2.6.1<br>
<latex>~\\<br>What does it mean for a category with finite products to have a \emph{natural numbers object}?<br></latex>	pg 10138<br>
<latex>~\\<br>What does it mean for a category with finite products to have a \emph{natural numbers object with parameters}?<br></latex>	<latex>~\\<br>pg 10138. Note that the definition should say $f : I \times 1 \to X$ rather than $x : I \times 1 \to X$.<br></latex><br>
<latex>~\\<br>What does it mean for a fibration with a fibred terminal object to have a \emph{fibred natural numbers object}?<br></latex>	pg 10139, def 2.6.2<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For a category $\mathbb B$ with finite products, the following statements are equivalent.<br>\begin{itemize}<br>\item $\mathbb B$ has an NNO with simple parameters<br>\item $\mathbb B$ has an NNO $0,S$ and for each $I \in B$, the functor $I^* : \mathbb B \to \mathbb B / \! \! / I$ applied to $0,S$ yields an NNO $I^*(0)$, $I^*(S)$ in the simple slice $\mathbb B / \!  \! / I$ over $I$.<br>\item The simple fibration $\vrt{s(\mathbb B)}{\mathbb B}$ on $\mathbb B$ has a fibred NNO.<br>\end{itemize}<br>Prove or disprove.<br></latex>	pg 10139. prop 2.6.3.<br>
<latex>~\\<br>Let $D,E$ be dcpo's. What does it mean for a partial function $f : D \rightharpoonup E$ to be \emph{continuous}?<br></latex>	pg 24573, def 1.4.17 (1)<br>
<latex>~\\<br>Let $D,D'$ and $E$ be cpo's. What does it mean for a continuous function $f : D \to E$ to be \emph{strict}?<br>What does it mean for a function $f : D \times D' \to E$ to be \emph{left-strict}? What does it mean for $f$ to be \emph{right-strict}?<br></latex>	pg 24573, def 1.4.17 (2)<br>
<latex>~\\<br>Let $D,E$ be dcpos. Consider the following statement:\\~\\<br>The following sets are in bijective correspondence.<br>\begin{itemize}<br>\item The set of partial continuous functions from $D$ to $E$<br>\item The set of continuous functions from $D$ to $E_{\bot}$<br>\item the set of strict continuous functions from $D_{\bot}$ to $E_{\bot}$<br>\end{itemize}<br>Prove or disprove.<br></latex>	true. pg 24573 bottom / pg 24574 top<br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>The lifting of a dcpo is a cpo. Lifting is right adjoint to the inclusion functor from $\mbf{Dcpo}$ to the category $\mbf{Pdcpo}$ of dcpo's and partial continuous functions.\\~\\<br>Prove or disprove.<br></latex>	pg 24574. prop 1.4.18 (1)<br><br>todo: add impostor?
<latex>~\\<br>Consider the following statement:\\~\\<br>The lifting functor is faithful, and its image is the category $\mbf{Scpo}$ of cpo's and strict continuous functions.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24574, prop 1.4.18 (2)<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Lifting is left adjoint to the inclusion functor from $\mbf{Scpo}$ to $\mbf{Cpo}$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24574, prop 1.4.18<br>
<latex>~\\<br>Let $D$ and $E$ be two cpo's. How do we define their \emph{smash product} $D \otimes E$?<br></latex>	pg 24574, def 1.4.20<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The smash product of two cpo's $D,D'$ is a cpo, and the function $\otimes : D \times D' \to D \otimes D'$ defined as follows is continuous:<br>$$ \otimes(x,x') \doteq \left \{ \begin{array}{ll} (x,x') & \text{if } (x,x') \in D \otimes D' \\ (\bot,\bot) & \text{otherwise} \end{array} \right$$<br>Prove or disprove.<br></latex>	true. pg 24575, prop 1.4.21 (1). The definition may seem confusing at first. Note that we are converting a standard product into a smash product: if either the left or right component is bottom, it maps to the result bottom. Otherwise, it behaves as an identity function.<br>
<latex>~\\<br>The smash product of two cpo's $D,E$ is a cpo, and the function $\otimes : D \times E \to D \otimes E$ defined as follows is continuous:<br>$$ \otimes(x,x') \doteq \left \{ \begin{array}{ll} (x,x') & \text{if } (x,x') \in D \otimes E \\ (\bot,\bot) & \text{otherwise} \end{array} \right$$<br>Consider the following statement:\\~\\<br>The function $\otimes$ is universal in the following sense: for any $E$ and any continuous function $f : D \times D' \to E$ that is both left-strict and right-strict, there exists a unique strict continuous function $\hat{f} : D \otimes D' \to E$ such that $\hat{f} \circ \otimes = f$.\\~\\<br>Prove or disprove.<br></latex>	<latex>~\\<br>Let $g : D \otimes D' \to E$ such that $(g \circ \otimes) = f$. If neither $d = \bot$ nor $d' = \bot$ then $\otimes(d,d') = (d,d')$, and so $g(d,d') = f(d,d')$. Otherwise $d = d' = \bot$, and since $g$ is strict, we must have $g(d,d') = g(\bot,\bot) = \bot$. TODO: show that this function $g$ is continuous (not hard, really).<br>pg 24575, prop 1.4.21 (2)<br></latex>
<latex>~\\<br>List the base types of $IA^+$<br></latex>	pg 26812 bottom right<br>pg 26813 top left<br>
<latex>~\\<br>Give the syntax of \emph{phrase types} for $IA^+$.<br></latex>	pg 26813, top-left<br>
<latex>~\\<br>Is $IA^+$ call-by-value or call-by-name? Does it accomodate the other technique somehow?<br></latex>	pg 26813 left column, "Our interepretation..."
<latex>~\\<br>What does a class definition look like in $IA^+$?<br></latex>	pg 26813, bottom left, top right<br>
<latex>~\\<br>In $IA^+$, what does $\mathit{Var}[\delta]$ denote? What is $\mathit{var}[\delta]$ an abbreviation for?<br></latex>	pg 26813, top right<br>
<latex>~\\<br>Is it possible in $IA^+$ to have a value of type $var[int]$ that does not belong to the class $Var[int]$?<br></latex>	yes. pg 26813, right column<br>
<latex>~\\<br>How is the ``product'' class combinator $\ast$ defined?<br></latex>	pg 26814, top left<br>
<latex>~\\<br>In $IA^+$ there is a combinator $<> : (\theta_1 \to cls~\theta_2) \times (\theta_2 \to cls~\theta_1) \to cls~(\theta_1 \times \theta_2)$. For $F_1 : \theta_1 \to cls~\theta_2$ and $F_2 : \theta_2 \to cls~\theta_1$, describe what an instance of $F_1 <> F_2$ is.<br></latex>	pg 26814, top left<br>
<latex>~\\<br>The array data structure can be regarded as a combinator in $IA^+$. What is the type of this combinator, and how does it work?<br></latex>	pg 26814, top-left<br>
<latex>~\\<br>Give $IA^+$'s type rules for cls types.<br></latex>	pg 26814, top right, figure 1.<br><br>
<latex>~\\<br>What does an expression of the form $\mbf{new}~C$ denote in $IA^+$?<br></latex>	pg 26814, left column.<br>
What can be said about the difference between the typing context in a class's constructor and a the typing context in a class's record of methods?	pg 26814, right column<br>
<latex>~\\<br>In $IA^+$, we use the abbreviation <br>$$a := e \overset{def}{=} \mbf{letval}~e~a$$<br>How does this abbreviation works?<br></latex>	letval's first argument is an expression of datatype delta. Its second argument is a function that maps the value of the first argument to some other type. (i.e., it first evaluates the expression based on the current state and then applies the second argument to the resulting value). If a is a var, then we can apply it as a function (see the subtyping assumptions on the left column of pg 26813)<br>
<latex>~\\<br>Give the $\beta$, $\eta$, and $\gamma$ rules for the introduction and elimination forms of the $cls~\theta$ type constructor.<br></latex>	pg 26815, top left corner.<br>
<latex>~\\<br>For each constant built in to $IA^+$, there is an equational rule governing its interaction with the $\mbf{new}$ construct. Give an equation for each of:<br>\begin{itemize}<br>\item skip<br>\item Sequencing \_;\_ (there are actually two similar rules here: give both)<br>\item $\mbf{letval}$<br>\item $\mbf{if}$<br>\end{itemize}<br></latex>	pg 26815, left column
<latex>~\\<br>What is \emph{specification logic}? What are its connectives? What forms do its atomic formulas have?<br></latex>	pg 26815, right column<br>
<latex>~\\<br>What is a \emph{reflective type class}?<br>What are \emph{passive types}? What are \emph{constant types}?<br>What are the proof rules for the non interference predicate $A \# B$? <br></latex>	pg 26822 left column (points 1,2,3,4, and also the text immediately preceding)<br>pg 26815, right column (points 1,2,3)<br>
<latex>~\\<br>$IA^+$ extends specification logic with formulas of the form ``$\mbf{Inst}$~C~x.\phi(x)$''. What is the meaning of such formulas?<br></latex>	pg 26815, right column.<br>
<latex>~\\<br>Conside the following specification:\\<br>$\mbf{Inst}$~Var[$\delta$]~x.\\<br>$~~\forall p: \mathit{exp}[\delta] \to \mathit{assert}.~x \# p \Longrightarrow$\\<br>$~~~~\{ p(k) \}~x.\mathit{put}~k~\{ p(x.get) \}$\\~\\<br>What does it mean?<br></latex>	pg 26815, bottom right corner.<br>
<latex>~\\<br>Give an equational specification for a queue class in $\emph{IA}^+$.<br></latex>	pg 26816
<latex>~\\<br>Give a Hoare-triple style specification for a queue class in $IA^+$.<br></latex>	pg 26816, figure 4<br><br>
<latex>~\\<br>Give the syntax of commands for $\smc{Imp}$.<br></latex>	pg 24575<br>
<latex>~\\<br>Give the operational semantics of the imperative language $\smc{Imp}$.<br></latex>	pg 24576, figure 1.1<br>
<latex>~\\<br>Set $w \doteq \mathit{while}~b~\mathit{do}~c$. Then consider the following statement:<br>$$w \approx \mathit{if}~b~\mathit{then}~(c;w)~\mathit{else}~\mathit{skip}$$<br>where $\approx$ is defined by: $c_0 \approx c_1$ iff $\forall \sigma, \sigma'.~ \langle c_0, \sigma \rangle \rightarrow \sigma' \Leftrightarrow \langle c_1, \sigma \rangle \to \sigma'$.\\~\\<br>Prove or disprove.<br></latex>	pg 24576, lemma 1.5.1<br>
Do exercise 1.5.2 on page 24576.<br>	pg 24576.<br>
<latex>~\\<br>The denotational semantics of $\mathit{Imp}$ is given by a function $\sem{-}$. What is its ``type signature''?<br>Give its definition by structural induction.<br></latex>	signatures is on pg 24577<br>definition is on pg 24578<br>
<latex>~\\<br>Consider the following soundness and completeness theorem regarding $\mathit{Imp}$:\\~\\<br>For any $c, \sigma, \sigma'$, $\langle c, \sigma \rangle \rightarrow \sigma' \Leftrightarrow \sem{c} \sigma = \sigma'$.\\~\\<br>Prove or disprove.<br></latex>	pg 24577, theorem 1.5.3<br>
Give Reynolds' syntax of type expressions.	pg 17546, bottom left<br>
<latex>~\\<br>Reynolds uses $\Omega$ to denote the set of all type expressions. What does $\Omega_c$ denote?<br></latex>	the subset of type expressions which do not contain variables.<br>pg 17546, bottom left.<br>
<latex>~\\<br>Reynolds uses $\Omega$ for the set of all type expressions. What does he use $\Omega^*$ to denote? Hint: it's not the Kleene star.<br></latex>	the type assignments on \Omega<br>pg 17546, top right<br><br>
<latex>~\\<br>Let $\omega \in \Omega_c$. Then what does $K_{\omega}$ denote? What does $E_{\pi \omega}$ denote?<br></latex>	pg 17546, right column: see (Ea), (Eb), etc.<br>
<latex>~\\<br>What is a \emph{set assignment}? Let $S$ be a set assignment. Then what does $S^\#$ denote?<br></latex>	pg 17546, "To specify the semantics of type expressions, we assume that we are given..." (right column, near bottom)<br>
<latex>~\\<br>Let $S$ be a set assignment. What does $S^{\#*}$ denote?<br></latex>	It maps each type assignment to the set of valuations corresponding to that assignment.<br>pg 17547 left<br>
<latex>~\\<br>A conventional set-theoretic semantics would be obtained by fixing some set assignmnet $S$ and defining a family of semantics functions from $E_{\pi \omega}$ to $S^{\# *} \pi \to S^{\#} \omega$. Why does Reynolds avoid doing this?<br></latex>	to capture abstraction properties we need to relate the meanings of an expression under different set assignments.<br>pg 17547 left<br>
<latex>~\\<br>Reynolds' function $\mu_{\pi \omega}$ for interpreting typed expressions has the domain $E_{\pi \omega}$. What is its codomain? Give the inductive definition of $\mu_{\pi \omega}$.<br></latex>	<latex>~\\<br>Its codomain is:<br>$$\prod_{S \in \mathcal S} (S^{\#*}\pi \to S^{\#}\omega)$$<br>pg 17547 left<br></latex>
<latex>~\\<br>Let $s$ be a set. What does Reynolds use $I(s)$ to denote?<br></latex>	pg 17547, right column<br>
<latex>~\\<br>Let $r \in Rel(s_1, s_2)$ and $r' \in Rel(s_1', s_2')$. What does $r \to r'$ denote? What does $r \times r'$ denote?<br></latex>	pg 17547, right column.<br><br>
<latex>~\\<br>For set assignments $S_1$ and $S_2$, what is a binary \emph{relation assignment} between $S_1$ and $S_2$?<br></latex>	pg 17547, right column<br>
<latex>~\\<br>If $R$ is a relation assignment between set assignments $S_1$ and $S_2$, then what does $R^{\#}$ denote?<br>What does $R^{\#*}$ denote?<br></latex>	pg 17547, bottom right corner.<br>pg 17548, top left corner.<br><br>
<latex>~\\<br>State Reynolds' \emph{Identity Extension Lemma}. How would we go about proving this lemma?<br></latex>	pg 17548, left column, near top. Note that T<sub>0</sub> is being defined "on the spot" here.<br><br><br>
State Reynolds' abstraction theorem.<br>	pg 17548, left column<br><br>
<latex>~\\<br>What does it mean for a type definition to be \emph{opaque}?<br></latex>	pg 17548, left column, section 4<br><br>
<latex>~\\<br>For $\tau \in T$ and $\omega, \omega' \in \Omega$, what does $\omega'/\tau \to \omega$ denote? For $\pi \in \Omega^*$, what does $\pi/\tau \to \omega$ denote?<br></latex>	pg 17548, bottom left (note that the first asterisk is erroneous).<br>
<latex>~\\<br>Consider the following equality:\\~\\<br>$S^{\#}(\omega' / \tau \to \omega) = [S \mid \tau \mapsto S^\# \omega]^{\#} \omega'$\\~\\<br>Prove or disprove.<br></latex>	true. pg 17548, top right<br>todo: add impostor?
<latex>~\\<br>Consider the following equality:\\~\\<br>$R^{\#}(\omega' / \tau \to \omega) = [R \mid \tau \mapsto R^\# \omega]^{\#} \omega'$\\~\\<br>Prove or disprove.<br></latex>	true. pg 17548, top right<br>todo: add impostor?<br>
<latex>~\\<br>For $\pi \in \Omega^*$ and $\tau \in T$, what does Reynolds use $\pi - \tau$ to denote?<br></latex>	pg 17548, right column<br>
<latex>~\\<br>Let $\eta \in S^{\# *}$. Consider the following statement:<br>$$\eta \upharpoonleft dom(\pi - \tau) \in [S \mid \tau \mapsto S^\# \omega]^{\# *}(\pi - \tau)$$<br>Why is this true? Why is it important?<br></latex>	pg 17548, right column.<br>
<latex>~\\<br>In Reynolds' language, a type definition has the form:\\~\\<br>$\mbf{lettype}~\tau = \omega~\mbf{in}~e$\\~\\<br>Provide the semantics for this type definition form.<br></latex>	pg 17548, right column, near bottom (the discussion directly above these definitions is also relevant)<br><br>
<latex>~\\<br>Let $S$ be a set assignment, $\omega_1, \omega_2 \in \Omega$, and $r$ a relation between $S^{\#} \omega_1$ and $S^{\#} \omega_2$. Consider the following statement:\\~\\<br>For all $\pi \in \Omega^*$, $\tau \in T$, $\omega' \in \Omega$, $e \in E_{\pi - \tau,\omega'}$, and $\eta \in S^{\# *}\pi$,\\~\\<br>$\langle \mu_{\pi,(\omega'/\tau \to \omega_1)} \sem{\mbf{lettype}~\tau = \omega_1~\mbf{in}~e}~S~\eta,\\ ~~\mu_{\pi,(\omega'/\tau \to \omega_2)} \sem{\mbf{lettype}~\tau = \omega_2~\mbf{in}~e}~S~\eta \rangle \in [\mathit{IA} \mid \tau \mapsto r]^{\#} \omega'$\\~\\<br>Prove or disprove.<br></latex>	pg 17548, right column, "Pure type definition theorem"
<latex>~\\<br>Reynolds provides a syntactic sugar for an extended lettype construct, which allows us to bind not only an abstract type, but also a primitive operator on that type. Show how this construct can be implemented as sugar using the vanilla lettype construct, which binds only an abstract type.<br></latex>	pg 17549, top left<br>
<latex>~\\<br>State Reynolds' \emph{General Type Definition Theorem}, which involves the extended lettype construct allowing us to bind a primitive operator along with the abstract type variable.<br></latex>	pg 17549 left<br>
<latex>~\\<br>When Reynolds develops his denotational semantics for domains rather than sets, how is $\mu_{\pi \omega}$ defined for the case of the if-then-else constructs?<br></latex>	in the obvious way<br>pg 17549<br>
<latex>~\\<br>How does Reynolds define denotational semantics for the fixpoint construct $Y$?<br></latex>	pg 17549, right column (Ei) and (Mi)<br>
<latex>~\\<br>What does it mean for a subset $C$ of a domain $D$ to be \emph{complete}? What does it mean for a relation between domains to be complete?<br></latex>	pg 17549, right column.<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Partial orderings of domains are complete relations that are preserved by $- \to - $ and $- \times -$, i.e.<br>$$ \sqsubseteq_s \to \sqsubseteq_{s'} = \sqsubseteq_{s \to s'}$$<br>and<br>$$\sqsubseteq_s \times \sqsubseteq_{s'} = \sqsubseteq_{s \times s'}$$<br>Prove or disprove.<br></latex>	true. pg 17550 left<br>
<latex>~\\<br>Let $s_1$ and $s_2$ be domains. What is a \emph{representation} between $s_1$ and $s_2$?<br></latex>	pg 17550 left<br><br>
<latex>~\\<br>For $\langle \phi, \psi \rangle \in \mathit{Rep}(s_1,s_2)$ and $\langle \phi', \psi'\rangle \in \mathit{Rep}(s_1',s_2')$, what does $\langle \phi, \psi \rangle \to \langle \phi', \psi' \rangle$ denote?<br>What does $\langle \phi, \psi \rangle \times \langle \phi', \psi' \rangle$ denote?<br></latex>	pg 17550, bottom left, top right
<latex>~\\<br>Let $S_1$ and $S_2$ be domain assignments.<br>Let $P$ be an element of the set<br>$$\prod_{\tau \in T} \mathit{Rep}(S_1 \tau, S_2 \tau)$$<br>I.e., $P$ is a representation assignment between $S_1$ and $S_2$. What does $P^\#$ denote? <br></latex>	pg 17550 right, (P1, P2, ...)<br><br>
Read pg 18017-18019 down to "This discussion of data abstraction..."	pg 18017<br>
<latex>~\\<br>Characterize the values that belong to the type $\forall \alpha. \alpha \to \alpha \to \alpha$.<br></latex>	pg 18019, near bottom.<br><br>
Read pg 18019 to 18020, from "Although a complete..." to bottom of pg 18020.<br>	pg 18019<br>
<latex>~\\<br>In the ``possible worlds'' semantic model of Algol-like languages, types are interpreted as \underline{~~~~~~} and phrases are interpreted as \underline{~~~~~~~~~~~}.<br></latex>	pg 18022, top<br>
Read page 18022<br>	pg 18022<br>
Give the type syntax of O'Hearn and Tennant's Algol-like language.	pg 18023, near top<br><br>
O'Hear and Tennant regard binary relations R as triples (W<sub>0</sub>,W<sub>1</sub>,S). Explain.<br>	pg 18023, section 2.2<br><br>
<latex>~\\<br>What do O'Hearn and Tennant use $R : W_0 \leftrightarrow W_1$ to denote? What about $w_0 [R] w_1$?<br></latex>	pg 18023, section 2.2<br>
<latex>~\\<br>Let $W$ be a set. What do O'Hearn and Tennant use $\Delta_W$ to denote?<br></latex>	pg 18023, section 2.2<br>
<latex>~\\<br>Give the syntax of the untyped lambda calculus. What does $\Lambda$ denote?<br></latex>	pg 24582, def 2.1.1<br><br>
<latex>~\\<br>In the untyped lambda calculus, what lambda term is $\Delta$ an abbreviation for? What about $S$?<br></latex>	pg 24582<br>
What does it mean for an untyped lambda term to be in <i>head normal form</i>?	pg 24582, def 2.1.2<br><br>
Any lambda term has one of the following to forms:<br>1.) HNF form<br>2.) __________ (complete the blank)	pg 24582, remark 2.1.3
<latex>~\\<br>Let $M$ be an untyped lambda term and $u$ a word over the alphabet $\{ 0, 1, 2 \}$. What does $M/u$ denote?<br></latex>	pg 24582, def 2.1.4<br>
<latex>~\\<br>If $M$ and $N$ are untyped lambda terms and $u$ is a word over $\{ 0, 1, 2 \}$, then what does $M[N/u]$ denote? <br></latex>	pg 24583. Right below figure at top.<br>
<latex>~\\<br>Let $u,v$ be words over the alphabet $\{ 0,1,2 \}$. What does $u \leq v$ mean? $u \not \uparrow v$?<br></latex>	pg 24583, right below figure at top<br>
<latex>~\\<br>Give the syntax for untyped lambda calculus contexts with numbered holes. Consider the following statement:\\~\\<br>For every term $M$ and every occurrence $u$ of $M$, there exists a unique context $C$ with a unique hole occurring exactly once, such that $M = C[M/u]$.\\~\\<br>Prove or disprove.<br></latex><br>	pg 24583, <br>definition 2.1.6,<br>prop 2.1.7<br><br>
Define the "filling" operation on numbered-hole contexts.	pg 24583, figure 2.1 at top<br>
<latex>~\\<br>Provide definitions of the predicates $Free(u,M)$ and $Bound(u,v,M)$.<br></latex>	pg 24583 bottom<br>pg 24584 top<br>
<latex>~\\<br>Let $M$ be an untyped lambda term. How do we define $FV(M)$? $BV(M)$? What does it mean for a variable $x$ to be \emph{fresh} relative to $M$?<br></latex>	pg 24584, below figure at top<br>
<latex>~\\<br>Give the $\beta$-reduction rules of the untyped lambda calculus. (hint: there are four of them)<br></latex>	pg 24585, figure 2.4<br>
<latex>~\\<br>Let $\to_{\beta}$ be the beta reduction relation. What relation does $=_{\beta}$ denote?<br></latex>	pg 24585, def 2.1.9<br>
<latex>~\\<br>Consider the following statement: $S~K~K = I$. Prove or disprove.<br></latex>	true. pg 24582 has the definitions of S and K and I, which make this obvious.
<latex>~\\<br>What can be said of a reduction sequence that starts from a head normal form: <br>$$\lambda x_1 \cdots x_n. x M_1 \cdots M_p$$<br></latex>	pg 24586, remark 2.1.11<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $M \to M'$, then $M[N/x] \to M'[N/x]$\\~\\<br>Prove or disprove.<br></latex>	true. pg 24586, lemma 2.1.12<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $N \to N'$, then $M[N/x] \to^{*} M[N'/x]$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24586, lemma 2.1.12 (2)<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>$\beta$-reduction is locally confluent: if $M \to N$ and $M \to P$, then $N \to^* Q$ and $P \to^* Q$ for some $Q$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24586, prop 2.1.13.<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statemen:\\~\\<br>The $\beta$-reduction relation is confluent, i.e. if $M \to^* N$ and $M \to^* P$, then $N \to^* Q$ and $P \to^* Q$ for some $Q$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 24586/24587, theorem 2.1.14
<latex>~\\<br>Suppose that three constants $D,F,S$ are added to the $\lambda$-calculus, together with the following new rewriting axiom:<br>$$(SP)~~D(Fx)(Sx) \to x$$<br>Is $\beta+(SP)$ confluent? Why or why not?<br></latex>	pg 24587, exercise 1.1.15<br>
Roughly/intuitively, what does it mean for a reduction from M to N to be <i>standard</i>?	pg 24587, above def 2.1.16<br>
<latex>~\\<br>If $u,v$ are redex occurrences in a term $M$, and if $M \to_{u} N$, then what does $v/u$ denote?<br></latex>	pg 24587/24588, def 2.1.16<br>
<latex>~\\<br>If $W_0$, $W_1$, $X_0$, and $X_1$ are sets and $R : W_0 \leftrightarrow W_1$ and $S : X_0 \leftrightarrow X_1$, what does $R \times S$ denote?<br></latex>	pg 18023, bottom<br>
<latex>~\\<br>If $W_0$, $W_1$, $X_0$, and $X_1$ are sets and $R : W_0 \leftrightarrow W_1$ and $S : X_0 \leftrightarrow X_1$, what does $R \to S$ denote?<br></latex>	pg 18024, top.<br>
<latex>~\\<br>How do O'Hearn and Tennant describe the collection $\Sigma$ of \emph{store shapes}?<br></latex>	It is a set that:<br>1.) contains each datatype's set of values<br>2.) is closed under finite products<br><br>pg 18024, "The collection \Sigma of ``store shapes''..."<br>
<latex>~\\<br>What are ``twin semantics'' for phrase types $\theta$? Inductively define such a twin semantics for the phrase types $\mbf{comm}$, $\mbf{exp}[\delta]$, and $\mbf{var}[\delta]$.<br></latex>	pg 18024, 18025<br>
<latex>~\\<br>Give the ``twin semantics'' for procedure phrase types $\vec{\theta} \to \beta$.<br></latex>	pg 18025 bottom / 18026 top<br>
<latex>~\\<br>Let $D$ and $E$ be partially ordered sets and $R : D \leftrightarrow E$. What does $R_{\bot}$ denote?<br></latex>	pg 18026, section 2.3<br>
<latex>~\\<br>Let $D$ and $E$ be directed-complete partially-ordered sets. What does it mean for a relation $R : D \leftrightarrow E$ to be \emph{complete}? \emph{pointed}?<br></latex>	pg 18026, section 2.3<br>
<latex>~\\<br>How do we modify the basic set-theoretic ``twin semantics'' of O'Hearn and Tennant's Algol-like language to accomodate recursion?<br></latex>	pg 18026, section 2.3<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Under O'Hearn and Tennant's ``twin semantics'', for each phrase type $\theta$ and store shape $W$, $\sem{\theta}\Delta_W = \Delta_{\sem{\theta} W}$.\\~\\<br>Prove or disprove.<br></latex>	pg 18027, lemma 1<br><br>
<latex>~\\<br>Let $f : W \to X$ be a bijection between store shapes. How is the isomorphism $f_{\theta} : \sem{\theta}W \to \sem{\theta} X$ defined?<br></latex><br>	<latex>~\\<br>pg 18027, near bottom **Note that $\to$ is exponentiation, and functoriality of both $-\to-$ and $-\times-$ is being used**\\<br>pg 18028 top<br></latex><br><br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Each $\sem{\theta}$ is a functorial on isomorphisms. That is, for all isomorphisms $R : W \leftrightarrow X$ in $\mathit{rel}(\Sigma)$,<br>\begin{itemize}<br>\item if $R$ is an isomorphism then so is the induced relation $\sem{\theta}R$<br>\item if $R : X \leftrightarrow Y$ and $S : Y \leftrightarrow W$ are isomorphisms, then $\sem{\theta}R;\sem{\theta}S = \sem{\theta}(R ; S)$ where semicolon is relational composition.<br>\end{itemize}<br>Prove or disprove.<br></latex>	true. pg 18028, lemma 2<br>
<latex>~\\<br>Let $f : W \to X$ be a bijection between store shapes and let $R_f : W \leftrightarrow X$ be the relation with the same graph as $f$. Consider the following statement:\\~\\<br>The relation $\sem{\theta} R_f$ and the function $f_{\theta}$ have the same graph.\\~\\<br>Prove or disprove.<br></latex>	true. pg 18028, lemma 2.<br>todo: add impostor?<br>
<latex>~\\<br>Recall the canonical unity and associativity isomorphisms between store shapes. (Here, $\mbf{1}$ is a singleton shape.)<br>\begin{mathpar}<br>unl : W \times \mbf{1} \to W <br>\and<br>unr : W \to W \times \mbf{1} <br>\and<br>assl : W \times (X \times Y) \to (W \times X) \times Y<br>\and<br>assr : (W \times X) \times Y \to W \times (X \times Y)<br>\end{mathpar}<br>Consider the following statement:\\~\\<br>If $R_i : X_i \leftrightarrow Y_i$ are relations between store shapes, for $i = 1,2,3$, then for all types $\theta$,<br>\begin{mathpar}<br>\mathit{unl}[\sem{\theta}(R_1 \times \Delta_{\mbf{1}}) \to \sem{\theta}R_1]\mathit{unl} <br>\and<br>\mathit{unr}[\sem{\theta}R_1 \to \sem{\theta}(R_1 \times \Delta_{\mbf{1}})]\mathit{unr}<br>\and<br>\mathit{assl}[\sem{\theta}(R_1 \times (R_2 \times R_3)) \to \sem{\theta}((R_1 \times R_2) \times R_3)]\mathit{assl}<br>\and<br>\mathit{assr}[\sem{\theta}((R_1 \times R_2) \times R_3) \to \sem{\theta}(R_1 \times (R_2 \times R_3))] \mathit{assr}<br>\end{mathpar}<br>Prove or disprove.<br></latex>	true. pg 18028.<br>todo: add impostor?
<latex>~\\<br>If $W$ and $X$ are store shapes, for each type $\theta$ we have a function<br>$$expand_{\theta}(W,X) : \sem{\theta}W \to \sem{\theta}(W \times X)$$<br>How is this function defined?<br></latex>	pg 18029, near top<br><br>
<latex>~\\<br>State and prove O'Hearn and Tennant's ``Expansion parametricity'' property.<br></latex>	pg 18029.<br>
<latex>~\\<br>Give the natural deduction style typing rules for O'Hearn and Tennant's Algol style language, for the following phrase constructs:\\~\\<br>\begin{itemize}<br>\item lambda abstractions (introduction and elimination)<br>\item variable assignments and dereferences<br>\item skip<br>\end{itemize}<br></latex>	pg 18030, table 1<br>
<latex>~\\<br>Give the natural deduction style typing rules for O'Hearn and Tennant's Algol style language, for the following phrase constructs:\\~\\<br>\begin{itemize}<br>\item command sequencing<br>\item if-then-else<br>\item do-result<br>\item new<br>\end{itemize}<br></latex>	pg 18030, table 1<br>
<latex>~\\<br>For a store shape $W$, what does $\sem{\pi}W$ denote? For a relation $R : W_0 \leftrightarrow W_1$ between store shapes, when does $u_0[\sem{\pi}R]u_1$ hold?<br></latex>	pg 18030, near bottom<br>pg 18031, near top.<br><br>
<latex>~\\<br>How do O'Hearn and Tennant interpret judgments of the form $\pi \vdash x : \beta$? What about judgments of the form $\pi \vdash x : \vec{\theta} \to \beta$?<br></latex>	pg 18031, text below table 2.<br>
<latex>~\\<br>Give the interpretations for typed phrases of the following forms:<br>\begin{itemize}<br>\item $\lambda x : \theta. M$<br>\item $\mbf{deref}~v$<br>\item $V := E$<br>\item $\mbf{skip}$<br>\end{itemize}<br></latex>	pg 18031<br>
<latex>~\\<br>Give the interpretations for typed phrases of the following forms:<br>\begin{itemize}<br>\item $C_1;C_2$<br>\item $\mbf{do}_\delta~C~\mbf{result}~E$<br>\item $\mbf{if}_t~B~\mbf{then}~M~\mbf{else}~N$<br>\end{itemize}<br>Where in the $\mbf{if}$ construct, t is either $\mbf{comm}$ or of the form $\mbf{exp}[\delta]$.<br></latex>	pg 18031, table 2<br>
<latex>~\\<br>What does a block expression, of the form $\mbf{do}~C~\mbf{result}~E$ mean in O'Hearn and Tennant's Algol-like language?<br></latex>	pg 18032, "The block expression..."<br>
Reynolds described a notion of "snapback semantics". Give a short phrase in O'Hearn and Tennant's Algol-like language which demonstrates snapback semantics.	pg 18032<br>
<latex>~\\<br>For a store shape $W$, $p \in \sem{\mbf{var}[\delta] \to \mbf{comm}} W$ and state $w \in W$,<br>How do we define $\sem{\mbf{new}_{\delta}}~W~u~p~w$?<br></latex>	pg 18032<br>
<latex>~\\<br>Suppose that we are given $\pi \vdash M : \theta,\vec{\theta} \to \beta$ and $\pi \vdash N : \theta$. Further suppose that $\theta = \beta'$ is a primitive type. How then do we define the following?\\~\\<br>$\sem{M~N}~W~u~\vec{d}$<br></latex>	pg 18032, near bottom<br><br>
<latex>~\\<br>Suppose that we are given $\pi \vdash M : \theta,\vec{\theta} \to \beta$ and $\pi \vdash N : \theta$. Further suppose that $\theta = \vec{\theta'} \to \beta'$, i.e., it is not a primitive type. How then do we define the following?\\~\\<br>$\sem{M~N}~W~u~\vec{d}$<br></latex>	pg 18032, near bottom<br><br>
State and prove O'Hearn and Tennant's version of "The Abstraction Theorem" for their Algol-like language.<br>	pg 18033<br>
<latex>~\\<br>In session types, what does $P :: x : A$ mean?<br></latex><br>	pg 20264<br>
What is the form of a session typing judgment, and what is its meaning?	pg 20264<br>
<latex>~\\<br>When a process $P$ \emph{offers} a service $A$ along $x$, and another process $Q$ \emph{uses} a service $A$ along $x$, the two can be composed so that they communicate along $x$. Give the session typing rule for such a communication.<br></latex>	pg 20265, cut<br>
Give the session typing equivalent of the linear logic's identity inference rule.	pg 20266<br>
What role do identity and cut play in session typing?	pg 20266, section 3, "In summary..."<br><br>
Read the top part of page 20267. (note that the pi calculus book goes more into detail on structural congruence, maybe post a link to that book on this page?)<br>	pg 20267<br>
<latex>~\\<br>What is the meaning/origin of the term \emph{session types}? What is the meaning of the connective $\multimap$?<br></latex>	pg 20268<br>
<latex>~\\<br>Give the $\multimap \! R$ and $\multimap \! L$ rules for session types.<br></latex>	pg 20268<br>
<latex>~\\<br>Demonstrate cut reduction for the $\multimap$ connective. Then, give the process (i.e. session typing) interpretation of this cut reduction.<br></latex>	pg 20269<br>
Read example 7, starting on page 20270, ending on page 20271	pg 20270<br>
<latex>~\\<br>Give the $\otimes R$ rule for intuitionistic linear logic. What is the session types equivalent of this rule?<br></latex>	pg 20274/20275
<latex>~\\<br>Give the $\otimes L$ rule for intuitionistic linear logic. Also give its equivalent typing rule for session types.<br></latex>	pg 20275.<br>
<latex>~\\<br>Explain how cut reduction works for the $\otimes$ connective of session typing.<br></latex>	pg 20275<br>
<latex>~\\<br>Give the $\mbf{1}R$ and $\mbf{1}L$ rules of intuitionistic linear logic. What are their equivalent session typing rules? Demonstrate the operational ($\pi$-calculus) interpretation of cut reduction for $\mbf{1}$.<br></latex>	pg 20276<br>
<latex>~\\<br>Consider the following function:~\\~\\<br>$\Lambda \tau. \lambda f : \tau \to \tau. \lambda x : \tau. f(f(x))$\\~\\<br>Intuitively, what does this function do? What is its type?<br></latex>	pg 17551, left column<br>
<latex>~\\<br>Give Reynolds' typing rule for expressions of the form $\Lambda \tau . e$. Also give his typing rule for expressions of the form $e[\omega]$.<br></latex>	pg 17551, bottom left corner (Ej) and (Ek)<br>
Explain the distinction between parameteric and ad-hoc polymorphism.	pg 17551, upper right corner.<br><br>
<latex>~\\<br>Let $\tau \in T$ and $\omega \in \Omega$. How does Reynolds define $S^{\#}(\Delta \tau. \omega)$.<br></latex>	pg 17551, bottom right (S5)<br>
<latex>~\\<br>If $e \in E_{\pi - \tau, \omega}$, how is the following defined?\\~\\<br>$\mu_{\pi, \Delta \tau. \omega}~\sem{\Lambda \tau. e}~S~\eta$<br></latex>	pg 17551, bottom right (Mj)<br>
<latex>~\\<br>If $e \in E_{\pi,\Delta \tau. \omega'}$, then how is the following defined?\\~\\<br>$\mu_{\pi,(\omega'/\tau \to \omega)}~\sem{e[w]}~S~\eta$<br></latex>	pg 17552, upper left corner.<br><br>
<latex>~\\<br>If $\tau \in T$ and $\omega \in \Omega$ and $R$ is a relation assignment between set assignments $S_1$ and $S_2$, then how is the following relation defined?<br>$$R^{\#}(\Delta \tau.~\omega)$$<br></latex>	pg 17552, (R5)<br>
<latex>~\\<br>How does Reynolds use the predicate \emph{parametric}$_{S\tau\omega}$? What does it mean?<br>What must be taken into consideration when defining this predicate?<br></latex>	usage on pg  17551, right column<br>motivation on pg 17552, left column<br><br>
What is the link between abstraction and parametric polymorphism?	pg 17552, bottom left<br><br>
<latex>~\\<br>How do we generalize from binary to multinary relations, using Reynolds' approach?<br></latex>	pg 17553, left column, "To generalize from binary to multinary relations, we assume..."
<latex>~\\<br>Let $\delta$ be an $I$-indexed family of sets. What does $\mathit{Krel}(\delta)$ denote?<br></latex>	pg 17533, bottom left<br>
<latex>~\\<br>Let $k \in \mathit{Krel}(\delta)$, $k' \in Krel(\delta')$. What does $k \to k'$ denote?<br></latex>	pg 17553, bottom left, top right<br><br><br>
<latex>~\\<br>If $S = \langle S_i \mid i \in I \rangle$ is an $I$-indexed family of set assignments,<br>then what is the set of \emph{Kripke relation assignments} among the $S_i$.<br></latex>	pg 17553, right column<br><br>
<latex>~\\<br>Let $K$ be a Kripke relation assignment. How is $K^\#$ defined?<br></latex>	pg 17553, right column<br>
<latex>~\\<br>Let $s$ be a set. What does $\mathit{IK}(s)$ denote? State the ``Generalized Abstraction Theorem'' and the ``Generalized Identity Extension Lemma''.<br></latex>	pg 17553, bottom right<br><br>
<latex>~\\<br>Let $W$ be any store shape and $E \subseteq \mathbb Z$. Define $R_E : W \leftrightarrow W \times \mathbb Z$ by<br>$$w [R_E] \langle w', z \rangle ~\dot{\Leftrightarrow}~ w = w' \text{ and } z \in E$$<br>Let $c \in \sem{\mbf{comm}}(W \times \mathbb Z)$ such that <br>$$skip[\sem{\mbf{comm}}R_E]c$$<br>Consider the following statement:\\~\\<br>If $p \in \sem{\mbf{comm} \to \mbf{comm}}W$ then,<br>$$p^*(skip) [\sem{\mbf{comm}}] p[Z](c)$$<br>where $p^* = unl;p[1];unr : \sem{\mbf{comm}}W \to \sem{\mbf{comm}}W$\\~\\<br>Prove or disprove.<br></latex>	pg 18034, Section 5<br>
<latex>~\\<br>Consider the first block of Algol code on page 18017. Use parametricity to prove that it is equivalent to the procedure call $P(skip)$.<br></latex>	pg 18035, near top (and some relevant text precedes that on pg 18034)<br>
Read the "typical counterexample" starting at the bottom paragraph on pg 18035<br>	<br>
<latex>~\\<br>Let $Z^{\oplus}$ be the set of \emph{nonnegative} integers. Then we have $\mathit{skip} [\sem{comm}R_{Z^{\oplus}}] \mathit{inc}$, where \emph{skip} and \emph{inc} have the obvious meanings.<br>How can we use this fact to prove that the variable $z$ is non-negative on termination of the following procedure?<br>\begin{verbatim}<br>begin<br>  integer z;<br>  z := 0;<br>  P(z := z + 1);<br>  ...<br>end<br>\end{verbatim} <br></latex>	pg 18036<br>
<latex>~\\<br>Consider the following code fragment:<br>\begin{verbatim}<br>begin<br>  integer z;<br>  z := 0;<br>  P(z)<br>end<br>\end{verbatim}<br>How can we use parametricity to prove that this fragment is equivalent to $P(0)$?<br></latex>	pg 18036, near bottom<br><br>
<latex>~\\<br>Page 18018 shows two different representations of a counter object. Use parametricity to show that they are equivalent.<br></latex>	pg 18037, "Next we consider..."<br>
<latex>~\\<br>Work through the abstract ``switch'' example listed on page 18037.<br></latex>	pg 18037, "The example involves an abstract `switch'".<br>
<latex>~\\<br>Let $p \in \sem{\mbf{comm} \to \mbf{comm}}\mbf{1}$. Consider the following statement:\\~\\<br>There is a natural number $n$ such that $p[N] (id_{\{ \ast \}} \times \mathit{succ})~\langle \ast, 0 \rangle = \langle \ast, n \rangle$, where $N$ is the set of natural numbers and $\mathit{succ}$ is the successor function.\\~\\<br>Prove or disprove.<br></latex>	true. pg 18038, "To begin, we consider..."<br><br>
How can we represent Church numerals in Algol-like languages (hint: a parametricity-style argument may be helpful).<br>	pg 18038, "To begin..."<br><br>
<latex>~\\<br>Consider the following statement:<br>$$\sem{\mbf{comm} \to \mbf{comm}} \alpha \cong (\alpha \times list[\alpha] \to \alpha) \to (\alpha \to \alpha \times list[\alpha])$$<br>Prove or disprove.<br></latex>	pg 18038, proposition 6<br><br>
Read page 18039<br>	pg 18039<br>
<latex>~\\<br>Recall the domain-theoretic version of O'Hearn and Tennant's Algol-like language, i.e. the version with recursion.<br>Let $Vnat$ be the vertical natural numbers, i.e., the natural numbers with the usual ``less than'' order, and with an extra top element $\infty$. Consider the following statement:<br>$$\sem{\mbf{comm} \to \mbf{comm}}\mbf{1} \cong N_{\bot} \otimes Vnat^{op}$$<br>Where $\otimes$ is the smash product. Prove or disprove.<br></latex>	pg 18039, near bottom<br>
<latex>~\\<br>Provide the definition of \emph{reflexive graph}.<br></latex>	pg 18041, "Here is a precise definition..."<br>the next paragraph provides an even better definition "An equivalent..."<br><br><br>
Read the first example of a reflexive graph, which O'Hearn and Tennant present at the top of page 18042.	pg 18042<br>
<latex>~\\<br>Read O'Hearn and Tennant's definition of the reflexive graph $\mathcal D$ given near the bottom of pg 18042.<br></latex>	pg 18042, "As our second example..."<br><br>
Provide the definition of O'Hearn and Tennant's reflexive graph of "worlds".<br>	Starts at the very bottom of pg 18042, and also covers most of pg 18043.<br>
<latex>~\\<br>What is a \emph{type operator} over a set of sets $\mathcal S$?<br></latex>	pg 26817, left column<br>
Read pg 26817, left column	<br>
<latex>~\\<br>Define the type operator $\forall Z. T(X,Z)$. What is its set part? What is its relation part?<br></latex>	pg 26817, bottom left<br><br>
<latex>~\\<br>Define the type operator $\exists Z. T(X,Z)$. What is its set part? What is its relation part?<br></latex>	pg 26817, top right.<br>
<latex>~\\<br>Explain the intuitive meaning of the type operator $\exists Z. T(X,Z)$. What is its set part? What is its relation part?<br></latex>	pg 26817, top right corner.<br><br>
<latex>~\\<br>A \emph{simulation} is a specific kind of relation related to existential type operators. Provide the definition of \emph{simulation}.<br></latex>	pg 26817, top right<br>
<latex>~\\<br>Give the interpretations of Reddy's type syntax as type operators.<br></latex>	pg 26817, right column. note that these definitions are constructed using type operator constructors: they entail both a set part and a relation part, see the left column.<br><br><br>
<latex>~\\<br>Consider the following two terms in Reddy's $\mathit{IA}^+$. First, we have the term:<br>\begin{verbatim}<br>class<br>  {inc : comm, val : exp[int]}<br>field<br>  Var[int] cnt<br>methods<br>  { inc = (cnt.put := cnt.get + 1),<br>    val = cnt.get }<br>init<br>  cnt.put 0<br>\end{verbatim}<br>Second, we have the term:<br>\begin{verbatim}<br>class<br>  {inc:comm, val : exp[int]}<br>fields <br>  Var[int] st<br>methods<br>  { inc = (s.put := st.get - 1),<br>    val = -st.get }<br>init<br>  st.put 0<br>\end{verbatim}<br>What can be said of the parametricity-based denotational interpretations of these terms?<br></latex>	pg 26817, bottom right.<br><br>
<latex>~\\<br>How are terms interpreted in Reddy's parametricity-based semantics for $\mathit{IA}^+$? How is the ``expand'' function $\mathit{expand}_{\theta}[Q,Z]$ defined?<br></latex>	pg 26818, left column<br>
<latex>~\\<br>What does Reddy use the notation $v \uparrow_{Q}^{Q \times Z}$ for?<br></latex>	pg 26818, left column<br>
<latex>~\\<br>If $v \in \sem{\mbf{comm}}(Q)$. What does $v \uparrow_{Q}^{Q \times Z}$ denote?<br></latex>	pg 26818, left column<br><br>
<latex>~\\<br>What is the relation between constant value of type $\theta$ and the $\mathit{expand}_\theta$ family of functions in the parametricity-based semantics of $\mathit{IA}^+$.<br></latex>	pg 26818, left column<br>
<latex>~\\<br>How are the semantics of a class term $\sem{\mbf{class}~\theta~\mbf{fields}~C~x~\mbf{methods}~M~\mbf{init}~A}$ defined?<br></latex>	pg 26818, left column<br><br>
<latex>~\\<br>Give the parametricity-based denotational interpretation $\sem{\mbf{new}~C~P}$ of the $\mbf{new}$ term construct in $\mathit{IA}^+$. <br></latex>	pg 26818, left column
<latex>~\\<br>How do we define the interpretation $\sem{\mathit{Var}[\delta]}$ of the term $\mathit{Var}[\delta]$ using Reddy's parametricity-based semantics?<br></latex>	pg 26818, top right<br>
<latex>~\\<br>The top-left corner of pg 26814 describes a ``product'' combinator. How do we provide parametricity-based denotational semantics for this combinator?<br></latex>	pg 26818, top right corner.<br>
Read the right column of pg 26818 (todo: generate some question cards from this passage?)	pg 26818<br>
Read the left column of page 26819 (which spills to its right column)	pg 26819<br>
<latex>~\\<br>Let $x$ be an instance of a counter class. How would we verify the following equation using trace semantics?<br>$$x.inc;g(x.val) = g(x.val + 1);x.inc$$<br></latex>	pg 26819, right column
<latex>~\\<br>Provide the definition of a \emph{coherent space}.<br></latex>	pg 26819, right column<br>
<latex>~\\<br>Let $A$ be a coherent space. What is the \emph{free object space} $A^*$ generated by $A$?<br></latex>	pg 26819, right column<br>
<latex>~\\<br>What is an \emph{element} of a coherence space? In particular, for a coherence space $A$, what is an element of the free object space $A^*$ generated by $A$?<br></latex>	pg 26819<br>
<latex>~\\<br>Let $A_1, \ldots, A_n, B$ be coherence spaces. What is a \emph{linear map} $F : A_1^*, \ldots, A_n^* \to B$? Given a linear map $F$, what does $F^*$ denote?<br></latex>	pg 26819, right column, kinda near bottom<br>
<latex>~\\<br>Under coherence semantics for Reddy's $\mathit{IA}^+$, what does a term $M$ denote?<br></latex>	pg 26820, left column, near top<br>
<latex>~\\<br>Give the coherence space interpretations of events for the following $\mathit{IA}^+$ types:<br>\begin{itemize}<br>\item exp[$\delta$]<br>\item comm<br>\item $A_1 \times A_2$<br>\item $A^* \to B$<br>\item cls $\theta$<br>\end{itemize}<br></latex>	pg 26820, figure 7<br>also see the top left corner of the text on pg 26820<br>
State the universal property of the smash product.<br>	pg 24575, prop 1.4.21 (2)<br>
Two additional command forms are added to Imp to obtain Imp' (Imp with control flow constructs). What are they?	pg 24578, near bottom<br>
Give the six inference rules used to judge whether an Imp' command is scope safe.<br>	pg 24579, near top<br>
<latex>~\\<br>How are the sets $\mathit{Cont}$ and $\mathit{Env}$ defined, for use in the denotational semantics of $\mathit{Imp}'$?<br></latex>	pg 24579<br>
<latex>~\\<br>What is the type of $\sem{-}'$, the command interpretation function for the language $\mathit{Imp}'$?<br></latex>	Env -> (Cont -> Cont)<br>pg 24579<br>
<latex>~\\<br>Give the $\mathit{Imp}'$ denotational interpretations of commands of the following forms:<br>\begin{itemize}<br>\item $\mbf{skip}$<br>\item $c_0;c_1$<br>\item $\mbf{if}~b~\mbf{then}~c_0~\mbf{else}~c_1$<br>\item $\mbf{goto}~l$<br>\item $l : c$<br>\end{itemize}<br></latex>	<latex>~\\<br>pg 24580, near top\\<br>remember:\\ $\sem{-}' : \mathit{Env} \to (\mathit{Cont} \to \mathit{Cont})$<br></latex>
<latex>~\\<br>Do exercise 1.6.1 on page 24579.\\<br>Note that $\sem{-}'$ is defined on the next page 24580.<br></latex>	pg 24579
<latex>~\\<br>Do exercise 1.6.2 on page 24579.\\<br>Note that $\sem{-}'$ is defined on the next page 24580, and that $\sem{-}$ is defined on page 24578.<br></latex>	pg 24579<br>
<latex>~\\<br>Give the operational semantics for $\mathit{Imp}'$.<br></latex>	pg 24579, bottom, spills onto pg 24580<br>
<latex>~\\<br>What is a \emph{Hagino signature}?<br></latex>	pg 10139, "Hagino signatures and strong functors", read the whole paragraph.<br>
<latex>~\\<br>Let $\mathbb B$ be a distributive category. Then each model $A : S \to \mathbb B$ of a set of atomic types $S$, together with a Hagino type $\sigma \in \overline{S \cup \{ X \}}$, determines a polynomial functor $T(A)_\sigma$. Provide the definition for $T(A)_\sigma$ by a case analysis on $\sigma$. <br></latex>	pg 10140, near top<br><br>
<latex>~\\<br>For an arbitrary endofunctor $T : \mathbb B \to \mathbb B$, what is an \emph{T-algebra}? What is a \emph{T-coalgebra}?<br></latex>	pg 10140, near top.<br>
<latex>~\\<br>How is the category $\mbf{Alg}(T)$ defined?<br></latex><br><br>	pg 10140, near bottom<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>An initial $T$-algebra $\varphi : T(Y) \to Y$ is an isomorphism.\\~\\<br>Prove or disprove.<br></latex>	pg 10141, lemma 2.6.5<br>todo: add impostor?<br>
<latex>~\\<br>Consider a type $\sigma(X)$ built with finite product and coproducts from $S \cup \{ X \}$ and a model $S : A \to \mathbb B$ of the atomic types in a distributive category $\mathbb B$. What is a \emph{(initial) model} in $\mathbb B$ of an inductive Hagino signature<br>\begin{tikzcd}<br>\sigma(X) \ar[r, "constr"] & X<br>\end{tikzcd}? What is a \emph{(terminal) model} of a co-inductive Hagino signature <br>\begin{tikzcd}<br>X \ar[r, "destr"] & \sigma(X)<br>\end{tikzcd}?<br></latex>	pg 10141, def 2.6.6<br>
Read the bottom paragraph of pg 10141 "Hagino signatures..." down to def 2.6.7 on page 10142.<br>	pg 10142<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. What does it mean for a functor $T : \mathbb B \to \mathbb B$ to be \emph{strong}?<br></latex>	pg 10142, def 2.6.7<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Every functor $T : \mbf{Sets} \to \mbf{Sets}$ is strong.\\~\\<br>Prove or disprove.<br></latex>	pg 10142, example 2.6.8<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>On a distributive category $\mathbb B$, identity functors and constant functors are strong. Moreover, if $T,S : \mathbb B \to \mathbb B$ are strong, then so are<br>$$Y \mapsto T(Y) \times S(Y)~~~~\text{and}~~~~Y \mapsto T(Y) + S(Y)$$<br>Prove or disprove.<br></latex>	pg 10143 (ii) at top<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products and $I \in \mathbb B_0$. WLet $T : \mathbb B \to \mathbb B$ be a strong functor. Then what does $T / \! \! / I$ denote?<br></latex>	pg 10143, prop 2.6.9<br>
<latex>~\\<br>Let $\mathbb B$ be a category with finite products. Consider the following statement:\\~\\<br>There is a bijective correspondence between strong functors \begin{tikzcd} \mathbb B \ar[r] & \mathbb B\end{tikzcd}\\~\\<br>and split functors <br>\begin{tikzcd}<br>s(\mathbb B) \ar[rr] \ar[dr] & & s(\mathbb B) \ar[dl] \\<br> & \mathbb B & <br>\end{tikzcd}\\~\\<br>Prove or disprove.<br></latex>	true. pg 10143, prop 2.6.9<br>The functor I* is defined near the bottom of page 10020<br><br>
<latex>~\\<br>Let $T : \mathbb B \to \mathbb B$ be a strong functor and $\varphi : TX \to X$ an algebra on this functor. What does it mean for $\varphi$ to be \emph{initial with simple parameters}?<br></latex>	pg 10143, def 2.6.10<br>
<latex>~\\<br>In the proof of 2.6.9 on page 10143, explain the claim ``It satisfies $I^* \circ \overline{R} = R_I \circ I^*$, and hence in particular for $X \in \mathbb B$, $\overline{R}(X) = R_I(X)$.<br></latex>	<latex>~\\<br>Note that the latter claim is not ``well-typed'', in that the left-hand-side is an object of $\mathbb B$ and the right-hand-side is an object of $\mathbb B / \! \! / I$. Jacobs is implicitly casting the right-hand-side to an object of $\mathbb B / \! \! / I$ by pairing it with $I$. \\~\\<br>There is really not much mathematical content to the latter part of the claim: it's just a notational shorthand.\\~\\<br>pg 10143\\~\\<br>TODO: prove $I^* \circ \overline{R} = R_I \circ I^*$<br></latex>
<latex>~\\<br>The bottom line of the proof of prop 2.6.9 on pg 10143 says "we leave it to the reader to verify that $\overline{\overline{T}} = T$ and $\overline{\overline{R}} = R$. Perform this verification.<br></latex>	pg 10143<br>
<latex>~\\<br>Let $M = I~((\lambda x.(Ix)x)(\lambda x. Ix))$. Recall that $u/v$ denotes the residuals of $v$ after the reduction $M \to_{u} N$. Give the following:<br>\begin{itemize}<br>\item 220/2101<br>\item $\epsilon$ / 2<br>\item 2/2<br>\item 220/2<br>\end{itemize}<br></latex>	pg 24588, example 2.1.18<br>
<latex>~\\<br>Let $u$ and $v$ be redex occurrences of $M$. What does it mean for $u$ to be \emph{to the left of} $v$?<br></latex>	pg 24588 bottom, def 2.1.18<br><br>
<latex>~\\<br>Formally, what does it mean for a derivation $D : M = M_0 \to_{u_1} M_1 \cdots \to_{u_n} M_n$ to be \emph{standard}?<br></latex>	pg 24589, def 2.1.19 at top<br>some relevant notaitons are defined at the top of pg 24588<br><br>
<latex>~\\<br>What is a \emph{normal derivation}? If $M$ is a lambda term, what does $\mathit{Val}(M)$ denote?<br></latex>	pg 24589, def 2.1.19<br><br>(note that "left of" is defined in def 2.1.18 on page 24588)<br><br>normal order is just call-by-value reduction (recall that Reynolds refers to cbv as ``normal order'')<br>
<latex>~\\<br>Is the derivation $(\lambda x. y)(\Delta \Delta) \to_{2} (\lambda x.y)(\Delta \Delta) \to_{\epsilon} y$ standard or non-standard? Why or why not?<br></latex>	WARNING: the textbook erroneously says that it is standard when it is non-standard.<br>pg 24589, example 2.1.20<br><br>the text of example 2.1.20 argues that it is non-standard, even though it accidentally uses the term "standard" rather than "non-standard".<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $D : M \overset{stnd}{\longrightarrow}^* \lambda x. N$, then $D$ decomposes into <br>$$M \overset{norm}{\longrightarrow}^{~*} Val(M) \overset{stnd}{\longrightarrow} \lambda x. N$$<br>Prove or disprove.<br></latex>	true. pg 24589, lemma 2.1.21<br>
<latex>~\\<br>What does it mean for a $\lambda$-term $M$ to be \emph{strongly normalizable}?<br></latex>	pg 24589, def 2.2.1<br>
<latex>~\\<br>What does $\mathit{SN}$ denote?<br></latex>	pg 24589, def 2.2.1 near bottom<br>
<latex>~\\<br>What is the \emph{size} of a $\lambda$-term $M$?<br></latex>	pg 24590, def 2.2.2<br>
<latex>~\\<br>Let $M \in \mathit{SN}$. What does $\mathit{depth}(M)$ denote?<br></latex>	pg 24590. def 2.2.2 near top<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $M \in \mathit{SN}$ and $M \to^* N$, then $M \overset{stnd}{\longrightarrow}~^*~N$.\\~\\<br>Prove or disprove.<br></latex>	pg 24590, lemma 2.2.3<br>todo: add impostor? (remove the part about SN)<br><br>
Read the example on pg 32652 right, at the very top, "Occasionally, you can create a resumptive..."<br>	pg 32652, top right<br>
What is a <i>summative modifier</i>? Give some examples.	pg 32652 right<br>
Consider the following passage:<br><br>Economic changes have reduced the region's population growth to less than zero, which will have serious social implications.<br><br>Is the above passage a good one? If not, what could be done to improve it?	pg 32652 right, "Summative modifiers"<br>
Consider the following passage:<br><br>Economic changes have reduced the region's population growth to less than zero, a demographic event that which will have serious social implications.<br><br>Is the above passage a good one? If not, what could be done to improve it?	It is used as an example of a good use of summative modifiers.<br><br>pg 32652, right "Summative modifiers"<br><br>
What is a <i>free modifier</i>? Give some examples.<br>	pg 32652, bottom right, "Free modifiers"<br>spills to pg 32653, top left<br>
Why are free modifiers called "free modifiers"? What does the adjective "free" mean here?	they can either begin or end a sentence, pg 32653 top left.<br>the top example ends a sentence, the next two examples have modifiers that begin sentences.
Consider the following passage:<br><br>The aspiring artist may find that even a minor, unfinished work which was botched may be an instructive model for how things should be done, while for the amateur spectator, such works are the daily fare which may provide good, honest nourishment, which can lead to an appreciation of deeper pleasures that are also more refined.<br><br>Is this passage well-written? Why or why not? If not, how would you improve it?	it's bad.<br><br>pg 32653 left, "Coordinate"<br>spills onto right side<br><br>
Consider the following passage:<br><br>We should devote a few final words to a matter that reaches beyond the techniques of research to the connections between those subjecteive values that reflect our deepest ethical choices and objective research.<br><br>Is this well written? Why or why not? If not, how would you improve it?	It is given on pg 32653, bottom right corner. The improved version is on pg 32653, top right.<br>
Read page 32654 left column, the four points below "This principle of short to long is,..."	pg 32654<br>
Consider the following passage:<br><br>The Golden Gate Bridge is an engineering marvel and a construction of stunning beauty.<br><br>Is this sentence good? Is there anything that can be done to improve it?	It's fine, but correlative conjunctions could improve it somewhat.<br><br>pg 32654, "quick tip" on right side.<br>
Consider the following passage:<br><br>When you punctuate carefully, you not only help readers understand a complex sentence more easily, but you enhance your own image as a good writer.<br><br>Is there anything wrong with this passage? If so, what is wrong and how would you fix it?	it is wrong.<br>pg 32654, right side, bottom of "quick tip"<br>
Do exercises 1-4 on page 32655 left.<br>(Note that the exercise statement starts in the bottom left corner of pg 32654)<br>	pg 32655<br>
Consider the following passage:<br><br>The committee recommends revising the curriculum to recognize trends in local employment and that the division be reorganized to reflect the new curriculum.<br><br>Is this passage well written? If not, why, and what would you do to revise it?	it's not well written<br><br>pg 32655, bottom left corner. correct version in top right corner.<br><br>
Consider the following passage:<br><br>The committe recommends revising the curriculum to recognize trends in local government and reorganizing the division to reflect the new curriculum.<br><br>Is this passage well written? If not, why, and how would you fix it?	it's used as an example of a well written passage<br><br>pg 32655, bottom left / top right<br>
Read pg 32655, right, starting with the text "However, some nonparallel coordinations do occur in well-written prose."	pg 32655<br>
Consider the following passage:<br><br>Grade inflation is a problem at many universities, and it leads to a devaluation of good grades earned by hard work and will not be solved simply by grading harder.<br><br>Is this sentence well written? If not, why, and how would you fix it?	this is part of the "faulty rhetorical coordination" section, which begins at the bottom right corner of pg 32655 and spills over to the top-left corner of pg 32656<br>
Consider the following passage:<br><br>Teachers should remember that students are vulnerable and uncertain about those everyday ego-bruising moments that adults ignore and that they do not understand that one day they will become as confident and as secure as the adults that bruise them.<br><br>Is this a well written sentence? If not, why, and what would you do to fix it?	pg 32656 left, "Unclear Connections"<br>
How might a "close" method of a file be written in a typestate-oriented programming language?	pg 19161, near bottom<br>
<latex>~\\<br>Consider the following method in a typestate-oriented programming language:<br>\begin{verbatim}<br>void m(OF >> CF f, OF >> OF g) {f.close(); print(g.file_desc.pos);}<br>\end{verbatim}<br>Why might this method cause trouble, and what is the solution to this problem? There are actually two solutions, one called \emph{access permissions} and the other called \emph{state guarantees}; describe both.<br></latex>	pg 19162 discusses access permissions<br>pg 19163 discusses state guarantees (particularly, see the snippet above the "premission flows") section<br><br>
What is an <i>state guarantee</i>? How do state guarantees appear syntacically in Garcia's typestate-oriented programming language?	pg 19163<br>
<latex>~\\<br>What does the type $\mbf{shared}(C)~C$ mean in typestate oriented programming?<br></latex>	pg 19163, "State guarantees improve modular reasoning"<br><br>
<latex>~\\<br>Consider the following snippet:~\\<br>\begin{verbatim}<br>class FileContainer{ shared(OF) OF file; }<br><br>full(Object) OF x = new OF(...);<br>pure(OF) OF y = x;<br>full(Object) FileContainer z = new FileContainer(x);<br>\end{verbatim}<br>Does the declaration of $y$ somehow affect the type of $x$? Does the declaration of $z$ somehow affect the type of $x$? Why or why not?<br></latex>	pg 19163, "Permission flows", spills to pg 19164<br><br><br>
<latex>~\\<br>Consider the example of a socket. A socket (of type S) is like a file in that it can be open (OS) or closed (CS). However, an open socket can also be ready (RS) or blocked (BS). The wait method accepts a blocked socket and waits until it is ready, while the read method gets data from the socket. The methods of socket have the following signatures:<br><br>\begin{verbatim}<br>void wait() [pure(OS) OS >> pure(OS) RS]<br>int read() [shared(OS) RS >> shared(OS) OS]<br>\end{verbatim}<br>Consider the  following snippet:<br>\begin{verbatim}<br>shared(OS) OS x = new OS(...);<br>x.wait();<br>x.read();<br>\end{verbatim}<br>Why is the above snippet ill-typed, and what can be done to solve this problem?<br></latex><br><br>	pg 19164, "Temporarily holding permissions"<br><br>
<latex>~\\<br>Each subobject fibration $\vrt{Sub(\mathbb B)}{\mathbb B}$ admites ``quantification along monos''. What is meant by this?<br></latex>	pg 10235, observation 4.4.1<br>
<latex>~\\<br>What does it mean for a category to have \emph{images}?<br></latex>	pg 10236, def 4.4.2 (i)<br>
<latex>~\\<br>What does it mean for a category to have \emph{stable images}?<br></latex>	pg 10236, def 4.4.2 (ii)<br>
<latex>~\\<br>What is a \emph{regular category}?<br></latex>	pg 10237, def 4.4.2 (iii) at bottom<br> <br>
<latex>~\\\<br>Let $\mathbb B$ be a regular category. Consider the following statement:\\~\\<br>The subobject fibration $\vrt{\mathit{Sub}(\mathbb B)}{\mathbb B}$ has coproducts $\coprod_u \dashv u^*$ satisfying Frobenius.\\~\\<br>Prove or disprove.<br></latex>	pg 10237, thm 4.4.4 (i) => (iii)<br>spills onto the next page.<br><br><br>
<latex>~\\<br>Suppose the subobject fibration $\vrt{\mathit{Sub}(\mathbb B)}{\mathbb B}$ has coproducts $\coprod_u \dashv u^*$ satisfying Frobenius. Consider the following statement:\\~\\<br>$\mathbb B$ is a regular category.\\~\\<br>Prove or disprove.<br></latex>	pg 10238, (iii) => (i)<br><br>
<latex>~\\\<br>Suppose the subobject fibration $\vrt{\mathit{Sub}(\mathbb B)}{\mathbb B}$ has simple coproducts $\coprod_{I,J} \dashv \pi^*_{I,J}$ satisfying Frobenius. Consider the following statement:\\~\\<br>The subobject fibration $\vrt{\mathit{Sub}(\mathbb B)}{\mathbb B}$ has coproducts $\coprod_u \dashv u^*$ satisfying Frobenius.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10238 (iv) => (iii) at bottom,<br>spills onto next page.<br>
Read the statement of theorem 4.4.4 on pg 10237.<br>	pg 10237.<br>
<latex>~\\<br>In a regular category, what does it mean for a morphism $u : I \to J$ to be a \emph{cover}?<br></latex>	pg 10239, def 4.4.5<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a regular category, a morphism $u$ is a cover if and only if $u$ is \emph{extremal}: for each factorisation $u = m \circ u'$ one has: $m$ is a mono implies that $m$ is an isomorphism.\\~\\<br>Prove or disprove.<br></latex>	pg 10240 proof part (i)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a regular category, all monic covers are isomorphisms.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10240, proof of part (ii)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a regular category, a morphism $u$ is a cover if and only if the map $\coprod_u(\top) \to \top$ is an isomorphism, where $\coprod_u$ is the induced left adjoint to $u^*$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10240, proof of part (iii)<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a regular category, every isomorphism is a cover. Furthermore, covers are closed under composition:<br>if $u,v$ are composable covers, then $u;v$ is a cover. Also, if $u;v$ and $u$ are covers, then $v$ is a cover.\\~\\<br>Prove or disprove.<br></latex>	pg 10240, proof of (iv)<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a regular category, covers are stable under pullback.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10240, proof of (v)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In a regular category, every map factorises as a cover followed by a mono.\\~\\<br>Prove or disprove.<br></latex>	true. pg 10240 (vi), near bottom (spills to next page)<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In regular categories, a morphism $u$ is a cover if and only if $u$ is \emph{orthogonal} to all monos. The latter means that in a commuting square<br>\begin{center}<br>\begin{tikzcd}<br>\cdot \ar[r,"u"] \ar[d] & \cdot \ar[d] \ar[dl, dashed] \\<br>\cdot \ar[r, tail] & \cdot<br>\end{tikzcd}<br>\end{center}<br>there is a unique diagonal as indicated, making everything in sight commute.\\~\\<br>Prove or disprove.<br></latex>	pg 10241, (vii) at top<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>In regular categories, a morphism $u$ is a cover if and only if $u$ is a regular epimorphism.\\~\\<br>Prove or disprove.<br></latex>	pg 10241 (viii)<br>todo: add impostor
What is the primary goal of the TAL type system?	pg 22167, top paragraph<br>
At the TAL level, how are closures represented?	pg 22167, "In addition to providing a set of built-in abstractions..."<br> 
What is the difference between labels in TAL and labels in standard untyped assembly languages?	TAL labels are ascribed with preconditions (which enforce the types of certain registers required to jump to the label)<br>pg 22167, "The typed assembly language we present here..."<br>
Give the System F type syntax.	pg 22169<br>
Give the System F term syntax.	pg 22169<br>
Morisett et al.'s System F contains a single base type. What is it?	integers<br>pg 22169, "Integers, the only base type..."<br>
Give Morisett's System F typing rule for the fix construct.	pg 22170, figure 2<br>
Give Morisett's System F typing rule for type-annotated terms.<br>	pg 22170, fig 2, top-right rule.<br>
Give Morisett's System F typing rules for type abstraction and type application.<br>	pg 22170<br>
Give Morisett's System F typing rule for if0 expressions.	pg 22170, figure 2, bottom right corner.<br>
<latex>~\\<br>Give the type syntax for Morisett's $\lambda_K$ (CPS) language.<br></latex>	pg 22170, "4. CPS conversion"<br><br>
<latex>~\\<br>Give the term syntax for Morisett's $\lambda_K$ (CPS) language.<br></latex>	pg 22170, "4. CPS Conversion"
<latex>~\\<br>Discuss the differences between functions in $\lambda_F$ and $\lambda_K$.<br></latex>	F has different abstraction forms for type abstractions and term abstractions, while K combines them (pg 22170, near bottom)<br>In F functions return values, whereas in K they do not (discussed near the top of pg 22171)
<latex>~\\<br>Give the Morisett's $\lambda_K$ typing rules for<br>\begin{itemize}<br>\item type-annotated values<br>\item function abstractions<br>\item function applications<br>\end{itemize}<br></latex>	pg 22171, figure 3<br>
<latex>~\\<br>Give the Morisett's $\lambda^K$ typing rules for<br>\begin{itemize}<br>\item let bindings (recall that there are three forms of let binding, each with their own rule)<br>\item if0<br>\item halt<br>\end{itemize}<br></latex>	pg 22171, figure 3<br><br>
<latex>~\\<br>Give the translation $\mathcal K$ from $\lambda^F$ types to $\lambda^K$ types.<br></latex>	pg 22172, fig 4, near top (involves the K_cont interpretation as well)<br><br>
<latex>~\\<br>Give the translation $\mathcal K_{cont}$ from $\lambda^F$ programs to $\lambda^K$ programs.<br></latex>	pg 22172, figure 4<br>
<latex>~\\<br>Give the translation $\mathcal K_{exp}$ from $\lambda^F$ expressions to $\lambda^K$ expressions.<br>Specifically, give the following cases:<br>\begin{itemize}<br>\item $y^\tau$<br>\item $i^\tau$<br>\item $fix~x(x_1:\tau_1):\tau_2.e)^{\tau}$<br>\end{itemize}<br></latex>	pg 22172, figure 4<br><br>
<latex>~\\<br>Give the translation $\mathcal K_{exp}$ from $\lambda^F$ expressions to $\lambda^K$ expressions.<br>Specifically, give the following cases:<br>\begin{itemize}<br>\item $(\Lambda \alpha. u^\tau)^{\tau'}$<br>\item $(u^\tau[\sigma])^{\tau'}$<br>\item $\langle u_1^{\tau_1}, \ldots, u_n^{\tau_n} \rangle^{\tau}$<br>\end{itemize}<br></latex>	pg 22172, figure 4<br>
<latex>~\\<br>Give the translation $\mathcal K_{exp}$ from $\lambda^F$ expressions to $\lambda^K$ expressions.<br>Specifically, give the following cases:<br>\begin{itemize}<br>\item $\pi_i(u^\tau)^{\tau'}$<br>\item $e_1~p~e_2^{~\tau}$<br>\item $\mathit{if0}(e_1,e_2,e_3)^{\tau}$<br>\end{itemize}<br></latex>	pg 22172, figure 4<br>
<latex>~\\<br>What are the differences between the type syntaxes of $\lambda^K$ and $\lambda^C$?<br>What are the differences between the value syntaxes?<br>What are the differences between the term syntaxes?<br></latex>	pg 22174, figure 5, near top<br>
<latex>~\\<br>Both the typing rule for $\mbf{fix}$ and the typing rules for applications changes between $\lambda^K$ and $\lambda^C$. Explain. Additionally, there are three new typing rules. Give each one.<br></latex>	pg 22174, figure 5<br><br>
<latex>~\\<br>In $\lambda^C$, Morisett et al. define a syntactic sugar that is written as $u^{\forall [\vec{\alpha}] (\vec{\sigma}) \to \mathit{void}}[\vec{\tau}]$. Give the desugaring.<br></latex>	pg 22174, fig 5 near bottom.<br><br>
Consider the following statement:<br><br>One half of an embedding projection pair determines the other.<br><br>Prove or disprove.<br>	true. this is a direct consequence of lemma 3 at the bottom of pg 26436<br>
<latex>~\\<br>Define the $\mbf{O}$-category $\mbf{Pfn}$ of sets and partial functions between them. Prove that it actually is an $\mbf{O}$-category. What are embeddings in this $\mbf{O}$-category? Do homsets have bottom elements? If so, is composition left-strict? Does this category have a terminal object? <br></latex>	pg 26441, example 1<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>All $\omega$-colimits exist in $\mbf{Pfn}^E$.\\~\\<br>Prove or disprove.<br></latex>	pg 26441, very bottom paragraph (spills onto 26442)<br><br>
<latex>~\\<br>Does the category $\mbf{Pfn}$ have sums? Is the sum functor in $\mbf{Pfn}$ locally continuous?<br></latex>	pg 26642<br>
<latex> <br>Does the $\mbf{O}$-category $\mbf{Pfn}$ have a $\Rightarrow$ bifunctor? Is it locally continuous?<br></latex>	pg 26442<br>
<latex>~\\<br>In what way can the category $\mbf{CPO}$ be viewed as an $\mbf{O}$-category? Do the homsets have bottom elements? Is composition left-strict?<br></latex>	pg 26442, example 2<br>
<latex>~\\<br>Does the category $\mbf{CPO}$ have products? Is the product space constructor for $\mbf{CPO}$ locally continuous? Why or why not? Is the function space constructor for $\mbf{CPO}$ locally continuous? Why or why not?<br></latex>	pg 26443<br>
<latex>~\\<br>Does the category $\mbf{CPO}$ have categorical sums? Why or why not?<br></latex>	pg 26443<br>
<latex>~\\<br>What are embedding in the category $\mbf{CPO}$? Are embeddings in $\mbf{CPO}$ strict in the sense of preserving $\bot$?<br></latex>	pg 26443, "and this shows that the sum is a locally continuous functor..."<br><br>
What does it mean for a poset to be <i>consistently complete</i>?<br>	pg 23652
<latex>~\\<br>What does it mean for an element of a cpo to be $\omega$-finite? <br></latex>	pg 23652, "Next, V has a very pleasant..."<br><br>
<latex>~\\<br>What does it mean for a cpo to be $\omega$-algebraic?<br></latex>	pg 23652, "Next, V has a very pleasant..."<br><br>
<latex>~\\<br>Let $X$ be a subset of a cpo. What does $X^{\circ}$ denote?<br></latex>	the set of all omega-finite elements of X.<br>pg 23652<br>
What does it mean for a cpo to be a <i>domain</i>?	pg 23652, "A cpo is a domain if..."<br>
<latex>~\\<br>Let $D$ and $E$ be domains. Simplify the expression $(D \times E)^{\circ}$. Prove equivalence with the simplified expression.<br></latex>	pg 23652, "All countable flate cpos..."<br><br>
<latex>~\\<br>Let $D$ and $E$ be domains. Simplify the expression $(D + E)^{\circ}$. Prove equivalence with the simplified expression.<br></latex>	pg 23652, "All countable flat cpos..."<br><br>
<latex>~\\<br>Let $D$ and $E$ be domains. For $a \in D^{\circ}$, $b \in E^{\circ}$, what does the \emph{step function} $a \Rightarrow b$ denote? What is the significance of step functions?<br></latex>	pg 23652<br>
<latex>~\\<br>Recall that the ''Limit-colimit coincidence'' (see ''Category Theoretic Solutions to Recursive Domain Equations'') is used to find the fixpoint of the functor underlying domain equation (2.1) on pg 23647. Using this strategy, the fixpoint is obtained as the limit of an $\omega$-chain. Consider the following statement:\\~\\<br>If all objects in the $\omega$-chain are domains then the colimit is also a domain.\\~\\<br>Prove or disprove.<br></latex>	pg 23652, bottom <br>"Finally, the kind of limit construction used for V produces..."<br>
What does it mean for a subset of a partial order to be an <i>order ideal</i>?<br>	pg 23653, items 1 and 2<br>
What does it mean for a subset of a domain to be an <i>ideal</i>?	pg 23653 <br>"A subset I of a domain D is an ideal if and only if..."<br>
<latex>~\\<br>Let $D$ be a domain. Explaim the difference between the following notations:<br>\begin{itemize}<br>\item $\mathcal{J}_0(D)$<br>\item $\mathcal J(D)$<br>\end{itemize}<br></latex>	-the set of order ideals<br>-the set of ideals<br><br>pg 23653<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The correspondence $I \mapsto I^{\circ}$ is an isomorphism of $\langle \mathcal J(D), \subseteq \rangle$ and $\langle \mathcal J_0(D^{\circ}), \subseteq \rangle$ with inverse $J \mapsto \{ \bigsqcup a_n \mid \langle a_n \rangle \text{ an increasing sequence in J} \}$.\\~\\<br>Prove or disprove.<br></latex>	pg 23653<br>"Ideals are determined by their finite elements..." along with proposition 1<br>todo: add impostor?<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The ideals of a domain form a complete lattice.\\~\\<br>Prove or disprove.<br></latex><br>	pg 23653, bottom paragraph.<br><br>Note that lubs are defined here in terms of their finite elements; this is possible due to the face mentioned directly above proposition 1 that "Ideals are determined by their finite elements".<br>
<latex>~\\<br>Let $D$ be a domain. What is a \emph{rank} function for $D$? If $I$ and $J$ are ideals in $D$, what is a \emph{witness} for $I$ and $J$? What is the \emph{closeness} $c(I,J)$ of $I$ and $J$?<br></latex>	<latex>~\\<br>pg 23654, definition near top.\\<br>Note that $\oplus$ here denotes the symmetric difference of two sets.<br></latex>
<latex>~\\<br>Let $c$ be a closeness function and $I$ and $J$ ideals of a domain. Consider the following statement:\\~\\<br>$c(I,J) = \infty$ iff $I = J$\\~\\<br>Prove or disprove.<br></latex>	pg 23654, prop 2 (i)<br>todo: add impostor?<br><br>
<latex>~\\<br>Let $c$ be a closeness function and $I$ and $J$ ideals of a domain. Consider the following statement:\\~\\<br>$c(I,J) = c(J,I)$\\~\\<br>Prove or disprove.<br></latex>	true. pg 23654, prop 2 (ii)<br>
<latex>~\\<br>Let $D$ be a domain and $I$,$J$, and $K$ ideals of $D$. Consider the following statement:\\~\\<br>$c(I,K) \geq min(c(I,J),c(J,K))$\\~\\<br>Prove or disprove.<br></latex>	pg 23654, prop 2 (iii)<br>todo: add impostor?<br>
<latex>~\\<br>How do we derive a distance metric between ideals of a domain from a closeness function on ideals of a domain?<br></latex>	pg 23654<br>"Given such a closeness function", one can derive 
<latex>~\\<br>What does it mean for a metric space to be \emph{complete}?<br></latex><br>	pg 23654<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>The metric space $\langle \mathcal J(D), d \rangle$ is complete. Indeed, if $\langle I_i \rangle_{i \geq 0}$ is a Cauchy sequence then its limit is $I$ where $I^\circ = \{ b \in D^{\circ} \mid \text{b is in almost all }I_i \}$.\\~\\<br>Prove or disprove.<br></latex>	being in "almost every I_i" means that for any n >= 0 there exists a j >= n such that b is an element of I_j.<br>pg 23655, theorem 3 at top<br><br>
<latex>~\\<br>MacQueen et al. define a ranking function mapping each element of their domain of values $\mbf{V}$ to a natural number. How is this ranking function $r : \mbf{V} \to \mathbb N$ defined?<br></latex>	pg 23655, paragraph above proposition 4
<latex>~\\<br>What are the ranks of the following constants in MacQueen et al's value domain?<br>\begin{itemize}<br>\item $\bot$<br>\item false<br>\item 3<br>\end{itemize}<br></latex>	0,1,1<br>pg 23655, prop 5<br>
<latex>~\\<br>Suppose $a$ and $b$ are finite elements whose lub exists. Consider the following statement:\\~\\<br>$r(a \sqcup b) \leq \mit{max}(r(a), r(b))$\\~\\<br>Prove or disprove.<br></latex>	pg 23655, prop 4 (ii)<br><br>todo: add impostor?
<latex>~\\<br>Suppose $a$ and $b$ are finite elements whose lub exists. Consider the following statement:\\~\\<br>$r(a \sqcup b) = \mit{max}(r(a), r(b))$\\~\\<br>Prove or disprove.<br></latex>	IMPOSTOR. Should be less than or equal to.<br>pg 23655, prop 4 (ii)<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Any finite element $c$ of $(\mbf{V} \times \mbf{V})$, other than $\bot$, is equal to $\langle a, b \rangle$ with $a$ and $b$ finite, $r(a) < r(c)$ and $r(b) < r(c)$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 23655 prop 4 (iv)<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Any finite element $c$ of $(\mbf{V} \to \mbf{V})$, other than $\bot$, is equal to $(a_1 \Rightarrow b_1) \sqcup \cdots \sqcup (a_n \Rightarrow b_n)$ with the $a_i$ and $b_i$ finite and $r(a_i) < r(c)$ and $r(b_i) < r(c)$ for all $i$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 23655 (vi).<br>todo: add impostor? (maybe change "any finite element" to "any element")<br><br><br>
<latex>~\\<br>Let $f : X \to Y$ be a function between metric spaces $X$ and $Y$. What does it mean for $f$ to be \emph{contractive}?<br></latex>	pg 23657, "In order to find ideals..."<br>
<latex>~\\<br>Let $f : X \to Y$ be a function between metric spaces $X$ and $Y$. What does it mean for $f$ to be \emph{non-expansive}? What does it mean for an $n$-variable function $f : X_1 \times \cdots \times X_n \to Y$ to be \emph{non-expansive}?<br></latex>	pg 23657, "and it is non-expansive..."<br><br>
<latex>~\\<br>State the Banach fixpoint theorem.<br></latex>	pg 23657<br>"The Banach fixpoint theorem states..."<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>A function $f : \mathcal J(D)^n \to \mathcal J(D)$ is contractive iff for all ideals $I_1,\cdots,I_n$ and $J_1,\ldots,J_n$ we have<br>$$c(f(I_1,\cdots,I_n),f(J_1,\ldots,J_n)) > \underset{i}{\mit{min}}~c(I_i,J_i)$$<br>Prove or disprove.<br></latex>	true. pg 23657, proposition 5.<br>
<latex>~\\<br>Are the projection maps $\pi_i : X_1 \times \cdots \times X_n \to X_i$ contractive?<br></latex>	Nope. But they are non-expansive.<br>pg 23658, section 4.1.<br>
<latex>~\\<br>When is the composition of a map $f : X_1 \times \cdots \times X_n \to Y$ with $g_i : V_1 \times \cdots \times V_m \to X_i$ nonexpansive?<br></latex>	pg 23658, section 4.1<br>
<latex>~\\<br>If $f : X_1 \times \cdots \times X_n \to Y$ is contractive and for $i \in 1..n$, $g_i : V_1 \times \cdots \times V_m \to X_i$ are non-expansive, what can be said of the composition of the $g_i$ with $f$?<br></latex>	It is contractive.<br>pg 23658<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $Y$ is an ultrametric space then a map $f : X_1 \times \cdots \times X_n \to Y$ as above is contractive iff it is contractive in each argument taken separately.\\~\\<br>Prove or disprove.<br></latex>	pg 23658, near bottom, right above proposition 6 <br>
<latex>~\\<br>Consider the following statement:\\~\\<br>Intersection and union are not contractive but are non-expansive, considered as binary functions over ideals.\\~\\<br>Prove or disprove.<br></latex>	true. <br>pg 23658, proposition 6, near bottom
<latex>~\\<br>Let $I$ and $J$ be ideals of a domain. How is $I \boxplus J$ defined? Is the $\boxplus : \mathcal I(D) \times \mathcal I(D) \to \mathcal I(D)$ function contractive?<br></latex>	pg 23659, Theorem 7<br><br>
<latex>~\\<br>Let $I$ and $J$ be ideals of a domain $D$. How is $I \boxtimes J$ defined? Is the $\boxtimes : \mathcal I(D) \times \mathcal I(D) \to \mathcal I(D)$ function contractive?<br></latex>	it's contractive<br>pg 23659, theorem 7
<latex>~\\<br>Let $I$ and $J$ be ideals of a domain. How is $I \boxto J$ defined? Is the function $\boxto : \mathcal I(D) \times \mathcal I(D) \to \mathcal I(D)$ contractive?<br></latex>	pg 23659, theorem 7<br>
<latex>~\\<br>Let $f : \mathcal I(D)^{n+1} \to \mathcal I(D)$ be a function of $n + 1$ arguments.How can we produce a function of $n$ arguments by ``universally quantifying'' over its first argument, relative to a given collection of ideals $\mathcal H \subseteq \mathcal I(D)$? What about ``existentially quantifying''?<br></latex>	pg 23660, bottom, section 4.3<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $f : \mathcal I(D)^{n+1} \to \mathcal I(D)$ is contractive in its last n arguments, so are its universal and existential quantifications.\\~\\<br>Prove or disprove.<br></latex>	pg 23661, theorem 8<br><br>
<latex>~\\<br>Let $f : X \times Y_1 \times \cdots \times Y_n \to X$ be a function of non-empty complete metric spaces that is contractive in its first argument. How is the function $\mu f$ defined?<br></latex>	pg 23661, paragraph above theorem 9<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>If $f : X \times Y_1 \times \cdots \times Y_n \to X$ is contractive then so is $\mu f$.\\~\\<br>Prove or disprove.<br></latex>	true. pg 23661, theorem 9.<br>
Give the term and type syntaxes used by MacQueen et al.<br>	pg 23662 bottom / 23663 top<br><br>
<latex>~\\<br>Consider a recursive type $\mu t. \sigma$. What does it mean for $\sigma$ to be \emph{formally contractive} in $t$?<br></latex>	pg 23663. "In fact, ..."<br><br>
<latex>~\\<br>What does it mean for a type $\sigma$ to be \emph{well-formed}?<br></latex>	pg 23663, "now we take, ..."<br><br>Note that this is somewhat non-standard: free variables are considered well formed. Read the paragraph below the inductive definition.<br>
<latex>~\\<br>What do MacQueen et al. use $\mbf{TExp}$ to denote?<br></latex>	pg 23663, "Now we take..."<br><br>
<latex><br>Give the ``type signature'' and inductive definition of the semantic function $\mathcal E$.<br></latex>	pg 23663 / 23664<br>
<latex><br>Give the ``type signature'' and inductive definition of the semantic function $\mathcal T$.<br></latex>	pg 23663 / 23664<br><br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For any $\sigma$ and any $t$, $\lambda I \in \mathcal I(D). \mathcal T \sem{\sigma}(\nu[I/t])$ is nonexpansive, and is contractive if $\sigma$ is contractive in $t$.\\~\\<br>Prove or disprove.<br></latex>	True. Theorem 10.<br>pg 23664<br>
<latex>~\\<br>Give the types of the following constants:\\~\\<br>\emph{pair}\\<br>\emph{inl}\\<br>\emph{cond}\\<br>\emph{isl}<br></latex>	pg 23665 near top<br>
<latex>~\\<br>Give the typing rules for:\\~\\<br>Variables\\<br>Arrow introduction and arrow elimination\\<br>Intersection introduction and intersection elimination<br></latex>	pg 23665<br>
Give the typing rules for:<br>Union intersection and elimination<br>Universal quantifier introduction and elimination<br><br>	pg 23665/23666<br>
Give the typing rules for:<br>Existential quantifier introduction and elimination.<br>Recursive type introduction and elimination.<br><br>	pg 23666<br>
<latex>~\\<br>How does MacQueen define $\vDash_{\rho,\nu} \mathcal A$? What about $\mathcal A \vDash_{\rho,\nu} e : \sigma$? What about $\mathcal A \vDash e : \sigma$?<br></latex>	pg 23668, above theorem 11<br>
<latex>~\\<br>Barendregt's $\lambda$-models rely on a reflexive object $D$ and a pair of arrows $i : D^D \to D$ and $j : D \to D^D$ with $j \circ i = id$. Given $f,d \in D$ what does $f \cdot d$ (i.e. an ``application'') of $f$ to $d$ denote?<br></latex>	pg 23695 near bottom<br>
<latex>~\\<br>What does Amadio use $D_{\infty}$ to denote?<br></latex>	it's just the colimit in Scott's inverse limit construction<br>pg 23696, near top<br><br>
<latex>~\\<br>How is the collection of \emph{approximating elements} of an inverse limit $D_{\infty}$ defined? Given some $d \in D_{\infty}$, what is meant by \emph{the approximating elements of} $d$?<br> </latex>	pg 23696, near middle "conventions and basic properties"<br><br>
<latex>~\\<br>Let $k : D_{\infty} \to (D_{\infty}^{D_{\infty}}) + (D_{\infty} \times D_{\infty}) + \mathit{At}$ be an isomorphism extracted from the inverse limits construction. What functions does Amadio use $j$ and $p$ to denote? <br></latex>	pg  23696, near bottom<br><br>
<latex>~\\<br>Let $f,e \in D_{\infty}$. Consider the following statement:\\~\\<br>$f \cdot e = \bigcup_{n < \omega} j(f_{n+1})(e_n)$\\~\\<br>Prove or disprove.<br></latex>	true. The proof isn't included, but it doesn't seem it should be too hard.<br>pg 23696<br>
<latex>~\\<br>Consider the following statement:\\~\\<br>For all $x,y \in D_{\infty}$ we have $[x,y]_{n+1} = [x_n, y_n]$.\\~\\<br>Prove or disprove.<br></latex>	pg 23696, near bottom<br>
<latex>~\\<br>Let $A$ denote a binary relation over a CPO $D$. What does it mean for $A$ to be a \emph{partial equivalence relation}? <br></latex>	pg 23697, def 1.2.1 (1)
<latex>~\\<br>Let $A$ denote a binary relation over a CPO $D$. What does it mean for $A$ to be \emph{pointed}? <br></latex>	pg 23607, def 1.2.1 (2)<br>
<latex>~\\<br>Let $A$ denote a binary relation over a CPO $D$. What does it mean for $A$ to be \emph{complete}? <br></latex>	pg 23697, def 1.2.1 (3)<br>I don't understand what they have written here, actually.<br><br>
<latex>~\\<br>Let $A$ denote a binary relation over a CPO $D$. What does it mean for $A$ to be \emph{uniform}? <br></latex>	pg 23697, def 1.2.1 (4)<br>
<latex>~\\<br>How does Amadio define the abbreviations \emph{cper}, \emph{cuper}, \emph{uper}, and \emph{per}$_{\bot}$?<br></latex>	pg 23697, "Terminology"<br><br>
What is a <i>double category</i>?	pg 19129 bottom, spills to page 19130<br>
Draw diagrams demonstrating the difference between the "horizontal square category" and the "vertical square category" of a double category.	pg 19130, near center of page<br>
<latex>~\\<br>In a double category with an object $A$, what is the relation between $1_{v_A}$ and $1_{h_A}$?<br></latex>	They are the same. pg 19131, near top.<br>
<latex>~\\<br>Provide the definition of $2$\emph{-category}. If $\mathcal K$ is a 2-category then what does $\mathcal K_0$ denote? What is \emph{vertical composition} in a 2-category? <br></latex>	pg 19131, near bottom<br>
<latex>~\\<br>What is \emph{horizontal composition} in a 2-category?<br></latex>	pg 19132<br>
<br>2-categories must satisfy a law relating horizontal composition and vertical composition. What is this law?<br><br>	<img src="horzvertcomp.png"><br><br>pg 19132
From a 2-category, we can derive a "horizontal composition" 1-category. The objects of the derived category are the same as the objects of the original 2-category. How does this derived category work? What are its identities?	pg 19132<br>
A 2-category satisfies a law involving diagrams of the following form:<br><img src="2-ident-comp.png"><br>State this law.	<latex><br>1_u \ast 1_f = 1_{f;u} <br></latex><br><br>pg 19132, near bottom
<latex>~\\<br>Give each of Benabou's two ``pasting'' situations, each paired with its corresponding diagram.<br></latex>	pg 19133, near middle of page<br><br>
What does the following diagram mean?<br><br><img src="pasting-squares.png">	pg 19133 
What does a diagram of the following form mean? In particular, why haven't we drawn a 2-cell arrow in the left square?<br><br><img src="square-paste-ident.png">	pg 19133 near bottom<br>
<latex>~\\<br>How do Kelly and Street distinguish between the category $\mathcal{CAT}$ and $\script{Cat}$?<br></latex>	pg 19134, section 1.3<br>
Skim over section 1.3 on pg 19134-19135<br>	<br>
What do Kelly and Street mean by the terms <i>2-functor</i> and <i>2-natural transformation</i>?	pg 19135, section 1.4. If this looks like Gibberish, refer to Kelly's "Basic Concepts of Enriched Category Theory". Or just read the elementary version in the second paragraph of section 1.4.<br><br>
In the terminology of 2-categories, what is a <i>modification</i>?	pg 19136 near top. You may need to review the definition of 2-natural transformations on the previous page.<br>
<latex>~\\<br>From a 2-category $\mathcal K$ we can obtain a 2-category $\mathit{End}~\mathcal{K}$. How is $\mathit{End}~\mathcal{K}$ defined?<br></latex>	pg 19136<br>
<latex>~\\<br>Kelly and Street often take a "strict" notion $N$ and modify it with ``pseudo-$N$'' or ``lax $N$''. What doe these modifications mean?<br></latex>	pg 19137, second-to-last paragraph<br>
<latex>~\\<br>Give the 2-categorical definition of \emph{adjunction}.<br></latex>	pg 19139<br>
<latex>~\\<br>Using the 2-categorical definition of adjunctions, let $\eta,\varepsilon : f \dashv u : A \to B$ be an adjunction in a $2$-category $\mathcal K$ and let $\eta_1,\varepsilon_1 : f_1 \dashv u_1 : B \to C$ a be a second adjunction in $\mathcal K$. Consider the following statement:\\~\\<br>We can form a composite adjunction $\eta_2,\varepsilon_2 : f f_1 \dashv u_1 u : A \to C$\\~\\<br>Prove or disprove.<br></latex>	true. pg 19139, near bottom. Note that not all of the details are spelled out. Try working out the details yourself!<br>
<latex>~\\<br>Let $\eta, \varepsilon : f \dashv u : A \to B$ and $\eta', \varepsilon' : f' \dashv u' : A' \to B'$. Let $a : A \to A'$ and $b : B \to B'$. Consider the following statement:\\~\\<br>There is a bijection between $2$-cells $\lambda : bu \Rightarrow u'a$ and $\mu : f'b \Rightarrow af$\\~\\<br>Prove or disprove.<br></latex>	true. pg 19140, prop 2.1. See section 2.2 on the previous page for an explanation.<br><br>
<latex>~\\<br>Let $\eta, \varepsilon : f \dashv u : A \to B$ and $\eta', \varepsilon' : f' \dashv u' : A' \to B'$. Let $a : A \to A'$ and $b : B \to B'$. We know there is a bijection between $2$-cells $\lambda : bu \Rightarrow u'a$ and $\mu : f'b \Rightarrow af$. (Exercise: give diagrams for this bijection.) This bijection is actually an isomorphism between two double categories. What are these double categories? \\~\\<br></latex>	pg 19140, see top for diagrams, prop 2.2 for theorem statement<br>proof is on pg 19141<br><br>
What does it mean for two natural transformations to be <i>mates</i> under an adjunction?<br>	pg 19141, right above prop 2.3<br><br>
<latex>~\\<br>Let $f \dashv u$ and $f' \dashv u$. Consider the following statement:\\~\\<br>$f$ and $f'$ are canonically isomorphic.\\~\\<br>Prove or disprove.<br></latex>	pg 19141, prop 2.3, spills to pg 19142<br>
<latex>~\\<br>Let $D : K \to L$ be a 2-functor. Then an adjunction $\eta, \varepsilon : f \dashv u : A \to B$ in $K$ clearly gives an adjunction $D \eta, D \varepsilon : Df \dashv Du : DA \to DB$ in $L$. <br>Consider the following statement:\\~\\<br>If $\lambda$ and $\mu$ are mates under the adjunctions $f \dashv u$ and $f' \dashv u'$ in $K$ and if $D : K \to L$ is a 2-functor, then $D\lambda$ and $D \mu$ are mates under the adjunctions $Df \dashv Du$ and $Df' \dashv Du'$ in $L$.\\~\\<br>Prove or disprove.<br></latex>	true. prop 2.4, pg 19142.<br>
<latex>~\\<br>Let $D,E : K \to L$ be 2-functors and let $\alpha : D \Rightarrow E$ be a 2-natural transformation. Consider the following statement:\\~\\<br>TODO: finish making a card for prop 2.5 on pg 19142<br><br></latex> 	pg 19142, prop 2.5<br><br>
<latex>~\\<br>What is a monad in the 2-category in the 2-category Cat? (You are welcome to use 2-categorical language in this definition; even though it isn't absolutely necessary it is convenient.)<br></latex>	pg 19143 (3.1)<br><br>
<latex>~\\<br>What is an \emph{action} of a monad $t : B \to B$ above a 1-cell $s : A \to B$?<br></latex>	pg 19143 (3.2) - I drew a diagram on the Sony Digital Paper that may or may not be helpful.<br>
